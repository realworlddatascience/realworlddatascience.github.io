<?xml version="1.0" encoding="UTF-8"?>
<rss  xmlns:atom="http://www.w3.org/2005/Atom" 
      xmlns:media="http://search.yahoo.com/mrss/" 
      xmlns:content="http://purl.org/rss/1.0/modules/content/" 
      xmlns:dc="http://purl.org/dc/elements/1.1/" 
      version="2.0">
<channel>
<title>Real World Data Science</title>
<link>https://realworlddatascience.net/viewpoints/index.html</link>
<atom:link href="https://realworlddatascience.net/viewpoints/index.xml" rel="self" type="application/rss+xml"/>
<description></description>
<image>
<url>https://realworlddatascience.net/images/rwds-logo-150px.png</url>
<title>Real World Data Science</title>
<link>https://realworlddatascience.net/viewpoints/index.html</link>
<height>83</height>
<width>144</width>
</image>
<generator>quarto-1.3.450</generator>
<lastBuildDate>Wed, 06 Dec 2023 00:00:00 GMT</lastBuildDate>
<item>
  <title>Evaluating artificial intelligence: How data science and statistics can make sense of AI models</title>
  <dc:creator>Brian Tarran</dc:creator>
  <link>https://realworlddatascience.net/viewpoints/posts/2023/12/06/ai-fringe.html</link>
  <description><![CDATA[ 




<p>A little over a month ago, governments, technology firms, multilateral organisations, and academic and civil society groups came together at Bletchley Park – home of Britain’s World War II code breakers – to discuss the safety and risks of artificial intelligence.</p>
<p>One output from that event was <a href="https://www.gov.uk/government/publications/ai-safety-summit-2023-the-bletchley-declaration/the-bletchley-declaration-by-countries-attending-the-ai-safety-summit-1-2-november-2023">a declaration</a>, signed by countries in attendance, of their resolve to “work together in an inclusive manner to ensure human-centric, trustworthy and responsible AI that is safe, and supports the good of all.”</p>
<p>We also heard from UK prime minister Rishi Sunak of <a href="https://www.gov.uk/government/news/prime-minister-launches-new-ai-safety-institute">plans for an AI Safety Institute</a>, to be based in the UK, which will “carefully test new types of frontier AI before and after they are released to address the potentially harmful capabilities of AI models, including exploring all the risks, from social harms like bias and misinformation, to the most unlikely but extreme risk, such as humanity losing control of AI completely.”</p>
<p>But at a panel debate at the Royal Statistical Society (RSS) the day before the Bletchley Park gathering, data scientists, statisticians, and machine learning experts questioned whether such an institute would be sufficient to meet the challenges posed by AI; whether data inputs – compared to AI model outputs – are getting the attention they deserve; and whether the summit was overly focused on <a href="https://realworlddatascience.net/viewpoints/posts/2023/06/05/no-AI-probably-wont-kill-us.html">AI doomerism</a> and neglecting more immediate risks and harms. There were also calls for AI developers to be more driven to solve real-world problems, rather than just pursuing AI for AI’s sake.</p>
<p>The RSS event was chaired by Andrew Garrett, the Society’s president, and formed part of the national <a href="https://aifringe.org/">AI Fringe programme of activities</a>. The panel featured:</p>
<ul>
<li>Mihaela van der Schaar, John Humphrey Plummer professor of machine learning, artificial intelligence and medicine at the University of Cambridge and a fellow at The Alan Turing Institute.</li>
<li>Detlef Nauck, head of AI and data science research at BT, and a member of the <a href="https://realworlddatascience.net/viewpoints/editors-blog/posts/2022/10/18/meet-the-team.html">Real World Data Science editorial board</a>.</li>
<li>Mark Levene, principal scientist in the Department of Data Science at the National Physical Laboratory.</li>
<li>Martin Goodson, chief executive of Evolution AI, and former chair of the RSS Data Science and AI Section.</li>
</ul>
<p>What follows are some edited highlights and key takeaways from the discussion.</p>
<div class="keyline">

</div>
<section id="ai-safety-and-ai-risks" class="level2">
<h2 class="anchored" data-anchor-id="ai-safety-and-ai-risks">AI safety, and AI risks</h2>
<p><strong>Andrew Garrett:</strong> For those who were listening to the commentary last week, the PM [prime minister] made a very interesting speech. Rishi Sunak announced the creation of the world’s first AI Safety Institute in the UK, to examine, evaluate and test new types of AI. He also stated that he pushed hard to agree the first ever international statement about the risks of AI because, in his view, there wasn’t a shared understanding of the risks that we face. He used the example of the IPCC, the Intergovernmental Panel on Climate Change, to establish a truly global panel to publish a “state of AI science” report. And he also announced an investment in raw computing power, so around a billion pounds in a supercomputer, and £2.5 billion in quantum computers, making them available for researchers and businesses as well as government.</p>
<p>The RSS provided two responses this year to prominent [AI policy] reviews. The first was in June <a href="https://rss.org.uk/RSS/media/File-library/Policy/2023/RSS-AI-white-paper-response-v2-2.pdf">on the AI white paper</a>, and the second was on <a href="https://rss.org.uk/RSS/media/File-library/Policy/RSS_Evidence_Communications_and_Digital_Lords_Select_Committee_Inquiry_Large_Language_Models_September_2023.pdf">the House of Lords Select Committee inquiry into large language models</a> back in September. How do they relate to what the PM said? There’s some good news here, and maybe not quite so good news.</p>
<p>First, the RSS had requested investments in AI evaluation and a risk-based approach. And you could argue, by stating that there will be a safety institute, that that certainly ticks one of the boxes. We also recommended investment in open source, in computing power, and in data access. In terms of computing power, that was certainly in the [PM’s] speech. We spoke about strengthening leadership, and in particular including practitioners in the [AI safety] debate. A lot of academics and maybe a lot of the big tech companies have been involved in the debate, but we want to get practitioners – those close to the coalface – involved in the debate. I’m not sure we’ve seen too much of that. We recommended that strategic direction was provided, because it’s such a fast-moving area, and the fact that the Bletchley Park Summit is happening tomorrow, I think, is good for that. And we also recommended that data science capability was built amongst the regulators. I don’t think there was any mention of that.</p>
<p>That’s the context [for the RSS event today]. What I’m going to do now is ask each of the panellists to give an introductory statement around the AI summit, focusing on the safety aspects. What do they see as the biggest risk? And how would they mitigate or manage this risk?</p>
<p><strong>Detlef Nauck:</strong> I work at BT and run the AI and data science research programme. We’ve been looking at the safety, reliability, and responsibility of AI for quite a number of years already. Five years ago, we put up a responsible AI framework in the company, and this is now very much tied into our data governance and risk management frameworks.</p>
<p>Looking at the AI summit, they’re focusing on what they call “frontier models,” and they’re missing a trick here because I don’t think we need to worry about all-powerful AI; we need to worry about inadequate AI that is being used in the wrong context. For me, AI is programming with data, and that means I need to know what sort of data has been used to build the model, and I need AI vendors to be upfront about it and to tell me: What is the data that they have used to build it, how have they built it, or if they’ve tested for bias? And there are no protocols around this. So, therefore, I’m very much in favour of AI evaluation. But I don’t want to wait for an institute for AI evaluation. I want the academic research that needs to be done around this, which hasn’t been done. I want everybody who builds AI systems to take this responsibility and document properly what they’re doing.</p>
<div class="pullquote-container">
<div class="grid">
<div class="g-col-12 g-col-lg-4">
<div class="quarto-figure quarto-figure-left">
<figure class="figure">
<p><img src="https://realworlddatascience.net/viewpoints/posts/2023/12/06/images/llm-3d-shapes-crop.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="g-col-12 g-col-lg-8 pullquote-grid pullquote">
<p><img src="https://realworlddatascience.net/images/pullquote-purple.png" class="img-fluid" width="50"></p>
<p>I hear more and more a lot of companies talking about AI general intelligence, and how AI is going to take over the world, and I’m tremendously concerned about this. There is an opportunity to build AI that is human empowering, that keeps us strong, able, capable, intelligent, and can support us in all our human capabilities.</p>
</div>
</div>
</div>
<p><strong>Mihaela van der Schaar:</strong> I am an AI researcher building AI and machine learning technology. Before talking about the risks, I also would like to say that I see tremendous potential for good. Many of these machine learning AI models can transform for the better areas that I find extremely important – healthcare and education. That being said, there are substantial risks, and we need to be very careful about that. First, if not designed well, AI can be both unsafe as well as biased, and that could lead to tremendous impact, especially in medicine and education. I completely agree with all the points that the Royal Statistical Society has made not only about open source but also about data access. This AI technology cannot be built unless you have access to high quality data, and what I see a lot happening, especially in industry, is people have data sources that they’ll keep private, build second-rate or third-rate technology on them, and then turn that into commercialised products that are sold to us for a lot of money. If data is made widely available, the best as well as the safest AI can be produced, rather than monopolised.</p>
<p>Another area of risk that I’m especially worried about is human marginalisation. I hear more and more a lot of companies talking about AI general intelligence, and how AI is going to take over the world, and I’m tremendously concerned as an AI researcher about this. There is an opportunity to build AI that is human empowering, that keeps us strong, able, capable, intelligent, and can support us in all our human capabilities.</p>
<p><strong>Martin Goodson:</strong> The AI Safety Summit is starting tomorrow. But, unfortunately, I think the government are focusing on the wrong risks. There are lots of risks to do with AI, and if you look at the scoping document for the summit, it says that what they’re interested in is misuse risk and the risk of loss of control. Misuse risk is that bad actors will gain access to information that they shouldn’t have and build chemical weapons and things like that. And the loss of control risk is that we will have this super intelligence which is going to take over and we should see, as is actually mentioned, the risk of the extinction of the human race, which I think is a bit overblown.</p>
<p>Both of these risks – the misuse risk and the loss of control risk – are potential risks. But we don’t really know how likely they are. We don’t even know whether they’re possible. But there are lots of risks that we do know are possible, like loss of jobs, and reductions in salary, particularly of white-collar jobs – that seems inevitable. There’s another risk, which is really important, which is the risk of monopolistic control by the small number of very powerful AI companies. These are the risks which are not just likely but are actually happening now – people are losing their jobs right now because of AI – and in terms of monopolistic control, OpenAI is the only company that has anything like a large language model as powerful as GPT-4. Even the mighty Google can’t really compete. This is a huge risk, I think, because we have no control over pricing: they could raise the prices if they wanted to; they could constrain access; they could only give access to certain people that they want to give access to. We don’t have any control over these systems.</p>
<p><strong>Mark Levene:</strong> I work in NPL as a principal scientist in the data science department. I’m also emeritus professor in Birkbeck, University of London. I have a long-standing expertise in machine learning and focus in NPL on trustworthy AI and uncertainty quantification. I believe that measurement is a key component in locking-in AI safety. Trustworthy AI and safe AI both have similar goals but different emphases. We strive to demonstrate the trustworthiness of an AI system so that we can have confidence in the technology making what we perceive as responsible decisions. Safe AI puts the emphasis on the prevention of harmful consequences. The risk [of AI] is significant, and it could potentially be catastrophic if we think of nuclear power plants, or weapons, and so on. I think one of the problems here is, who is actually going to take responsibility? This is a big issue, and not necessarily an issue for the scientist to decide. Also, who is accountable? For instance, the developers of large language models: are they the ones that are accountable? Or is it the people who deploy the large language models and are fine-tuning them for their use cases?</p>
<p>The other thing I want to emphasise is the socio-technical characteristics [of the AI problem]. We need to get an interdisciplinary team of people to actually try and tackle these issues.</p>
</section>
<section id="do-we-need-an-ai-safety-institute" class="level2">
<h2 class="anchored" data-anchor-id="do-we-need-an-ai-safety-institute">Do we need an AI Safety Institute?</h2>
<p><strong>Andrew Garrett:</strong> Do we need to have an AI Safety Institute, as Rishi Sunak has said? And if we don’t need one, why not?</p>
<p><strong>Detlef Nauck:</strong> I’m more in favour of encouraging academic research in the field and funding the kind of research projects that can look into how to build AI safely, [and] how to evaluate what it does. One of the key features of this technology is it has not come out of academic research; it has been built by large tech companies. And so, I think we have to do a bit of catch up in scientific research and in understanding how are we building these models, what can they do, and how do we control them?</p>
<p><strong>Mihaela van der Schaar:</strong> This technology has a life of its own now, and we are using it for all sorts of things that maybe initially was not even intended. So, shall we create an AI [safety] institute? We can, but we need to realise first that testing AI and showing that it’s safe in all sorts of ways is complicated. I would dare say that doing that well is a big research challenge by itself. I don’t think just one institute will solve it. And I feel the industry needs to bear some of the responsibility. I was very impressed by Professor [Geoffrey] Hinton, who came to Cambridge and said, “I think that some of these companies should invest as much money in making safe AI as developing AI.” I resonated quite a lot with that.</p>
<p>Also, let’s not forget, many academic researchers have two hats nowadays: they are professors, and they are working for big tech [companies] for a lot of money. So, if we take this academic, we put them in this AI tech safety institute, we have potential for corruption. I’m not saying that this will happen. But one needs to be very aware, and there needs to be a very big separation between who develops [AI technology] and who tests it. And finally, we need to realise that we may require an enormous amount of computation to be able to validate and test correctly, and very few academic or governmental organisations may have [that].</p>
<div class="pullquote-container">
<div class="grid">
<div class="g-col-12 g-col-lg-8 pullquote-grid pullquote">
<p><img src="https://realworlddatascience.net/images/pullquote-purple.png" class="img-fluid" width="50"></p>
<p>I think it’s an insult to the UK’s scientific legacy that we’re reduced to testing software that has been made by US companies. We have huge talents in this country. Why aren’t we using that talent to actually build something instead of testing something that someone else has made?</p>
</div>
<div class="g-col-12 g-col-lg-4">
<div class="quarto-figure quarto-figure-right">
<figure class="figure">
<p><img src="https://realworlddatascience.net/viewpoints/posts/2023/12/06/images/llm-3d-shapes-crop.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</div>
<p><strong>Martin Goodson:</strong> Can I disagree with this idea of an evaluation institute? I think it’s a really, really bad idea, for two reasons. The first is an argument about fairness. If you look at drug regulation, who pays for clinical trials? It’s not the government. It’s the pharmaceutical companies. They spend billions on clinical trials. So, why do we want to do this testing for free for the big tech companies? We’re just doing product development for them. It’s insane! They should be paying to show that their products are safe.</p>
<p>The other reason is, I think it’s an insult to the UK’s scientific legacy that we’re reduced to testing software that has been made by US companies. I think it’s pathetic. We were one of the main leaders of the Human Genome Project, and we really pushed it – the Wellcome Trust and scientists in the UK pushed the Human Genome Project because we didn’t want companies to have monopolistic control over the human genome. People were idealistic, there was a moral purpose. But now, we’re so reduced that all we can do is test some APIs that have been produced by Silicon Valley companies. We have huge talents in this country. Why aren’t we using that talent to actually build something instead of testing something that someone else has made?</p>
<p><strong>Mark Levene:</strong> Personally, I don’t see any problem in having an AI institute for safety or any other AI institutes. I think what’s important in terms of taxpayers’ money is that whatever institute or forum is invested in, it’s inclusive. One thing that the government should do is, we should have a panel of experts, and this panel should be interdisciplinary. And what this panel can do is it can advise government of the state of play in AI, and advise the regulators. And this panel doesn’t have to be static, it doesn’t have to be the same people all the time.</p>
<p><strong>Andrew Garrett:</strong> To evaluate something, whichever way you chose to do it, you need to have an inventory of those systems. So, with the current proposal, how would this AI Safety Institute have an inventory of what anyone was doing? How would it even work in practice?</p>
<p><strong>Martin Goodson:</strong> Unless we voluntarily go to them and say, “Can you test out our stuff?” then they wouldn’t. That’s the third reason why it’s a terrible idea. You’d need a licencing regime, like for drugs. You’d need to licence AI systems. But teenagers in their bedrooms are creating AI systems, so that’s impossible.</p>
</section>
<section id="lets-do-reality-centric-ai" class="level2">
<h2 class="anchored" data-anchor-id="lets-do-reality-centric-ai">Let’s do reality-centric AI!</h2>
<p><strong>Andrew Garrett:</strong> What are your thoughts about Rishi Sunak wanting the UK to be an AI powerhouse?</p>
<p><strong>Martin Goodson:</strong> It’s not going to be a powerhouse. This stuff about us being world leading in AI, it’s just a fiction. It’s a fairy tale. There are no real supercomputers in the UK. There are moves to build something, like you mentioned in your introduction, Andrew. But what are they going do with it? If they’re just going to build a supercomputer and carry on doing the same kinds of stuff that they’ve been doing for years, they’re not going to get anywhere. There needs to be a big project with an aim. You can build as many computers as you want. But if you haven’t got a plan for what to do with them, what’s the point?</p>
<p><strong>Mihaela van der Schaar:</strong> I really would agree with that. What about solving some real problem: trying to solve cancer; trying to solve our crisis in healthcare, where we don’t have enough infrastructure and doctors to take care of us? What about solving the climate change problem, or even traffic control, or preventing the next financial crisis? I wrote a little bit about that, and I call it “let’s do reality-centric AI.” Let’s have some goal that’s human empowering, take a problem that we have – energy, climate, cancer, Alzheimer’s, better education for children, and more diverse education for children – and let us solve these big challenges, and in the process we will build AI that’s hopefully more human empowering, rather than just saying, “Oh, we are going to solve everything if we have general AI.” Right now, I hear too much about AI for the sake of AI. I’m not sure, despite all the technology we build, that we have advanced in solving some real-world problems that are important for humanity – and imminently important.</p>
<p><strong>Martin Goodson:</strong> So, healthcare– I tried to make an appointment with my GP last week, and they couldn’t get me an appointment for four weeks. In the US you have this United States Medical Licencing Examination, and in order to practice medicine you need to pass all three components, you need to pass them by about 60%. They are really hard tests. GPT-4 for gets over 80% in all three of those. So, it’s perfectly plausible, I think, that an AI could do at least some of the role of the GP. But, you’re right, there is no mission to do that, there is no ambition to do that.</p>
<p><strong>Mihaela van der Schaar:</strong> Forget about replacing the doctors with ChatGPT, which I’m less sure is such a good idea. But, building AI to do the planning of healthcare, to say, “[Patient A], based on what we have found out about you, you’re not as high risk, maybe you can come in four weeks. But [patient B], you need to come tomorrow, because something is worrisome.”</p>
<p><strong>Martin Goodson:</strong> We can get into the details, but I think we are agreeing that a big mission to solve real problems would be a step forward, rather than worrying about these risks of superintelligences taking over everything, which is what the government is doing right now.</p>
</section>
<section id="managing-misinformation" class="level2">
<h2 class="anchored" data-anchor-id="managing-misinformation">Managing misinformation</h2>
<p><strong>Andrew Garrett:</strong> We have some important elections coming up in 2024 and 2025. We haven’t talked much about misinformation, and then disinformation. So, I’m interested to get your views here. How much is that a problem?</p>
<p><strong>Detlef Nauck:</strong> There’s a problem in figuring out when it happens, and that’s something we need to get our heads around. One thing that we’re looking at is, how do we make communication safe from bad actors? How do you know that you’re talking to the person you see on the camera and it’s not a deep fake? Detection mechanisms don’t really work, and they can be circumvented. So, it seems like what we need is new standards for communication systems, like watermarks and encryption built into devices. A camera should be able to say, “I’ve produced this picture, and I have watermarked it and it’s encrypted to a certain level,” and if you don’t see that, you can’t trust that what you see comes from a genuine camera, and it’s not artificially created. It’s more difficult around text and language – you can’t really watermark text.</p>
<p><strong>Mark Levene:</strong> Misinformation is not just a derivative of AI. It’s a derivative of social networks and lots of other things.</p>
<p><strong>Mihaela van der Schaar:</strong> I would agree that this is not only a problem with AI. We need to emphasise the role of education, and lifelong education. This is key to being able to comprehend, to judge for ourselves, to be trained to judge for ourselves. And maybe we need to teach different methods – from young kids to adults that are already working – to really exercise our own judgement. And that brings me to this AI for human empowerment. Can we build AI that is training us to become smarter, to become more able, more capable, more thoughtful, in addition to providing sources of information that are reliable and trustworthy?</p>
<p><strong>Andrew Garrett:</strong> So, empower people to be able to evaluate AI themselves?</p>
<p><strong>Mihaela van der Schaar:</strong> Yes, but not only AI – all information that is given to us.</p>
<p><strong>Martin Goodson:</strong> On misinformation, I think this is really an important topic, because large language models are extremely persuasive. I asked ChatGPT a puzzle question, and it calculated all of this stuff and gave me paragraphs of explanations, and the answer was [wrong]. But it was so convincing I was almost convinced that it was right. The problem is, these things have been trained on the internet and the internet is full of marketing – it’s trillions of words of extremely persuasive writing. So, these things are really persuasive, and when you put that into a political debate or an election campaign, that’s when it becomes really, really dangerous. And that is extremely worrying and needs to be regulated.</p>
<div class="pullquote-container">
<div class="grid">
<div class="g-col-12 g-col-lg-4">
<div class="quarto-figure quarto-figure-left">
<figure class="figure">
<p><img src="https://realworlddatascience.net/viewpoints/posts/2023/12/06/images/llm-3d-shapes-crop.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="g-col-12 g-col-lg-8 pullquote-grid pullquote">
<p><img src="https://realworlddatascience.net/images/pullquote-purple.png" class="img-fluid" width="50"></p>
<p>At the moment, if you type something into ChatGPT and you ask for references, half of them will be made up. We know that, and also OpenAI knows that. But it could be that, if there’s regulation that things are traceable, you should be able to ask, ‘How did this information come about? Where did it come from?’</p>
</div>
</div>
</div>
<p><strong>Mark Levene:</strong> You need ways to detect it. Even that is a big challenge. I don’t know if it’s impossible, because, if there’s regulation, for example, there should be traceability of data. So, at the moment, if you type something into ChatGPT and you ask for references, half of them will be made up. We know that, and also OpenAI knows that. But it could be that, if there’s regulation that things are traceable, you should be able to ask, “How did this information come about? Where did it come from?” But I agree that if you just look at an image or some text, and you don’t know where it came from, it’s easy to believe. Humans are easily fooled, because we’re just the product of what we know and what we’re used to, and if we see something that we recognise, we don’t question it.</p>
</section>
<section id="audience-qa" class="level2">
<h2 class="anchored" data-anchor-id="audience-qa">Audience Q&amp;A</h2>
<section id="how-can-we-help-organisations-to-deploy-ai-in-a-responsible-way" class="level3">
<h3 class="anchored" data-anchor-id="how-can-we-help-organisations-to-deploy-ai-in-a-responsible-way">How can we help organisations to deploy AI in a responsible way?</h3>
<p><strong>Detlef Nauck:</strong> Help for the industry to deploy AI reliably and responsibly is something that’s missing, and for that, trust in AI is one of the things that needs to be built up. And you can only build up trust in AI if you know what these things are doing and they’re properly documented and tested. So that’s the kind of infrastructure, if you like, that’s missing. It’s not all big foundation models. It’s about, how do you actually use this stuff in practice? And 90% of that will be small, purpose-built AI models. That’s an area where the government can help. How do you empower smaller companies that don’t have the background of how AI works and how it can be used, how can they be supported in knowing what they can buy and what they can use and how they can use it?</p>
<p><strong>Mark Levene:</strong> One example from healthcare which comes to mind: when you do a test, let’s say, a blood test, you don’t just get one number, you should get an interval, because there’s uncertainty. What current [AI] models do is they give you one answer, right? In fact, there’s a lot of uncertainty in the answer. One thing that can build trust is to make transparent the uncertainty that the AI outputs.</p>
</section>
<section id="how-can-data-scientists-and-statisticians-help-us-understand-how-to-use-ai-properly" class="level3">
<h3 class="anchored" data-anchor-id="how-can-data-scientists-and-statisticians-help-us-understand-how-to-use-ai-properly">How can data scientists and statisticians help us understand how to use AI properly?</h3>
<p><strong>Martin Goodson:</strong> One big thing, I think, is in culture. In machine learning – academic research and in industry – there isn’t a very scientific culture. There isn’t really an emphasis on observation and experimentation. We hire loads of people coming out of an MSc or a PhD in machine learning, and they don’t know anything, really, about doing an experiment or selection bias or how data can trip you up. All they think about is, you get a benchmark set of data and you measure the accuracy of your algorithm on that. And so there isn’t this culture of scientific experimentation and observation, which is what statistics is all about, really.</p>
<p><strong>Mihaela van der Schaar:</strong> I agree with you, this is where we are now. But we are trying to change it. As a matter of fact, at the next big AI conference, NeurIPS, we plan to do a tutorial to teach people exactly this and bring some of these problems to the forefront, because trying really to understand errors in data, biases, confounders, misrepresentation – this is the biggest problem AI has today. We shouldn’t just build yet another, let’s say, classifier. We should spend time to improve the ability of these machine learning models to deal with all sorts of data.</p>
</section>
<section id="do-we-honestly-believe-yet-another-institute-and-yet-more-regulation-is-the-answer-to-what-were-grappling-with-here" class="level3">
<h3 class="anchored" data-anchor-id="do-we-honestly-believe-yet-another-institute-and-yet-more-regulation-is-the-answer-to-what-were-grappling-with-here">Do we honestly believe yet another institute, and yet more regulation, is the answer to what we’re grappling with here?</h3>
<p><strong>Detlef Nauck:</strong> I think we all agree, another institute is not going to cut it. One of the main problems is regulators are not trained on AI, so it’s the wrong people looking into it. This is where some serious upskilling is required.</p>
</section>
<section id="are-we-wrong-to-downplay-the-existential-or-catastrophic-risks-of-ai" class="level3">
<h3 class="anchored" data-anchor-id="are-we-wrong-to-downplay-the-existential-or-catastrophic-risks-of-ai">Are we wrong to downplay the existential or catastrophic risks of AI?</h3>
<p><strong>Martin Goodson:</strong> If I was an AI, a superintelligent AI, the easiest path for me to cause the extinction of the human race would be to spread misinformation about climate change, right? So, let’s focus on misinformation, because that’s an immediate danger to our way of life. Why are we focusing on science fiction? Let’s focus on reality.</p>
</section>
<section id="ai-tech-has-advanced-but-evaluation-metrics-havent-moved-forward.-why" class="level3">
<h3 class="anchored" data-anchor-id="ai-tech-has-advanced-but-evaluation-metrics-havent-moved-forward.-why">AI tech has advanced, but evaluation metrics haven’t moved forward. Why?</h3>
<p><strong>Mihaela van der Schaar:</strong> First, the AI community that I’m part of innovates at a very fast pace, and they don’t reward metrics. I am a big fan of metrics, and I can tell you, I can publish much faster a method in these top conferences then I can publish a metric. Number two, we often have in AI very stupid benchmarks, where we test everything on one dataset, and these datasets may be very wrong. On a more positive note, this is an enormous opportunity for machine learners and statisticians to work together and advance this very important field of metrics, of test sets, of data generating processes.</p>
<p><strong>Martin Goodson:</strong> The big problem with metrics right now is contamination, because most of the academic metrics and benchmark sets that we’re talking about, they’re published on the internet, and these systems are trained on the internet. I’ve already said that I don’t think this [evaluation] institute should exist. But if it did exist, there’s one thing that they could do, which is important, and that would be to create benchmark datasets that they do not publish. But obviously, you may decide, also, that the traditional idea of having a training set and a test set just doesn’t make any sense anymore. And there are loads of issues with data contamination, and data leakage between the training sets and the test sets.</p>
</section>
</section>
<section id="closing-thoughts-what-would-you-say-to-the-ai-safety-summit" class="level2">
<h2 class="anchored" data-anchor-id="closing-thoughts-what-would-you-say-to-the-ai-safety-summit">Closing thoughts: What would you say to the AI Safety Summit?</h2>
<p><strong>Andrew Garrett:</strong> If you were at the AI Safety Summit and you could make one point very succinctly, what would it be?</p>
<p><strong>Martin Goodson:</strong> You’re focusing on the wrong things.</p>
<p><strong>Mark Levene:</strong> What’s important is to have an interdisciplinary team that will advise the government, rather than to build these institutes, and that this team should be independent and a team which will change over time, and it needs to be inclusive.</p>
<p><strong>Mihaela van der Schaar:</strong> AI safety is complex, and we need to realise that people need to have the right expertise to be able to really understand the risks. And there is risk, as I mentioned before, of potential collusion, where people are both building the AI and saying it’s safe, and we need to separate these two worlds.</p>
<p><strong>Detlef Nauck:</strong> Focus on the data, not the models. That’s what’s important to build AI.</p>
<div class="article-btn">
<p><a href="../../../../../viewpoints/index.html">Discover more Viewpoints</a></p>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-6">
<dl>
<dt>Copyright and licence</dt>
<dd>
© 2023 Royal Statistical Society
</dd>
</dl>
<p>Images by <a href="https://cream3d.com/">Wes Cockx</a> &amp; <a href="https://deepmind.google/discover/visualising-ai/">Google DeepMind</a> / <a href="https://www.betterimagesofai.org">Better Images of AI</a> / AI large language models / <a href="https://creativecommons.org/licenses/by/4.0/">Licenced by CC-BY 4.0</a>.</p>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>How to cite</dt>
<dd>
Tarran, Brian. 2023. “Evaluating artificial intelligence: How data science and statistics can make sense of AI models.” Real World Data Science, December 6, 2023. <a href="https://realworlddatascience.net/viewpoints/posts/2023/12/06/ai-fringe.html">URL</a>
</dd>
</dl>
</div>
</div>
</div>


</section>

 ]]></description>
  <category>AI</category>
  <category>Large language models</category>
  <category>Accountability</category>
  <category>Regulation</category>
  <category>Metrics</category>
  <category>Events</category>
  <guid>https://realworlddatascience.net/viewpoints/posts/2023/12/06/ai-fringe.html</guid>
  <pubDate>Wed, 06 Dec 2023 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/viewpoints/posts/2023/12/06/images/llm-3d-shapes.png" medium="image" type="image/png" height="105" width="144"/>
</item>
<item>
  <title>‘I would like modellers to be less ambitious in developing monster models that are impossible to inspect’</title>
  <dc:creator>Brian Tarran</dc:creator>
  <link>https://realworlddatascience.net/viewpoints/interviews/posts/2023/11/24/politics-of-modelling.html</link>
  <description><![CDATA[ 




<p>It was during the first wave of the Covid-19 pandemic, when citizens in many countries around the world were confined to their homes, that Andrea Saltelli and colleagues were inspired to write “a manifesto for responsible modelling.” The television news was, Saltelli recalls, dominated by models of Covid infections, hospitalisations, and deaths. Politicians pointed to charts showing those model projections and spoke of “flattening the curve” – driving down case numbers – so as not to overwhelm healthcare systems.</p>
<p>While all this was going on, Saltelli came into contact “with a fantastic group of people,” he says, “all of whom were, in a sense, concerned by the sudden eruption of mathematical modelling into everyday life.”</p>
<p>“We were concerned that this [modelling] was not being done properly, that too much importance was given to those numbers, too much certainty was attached to them, and nobody seemed to realise that the selection of certain numbers rather than others would eventually and dramatically bias the message that was given.”</p>
<p>In June 2020, Saltelli – along with Monica Di Fiore, Deborah Mayo, Theodore Porter, Philip Stark and others – published in <em>Nature</em> their manifesto setting out “<a href="https://www.nature.com/articles/d41586-020-01812-9">Five ways to ensure that models serve society</a>.” The ideas proposed in that three-page comment piece have now been given a book-length treatment, so we sat down with Saltelli to discuss <a href="https://global.oup.com/academic/product/the-politics-of-modelling-9780198872412?cc=gb&amp;lang=en&amp;"><em>The Politics of Modelling: Numbers Between Science and Policy</em></a>.</p>
<div class="keyline">
<hr>
</div>
<p><strong>Can you tell our readers a little about yourself?</strong><br>
I am a chemist. I got my degree in chemistry, but for most of my life I have worked as a mathematical modeller and applied statistician. More recently, let’s say in the last 10 years or so, I have also moved into issues of epistemology – meaning, how do we decide that we know what we know, and how do we do that when the source of the knowledge is represented by a mathematical model?</p>
<p><strong>I’d like to dig into the title of your new book. What should people understand about <em>The Politics of Modelling</em>?</strong><br>
It starts from a broader discussion of a state of exception enjoyed by mathematical modelling. One point we try to make in the book is that models are exceptional because they have an incredible palette of methodologies – even more than statistics. They are not a discipline, because everyone does modelling in their own craft in a different way. Modelling even escapes the gaze of sociologists most of the time because sociologists are more interested in algorithms and statistics. And, as a consequence of this state of exception, models enjoy many privileges, including a better defence of the pretence of neutrality, and they maintain, in a certain sense, a lapse of symmetry between developers and users. They also have a very strong grip on policy, whereby models can enjoy a high epistemic authority, and this epistemic authority seems to be proportional to the dimension of the model or the base of data on which the model has been calibrated. All of this creates a situation which leads to a problem – a problem for society, on the one hand, because models are used to suggest policies which are not optimal, and on the other hand, trust is consumed, trust is lost, and this may have been happening as a result of the Covid-19 epidemic and the way mathematical modelling was used in the context of the epidemic.</p>
<p><strong>The book emerged out of the “manifesto for responsible modelling” that you published in <em>Nature</em> a few years back. Could you describe that manifesto?</strong><br>
The manifesto was something which came out of the pandemic, in fact, because we were all locked up at home and we could spend some time reflecting and writing. We tried to produce a set of recommendations for both society and the modellers: for society to be a bit more circumspect in accepting results from mathematical modelling, and for modellers to be more cautious in formulating their predictions. But, beyond the issue of apparent precision of mathematical models, there was also the issue that models are built on a series of assumptions, each of which may have a great bearing on the result. And not only that but also, at the point where you formulate a mathematical model, you assume that you have already decided what is the problem, what is the direction of progress. So, there are really many normative assumptions which are embedded into that. Then there is the issue that mathematical models are not done by everyone; they are done by specific groups of people who belong to, normally, a certain identified class, some kind of elite – not a financial elite, but an elite in terms of competencies and knowledge. And this also creates bias, because – to put it brutally – if you can work at home with your laptop, the epidemic doesn’t affect you so much. But if you work in a plant and the plant is closed, and you are not paid, this destroys your life, or the life of your family. This asymmetry – or inequality, let’s say, or implicit bias – in those who are producing the analysis, this was, for many of us, an issue which needed to be brought to the attention of the public.</p>
<div class="pullquote-container">
<div class="grid">
<div class="g-col-12 g-col-lg-4">
<div class="quarto-figure quarto-figure-left">
<figure class="figure">
<p><img src="https://realworlddatascience.net/viewpoints/interviews/posts/2023/11/24/images/andrea-saltelli-sq.png" class="img-fluid figure-img" alt="Andrea Saltelli, co-editor of 'The Politics of Modelling'"></p>
<figcaption class="figure-caption">Andrea Saltelli, co-editor of ‘The Politics of Modelling.’</figcaption>
</figure>
</div>
</div>
<div class="g-col-12 g-col-lg-8 pullquote-grid pullquote">
<p><img src="https://realworlddatascience.net/images/pullquote-purple.png" class="img-fluid" width="50"></p>
<p>The manifesto was something which came out of the pandemic… We tried to produce a set of recommendations for both society and the modellers: for society to be a bit more circumspect in accepting results from mathematical modelling, and for modellers to be more cautious in formulating their predictions.</p>
</div>
</div>
</div>
<p><strong>Surely the urgency of the Covid situation prevented people from taking a step back and thinking more deeply about how models are constructed. Is it not forgivable in a situation like that? Or, is your argument that we should be doing this at all times, regardless of the urgency, regardless of the time pressures?</strong><br>
I am tempted to say both yes and no. Yes, because surely the situation was urgent, and many things which were done in a way which one would consider suboptimal were later justified on the grounds of urgency. We noted incredible differences in the measures adopted in several countries, so for us it was obvious that even though everyone was claiming to “follow the science,” they seemed to be following different sciences, or perhaps they were following “the science” which was more instrumental or more convenient to justify what was simply politically expedient.</p>
<p>Beyond that, I would say: it’s always urgent, no? We are very often in these kinds of situations. One might say that even the regulation of artificial intelligence today is urgent. Regulation of pesticides is urgent. Not to mention geopolitics… Everything seems to be urgent, and this seems to be a constant in our relationship with technology in particular: we don’t want to kill innovation, but if we wait to see what a new piece of technology does before we regulate it, then maybe it’s too late to change it. This is exploited by many people, not least [Mark] Zuckerberg [CEO of Facebook owner Meta]. He says, “Move fast and break things,” but once things are broken, they’re broken.</p>
<p>And talking about things being broken, what we discuss in the book is also this issue of broken trust. People are losing faith in expertise – not in all countries in the same way; there are national differences that are important. But, in general, if you measure trust in science – which is still very high – it’s taken quite a dent during the pandemic, and we argue that this was in part due to abuse of mathematical models.</p>
<p><strong>The book, which you’ve edited with Monica Di Fiore, breaks down the manifesto for responsible modelling into extended essays from different contributors, looking at different aspects of modelling – the framing of models, the assumptions, the consequences. For these essays, you draw on experts from different fields: sociology, philosophy, statistics, civil engineering, geography, law, environmental sciences, and others. Why was it important to get such diverse perspectives on these various aspects of modelling?</strong><br>
There is a major divide between social science – humanities – on the one hand and natural sciences on the other hand, with lots of suspicion between the two fields and sometimes open hostility. Mathematical modelling is particularly impenetrable, as we argue, to the gaze coming from a social scientist – at least, more impenetrable than statistics or algorithms, which have been very much studied in recent years. And so, it was important to allow the two fields, the two big communities, to communicate and to speak to one another in a critical way.</p>
<p><strong>You write in your introduction to the book that the field of statistics has spent more time thinking more deeply about questions of data ethics, model assumptions, and so on. Can you give an example?</strong><br>
There is a book by a group of French statisticians, <em>Statactivisme</em>, which is rich with examples of how a statistician could make a difference by simply producing better numbers. They don’t say, “Throw away the model, throw away the numbers,” but simply be careful of what numbers you use. And I think models and modellers need something like this, some kind of systematic debate – a societal debate – with other disciplines on what they’re doing.</p>
<p><strong>One of the quotes that jumped out at me from the book was, “Models are underexplained but overinterpreted.” How do we reset that balance?</strong><br>
This is more easily said than done. The remedies to this are, maybe we should spend some time thinking about reproducibility, even in mathematical modelling. This is not done. We talk about the reproducibility of data but very few people talk about the reproducibility of a mathematical model. Another thing which I think would be useful is to think more about how to interpret models and less about how to make them bigger. And then, of course, there is the practice of “assumption hunting.” If you use a model, go and hunt for the assumptions contributing to its construction.</p>
<p>To the modellers we say, engage yourself in something that might be called “modelling of the model process,” which means, try to imagine what would happen if you took a different branch in the construction of the model. In this we make an analogy to the “garden of the forking paths,” something that statisticians discuss, because they understand that when they build a statistical construction, they can take one way or another way, and when they measure the impact of taking a different path – as, for instance, when they give the same data to different teams – they find an amazing diversity of results that are totally unexpected. We are learning now that not only in statistics and mathematical modelling but in the laboratory, too – conducting physical experiments, not numerical ones – you can have a diverging set of outcomes depending on who is doing the analysis.</p>
<p>All this should call for a science that is more humble – one that accepts this kind of possibility and works actively to make these issues evident but also solves them in order to produce knowledge that is useful.</p>
<p><strong>Earlier, you spoke about modellers coming from a specific group or class of people – an elite. We interviewed, earlier this year, <a href="https://realworlddatascience.net/viewpoints/interviews/posts/2023/01/25/erica-thompson.html">Erica Thompson</a>, author of the book <em>Escape from Model Land</em>, and one of the points Erica discussed was how to bring more diversity of thought and of voices into the modelling process. How do we engage broader communities in the construction of models – maybe not building the model itself, but thinking about what is important, what needs to be measured, what are we looking to understand?</strong><br>
This could be achieved if models were used in a context of what we, the authors, call an “extended peer community.” In other words, this is the idea that when you are discussing an issue, you should talk to the people directly affected by the issue because they have some knowledge about it. For this to take place, the model must be one instrument, which the community can get together to discuss, and so the model must not be too complex.</p>
<p><strong>Now that your book is out, what do you hope will be its impact?</strong><br>
Looking from the point of view of the modellers, I would like them to be more humble and less ambitious in developing monster models that are impossible to inspect and explore. From society I would like to see a more circumspect attitude, as I said before. Society has been trained to be sceptical of statistical information, but we should also be circumspect about the output of mathematical modelling. Ask more questions; ask, for instance, for the uncertainty range for a given number, or whether the number tells the entire story.</p>
<div class="article-btn">
<p><a href="../../../../../../viewpoints/interviews/index.html">Find more Interviews</a></p>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-6">
<dl>
<dt>Copyright and licence</dt>
<dd>
© 2023 Royal Statistical Society
</dd>
</dl>
<p><a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> <img style="height:22px!important;vertical-align:text-bottom;" src="https://realworlddatascience.net/viewpoints/interviews/posts/2023/11/24/https:/mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://realworlddatascience.net/viewpoints/interviews/posts/2023/11/24/https:/mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"></a> This article is licensed under a Creative Commons Attribution 4.0 (CC BY 4.0) <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> International licence</a>.</p>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>How to cite</dt>
<dd>
Tarran, Brian. 2023. “‘I would like modellers to be less ambitious in developing monster models that are impossible to inspect.’” Real World Data Science, November 24, 2023. <a href="https://realworlddatascience.net/viewpoints/interviews/posts/2023/11/24/politics-of-modelling.html">URL</a>
</dd>
</dl>
</div>
</div>
</div>



 ]]></description>
  <category>Modelling</category>
  <category>Public policy</category>
  <guid>https://realworlddatascience.net/viewpoints/interviews/posts/2023/11/24/politics-of-modelling.html</guid>
  <pubDate>Fri, 24 Nov 2023 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/viewpoints/interviews/posts/2023/11/24/images/andrea-saltelli.png" medium="image" type="image/png" height="105" width="144"/>
</item>
<item>
  <title>How data science and statistics can shape the UK’s AI strategy</title>
  <dc:creator>Brian Tarran</dc:creator>
  <link>https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/10/30/ai-conf-panel.html</link>
  <description><![CDATA[ 




<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/7aZrkQIComM?si=7efQPy5m3ZCxe4sg" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<section id="about-the-panelists" class="level2">
<h2 class="anchored" data-anchor-id="about-the-panelists">About the panelists</h2>
<p><strong>Andrew Garrett</strong> (chair) is president of the Royal Statistical Society. He is executive vice president of scientific operations at the clinical research organisation ICON plc, where he is responsible for the strategic direction and operational delivery of a range of clinical trial services. Having worked extensively in the area of rare diseases, he has held various biostatistics managerial positions in the pharmaceutical industry, including vice president of biostatistics, medical writing and regulatory affairs at Quintiles (now IQVIA).</p>
<p><strong>Peter Wells</strong> is a technologist, who accidentally started a second career in public policy. He has both worked on AI policy and helped design AI-enabled services. After 20 years in the telecoms industry, he found himself spending 2014 developing digital government policy for the Labour Party. Since then he has worked with multiple governments and organisations including the Open Data Institute, Projects by IF, Google, Meta and the Government Digital Service.</p>
<p><strong>Maxine Setiawan</strong> is a data scientist specialising in AI and data risk and trusted AI in EY UK&amp;I. She works to help clients from various industries assess and manage risks from analytics and AI systems, and implement AI governance to ensure AI systems are implemented with fair, accountable, and trustworthy principles. She combines her socio-technical background with an MSc in Social Data Science from the University of Oxford, and her experience working in data science within consulting firms.</p>
<p><strong>Sophie Carr</strong> is chair of the <a href="https://realworlddatascience.net/viewpoints/editors-blog/posts/2022/10/18/meet-the-team.html">Real World Data Science editorial board</a> and is the founder and owner of Bays Consulting, a data science company. Having trained as an aeronautical engineer, Sophie completed her PhD in Bayesian analysis part time whilst she worked and, following redundancy, founded her own company. She is the VP for education and statistical literacy at the RSS and sits on the executive committees of the Academy for Mathematical Sciences and the International Centre for Mathematical Sciences. She is also currently <a href="https://ima.org.uk/12382/worlds-most-interesting-mathematician-2019-dr-sophie-carr/">the world’s most interesting mathematician</a>.</p>
<p><strong>Chris Nemeth</strong> is a professor of statistics at Lancaster University. His primary research area is in probabilistic machine learning and computational statistics. He holds an EPSRC-funded Turing AI fellowship on Probabilistic Algorithms for Scalable and Computable Approaches to Learning (PASCAL), and through his fellowship he works closely with partners including Shell, Tesco, Elsevier, Microsoft Research and The Alan Turing Institute. He is chair of the <a href="https://rss.org.uk/membership/rss-groups-and-committees/sections/statistical-computing/">Royal Statistical Society Section on Computational Statistics and Machine Learning</a>.</p>
<p><strong>Karen Tingay</strong> is a principal statistical methodologist at the Office for National Statistics where she specialises in natural language processing and in managing complex survey imputation. She established and heads up the Text Data Subcommunity, a large network of public sector analysts to build capability and best practice guidance in managing and analysing unstructured text data, on behalf of the Government Data Science Community. She sits on several cross-government and international working groups on responsible use of generative AI.</p>
<div class="article-btn">
<p><a href="../../../../../../viewpoints/editors-blog/index.html">Back to Editors’ blog</a></p>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-6">
<dl>
<dt>Copyright and licence</dt>
<dd>
© 2023 Royal Statistical Society
</dd>
</dl>
<p><a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> <img style="height:22px!important;vertical-align:text-bottom;" src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/10/30/https:/mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/10/30/https:/mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"></a> This article is licensed under a Creative Commons Attribution 4.0 (CC BY 4.0) <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> International licence</a>.</p>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>How to cite</dt>
<dd>
Tarran, Brian. 2023. “How data science and statistics can shape the UK’s AI strategy.” Real World Data Science, October 30, 2023. <a href="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/10/30/ai-conf-panel.html">URL</a>
</dd>
</dl>
</div>
</div>
</div>


</section>

 ]]></description>
  <category>AI</category>
  <category>Large language models</category>
  <category>Events</category>
  <guid>https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/10/30/ai-conf-panel.html</guid>
  <pubDate>Mon, 30 Oct 2023 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/10/30/images/panel.png" medium="image" type="image/png" height="105" width="144"/>
</item>
<item>
  <title>‘Statistics and data science are at the heart of the AI movement – we want to be a strong voice in the debate’</title>
  <dc:creator>Brian Tarran</dc:creator>
  <link>https://realworlddatascience.net/viewpoints/interviews/posts/2023/10/25/evaluating-ai.html</link>
  <description><![CDATA[ 




<p>Next week, the Royal Statistical Society (RSS) is hosting a panel debate on <a href="https://rss.org.uk/training-events/events/events-2023/rss-events/evaluating-artificial-intelligence-how-data-scienc/#fulleventinfo">“Evaluating artificial intelligence: How data science and statistics can make sense of AI models.”</a> The event forms part of the <a href="https://aifringe.org/">AI Fringe programme of activities</a> and is timed to precede the <a href="https://www.gov.uk/government/publications/ai-safety-summit-introduction">UK government’s AI Safety Summit at Bletchley Park</a>.</p>
<p>RSS president Andrew Garrett is chairing this free, in-person event on 31 October, and he’ll be joined by five panellists to discuss big questions around AI model development, evaluation, risk and benefits:</p>
<ul>
<li>Mihaela van der Schaar, John Humphrey Plummer professor of machine learning, artificial intelligence and medicine at the University of Cambridge and a fellow at The Alan Turing Institute</li>
<li><a href="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/01/27/talking-chatgpt.html">Detlef Nauck</a>, head of AI and data science research, BT</li>
<li><a href="https://realworlddatascience.net/viewpoints/interviews/posts/2023/04/28/stephanie-hare.html">Stephanie Hare</a>, researcher, broadcaster, and author of <em>Technology is Not Neutral</em></li>
<li>Mark Levene, principal scientist, department of data science, National Physical Laboratory</li>
<li><a href="https://realworlddatascience.net/viewpoints/posts/2023/10/20/ai-for-humanity.html">Martin Goodson</a>, chief executive, Evolution AI, and former chair of the RSS Data Science and AI Section</li>
</ul>
<p>We sat down with Andy for a quick-fire Q&amp;A to hear more of what’s in store for next week’s event.</p>
<div class="keyline">
<hr>
</div>
<p><strong>The RSS event takes place one day before the UK government’s AI Safety Summit. Why is it so important for statisticians and data scientists to be involved in the debate over AI safety?</strong><br>
Statistics and data science are at the heart of the AI movement – it’s really a question of taking data and information, and using statistical algorithms to create outputs. That’s at the core of what we do as statisticians and data scientists. Although it’s called AI, it uses mathematical and statistical methods.</p>
<p><strong>The AI Safety Summit focuses on risks posed by certain types of AI systems. Where do you see the biggest risk?</strong><br>
Risk depends upon the purpose and the impact of the AI. It’s very different whether something is being used to inform or recommend or persuade or decide. If it’s a decision-making system, say, there is a bigger risk associated with it if the decision to be made will have an important impact on your life – so, that might be a medical decision or a decision on whether you’re to receive benefits or housing, or how you’re treated in the judicial system. It’s important to understand what the AI is being used for and how much control you have over it, and also how much oversight there is. Will the decision be made solely by an algorithm, or is there human oversight?</p>
<p>There is a particular concern moving forward around misinformation and disinformation. That is a genuine concern, particularly with big elections coming up in the UK and beyond. People are sharing things that they don’t realise are disinformation, so it is really important to understand where the information is coming from, its provenance; that’s incredibly important. We’ve seen with hallucinogenic AI that sometimes there are references given for outputs that don’t actually exist. So we need to constantly scrutinise where information sources are coming from and, if sources are quoted, do they really exist?</p>
<p><strong>The <a href="https://rss.org.uk/RSS/media/File-library/Policy/2023/RSS-AI-white-paper-response-v2-2.pdf">RSS policy response</a> to the UK government’s <a href="https://www.gov.uk/government/publications/ai-regulation-a-pro-innovation-approach/white-paper">AI regulation whitepaper</a> urges investment in a Centre for AI Evaluation Methodology. What informed this recommendation?</strong><br>
The white paper uses the word “proportionate” many, many times. When you talk about safety, inevitably you move into the area of risk, and if you want safety measures to be proportionate, and you want those measures to be based upon risk, then – effectively – you have to understand how you evaluate risk, how you evaluate the probability of something happening, and what the impact might be if it does happen. That naturally lends itself to needing to evaluate both the potential harm but also the potential benefit of using AI. I think the summit is focused more around harm, and the concerns around potential harms, rather than the trade off between harm and benefit. But that was certainly the reason we got into talking about the importance of evaluation, and evaluation is used in other industries where there is high risk. Drug development is an example, as is healthcare, where treatments and new methods are evaluated so that people are informed about both the potential harms and the potential benefits.</p>
<div class="pullquote-container">
<div class="grid">
<div class="g-col-12 g-col-lg-4">
<div class="quarto-figure quarto-figure-left">
<figure class="figure">
<p><img src="https://realworlddatascience.net/viewpoints/interviews/posts/2023/10/25/images/andy-garrett-crop.png" class="img-fluid figure-img" alt="Portrait photo of Andrew Garrett"></p>
<figcaption class="figure-caption">Andrew Garrett, president, Royal Statistical Society</figcaption>
</figure>
</div>
</div>
<div class="g-col-12 g-col-lg-8 pullquote-grid pullquote">
<p><img src="https://realworlddatascience.net/images/pullquote-purple.png" class="img-fluid" width="50"></p>
<p>We have a really important role to play in focusing attention not only on AI outputs but on inputs. That is an area that hasn’t received enough attention but it is one that statisticians understand incredibly well.</p>
</div>
</div>
</div>
<p><strong>A lot of the focus of the AI debate is on outputs. Should we be talking more about inputs – the data the models are trained on, where the data is coming from, and issues of quality and bias, etc.?</strong><br>
There should be more discussion of this, yes. Statisticians and data scientists, but statisticians in particular, are trained very much around the data generating process, so we naturally think about how data is gathered, the potential biases in a dataset, and the representation that you need for a study. We understand that the data going in is as important as the outputs produced. And I think it’s becoming more and more necessary to understand where exactly the data is coming from, whether it’s diverse, whether it’s representative of the populations you want to study, and so on. This is an incredibly important area, and provenance of data – like provenance of information – will become ever more important. So, with a large language model, for example, what information is it trained on? Did the developers have permission to use that information? How representative is that information? These sorts of questions need to be addressed, because your outputs will only ever be as good as your inputs.</p>
<p><strong>AI systems are having wide-reaching effects across society. What impact are AI tools having on the work of statisticians and data scientists, and how would you evaluate the impacts so far: good, bad, or neutral?</strong><br>
You have to be a cynic and an evangelist at the same time. There is some very good work being done but also some very naive work. AI is not magic. It requires the same thoroughness and lifecycle management as anything else. Certainly in terms of pattern recognition, image recognition, it’s been very useful. On MRI images, for example, can you reduce the amount of time humans need to spend looking at the data because you have an AI tool helping with the assessment? Of course, the challenge is then, when you have an AI assessment, what do you compare it to? You could compare it to what an expert would assess, but is that a suitable reference point for saying something is a good system, knowing that humans themselves are not perfect? AI systems are able to handle large datasets, large images, very quickly. And so the speed of being able to do that has a potential advantage, although it depends on the level of human oversight. Where we’re seeing these tools being advantageous, I think, is where you have some human oversight but some of the heavy lifting is being done by the AI systems.</p>
<p><strong>What do you hope will emerge from the panel debate at the RSS next week? Reaching consensus on such a big, broad topic is unlikely, perhaps, but what are the kinds of things that you’re hoping to learn and take away from the discussion?</strong><br>
We’ve got some very good practitioners on the panel, and I’m hoping that we’ll generate some really good discussion from the panel and some really good questions from the audience. When it comes to the AI conversation generally, there’s a danger that it has focused too much so far on either the academic view of things or the large tech company perspective, so we’re probably missing out a whole tranche of people who are working at the coalface on these things, working in smaller companies. So, I’d like to understand a little bit more about what is happening in that part of industry. I know there’s a big focus on things like building out capability in the UK, and that’s not simply a question of having people with expertise – it’s about having access to things like the right sort of computing environments. So, I think there’s going to be some interesting discussion around what’s holding back industry. Overall, though, what I’d like to see come out of this meeting is a more proportionate response, from people who are working on this on a day-to-day basis. Statisticians are good at that – at coming up with a measured response, an informed response. Do we have the same concerns about the existential threat of AI that have been discussed by some of the larger companies, for example?</p>
<p><strong>Aside from coming along and contributing to this panel discussion, how else can statisticians and data scientists engage with the AI debate and help shape a collective response to this major issue?</strong><br>
I’d certainly encourage them to join the RSS and be a part of our work on this. We want to be a strong voice in the debate on AI because it is underpinned by statistical and mathematical techniques, as I mentioned at the start. We have a really important role to play in focusing attention not only on AI outputs but on inputs. That is an area that hasn’t received enough attention but it is one that statisticians understand incredibly well – and it’s one that brings into discussion issues such as ethics, consent, copyright, etc., and that’s very much where we should be engaging as well.</p>
<div class="callout callout-style-simple callout-note">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-body-container">
<p>Register now for <a href="https://rss.org.uk/training-events/events/events-2023/rss-events/evaluating-artificial-intelligence-how-data-scienc/#fulleventinfo">“Evaluating artificial intelligence: How data science and statistics can make sense of AI models,”</a> a free, in-person debate at the RSS offices in London, 4 pm – 6 pm, Tuesday, October 31.</p>
</div>
</div>
</div>
<div class="article-btn">
<p><a href="../../../../../../viewpoints/interviews/index.html">Find more Interviews</a></p>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-6">
<dl>
<dt>Copyright and licence</dt>
<dd>
© 2023 Royal Statistical Society
</dd>
</dl>
<p><a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> <img style="height:22px!important;vertical-align:text-bottom;" src="https://realworlddatascience.net/viewpoints/interviews/posts/2023/10/25/https:/mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://realworlddatascience.net/viewpoints/interviews/posts/2023/10/25/https:/mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"></a> This article is licensed under a Creative Commons Attribution 4.0 (CC BY 4.0) <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> International licence</a>.</p>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>How to cite</dt>
<dd>
Tarran, Brian. 2023. “‘Statistics and data science are at the heart of the AI movement – we want to be a strong voice in the debate.’” Real World Data Science, October 25, 2023. <a href="https://realworlddatascience.net/viewpoints/interviews/posts/2023/10/25/evaluating-ai.html">URL</a>
</dd>
</dl>
</div>
</div>
</div>



 ]]></description>
  <category>AI</category>
  <category>Events</category>
  <category>Algorithms</category>
  <category>Risk</category>
  <guid>https://realworlddatascience.net/viewpoints/interviews/posts/2023/10/25/evaluating-ai.html</guid>
  <pubDate>Wed, 25 Oct 2023 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/viewpoints/interviews/posts/2023/10/25/images/andy-garrett.png" medium="image" type="image/png" height="105" width="144"/>
</item>
<item>
  <title>An AI for humanity</title>
  <dc:creator>Martin Goodson</dc:creator>
  <link>https://realworlddatascience.net/viewpoints/posts/2023/10/20/ai-for-humanity.html</link>
  <description><![CDATA[ 




<div class="callout callout-style-simple callout-note" style="margin-top: 0;">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-body-container">
<p>This is the text of a talk Martin Goodson gave to the European Commission in Brussels on October 10, 2023. It is republished with permission from the <a href="https://rssdsaisection.substack.com/p/an-ai-for-humanity">Royal Statistical Society Data Science and AI Section Newsletter Substack</a>. The views expressed are the author’s own and do not necessarily represent those of the RSS.</p>
</div>
</div>
</div>
<p>For years academics have published studies about the limits of automation by AI, suggesting that jobs requiring creativity were the least susceptible to automation. That <a href="https://www.businessinsider.com/lost-job-chatgpt-made-me-obsolete-copywriter-2023-7?r=US&amp;IR=T">turned</a>. <a href="https://www.washingtonpost.com/technology/2023/06/02/ai-taking-jobs/">out</a>. <a href="https://www.theguardian.com/film/2023/aug/21/ai-jobs-hollywood-writers-actors-strike">well</a>.</p>
<p>Actually, that’s not completely true: some said that jobs that need a long period of education, like teaching and healthcare, were going to be the hardest of all to automate. <a href="https://www.khanacademy.org/khan-labs">Oh</a>. <a href="https://www.microsoft.com/en-us/research/uploads/prod/2023/03/GPT-4_medical_benchmarks.pdf">dear</a>.</p>
<p>Let’s face it, all predictions about the limits of AI have been hopelessly wrong. Maybe we need to accept that there aren’t going to be any limits. How is this going to affect our society?</p>
<p>Studies came out from <a href="https://www.nber.org/papers/w31161">Stanford</a> and <a href="https://www.science.org/doi/10.1126/science.adh2586">MIT</a> this year, looking at the potential of AI assistants to improve the productivity of office workers. Both came to the same conclusion – that the workers with the lowest ability and least experience were the ones who gained the most in productivity.</p>
<p>In other words, AI has made human knowledge and experience less valuable.</p>
<p>Researchers at Microsoft and Open AI <a href="https://arxiv.org/abs/2303.13375">wrote</a> something important on this phenomenon that I’d like to quote in full:</p>
<blockquote class="blockquote">
<p>Large swaths of modern society are predicated on a “grand bargain” in which professional classes invest years or even decades in technical education and training and are [afforded] the exclusive right to practice in their field, social prestige, and above-average compensation.</p>
<p>Technical disruption of this social contract can have implications not only for the medical field but for numerous other knowledge-intensive professions including law, banking, engineering, accounting, and others.</p>
</blockquote>
<p>Let’s talk about the fairness of this. Because the AI models didn’t invent medicine, accountancy or engineering. They didn’t learn anything directly from the world – human experts taught AI models how to do these things. And they [the human experts] did it without giving their permission, or even knowing that it was happening.</p>
<p>The large tech companies have sucked up all of human knowledge and culture and now provide access to it for the price of an API call. This is a huge transfer of power and value from humanity to the tech companies.</p>
<p>Biologists in the 1990s found themselves in a very similar position. Celera Genomics was trying to achieve commercial control over the human genome. To stop this happening, the publicly funded Human Genome Project (HGP) resolved to sequence the human genome and release the data for free on a daily basis, before Celera could patent any of it.</p>
<p>The HGP was criticised because of ethical concerns (including concerns about eugenics), and because it was thought to be a huge waste of money. The media attacked it, claiming that a publicly funded initiative could not possibly compete with the commercial sector. Fortunately for humanity, a group of scientists with a vision worked together to make it a success.</p>
<p>And it was a huge success: in purely economic terms it produced nearly $1 trillion in economic impacts for investment of about $4 billion. Apart from the economics, the Human Genome Project accelerated development of the genomic technologies that underlie things like mRNA vaccine technology.</p>
<p>The parallels to our current situation with AI are striking. With OpenAI, just like Celera, we have a commercial enterprise that launched with an open approach to data sharing but eventually changed to a more closed model.</p>
<p>We have commentators suggesting that a publicly funded project to create an open-source AI would be ethically dubious, a waste of money and beyond the competency of the public sector. Where the analogy breaks down is that unlike in the 1990s, we do not have any strong voices arguing on the other side, for openness and the creation of shared AI models for all humanity.</p>
<p>Public funding is needed for an “AI for humanity” project, modelled on the Human Genome Project. How else can we ensure the benefits of AI are spread widely across the global population and not concentrated in the hands of one or two all-powerful technology companies?</p>
<p>We’ll never know what the world would have looked like if we’d let Celera gain control over the human genome. Do we want to know a world where we let technology companies gain total control over artificial intelligence?</p>
<section id="faq" class="level2">
<h2 class="anchored" data-anchor-id="faq">FAQ</h2>
<section id="how-about-all-the-ethical-considerations-around-ai-shouldnt-we-consider-this-before-releasing-any-open-source-models" class="level5">
<h5 class="anchored" data-anchor-id="how-about-all-the-ethical-considerations-around-ai-shouldnt-we-consider-this-before-releasing-any-open-source-models">How about all the ethical considerations around AI – shouldn’t we consider this before releasing any open-source models?</h5>
<p>Of course. Obviously, there are ethical implications that need to be considered carefully, just as there were for the genome project. At the start of that project, the ethical, legal, and social issues (or ELSI) program was set up. The National Institutes of Health (NIH) devoted about 5% of their total Human Genome Project budgets to the ELSI program and it is now the largest bioethics program in the world. All important ethical issues were considered carefully and resolved without drama.</p>
</section>
<section id="arent-there-enough-community-efforts-to-build-open-source-ai-models-already" class="level5">
<h5 class="anchored" data-anchor-id="arent-there-enough-community-efforts-to-build-open-source-ai-models-already">Aren’t there enough community efforts to build open-source AI models already?</h5>
<p>There are good projects producing open-source large language models, like Llama 2 from Meta and Falcon from the TII in the United Arab Emirates. These are not quite as powerful as [Open AI’s] GPT-4 but they prove the concept that open-source models can approach the capabilities of the front-running commercial models; even when produced by a single well-funded lab (and a state-funded lab in the case of the TII). A coordinated international publicly funded project will be needed to surpass commercial models in performance.</p>
<p>In any case, do we want to be dependent on the whims of the famously civic-minded Mark Zuckerberg [CEO of Meta] for access to open-source AI models? We shouldn’t forget that the original Llama model was released with a restrictive licence that was eventually changed to something more open after a community outcry. We are lucky they made this decision. But the future of our societies needs to rely on more than luck.</p>
</section>
<section id="how-about-the-uk-government-ai-safety-summit-and-ai-safety-institute-wont-they-be-doing-similar-work" class="level5">
<h5 class="anchored" data-anchor-id="how-about-the-uk-government-ai-safety-summit-and-ai-safety-institute-wont-they-be-doing-similar-work">How about the UK Government AI Safety Summit and AI Safety Institute – won’t they be doing similar work?</h5>
<p>Absolutely not! The limit of the UK Government’s ambition seems to be to set the UK up as a sort of <a href="https://www.politico.eu/article/uk-pitch-ai-safety-institute-rishi-sunak/">evaluation and testing</a> station for AI models made in Silicon Valley. This is as far from the spirit of the Human Genome Project as it’s possible to be.</p>
<p>Sir John Sulston, the leader of the HGP in the UK, was a Nobel Prize-winning scientific hero who wanted to stop Celera Genomics from gaining monopolistic control over the human genome at all costs. The current UK ambition would be like reducing the Human Genome Project to merely testing Celera Genomics’ data for errors.</p>
</section>
<section id="how-will-an-international-ai-for-humanity-project-avoid-the-devaluation-of-human-knowledge-and-experience-and-consequent-job-losses" class="level5">
<h5 class="anchored" data-anchor-id="how-will-an-international-ai-for-humanity-project-avoid-the-devaluation-of-human-knowledge-and-experience-and-consequent-job-losses">How will an international ‘AI for humanity’ project avoid the devaluation of human knowledge and experience, and consequent job losses?</h5>
<p>It may not be possible to avoid this. But governments will at least be able to mitigate societal disruption if they can redistribute some of the wealth gained via AI (e.g., via universal basic income). They will not be able to do this if all of the wealth accrues to only one or two technology companies based in Silicon Valley.</p>
</section>
<section id="how-about-existential-risk" class="level5">
<h5 class="anchored" data-anchor-id="how-about-existential-risk">How about existential risk?</h5>
<p>‘Existential risk’ is a science fiction smokescreen generated by large tech companies to distract from the real issues. I cannot think of a better response than the words of Prof <a href="https://www.independent.co.uk/tech/rishi-sunak-university-of-oxford-san-francisco-government-people-b2349105.html">Sandra Wachter</a> at the University of Oxford: “Let’s focus on people’s jobs being replaced. These things are being completely sidelined by the Terminator scenario.”</p>
<div class="callout callout-style-simple callout-note">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-body-container">
<p>Martin Goodson will be speaking live at the Royal Statistical Society on October 31, 2023, as part of a panel discussion on “Evaluating artificial intelligence: How data science and statistics can make sense of AI models.” <a href="https://rss.org.uk/training-events/events/events-2023/rss-events/evaluating-artificial-intelligence-how-data-scienc/#fulleventinfo">Register now</a> for this free in-person debate. The event forms part of the <a href="https://aifringe.org/">AI Fringe</a> programme of activities, which runs alongside the UK Government’s <a href="https://www.gov.uk/government/topical-events/ai-safety-summit-2023">AI Safety Summit</a> (1–2 November).</p>
</div>
</div>
</div>
<div class="article-btn">
<p><a href="../../../../../viewpoints/index.html">Discover more Viewpoints</a></p>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-12">
<dl>
<dt>About the author</dt>
<dd>
<strong>Martin Goodson</strong> is the former chair of the <a href="https://rss.org.uk/membership/rss-groups-and-committees/sections/data-science-section/">RSS Data Science and AI Section</a> (2019–2022). He is the organiser of the <a href="https://www.meetup.com/london-machine-learning-meetup/">London Machine Learning Meetup</a>, the largest network of AI practitioners in Europe, with over 11,000 members. He is also the CEO of AI startup, <a href="https://www.evolution.ai/">Evolution AI</a>.
</dd>
</dl>
</div>
<div class="g-col-12 g-col-md-12">
<dl>
<dt>Copyright and licence</dt>
<dd>
© 2023 Martin Goodson
</dd>
</dl>
<p>Thumbnail image by <a href="https://unsplash.com/@etiennegirardet?utm_content=creditCopyText&amp;utm_medium=referral&amp;utm_source=unsplash">Etienne Girardet</a> on <a href="https://unsplash.com/photos/a-red-wall-with-a-white-sticker-on-it-_HO6LmpGDl8?utm_content=creditCopyText&amp;utm_medium=referral&amp;utm_source=unsplash">Unsplash</a>.</p>
</div>
</div>
</div>


</section>
</section>

 ]]></description>
  <category>AI</category>
  <category>Open source</category>
  <guid>https://realworlddatascience.net/viewpoints/posts/2023/10/20/ai-for-humanity.html</guid>
  <pubDate>Fri, 20 Oct 2023 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/viewpoints/posts/2023/10/20/images/etienne-girardet-_HO6LmpGDl8-unsplash.png" medium="image" type="image/png" height="105" width="144"/>
</item>
<item>
  <title>‘Feelings about sharing data can be context and time dependent – you can’t just do one survey or focus group’</title>
  <dc:creator>Brian Tarran</dc:creator>
  <link>https://realworlddatascience.net/viewpoints/interviews/posts/2023/10/16/data-sharing-in-gov.html</link>
  <description><![CDATA[ 




<p>This summer, the UK Office for Statistics Regulation (OSR) published its report on <a href="https://osr.statisticsauthority.gov.uk/publication/data-sharing-and-linkage-for-the-public-good/">Data Sharing and Linkage for the Public Good</a>. In the report, the OSR notes that the value of sharing and linking data has become widely recognised within government, though there remain areas of challenge and uncertainties about “the public’s attitude to, and confidence in, data sharing.”</p>
<p>The report also warns that “unless significant changes are implemented… progress that has been made could be lost and the potential for data sharing and linkage to deliver public good will not be achieved.”</p>
<p>To find out more about the report and its recommendations for change, we sat down with Helen Miller-Bakewell, OSR’s head of development and impact. Listen to the full interview below or on YouTube.</p>
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/72eqvS34n7c?si=tzoiivVk-m4su1aT" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<section id="transcript" class="level2">
<h2 class="anchored" data-anchor-id="transcript">Transcript</h2>
<div class="callout callout-style-simple callout-warning" style="margin-top: 0.75rem;">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-body-container">
<p>This transcript has been produced using <a href="https://otter.ai/">speech-to-text transcription software</a>. It has been only lightly edited to correct mistranscriptions and remove some repetitions.</p>
</div>
</div>
</div>
<p><strong>Brian Tarran</strong><br>
Hello, I’m Brian Tarran, editor of realworlddatascience.net. And welcome to another Real World Data Science interview. Today I’m speaking with Helen Miller-Bakewell of the Office for Statistics Regulation. And we’re talking about the Office’s July 2023 report, Data Sharing and Linkage for the Public Good. In this report, the OSR reviews progress that has been made towards sharing and linking data for the public good. It says that the value of sharing and linking data has become widely recognised within government, though there remain areas of challenge and uncertainties about, quote, the public’s attitude to and confidence in data sharing. The report warns that quote, unless significant changes are implemented, the OSR is concerned that progress that has been made could be lost and the potential for data sharing and linkage to deliver public good will not be achieved. In my interview with Helen, we talk about some of the key highlights and findings of the report some of its main recommendations, some examples of data sharing and linkage that are going on now within government. So let’s hand over now to Helen, who will begin by introducing herself, her role within OSR and some of the background to the report.</p>
<p><strong>Helen Miller-Bakewell</strong><br>
So I’m Helen, Helen Miller-Bakewell, I have an official title of head of development and impact within OSR. OSR as a whole, our kind of formal job is to regulate statistics produced by government, we are the regulatory arm of the UK Statistics Authority. And our aim is to work towards statistics that serves the public good, and a government that produces and uses statistics analysis in a way that means the public can feel confident in them, and the analysis that that’s done and how they’re used. Within OSR, I used to be a regulator of statistics, I was out there looking at official statistics on crime and security, holding them up against our code of practice for statistics, which sets the standards that we would like to see government statistics meet. In my role now I actually oversee a few of our cross organisation functions, that all are designed to try and improve the way that OSR as a whole works, and to do work that can support the statistical system as a whole. And the most relevant one for today is the data and methods function. And a key piece of work that that function has been working on for the last year is looking at how data sharing and linkage is done across government, and that supports one of OSR’s wider interests and ambitions. One of our ambitions for the current five years is to make greater data available in a secure way for research and evaluation. That’s what this report that we’re going to be talking about has contributed to.</p>
<p><strong>Brian Tarran</strong><br>
Before we get stuck into the report, maybe it’s worth setting out what does OSR mean when it’s talking about data sharing and linkage? What’s the driver for this being a kind of a priority, something that OSR wants to encourage and to see happen? What are the public benefits that you hope to accrue from it?</p>
<p><strong>Helen Miller-Bakewell</strong><br>
The general premise that’s underpinned the report, and the reason that we have been a champion and advocate for date sharing and linkage for a while, is that we think data can be more powerful when it’s linked, and when it’s made accessible, in a secure way, to a wider audience for analysis. And it can offer more insights and better fulfil its potential to serve the public goods. And again, I keep saying serve the public goods. Within OSR, we very much think that statistics analysis, it shouldn’t just be for government, for decision makers in government, it should be available to the public, to all stakeholders, really, who wants to use it to make decisions hold government to account.</p>
<p><strong>Brian Tarran</strong><br>
So for people reading this or listening to this, who haven’t yet had a chance to dig into the report – and it’s very interesting report – what are the key messages that you want to share with people? What is the, I guess, what’s the assessment of the current state of data sharing and linkage?</p>
<p><strong>Helen Miller-Bakewell</strong><br>
I think some of the key messages do echo what other reports have said in this space, which is that there really has been some excellent progress in terms of data sharing and data linkage. We last reported on data sharing and linkage back in 2018 and 2019, when the DA was kind of coming into force and things were starting to move slowly.</p>
<p><strong>Brian Tarran</strong><br>
Sorry to interrupt you. But what is the DEA did you say?</p>
<p><strong>Helen Miller-Bakewell</strong><br>
It’s the Digital Economy Act. So there was some amendments to the DEA, it created new, new powers to enable greater sharing of data for research and statistics, and it put the Office for National Statistics at the centre of those powers. It kind of gave ONS greater powers to ask other departments across the government to share data with them for research and statistical purposes. And the UK Statistics Authority as well have powers to accredit researcher and accredit processing environments so that people can have access to more data as well across governments.</p>
<p><strong>Brian Tarran</strong><br>
So your last report was in 2018, 2019 time. There’s been good progress, you say, since then. I wanted to ask you about some good examples of data linkage that you’ve seen in that time. Maybe the obvious one is Covid, I’m guessing. The pandemic, that offered a lot of opportunities for linking different datasets together. But are there– is that it? Or are there others that you want to highlight?</p>
<p><strong>Helen Miller-Bakewell</strong><br>
I think the pandemic definitely provided a really strong impetus to share data, to link data. And I think, you know, we saw things done which hadn’t been possible previously, it broke down barriers, and was a kind of an excellent enabler, which is fantastic, because it was a crisis situation. And actually, yes, one of the examples that I would highlight, and I know others in OSR would highlight that was doing Covid, was Office for National Statistics estimates of Covid-19 mortality rates among different ethnic groups, and that drew on census data, it drew on death registration data at your on hospital episode statistics, it drew on data from lots of different places to create some really, really important analysis. It’s exciting to be able to say now that there are good examples of data sharing and linkage across different topic areas and different organisations. And I think if you spoke to regulators in OSR working in different domains, they will each have like their favourite examples of, of data sharing and linkage. Having worked in crime and security regulation myself, the one that comes straight to mind is Data First, which is data linkage project led by Ministry of Justice, working with ADR UK – another one, I don’t have to say full often, Administrative Data Research UK – and that’s done a fantastic job of kind of opening up access again, in a secure way, a real focus on security, to a wealth of data from across MOJ systems, sometimes horrible, clunky legacy systems – I hope none won’t be offended if I say that – but making it valuable because people can, you know, to a greater extent now link it and link it to data from other departments as well.</p>
<p>I did ask a couple of colleagues if they wanted to throw me any other examples of data sharing and linkage that they particularly think highly of, and another one that came up was the Registration and Population Interaction Database, RAPID database, which has been created by DWP [Department for Work and Pensions]. And that provides that brings together data, information from DWP, HMRC [His Majesty’s Revenue &amp; Customs] and local authorities to try and give a view of citizens’ interactions across the breadth of DWP services. What the report does say is, although we have these good examples, there are still barriers and challenges to doing data sharing and linkage. And that, that can, can be true across the whole process, right from getting support for the idea, through the practical steps of finding out what data is available, where, who owns it, how you can get to it, and then actually doing the linkage bit technically at the end. So we’ve been in a situation where things definitely have improved. But it’s, in many cases, it is not easy or efficient yet to share or link data. Our report talks about different barriers we heard about during the course of interviews with stakeholders, that we’ve encountered through our regulatory work as well. And we make 16 – to be precise – recommendations for how we could, or how government could, could start to chip away at those to, to improve the situation going forward.</p>
<p><strong>Brian Tarran</strong><br>
Yeah, and I would like to talk about some of those recommendations, I guess the more technical side of the recommendations, a bit, a bit later. One thing I wanted to ask you now about was about a word that sort of jumped out at me in, in the report was this idea of needing there to be a social licence for data sharing. And in the report, social licence has, has been defined as the, like, the level of acceptance or approval in local communities for data linkage projects. Now, I guess for something like the pandemic, right, you can argue that there is a kind of an implicit social licence, it was an emergency situation, there was, you know, people at risk. So that sort of use case was kind of justified, but I was curious about how social licences for these things can best be established and, and maintained, because that’s about kind of interaction with the public, right? You know, you could put a load of government statisticians and data scientists into a room and say, what could you do with this, all this data and how you could, could you link it all together? And they’d get very excited about it? But actually, then, how do you then take that to the public and convince them that it’s a good idea, or are there other ways of making sure this social licence has been obtained?</p>
<p><strong>Helen Miller-Bakewell</strong><br>
So, social licence and public engagement were one of the topics that was good, most consistently mentioned across the interview– interviews we held. And yeah, there just seemed to be a consensus which we would support that those working on data sharing and linkage should be prioritising public engagement around their work, both to kind of gauge the amount of social licence that there might be, or any sticking points, and potentially start to build social licence as well. And I think, you know, it’s really great to see people thinking like that, and I would actually say as well, it seems to be a recurring theme. And it’s really nice to see that having prominence. Another finding from the interviews was, you know, the flip side of this, yes, people think it’s important, but often people can not quite know how to approach public engagement, building social licence. And there are actually a few examples we highlight in the report where we, where we think public engagement has been done, done well, hopefully, to kind of inspire people. I would say, you know, I have a few kind of overarching thoughts on what can be important. And I think it, it comes so much to trust and trustworthiness. And I think the way, some ways that you can support trust with the public are transparency, saying what you’re going to do and why, and how, and actually the outcomes as well, when possible, let’s sit closing the circle. Thinking about this interview, I remembered OSR ran a public dialogue last year with ADR UK. And we were trying to talk to members of the public about what they understand by the public good of statistics and data. And one of the messages that came up there was people want to feel the impact their data and feel that outcome. And they don’t always feel they get that knowledge back. Like, what, what was, so what was the outcome of you having my data and doing these things that you kind of said you would do? So yeah, transparency, and then kind of linked to that, I guess, like continuous engagement, and considered engagement. And the public is not a homogenous group, there will be different groups that are important to engage for different data sharing, different data linkage projects, and you kind of need to consider who are the people you need to really engage with for your specific initiatives. And then it’s, I’m afraid you can’t just do one survey or one focus group, there needs to be some kind of mechanism for getting more continuous engagement to keep an eye on actually, how are people feeling now, because we know that social licence and people’s feelings about sharing data, it can be context dependent, it can be time dependent. And actually the first couple of recommendations in the report, so right there at one and two, number one is about the value of trackers like CDEI’s [Centre for Data Ethics and Innovation] Public Attitudes Survey, which, you know, are run on a semi-regular basis to try and track how the public are feeling at a high level about questions around data. And then our second recommendation is about having an organisation that can do more to produce guidance and support people doing research to do public engagement well.</p>
<p><strong>Brian Tarran</strong><br>
Does the mission statement of statistics for the public good, does that kind of help guide the approach, right? So any data linkage, data sharing project, you need to understand, you need to think about okay, what’s the public good that we’re trying to achieve here? And then that becomes your, almost the point, the focal point of the discussion with the public about why we want to do this and why we think there’ll be a benefit.</p>
<p><strong>Helen Miller-Bakewell</strong><br>
Absolutely. This focus on the public good is what we always come back to in, in OSR. And again, it is something that can sometimes slightly differentiate us from other organisations in this space where there may be a very internal government focus. Yeah, absolutely. What’s the outcome that’s seeking to be achieved? And will we achieve it? Did we achieve it?</p>
<p><strong>Brian Tarran</strong><br>
One of the parts of the report that I was quite interested in was the four future scenarios. The task you set yourself was to look five years from, from now at where we might be, and I guess give a range of, like, scenarios in which data linkage is great, and everyone’s doing it and it’s fully supported, down to it’s, you know, it’s happening on a piecemeal basis or not at all. So what I wanted to understand was, how those scena– whether any of those scenarios are more likely than others to emerge, and whether the kind of likelihood of those scenarios emerging are dependent on certain of your recommendations.</p>
<p><strong>Helen Miller-Bakewell</strong><br>
The scenarios just allowed us to explore in a theoretical way, like, yeah, where, where could we end up? We hope the 16 recommendations we’ve made, taken together, if they could all be fully delivered, could lead us towards that ultimate scenario of data sharing and linkage for the public good. And you can put quite neatly different recommendations against different bits of that scenario to help get, get us there. I think if, if I reflect on the scenarios like right now, the one that feels like most familiar to me is data sharing and linkage in silos. We’ve kind of spoken a little bit earlier already about how there are some areas of government and some topic areas and some organisations that are doing some really brilliant work. And I could see quite a realistic scenario where that kind of becomes more entrenched over, over the next five years. But, you know, maybe that’s actually just realistic, right? Maybe it’s unrealistic to expect that every organisation [in] government with different, different sizes, different funding, different priorities, could, could end up in exactly the same place on date sharing and linkage, all at the kind of, the top level. But I do, I do think if we can chip away at the recommendations we’ve made, then every organisation could improve on their starting point and move towards that, that scenario.</p>
<p><strong>Brian Tarran</strong><br>
Okay, so let’s talk about some of the recommendations of how we get there. And there were a couple of areas I particularly wanted to focus on. One was talking about career frameworks, and having those kind of reflect, and I guess, reward the skills of those who are working on data and data linkage projects. So I was kind of wondering, you know, are there, are these skills that are kind of currently either underserved or under recognised within the existing career frameworks? And if so, how do we change that? Or was that is that beyond the scope of your report to recommend that?</p>
<p><strong>Helen Miller-Bakewell</strong><br>
I think the situation across government is perhaps relatively complicated here. And I think what we, what we’d really like to see, essentially, is a situation where people in roles, in data roles, basically feel valued, and they can see a clear career pathway for them within government. And I think what we have at the moment is a variety of career frameworks that support people working in in roles with data and a decentralised pay model. Which means pay scales across, across roles can, can – and frameworks – can vary. You can see intuitively, how that has the potential to kind of create confusion for individuals – like well, which career framework should I look at – and, and then on the pay side, the potential to create kind of skills sink, where people want to go and work particular areas simply because they can be paid more, and in some cases it’s a considerable amount more, actually. And the reason I say it’s complicated is because, I mean, to some extent, this, what we have, is appropriate. People who work on data and sharing and linkage projects can come from lots of different analytical backgrounds – like, you could have a statistician or a social researcher or a data scientist or data architect, they could all be working on a, on a data sharing project, shall we say. And actually, it kind of makes sense that people in those kind of different roles might have different career frameworks and paths. And similarly, as I say, pay is decentralised, I don’t think OSR has much power to change too much there. But, you can see there are arguments for departments being able to have their own say on what skills they need to kind of pay more for in different circumstances at different times to, to bolster things. However, what we have said in the report, what we call for, and what we will try and speak to people who own frameworks to try and facilitate, is just a bit more awareness between people who own different frameworks about what else is out there, and a bit more consistency, therefore, about how different data skills perhaps are reflected and where they’re reflected in different frameworks. So we’re not asking for one single framework, I don’t think that would be practical, or particularly serve people working in data very well. But yeah, like more awareness, better joined up working, more consistent use of frameworks in, in job adverts, for example, just to help people see more clarity about their careers and where they can take them.</p>
<p><strong>Brian Tarran</strong><br>
I was at an event recently where, you know, people working in, in data science or data, data kind of roles in government, were talking about how, like, the sort of career pathways and that there’s a feeling that technical skills, or growing technical skills aren’t always as well rewarded as greater sort of managerial responsibilities, so that if you become a, someone who’s excellent at being able to solve the, the knotty problems of data linkage and sharing, right, you might not be as well compensated for that as you might be if you were, say, running a team of 20, 30 people and sort of not actually applying those technical skills on a day-to-day basis. So it’s, I guess that was where my question was coming from was, is it that sort of thing that we kind of need to, need to address in some way? But, again, that might be beyond the scope of, you know, what you were looking at it on this particular matter?</p>
<p><strong>Helen Miller-Bakewell</strong><br>
Well, I think it’s something for us to think more about, if I’m honest. We have committed ourselves to a follow on report for this. And we want to kind of take a look at the recommendations next year and see, you know, how far everything’s got. So, you know, any, any additional bits that we haven’t covered in this first report are good for us to think about. I think the situation you’ve just outlined sounds very familiar, to be honest, and not just across data science, across a whole load of roles where, yeah, actually your technical skills, they take you really well to middle management, but then there often comes a point where, if you want to go higher and have greater remuneration, you might have to move more to those softer skills, those managerial skills. That’s something we can think a bit more about, actually. And when we do have conversations with those who we kind of pointed to for the frameworks recommendation, maybe have a look into it a bit more.</p>
<p><strong>Brian Tarran</strong><br>
This is, I guess, some somewhat related to the previous point. But the other aspect of the recommendations that jumped out to me were the discussion around quality metadata and documentation, standardisation and things like that as being priorities for effective data linkage, these are the things that need to be in place. But again, when you chat to researchers, not just in government but all over the place, these less glamorous aspects of data management are kind of underappreciated. And often teams are, the way that, the way teams work, the way projects work is you finish one, you move on to the next, you don’t really want to think too much about the one that you just worked on, because you’ve got a new priority or a new round of funding or whatever it is. So how do we convince senior leaders that, that there are sufficient resources for this sort of work that needs to be done? It might not sort of deliver necessarily immediate value and benefits, but it’s about kind of accruing the kind of infrastructure, I guess, to, to make sure that data sharing and linkage, you can achieve your, you know, your most optimistic vision of data sharing and linkage being widespread in government.</p>
<p><strong>Helen Miller-Bakewell</strong><br>
Yeah, I think it’s a really important question. And yeah, having worked as a statistician as well, before I came into this world of regulation, yep, I recognise what you just described. And, you know, I think it’s always going to be a challenge in these kind of fast-paced multiple priority environments, where often people are resource stretched in terms of people, time, money, all those things together. Though, I think there’s a couple of tacks. One, I think, is maybe improving the data literacy of senior leaders, and trying to give them a greater understanding of, of data, how it’s used, and around these issues of kind of standardisation, and why they’re why they’re so important. And, actually, a couple of the recommendations earlier on in the report, in the people section, are around improving the– or strengthening the statistical literacy and the data literacy of senior leaders and recommending they go on, for example, the Data Science Campus in ONS run a master class for senior leaders across the service. So I think there was a kind of a bit of a, an education thing. And yeah, I guess, you know, part of that is setting out, like, what are the benefits? And what are the risks of not doing this? I think that, you know, here comes a role for people like OSR in setting expectations, especially in the world of official statistics, it is completely within our power to set the expectation for what government statistics should be doing with regards to metadata, or kind of following, following best practice and things like that. Our code of practice for statistics does do that to some extent already. And us as well, there’s a role for us in demonstrating the benefits and saying why we’re asking people to do these things and, and what’s good when it, when it goes well. I was thinking about this, and it drew to mind the EAST Framework. I don’t know if you’ve come across that. It’s a framework that was introduced to me by the Behavioural Insights Team for bringing about change and what you– what interventions need to be if they’re going to be successful, and it’s Easy, Attractive, Social and Timely. And I think when we and when other organisations who are kind of working on metadata standardisation, like the Central Digital Data Office, like Department for Science, Innovation and Technology, there’s, you know, there’s a few players here. We need to be keeping these, the EAST in mind as we design to try and help people kind of come on board with things more easily. And yeah, recommendation 16 in the report, the final one, is about standardisation and about, there are lots of players in this space and can we, can we bring them together a bit to be even more effective? So that’s, that’s definitely something we’ll be looking at in the coming months.</p>
<p><strong>Brian Tarran</strong><br>
And you said that there’ll be a follow up report soon. When is that? When are you targeting?</p>
<p><strong>Helen Miller-Bakewell</strong><br>
We’re planning next summer. So last time when we did our first report on Joined-up Data in 2018. And then we did a follow on one year on in 2019. We found that was quite an effective way to, for us and others, to kind of build and maintain momentum. And yeah, again, you know, feels a bit unfair almost to just put out a load of recommendations, and then then leave, leave the world to it. We’d like to see if we can help facilitate and then tell people how we’ve been getting on.</p>
<p><strong>Brian Tarran</strong><br>
And I’m guessing it’s not, you’re not looking for all recommend– 16 recommendations to be implemented by next year. But it’s, are we making steps towards some of them? Are we are we heading in the right direction?</p>
<p><strong>Helen Miller-Bakewell</strong><br>
You know, let’s practice what we preach. A bit of transparency. Yeah, are we heading in the right direction? And if we’re not, you know, is there a plan? I’d love to be optimistic. That optimistic. I wouldn’t expect that we can just put ticks against all 16 recommendations next year. But hopefully, yeah, we can, we could do some progress bars.</p>
<p><strong>Brian Tarran</strong><br>
Excellent. Well, we should probably schedule a follow up interview for a year’s time then. But Helen, thank you very much for your time today.</p>
<p><strong>Helen Miller-Bakewell</strong><br>
Oh, you’re very welcome. And if anyone, any of your listeners interested in, in the report, please do get in touch with OSR. We’d be very happy to talk about the report that we’ve just written or about, you know what we’re doing. Following on from that? Yeah, thank you.</p>
<p><strong>Brian Tarran</strong><br>
So we’ll definitely put a link to the report in the show notes. So once again, Helen, thank you very much for joining us.</p>
<p><strong>Helen Miller-Bakewell</strong><br>
Oh, you’re welcome. Thank you.</p>
<div class="article-btn">
<p><a href="../../../../../../viewpoints/interviews/index.html">Find more Interviews</a></p>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-6">
<dl>
<dt>Copyright and licence</dt>
<dd>
© 2023 Royal Statistical Society
</dd>
</dl>
<p><a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> <img src="https://realworlddatascience.net/viewpoints/interviews/posts/2023/10/16/https:/mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1" style="height:22px!important;vertical-align:text-bottom;"><img src="https://realworlddatascience.net/viewpoints/interviews/posts/2023/10/16/https:/mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1" style="height:22px!important;margin-left:3px;vertical-align:text-bottom;"></a> This interview is licensed under a Creative Commons Attribution 4.0 (CC BY 4.0) <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> International licence</a>.</p>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>How to cite</dt>
<dd>
Tarran, Brian. 2023. “‘Feelings about sharing data can be context and time dependent – you can’t just do one survey or focus group.’” Real World Data Science, October 16, 2023. <a href="https://realworlddatascience.net/viewpoints/interviews/posts/2023/10/16/data-sharing-in-gov.html">URL</a>
</dd>
</dl>
</div>
</div>
</div>


</section>

 ]]></description>
  <category>Data sharing</category>
  <category>Data linkage</category>
  <category>Public engagement</category>
  <guid>https://realworlddatascience.net/viewpoints/interviews/posts/2023/10/16/data-sharing-in-gov.html</guid>
  <pubDate>Mon, 16 Oct 2023 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/viewpoints/interviews/posts/2023/10/16/images/helen-miller-bakewell.png" medium="image" type="image/png" height="105" width="144"/>
</item>
<item>
  <title>Join Real World Data Science at three events this October!</title>
  <dc:creator>Brian Tarran</dc:creator>
  <link>https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/10/10/october-events.html</link>
  <description><![CDATA[ 




<p>Summer 2023 for us was a blur of excellent data science and statistics events. There was the <a href="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/08/06/jsm-blog.html">Joint Statistical Meetings in Toronto</a>, the <a href="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/08/24/rss-conference.html">Royal Statistical Society Conference in Harrogate</a>, and <a href="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/09/19/positconf-blog.html">posit::conf(2023) in Chicago</a>. But if that wasn’t enough, autumn promises more good stuff, and more opportunities to meet with Real World Data Science in person and online.</p>
<section id="an-introduction-to-real-world-data-science" class="level3">
<h3 class="anchored" data-anchor-id="an-introduction-to-real-world-data-science">An introduction to Real World Data Science</h3>
<p><strong>Date:</strong> Monday, October 16, 2023 <strong>Time:</strong> 12 pm – 1 pm <strong>Location:</strong> Online</p>
<p>Next week is Members’ Week at the Royal Statistical Society (RSS), and the RSS calendar is full of events targeted at members – prospective members, new members, and established members. Kicking things off on Monday lunchtime is <a href="https://rss.org.uk/training-events/events/events-2023/rss-events/the-real-world-data-science/">an online event to introduce Real World Data Science</a>. We’ll discuss the aims of this project, our guiding ethos and content plans, and we’ll explain the various ways in which people can contribute to the site.</p>
<p>Chances are, if you’re reading this blog, you won’t need much of an introduction to Real World Data Science. But do please help spread the word to potential new readers, and encourage them to <a href="https://rss.org.uk/training-events/events/events-2023/rss-events/the-real-world-data-science/">register for this free event</a>.</p>
</section>
<section id="nhs-r-community-annual-conference" class="level3">
<h3 class="anchored" data-anchor-id="nhs-r-community-annual-conference">NHS-R Community Annual Conference</h3>
<p><strong>Date:</strong> Tuesday, October 17, 2023 <strong>Time:</strong> 9:30 am – 10:00 am <strong>Location:</strong> Edgbaston Stadium, Birmingham (in person) and online</p>
<p>It’s a real honour for us to be invited to give a keynote talk at <a href="https://nhsrcommunity.com/events/nhs-r-community-conference-2023-ticket-for-in-person-attendance-on-tuesday-17th-october-2023/">this annual gathering of the NHS-R Community</a>, a group dedicated to promoting the use of R in the National Health Service. Our talk is titled, “Forging community links: NHS-R, the Royal Statistical Society and Real World Data Science,” and we’ll explain how the Real World Data Science project came about, how we embraced open-source tools and the idea of collaborative content development, and why there’s so much to be gained from sharing data science case studies across domains.</p>
</section>
<section id="evaluating-artificial-intelligence-how-data-science-and-statistics-can-make-sense-of-ai-models" class="level3">
<h3 class="anchored" data-anchor-id="evaluating-artificial-intelligence-how-data-science-and-statistics-can-make-sense-of-ai-models">Evaluating artificial intelligence: How data science and statistics can make sense of AI models</h3>
<p><strong>Date:</strong> Tuesday, October 31, 2023 <strong>Time:</strong> 4 pm – 6 pm <strong>Location:</strong> RSS, London (in person only)</p>
<p>Real World Data Science has partnered with colleagues and volunteers across the RSS to organise another <a href="https://rss.org.uk/training-events/events/events-2023/rss-events/evaluating-artificial-intelligence-how-data-scienc/#fulleventinfo">AI panel debate</a>, following up on the AI discussion at the <a href="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/08/24/rss-conference.html">RSS Annual Conference</a>.</p>
<p>This event forms part of the <a href="https://aifringe.org/">AI Fringe programme of events</a>, which coincides with <a href="https://www.gov.uk/government/publications/ai-safety-summit-introduction">the UK government’s AI Safety Summit on 1–2 November</a>.</p>
<p>Our free event focuses on big questions around AI model evaluation, which will also be a key topic of discussion at the summit. One of the government’s stated objectives is for the summit to identify “areas for potential collaboration on AI safety research, including evaluating model capabilities and the development of new standards to support governance,” and so we’ll be asking:</p>
<ul>
<li>What should AI evaluation look like?</li>
<li>How will it work in practice?</li>
<li>What metrics are most important?</li>
<li>Who gets to decide all of this?</li>
</ul>
<p><a href="https://rss.org.uk/training-events/events/events-2023/rss-events/evaluating-artificial-intelligence-how-data-scienc/#fulleventinfo">Register via the RSS website</a> to attend this free in-person event, chaired by RSS president Andy Garrett. Panellists will be announced soon, so stay tuned!</p>
<div class="article-btn">
<p><a href="../../../../../../viewpoints/editors-blog/index.html">Back to Editors’ blog</a></p>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-6">
<dl>
<dt>Copyright and licence</dt>
<dd>
© 2023 Royal Statistical Society
</dd>
</dl>
<p><a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> <img style="height:22px!important;vertical-align:text-bottom;" src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/10/10/https:/mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/10/10/https:/mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"></a> This article is licensed under a Creative Commons Attribution 4.0 (CC BY 4.0) <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> International licence</a>.</p>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>How to cite</dt>
<dd>
Tarran, Brian. 2023. “Join Real World Data Science at three events this October!” Real World Data Science, October 10, 2023. <a href="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/10/10/october-events.html">URL</a>
</dd>
</dl>
</div>
</div>
</div>


</section>

 ]]></description>
  <category>AI</category>
  <category>Large language models</category>
  <category>Communities</category>
  <category>Events</category>
  <category>Updates</category>
  <guid>https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/10/10/october-events.html</guid>
  <pubDate>Tue, 10 Oct 2023 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/10/10/images/oct-events.png" medium="image" type="image/png" height="105" width="144"/>
</item>
<item>
  <title>American Statistical Association joins Real World Data Science as partner</title>
  <dc:creator>Brian Tarran</dc:creator>
  <link>https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/10/02/asa-partner.html</link>
  <description><![CDATA[ 




<p>The first version of Real World Data Science was launched almost one year ago by the <a href="https://rss.org.uk/">Royal Statistical Society</a> (RSS). As we approach our first birthday, we’re delighted to announce that the <a href="https://www.amstat.org/">American Statistical Association</a> (ASA) has become a partner in this project.</p>
<p>ASA shares our goal of developing Real World Data Science as a free and beneficial resource for the entire data science community – one that informs, inspires and strengthens the community by bringing together students, practitioners, leaders, and educators to share knowledge about real-world applications of data science.</p>
<p>The data science profession is geographically and academically diverse. We believe that Real World Data Science can best achieve its goal of being a trusted, go-to resource for all data scientists if a range of partner organisations work together to develop the site and its content, so we’re thrilled that ASA is taking the first step with us towards fulfilling this vision.</p>
<p>Ron Wasserstein, executive director of the American Statistical Association, shared: “We are delighted to be partnering with RSS on Real World Data Science. This is important for our community and serves to further strengthen our valuable relationship with RSS.”</p>
<p>Sarah Cumbers, chief executive of the Royal Statistical Society, commented: “We’re thrilled to have ASA on board as a partner for Real World Data Science. We have big plans for the project and this partnership will help us achieve these by allowing us to reach more of the data science community and strengthen our content offering.”</p>
<p>As part of this new partnership with ASA, we will shortly welcome two ASA members to our <a href="https://realworlddatascience.net/viewpoints/editors-blog/posts/2022/10/18/meet-the-team.html">editorial board</a>. So, on behalf of the entire – and soon-to-be expanded – editorial board, we’d like to say a huge thanks to ASA for their support and endorsement of Real World Data Science.</p>
<p>ASA members, groups, and sections interested in contributing to the site are encouraged to review our <a href="https://realworlddatascience.net/contributor-docs/call-for-contributions.html">call for contributions</a> and to <a href="https://realworlddatascience.net/contact.html">contact us</a> via email or our social media channels to discuss content ideas.</p>
<div class="article-btn">
<p><a href="../../../../../../viewpoints/editors-blog/index.html">Back to Editors’ blog</a></p>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-6">
<dl>
<dt>Copyright and licence</dt>
<dd>
© 2023 Royal Statistical Society
</dd>
</dl>
<p><a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> <img style="height:22px!important;vertical-align:text-bottom;" src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/10/02/https:/mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/10/02/https:/mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"></a> This article is licensed under a Creative Commons Attribution 4.0 (CC BY 4.0) <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> International licence</a>.</p>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>How to cite</dt>
<dd>
Tarran, Brian. 2023. “American Statistical Association joins Real World Data Science as partner.” Real World Data Science, October 2, 2023. <a href="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/10/02/asa-partner.html">URL</a>
</dd>
</dl>
</div>
</div>
</div>



 ]]></description>
  <category>News</category>
  <category>Updates</category>
  <category>Call for contributions</category>
  <guid>https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/10/02/asa-partner.html</guid>
  <pubDate>Mon, 02 Oct 2023 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/10/02/images/laptop-connect.png" medium="image" type="image/png" height="105" width="144"/>
</item>
<item>
  <title>Live from Chicago: Real World Data Science at posit::conf(2023)</title>
  <dc:creator>Brian Tarran</dc:creator>
  <link>https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/09/19/positconf-blog.html</link>
  <description><![CDATA[ 
<script src="https://cdn.jsdelivr.net/npm/monaco-editor@0.43.0/min/vs/loader.js"></script>
<script type="module" id="webr-monaco-editor-init">

  // Configure the Monaco Editor's loader
  require.config({
    paths: {
      'vs': 'https://cdn.jsdelivr.net/npm/monaco-editor@0.43.0/min/vs'
    }
  });
</script>




<div class="callout callout-style-simple callout-note" style="margin-top:0">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-body-container">
<p>posit::conf(2023) is over, but this blog remains open for contributions. If you want to share personal highlights or reflections on your time at conference: 1. Fork <a href="https://github.com/realworlddatascience/realworlddatascience.github.io">our repo</a>, 2. update <a href="https://github.com/realworlddatascience/realworlddatascience.github.io/blob/positconf-blog/viewpoints/editors-blog/posts/2023/09/19/positconf-blog.qmd">this file</a> in the <code>positconf-blog</code> branch (or create a new branch of your own), and 3. make a pull request! You can also <a href="https://realworlddatascience.net/contact.html">email contributions</a>.</p>
</div>
</div>
</div>
<section id="tuesday-september-19" class="level2">
<h2 class="anchored" data-anchor-id="tuesday-september-19">Tuesday, September 19</h2>
<section id="from-data-confusion-to-data-intelligence" class="level3">
<h3 class="anchored" data-anchor-id="from-data-confusion-to-data-intelligence">From data confusion to data intelligence</h3>
<p>An inspiring start to posit::conf(2023) this morning, with keynote talks from Elaine McVey, senior director of analytics at Chief, and David Meza, head of analytics for human capital at NASA, sharing stories and insights on how to build strong data science foundations in organisations.</p>
<p>McVey spoke about the frequent mismatch between high levels of hope for what data science can achieve within organisations, and low levels of understanding about how to set up data science teams for success. The best chance for success, she said, is if data scientists take the lead in helping organisations learn how to make best use of data science expertise.</p>
<p>From there, McVey went on to present a set of “guerilla data science tactics” that data scientists can use to get around any obstacles they may encounter, as illustrated in the slide below:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/09/19/images/mcvey-slide.png" class="img-fluid figure-img" alt="Elaine McVey's 'guerilla data science tactics' for building successful data science teams. Start by 'scanning for opportunities', then 'show, don't tell', 'take the data and run', 'nail the landing', and 'up the ante'."></p>
<figcaption class="figure-caption">Elaine McVey’s “guerilla data science tactics” for building successful data science teams.</figcaption>
</figure>
</div>
<p>Data scientists should start by scanning for opportunities to help the organisation, before building a small-scale version of what it is they propose to do. Once buy-in is achieved, and data is made available, it’s time to run with the project. Once complete, you need to “nail the landing,” McVey said, and make sure to communicate results broadly – not just to primary stakeholders, but across the organisation. Then comes time to “up the ante”: if your first project has built some organisational goodwill, leverage that and look for something higher risk, with higher potential reward for the organisation.</p>
<p>Throughout this process, McVey said, data scientists should be building foundations for future projects – creating data pipelines, R packages, etc., that can be reused later. This was a point picked up and developed upon by Meza, who walked through in detail the steps required to establish “data foundations” within organisations, drawing on his own past experiences. Typically, he said, organisations seem to collect data just to store it – but always data should be collected, stored, and managed with analysis in mind.</p>
</section>
<section id="a-hackers-guide-to-open-source-llms" class="level3">
<h3 class="anchored" data-anchor-id="a-hackers-guide-to-open-source-llms">A hacker’s guide to open source LLMs</h3>
<p>Fast.ai’s Jeremy Howard lifted the hood on large language models (LLMs) in the second of two keynotes this morning.</p>
<p>Beginning with an accessible overview of what LLMs are, how they work, and how they are trained, Howard then addressed some of the criticisms made of LLMs – that they “can’t reason” or give correct answers.</p>
<p>As Howard explained, a model like OpenAI’s GPT-4 is not trained at any point to give correct answers to prompts – only to predict the most likely next word, or word token, in a sequence.</p>
<p>The pre-training step, for example, does not involve only feeding the model with “correct answers,” instead relying on a corpus of text from the internet – some (or, maybe, much) of which may consist of factual inaccuracies, errors, falsehoods, etc. And in the fine-tuning stage, when human feedback is used to either reward or penalise model outputs, Howard said there is a preference for confident-sounding responses – and so, again, this doesn’t necessarily reward the model for giving correct answers.</p>
<p>Howard made the case that users have to help language models to give good answers, and that custom instructions can be used to change the way models respond. He then walked delegates through a series of demos using open-source LLMs, to show how outputs can be refined and improved.</p>
<p>“My view is that if you are going to be good at language modelling in any way,” said Howard, “you have to be good at using language models.”</p>
</section>
<section id="documenting-things-openly-for-future-us" class="level3">
<h3 class="anchored" data-anchor-id="documenting-things-openly-for-future-us">Documenting Things: Openly for Future Us</h3>
<p>Julia Stewart Lowndes, founding director of <a href="https://openscapes.org/">Openscapes</a>, gave a compelling talk advocating for the importance of documentation for data science projects.</p>
<p>Documenting things, Lowndes said, should be done for the benefit of “Future Us”: not only ourselves but our teams and our communities who may be contributing to or revisiting the project in the next hours, days, weeks, months and years.</p>
<p>Documenting things does not have to be painful, Lowndes said. In fact, it’s supposed to be helpful. It does, however, take time and intention. And it means slowing down briefly to write things down now, in order that work speeds up in the longer term.</p>
<p>Lowndes then shared some pointers to help people get started with documentation:</p>
<ol type="1">
<li>Have a place to write things down – Google Docs, GitHub, wherever – ideally a place where people can work collaboratively.
<ol type="i">
<li>Develop the habit of writing things down as you go.</li>
<li>Write in a modular way – small bits of text are less daunting and easier to maintain collaboratively.</li>
</ol></li>
<li>Have an audience in mind – you are writing this for someone, so make it engaging for them.
<ol type="i">
<li>write in an inclusive tone.</li>
<li>Narrate code in small chunks, and in a way that you’d say out loud if teaching.</li>
<li>Share, and share early – you want to be able to iterate on your documentation and receive feedback. Also, sharing openly does not always mean publicly – manage permissions as necessary.</li>
</ol></li>
<li>Design for readability and accessibility.
<ol type="i">
<li>Use section headers – particularly important for screen readers, but this also helps generally to describe the flow of a document. Plus, you can link readers directly to specific parts of a document.</li>
<li>Use text formatting.</li>
<li>Use alt-text for images, describing the take-home message of the image.</li>
</ol></li>
</ol>
</section>
<section id="teaching-data-science-in-adverse-circumstances-posit-cloud-and-quarto-to-the-rescue" class="level3">
<h3 class="anchored" data-anchor-id="teaching-data-science-in-adverse-circumstances-posit-cloud-and-quarto-to-the-rescue">Teaching Data Science in Adverse Circumstances: Posit Cloud and Quarto to the Rescue</h3>
<p>Professor Aleksander Dietrichson of the Universidad de San Martin brought a valuable perspective to posit::conf(2023) on the challenges of teaching data science in the face of technology and language barriers.</p>
<p>At the public, state-funded university in Argentina where Dietrichson works, more than half of students do not have access to laptops or computers at home, and those who do have access – whether at home or at school – may not have access to the latest kit. But “<a href="https://posit.cloud/">Posit Cloud</a> solves the resource issue,” Dietrichson said. The free-to-use, online browser-based version of Posit’s tools runs on anything; Dietrichson said he’s tested it successfully on both decade-old computers and cellphones – though he doesn’t recommend using it on a cellphone!</p>
<p>On language barriers, he pointed out that learning to code in R and Python can be challenging when English isn’t your first language – if you don’t have semantic access to function names, for example, there will be a steeper learning curve for students.</p>
<p>Dietrichson also has to deal with the problem of “arithmaphobia” among some of the liberal arts students he teaches. This has necessitated a reshuffling of the typical statistics curriculum, he said, in order to make it easier for students to access. But the work is worth it, Dietrichson explained: many of his students want to work in careers like journalism, and he believes that “journalists should be statistically literate.”</p>
</section>
<section id="dynamic-interactions-empowering-educators-and-researchers-with-interactive-quarto-documents-using-webr" class="level3">
<h3 class="anchored" data-anchor-id="dynamic-interactions-empowering-educators-and-researchers-with-interactive-quarto-documents-using-webr">Dynamic Interactions: Empowering Educators and Researchers with Interactive Quarto Documents Using webR</h3>
<p>Some of my favourite sessions at posit::conf(2023) were about <a href="https://quarto.org/">Quarto</a>. Understandable, really, when you consider that we used it to build this very site! Albert Rapp has described Quarto as a <a href="https://albert-rapp.de/posts/16_html_css_for_r/16_html_css_for_r.html">web dev gateway drug</a>, and I’d agree with him:</p>
<blockquote class="blockquote">
<p>Quarto is a powerful tool for creating beautiful and interactive documents. I think of it as a gateway drug to web development: While it offers a user-friendly interface for creating documents and blogs, it also allows users to delve into the world of HTML &amp; CSS without even realizing it.</p>
</blockquote>
<p>I spoke a bit about my own journey into web dev in one of the Quarto sessions at posit::conf, but what I loved most about these sessions was learning about all the cool new things I’ve yet to discover and try out. For example, <a href="https://thecoatlessprofessor.com/about/">James Balamuta</a>’s talk and demonstration of building interactive code cells into Quarto webpages was an eye-opener!</p>
<p>Since returning from Chicago I’ve tested out this functionality and added Balamuta’s example here. First run the code that’s already in the code block but also edit it to try out your own examples.</p>
<button class="btn btn-default btn-webr" disabled="" type="button" id="webr-run-button-1">Loading
  webR...</button>
<div id="webr-editor-1"></div>
<div id="webr-code-output-1" aria-live="assertive">
  <pre style="visibility: hidden"></pre>
</div>
<script type="module">
  // Retrieve webR code cell information
  const runButton = document.getElementById("webr-run-button-1");
  const outputDiv = document.getElementById("webr-code-output-1");
  const editorDiv = document.getElementById("webr-editor-1");

  // Add a light grey outline around the code editor
  editorDiv.style.border = "1px solid #eee";

  // Load the Monaco Editor and create an instance
  let editor;
  require(['vs/editor/editor.main'], function () {
    editor = monaco.editor.create(editorDiv, {
      value: `fit = lm(mpg ~ am, data = mtcars)
summary(fit)`,
      language: 'r',
      theme: 'vs-light',
      automaticLayout: true,           // TODO: Could be problematic for slide decks
      scrollBeyondLastLine: false,
      minimap: {
        enabled: false
      },
      fontSize: '17.5rem',               // Bootstrap is 1 rem
      renderLineHighlight: "none",     // Disable current line highlighting
      hideCursorInOverviewRuler: true  // Remove cursor indictor in right hand side scroll bar
    });

    // Dynamically modify the height of the editor window if new lines are added.
    let ignoreEvent = false;
    const updateHeight = () => {
      const contentHeight = editor.getContentHeight();
      // We're avoiding a width change
      //editorDiv.style.width = `${width}px`;
      editorDiv.style.height = `${contentHeight}px`;
      try {
        ignoreEvent = true;

        // The key to resizing is this call
        editor.layout();
      } finally {
        ignoreEvent = false;
      }
    };

    // Helper function to check if selected text is empty
    function isEmptyCodeText(selectedCodeText) {
      return (selectedCodeText === null || selectedCodeText === undefined || selectedCodeText === "");
    }

    // Registry of keyboard shortcuts that should be re-added to each editor window
    // when focus changes.
    const addWebRKeyboardShortCutCommands = () => {
      // Add a keydown event listener for Shift+Enter to run all code in cell
      editor.addCommand(monaco.KeyMod.Shift | monaco.KeyCode.Enter, () => {

        // Retrieve all text inside the editor
        executeCode(editor.getValue());
      });

      // Add a keydown event listener for CMD/Ctrl+Enter to run selected code
      editor.addCommand(monaco.KeyMod.CtrlCmd | monaco.KeyCode.Enter, () => {

        // Get the selected text from the editor
        const selectedText = editor.getModel().getValueInRange(editor.getSelection());
        // Check if no code is selected
        if (isEmptyCodeText(selectedText)) {
          // Obtain the current cursor position
          let currentPosition = editor.getPosition();
          // Retrieve the current line content
          let currentLine = editor.getModel().getLineContent(currentPosition.lineNumber);

          // Propose a new position to move the cursor to
          let newPosition = new monaco.Position(currentPosition.lineNumber + 1, 1);

          // Check if the new position is beyond the last line of the editor
          if (newPosition.lineNumber > editor.getModel().getLineCount()) {
            // Add a new line at the end of the editor
            editor.executeEdits("addNewLine", [{
            range: new monaco.Range(newPosition.lineNumber, 1, newPosition.lineNumber, 1),
            text: "\n", 
            forceMoveMarkers: true,
            }]);
          }
          
          // Run the entire line of code.
          executeCode(currentLine);

          // Move cursor to new position
          editor.setPosition(newPosition);
        } else {
          // Code to run when Ctrl+Enter is pressed with selected code
          executeCode(selectedText);
        }
      });
    }

    // Register an on focus event handler for when a code cell is selected to update
    // what keyboard shortcut commands should work.
    // This is a workaround to fix a regression that happened with multiple
    // editor windows since Monaco 0.32.0 
    // https://github.com/microsoft/monaco-editor/issues/2947
    editor.onDidFocusEditorText(addWebRKeyboardShortCutCommands);

    // Register an on change event for when new code is added to the editor window
    editor.onDidContentSizeChange(updateHeight);

    // Manually re-update height to account for the content we inserted into the call
    updateHeight();
  });

  // Function to execute the code (accepts code as an argument)
  async function executeCode(codeToRun) {
    // Disable run button for code cell active
    runButton.disabled = true;

    // Create a canvas variable for graphics
    let canvas = undefined;

    // Initialize webR
    await globalThis.webR.init();

    // Setup a webR canvas by making a namespace call into the {webr} package
    await webR.evalRVoid("webr::canvas(width=504, height=360)");

    // Capture output data from evaluating the code
    const result = await webRCodeShelter.captureR(codeToRun, {
      withAutoprint: true,
      captureStreams: true,
      captureConditions: false//,
      // env: webR.objs.emptyEnv, // maintain a global environment for webR v0.2.0
    });

    // Start attempting to parse the result data
    try {

      // Stop creating images
      await webR.evalRVoid("dev.off()");

      // Merge output streams of STDOUT and STDErr (messages and errors are combined.)
      const out = result.output.filter(
        evt => evt.type == "stdout" || evt.type == "stderr"
      ).map((evt) => evt.data).join("\n");

      // Clean the state
      const msgs = await webR.flush();

      // Output each image stored
      msgs.forEach(msg => {
        // Determine if old canvas can be used or a new canvas is required.
        if (msg.type === 'canvas'){
          // Add image to the current canvas
          if (msg.data.event === 'canvasImage') {
            canvas.getContext('2d').drawImage(msg.data.image, 0, 0);
          } else if (msg.data.event === 'canvasNewPage') {
            // Generate a new canvas element
            canvas = document.createElement("canvas");
            canvas.setAttribute("width", 2 * 504);
            canvas.setAttribute("height", 2 * 360);
            canvas.style.width = "700px";
            canvas.style.display = "block";
            canvas.style.margin = "auto";
          }
        }
      });

      // Nullify the outputDiv of content
      outputDiv.innerHTML = "";

      // Design an output object for messages
      const pre = document.createElement("pre");
      if (/\S/.test(out)) {
        // Display results as text
        const code = document.createElement("code");
        code.innerText = out;
        pre.appendChild(code);
      } else {
        // If nothing is present, hide the element.
        pre.style.visibility = "hidden";
      }
      outputDiv.appendChild(pre);

      // Place the graphics on the canvas
      if (canvas) {
        const p = document.createElement("p");
        p.appendChild(canvas);
        outputDiv.appendChild(p);
      }
    } finally {
      // Clean up the remaining code
      webRCodeShelter.purge();
      runButton.disabled = false;
    }
  }

  // Add a click event listener to the run button
  runButton.onclick = function () {
    executeCode(editor.getValue());
  };
</script>
<p>Visit the <a href="https://quarto-webr.thecoatlessprofessor.com/">quarto-webr website</a> for details on how to make full use of this capability. Once you’re up to speed, why not <a href="https://realworlddatascience.net/contributor-docs/contributor-guidelines.html">contribute a webR-enabled article for Real World Data Science</a>?</p>
<!-- ### Talk title
Add write-up here

*Add your name and affiliation here* -->
</section>
</section>
<section id="wednesday-september-20" class="level2">
<h2 class="anchored" data-anchor-id="wednesday-september-20">Wednesday, September 20</h2>
<section id="r-not-only-in-production" class="level3">
<h3 class="anchored" data-anchor-id="r-not-only-in-production">R Not Only In Production</h3>
<p>Kara Woo, senior data science engineer at InsightRX, began her Wednesday morning keynote with a rousing description of posit::conf(2023) being like a “great community garden” where things are being cultivated and shared for the benefit of all. This is an important feeling, Woo said, because it doesn’t always feel like that in our day jobs. Data scientists can feel siloed, not able to share ideas with like-minded people, and facing resistance from people who say “R can’t do that, R isn’t a real programming language” – a comment that elicited a groan of weary familiarity from sections of the crowd.</p>
<p>But as Woo went on to explain, “it is possible to build quality software in R” and “it is possible to have an organisation where the strengths of R and the people who use it influence the organisation as a whole.”</p>
<p>Woo was speaking from her experience at InsightRX, a precision medicine company, which makes software for clinicians to inform individualised dosing decisions for patients. Through a tool called Nova, clinicians feed in data about a patient’s unique characteristics, which is then passed to R for analysis, which then returns dosage recommendations to Nova.</p>
<p>In InsightRX, R has also been used to solve problems that are not strictly data science problems. Woo gave the example of working with a colleague to write an R package to identify data labels that have been changed and rollout translations for those labels in multiple languages for software users in different parts of the world.</p>
<p>“Our mindset of R being a first-class language empowers us to solve problems,” said Woo.</p>
</section>
<section id="its-abstractions-all-the-way-down" class="level3">
<h3 class="anchored" data-anchor-id="its-abstractions-all-the-way-down">It’s Abstractions All the Way Down…</h3>
<p>The second of the morning keynotes on day two of posit::conf(2023) was by JD Long, vice president of risk management at RenaissanceRe.</p>
<p>During Long’s insightful – and frequently very funny – talk, this slide appeared:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/09/19/images/jd-slide.PNG" class="img-fluid figure-img" alt="JD Long's slide reads: 'The single biggest business value derived from the data science movement in the last 13 years is making it legitimate to code outside of IT roles.'"></p>
<figcaption class="figure-caption">JD Long’s assertion #1.</figcaption>
</figure>
</div>
<p>Do you agree with Long’s assertion? If you don’t, what <em>is</em> the single biggest business value that’s been derived from the data science movement? Share your thoughts in the comments below.</p>
</section>
<section id="its-all-about-perspective-making-a-case-for-generative-art" class="level3">
<h3 class="anchored" data-anchor-id="its-all-about-perspective-making-a-case-for-generative-art">It’s All About Perspective: Making a Case for Generative Art</h3>
<p>Hobbies are important, right? They are a way to relax, to unwind. But also a great opportunity to learn things that might come in handy professionally. At least, that is the experience of Meghan Santiago Harris, a data scientist in the Prostate Cancer Clinical Trials Consortium at Memorial Sloan Kettering.</p>
<p>Harris shared with delegates her journey into generative art, and how skills acquired using ggplot2 for “fun stuff” had a positive impact on her work.</p>
<p>She first defined generative art as artwork created through a program in any language or interface, so long as the program itself executes the generation of the art. To make generative art, Harris said, you just need data and the ability to “think outside the grid” of your favourite graphics software or package. Harris’s tool of choice is ggplot2, but any will do: “If a tool lets you plot data, it will let you make art,” she said.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/09/19/images/gen-art.png" class="img-fluid figure-img" alt="The generative art image shows a setting sun on a red background, with the silhouettes of tall buildings in the foreground."></p>
<figcaption class="figure-caption">A slide from Meghan Santiago Harris’s talk, with an example of how to create an image of the sun setting on a city using lines of R code.</figcaption>
</figure>
</div>
<p>Harris’s passion for generative art bloomed during a recent period of maternity leave. She was coding for fun but also deepening her understanding and expertise in areas like code iteration, development and communication. And, in August, Harris published an R package called <a href="https://meghansaha.github.io/artpack/">artpack</a>, which is now available on CRAN and designed “to help generative artists of all levels create generative art in R.”</p>
<p>Generative art was a motivation to learn and do more, Harris said, and doing something she loved helped make programming and data science more digestible.</p>
</section>
<section id="how-the-r-for-data-science-r4ds-online-learning-community-made-me-a-better-student" class="level3">
<h3 class="anchored" data-anchor-id="how-the-r-for-data-science-r4ds-online-learning-community-made-me-a-better-student">How the R for Data Science (R4DS) Online Learning Community Made Me a Better Student</h3>
<p>Following straight after Meghan Santiago Harris was Lydia Gibson, a data scientist from Intel, with an inspiring talk about her route into data science. Gibson began by explaining how, when younger, “I wanted to be a fashion designer.” For her high school prom, Gibson even designed her own dress, which her grandmother made for her.</p>
<p>In 2011, Gibson earned a BS in economics and worked in retail customer service and state and local government for a time before deciding to return to school to do a Masters in statistics in 2021. She had “no experience of programming” when she made this decision, but soon learned that R is “a necessary evil if you have to go back to school to do statistics.”</p>
<p>Gibson told delegates that discovering data visualisation was what made her care about R. She could “feed [her] need for creativity” while also learning about things that were required for her course.</p>
<p>And it was the <a href="https://rfordatasci.com/">R for Data Science (R4DS) Online Learning Community</a> that helped take her learning to the next level. Gibson described R4DS as “an amazing, welcoming learning environment where beginners and advanced folks alike can come together to learn not only R but data science as a whole.”</p>
<p>“Being surrounded by folks more advanced than you is a gift, not a curse,” she said, and she urged delegates to find what they are passionate about and explore its depths.</p>
</section>
<section id="github-copilot-integration-with-rstudio-its-finally-here" class="level3">
<h3 class="anchored" data-anchor-id="github-copilot-integration-with-rstudio-its-finally-here">GitHub Copilot integration with RStudio, it’s finally here!</h3>
<p>Tom Mock, product manager for Posit Workbench and RStudio, had a full house for his talk about the upcoming integration of <a href="https://github.com/features/copilot">GitHub’s code Copilot product</a> into RStudio. Copilot, Mock said, is an AI pair programmer that offers autocomplete-style suggestions for code – and this integration is one of the most popular requested features among RStudio users on GitHub.</p>
<p>To make use of the integration, you’ll need a Copilot subscription from GitHub. But more than that, Mock said, users will need to experiment to learn how to get the most out of the “generative [AI] loop.”</p>
<p>See Mock’s slide deck below for more details.</p>
<iframe width="100%" height="563px" src="https://colorado.posit.co/rsc/rstudio-copilot/#/TitleSlide"></iframe>
<!-- ### Talk title
Add write-up here

*Add your name and affiliation here* -->
<div class="callout callout-style-simple callout-note" style="margin-top:0">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-body-container">
<p>posit::conf(2023) is over, but this blog remains open for contributions. If you want to share personal highlights or reflections on your time at conference: 1. Fork <a href="https://github.com/realworlddatascience/realworlddatascience.github.io">our repo</a>, 2. update <a href="https://github.com/realworlddatascience/realworlddatascience.github.io/blob/positconf-blog/viewpoints/editors-blog/posts/2023/09/19/positconf-blog.qmd">this file</a> in the <code>positconf-blog</code> branch (or create a new branch of your own), and 3. make a pull request! You can also <a href="https://realworlddatascience.net/contact.html">email contributions</a>.</p>
</div>
</div>
</div>
<div class="article-btn">
<p><a href="../../../../../../viewpoints/editors-blog/index.html">Back to Editors’ blog</a></p>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-6">
<dl>
<dt>Copyright and licence</dt>
<dd>
© 2023 Royal Statistical Society
</dd>
</dl>
<p><a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> <img style="height:22px!important;vertical-align:text-bottom;" src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/09/19/https:/mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/09/19/https:/mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"></a> This article is licensed under a Creative Commons Attribution 4.0 (CC BY 4.0) <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> International licence</a>.</p>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>How to cite</dt>
<dd>
Tarran, Brian. 2023. “Live from Chicago: Real World Data Science at posit::conf(2023).” Real World Data Science, September 19, 2023, updated September 27, 2023. <a href="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/09/19/positconf-blog.html">URL</a>
</dd>
</dl>
</div>
</div>
</div>


</section>
</section>

 ]]></description>
  <category>Conferences</category>
  <category>Events</category>
  <guid>https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/09/19/positconf-blog.html</guid>
  <pubDate>Wed, 27 Sep 2023 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/09/19/images/chicago-theatre.png" medium="image" type="image/png" height="105" width="144"/>
</item>
<item>
  <title>‘What if we try to bring R to the classroom? That was our wacky idea’</title>
  <dc:creator>Brian Tarran</dc:creator>
  <link>https://realworlddatascience.net/viewpoints/interviews/posts/2023/09/25/rgirls-interview.html</link>
  <description><![CDATA[ 




<p><a href="https://rgirls.org.uk/">R-Girls</a> is an exciting new project launched by Green Oak Academy, a faith-based independent secondary school for girls based in Birmingham, England. The project aims to promote the use of R in schools through the development and delivery of R-based lesson plans for a range of subjects.</p>
<p>To find out more about R-Girls, its origins and ambitions, Real World Data Science met with <strong>Mohammed Mohammed</strong>, a governor at Green Oak Academy, principal consultant for the National Health Service (NHS) Midlands and Lancashire Strategy Unit, and a founder of the NHS-R Community.</p>
<section id="what-inspired-r-girls" class="level2">
<h2 class="anchored" data-anchor-id="what-inspired-r-girls">What inspired R-Girls?</h2>
<p>“It was the confluence of a few different things. Firstly, Dr Razia Ghani, head teacher at Green Oak Academy, has a PhD in mathematics from the University of Birmingham, has some experience of doing statistics in the pharmaceutical sector, and teaches mathematics. That meant we had a lot of shared capital in our background and thinking about things.</p>
<p>“When I became a governor of the school, the staff were doing progress reports for pupils, and I wrote a little programme in R to help them with this. So, that was one of the early uses of R in the school.</p>
<p>“I know R because of my experience in academia, and I had previously put in a proposal to the Health Foundation to introduce R to the National Health Service. The Health Foundation agreed to that, they funded it, and we now have an <a href="https://nhsrcommunity.com/">NHS-R Community</a> which is basically promoting the use of R in the health service.</p>
<p>“And so I said to the head teacher, ‘What about if we try to bring R to the classroom?’ That was our wacky idea, and we put in a bid to the <a href="https://www.r-consortium.org/">R Consortium</a>, and they gave us seed funding, and that’s how we got started.”</p>
</section>
<section id="what-are-the-aims-of-the-project" class="level2">
<h2 class="anchored" data-anchor-id="what-are-the-aims-of-the-project">What are the aims of the project?</h2>
<p>“The aims of the project are threefold:</p>
<ul>
<li>To promote the use of R in secondary schools for girls.</li>
<li>To inspire teachers to incorporate R into their lessons.</li>
<li>To enable students to experience the joy of R.</li>
</ul>
<p>“On our website, we have prepared 10 or so oven-ready lesson plans – they have to be oven-ready for any teacher to ever think about using them; they have to be polished, ready, and easy to use. As well as our website, we have a <a href="https://twitter.com/R_Girls_School">Twitter</a> page and a community on <a href="https://r-girls.slack.com/">Slack</a>.</p>
<p>“One key thing to note is that we didn’t set out to teach programming. The history of computer science in our school is that computer science was really not liked at all by the girls. They wouldn’t choose it as a subject to pursue further. So, we decided to use R to support other subjects. This was a key strategic decision, really.</p>
<p>“People have attempted to develop lesson plans to teach Python, but that would be a non-starter in my school because (a) there isn’t much curriculum space, and (b) no teacher is enthusiastic enough to take on that activity and learn Python and become the Python expert in class. Whereas using R as a tool to facilitate learning in other subjects just opens up the whole world of data science in a way that is so much more accessible and appealing. People may say we’re really not teaching students how to code – but we’re not putting them off coding either!”</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://realworlddatascience.net/viewpoints/interviews/posts/2023/09/25/images/screenshot-1.png" class="img-fluid figure-img" alt="Screenshot of R-Girls website, showing a few taster lessons for setting up and using R in class."></p>
</figure>
</div>
<div class="figure-caption" style="text-align: center;">
<p>The R-Girls website includes <a href="https://rgirls.org.uk/getting_started.html">tutorials on how to get started using R in school</a>.</p>
</div>
</section>
<section id="how-is-r-being-used-in-different-subjects-in-school" class="level2">
<h2 class="anchored" data-anchor-id="how-is-r-being-used-in-different-subjects-in-school">How is R being used in different subjects in school?</h2>
<p>“In maths lessons we do things like generate sequences, plot graphs, do Pythagoras’ Theorem. In geography, we have mapping lessons and lessons on plotting rainfall data from Australian cities.</p>
<p>“Our lesson plans are set up in R Markdown, but the key thing from the teacher’s point of view is that they recognise the structure: What stage is it in terms of the curriculum? What are the objectives, the success criteria and keywords? Typically, we’ll show a worked example and then give the students an exercise to draw a different graph, say – they learn to tweak existing code rather than start from scratch.</p>
<p>“We first taught them how to use R using R Markdown – a way of writing script and code and data all together in one document. And after the first lesson, we were absolutely astonished. This is feedback from one of the girls: ‘Today’s lesson was very interesting and exciting. I’ve learnt a lot of new things about coding and found a new hobby…’ From subsequent lessons, here’s more feedback: ‘Programming and coding was actually quite fun… It was a great feeling knowing that I was able to code a whole bar chart all by myself…’</p>
<p>“A new thing that we’ve done recently is that one of the teachers has been inspired and has learned how to build a website in R, and she’s then decided to teach the Year 9 girls how to build their own websites. One quote from a student was: ‘I learnt how to make a website; I feel like an independent woman now.’ Another said: ‘This was very stressful. But it will look good on my CV.’</p>
<p>“One of the key challenges we face in education is that teachers are very stressed, and Covid didn’t help. Workloads are a massive issue in teaching, and of course that’s the same for our teachers. So, we had to make sure that whatever we do does not feel like it’s adding to the workload. One of the things we do is to use R in the cloud, so there is no installation and debugging on local computers. We try to minimise the pain, really.”</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://realworlddatascience.net/viewpoints/interviews/posts/2023/09/25/images/screenshot-2.png" class="img-fluid figure-img" alt="Screenshot of R-Girls website, showing two geography lessons: one on plotting rainfall data from Australian cities, and one on mapping."></p>
</figure>
</div>
<div class="figure-caption" style="text-align: center;">
<p>Lesson plans developed so far include ones for maths, science, and geography classes (pictured).</p>
</div>
</section>
<section id="how-do-you-want-to-see-the-r-girls-project-grow-and-what-will-success-look-like-for-you" class="level2">
<h2 class="anchored" data-anchor-id="how-do-you-want-to-see-the-r-girls-project-grow-and-what-will-success-look-like-for-you">How do you want to see the R-Girls project grow, and what will success look like for you?</h2>
<p>“It would be really nice to see that girls introduced to R through the R-Girls project felt there was a natural progression for them to join the <a href="https://rladies.org/">R-Ladies Group</a>, so that data science becomes part of their future aspirations.</p>
<p>“The second thing is that I’d like to set up an annual conference for girls at school, which would be online and which becomes part of the extracurricular landscape, so that any girl interested in R can join.</p>
<p>“We’d also love to see other schools, especially girls schools, joining the project – and joining the project just means agreeing to take the lessons we have and trying them in class. We would welcome other schools contributing additional lessons to the library of lessons, so that it becomes an open community resource that anybody can use. There’s nothing in this which is designed to make it explicitly local to an English independent school in Birmingham!</p>
<p>“We are keen to hear from others, so please reach out to us on <a href="mailto:rgirlsschool@gmail.com">rgirlsschool@gmail.com</a>.”</p>
<div class="article-btn">
<p><a href="../../../../../../viewpoints/interviews/index.html">Find more Interviews</a></p>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-6">
<dl>
<dt>Copyright and licence</dt>
<dd>
© 2023 Royal Statistical Society
</dd>
</dl>
<p><a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> <img src="https://realworlddatascience.net/viewpoints/interviews/posts/2023/09/25/https:/mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1" style="height:22px!important;vertical-align:text-bottom;"><img src="https://realworlddatascience.net/viewpoints/interviews/posts/2023/09/25/https:/mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1" style="height:22px!important;margin-left:3px;vertical-align:text-bottom;"></a> This interview is licensed under a Creative Commons Attribution 4.0 (CC BY 4.0) <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> International licence</a>.</p>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>How to cite</dt>
<dd>
Tarran, Brian. 2023. “‘What if we try to bring R to the classroom? That was our wacky idea’” Real World Data Science, September 25, 2023. <a href="https://realworlddatascience.net/viewpoints/interviews/posts/2023/09/25/rgirls-interview.html">URL</a>
</dd>
</dl>
</div>
</div>
</div>


</section>

 ]]></description>
  <category>R</category>
  <category>Education</category>
  <category>Outreach</category>
  <guid>https://realworlddatascience.net/viewpoints/interviews/posts/2023/09/25/rgirls-interview.html</guid>
  <pubDate>Mon, 25 Sep 2023 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/viewpoints/interviews/posts/2023/09/25/images/rgirls.png" medium="image" type="image/png" height="105" width="144"/>
</item>
<item>
  <title>‘Pseudo data science’ and other pitfalls: lessons from the UK’s stats regulator on how not to be misleading</title>
  <dc:creator>Ed Humpherson</dc:creator>
  <link>https://realworlddatascience.net/viewpoints/posts/2023/09/18/pseudo-data-science.html</link>
  <description><![CDATA[ 




<p>A typical article on data science hails new data sources, new tools, and new visualisations, and thereby supports the case for the value of data science.</p>
<p>But this article takes a different angle: it talks about potential pitfalls that can face data scientists. It is based on our work as the Office for Statistics Regulation (OSR), the UK’s regulator for official statistics. We see lots of great work done by statisticians in government. But we also see some of the challenges they face – and data scientists are also likely to encounter the same challenges.</p>
<p>The problems arise from the fact that neither statisticians nor data scientists do their work in isolation. The work usually takes places within organisations – businesses, government bodies, think tanks, academic institutions – and as a result, the statisticians and/or data scientists are not the only players who get to influence how data science is presented and used.</p>
<p>What are the pitfalls we see in our work as regulator?</p>
<section id="pseudo-data-science" class="level2">
<h2 class="anchored" data-anchor-id="pseudo-data-science">Pseudo data science</h2>
<p>The first type of pitfall is pseudo data science.</p>
<p>Pseudo data science is a term we use to describe attempts to pass off crude work as being more data science-y than it really is. That reflects a sense in public life that data science is new, innovative, somehow the Future. In this context, people who are not data scientists can be tempted to dress themselves up in the clothes of data science to enhance their credibility. This dressing up is usually well-intentioned – communications professionals who want to illuminate and explain complex issues in an engaging way.</p>
<p>The trouble is, it can sometimes backfire. In our work at OSR, we have over the last year seen several examples where organisations have sought to publish visualisations that look like they are the product of in-depth data analysis – when in fact they have been drawn by communications staff using graphic design packages. Examples include <a href="https://osr.statisticsauthority.gov.uk/correspondence/ed-humpherson-to-david-pares-treasury-inflation-infographic/">inflation</a>, <a href="https://uksa.statisticsauthority.gov.uk/correspondence/response-from-sir-robert-chote-to-andrew-gwynne-mp-dhsc-chart-on-nurses-pay/">nurses pay</a>, and <a href="https://uksa.statisticsauthority.gov.uk/correspondence/letter-to-rachel-reeves-mp-gdp-growth-chart/">comparisons of UK economic performance with other countries</a>. To be fair, whenever we have pointed out issues like this, organisations have responded well, putting in place new procedures to ensure that analysts sign off on this kind of visualisations. Nevertheless, we suspect that the temptations to indulge in pseudo data science will remain strong – and we may need to intervene on similar cases in future.</p>
</section>
<section id="unintelligent-transparency" class="level2">
<h2 class="anchored" data-anchor-id="unintelligent-transparency">Unintelligent transparency</h2>
<p>The second pitfall is a failure of <a href="https://osr.statisticsauthority.gov.uk/publication/regulatory-guidance-on-intelligent-transparency/">intelligent transparency</a>.</p>
<p>There is a raw form of transparency – quoting a single number (a naked number we call it); or dumping data out into the public domain with no explanation. This is not intelligent transparency. The latter involves being clear where data come from, what their source is, and making underlying data available so that others can understand and verify the statements that are being made. Raw transparency and naked numbers treat an audience with little respect; intelligent transparency helps the audience understand and appreciate what sits behind high level claims.</p>
<p>Data science outputs can sometimes seem to communications teams easy to cherry pick for the most attractive number. Again, like pseudo data science, this reflects largely good intentions – to communicate complex things through ideas. But it becomes easy for a single, unsupported number to be used and reused until it loses most of its meaning. We call this weaponization of data, and it is the antithesis of intelligent transparency. And there is a lot of it about – for example the way in which the former Prime Minister of the UK talked repeatedly about <a href="https://uksa.statisticsauthority.gov.uk/correspondence/sir-david-norgrove-to-prime-minister-employment-statistics/">employment</a>; or <a href="https://uksa.statisticsauthority.gov.uk/correspondence/response-from-sir-robert-chote-to-alex-cole-hamilton-msp-scottish-renewable-energy-statistics/">claims</a> about Scotland’s capacity for <a href="https://uksa.statisticsauthority.gov.uk/correspondence/sir-robert-chote-to-stephen-kerr-msp-renewable-energy/">renewable energy</a>. These examples indicate the pathology of weaponization that can impact data science outputs. They also act as a reminder that data scientists can counter weaponization of their own outputs by delivering engaging and insightful communication.</p>
</section>
<section id="context-collapse" class="level2">
<h2 class="anchored" data-anchor-id="context-collapse">Context collapse</h2>
<p>The third type of pitfall surrounds context collapse.</p>
<p>This idea comes from the work of the philosopher <a href="http://lucymcdonald.co.uk/wp-content/uploads/2023/02/Context-Collapse-Online-LMcDonald.pdf">Lucy McDonald</a> (who in turn has built on the ideas of <a href="https://www.danah.org/">danah boyd</a>). What is context collapse? Imagine a swimming pool – with neat divisions of the pool into different lanes. All is clearly labelled – fast, medium, slow – for lane swimmers, who are in turn separated from the splash area for families and the deep end for divers. Removing the lanes, and thus taking away any signposting, increases the likelihood for things to go wrong. The fast swimmers doing front crawl clash with the slower breaststroke swimmers; both are constantly having to avoid the families with young children; and all need to watch for the periodic big splashes created by the divers. This is the online communication environment, in which formerly private and casual statements can go viral; in which a brief statement in a media environment can be picked up on and circulated many times; and in which some bad actors (the divers) may wish to disrupt deliberately the debate by breaking all the rules.</p>
<p>How can this affect data science? It happens when individual bits of data are taken from their context, and used in service of a different, and bigger, argument. A good example is data on Covid vaccinations. Here, UK organisations like the Office for National Statistics and the UK Health Security Agency published comprehensive data in good faith about vaccinations and their impact. Some of the underlying data, however, was taken out of the broader context and used in isolation to support criticisms of vaccines – criticisms that the wider evidence base did not support.</p>
<p>The challenge then became how the organisations should respond. At an organisational level, they did not wish to withdraw the data – because that would reduce transparency. Instead they sought to both caveat their data more clearly; and directly rebut the more egregious misuses of the data. In a sense, then, what began as an individual analytical output became part of a broader organisational judgement on positioning in the face of misinformation.</p>
<p>It is fair to say that, against this third pitfall, there is not yet a clear consensus on how to address it. Practice is emerging all the time and we at OSR continue to support producers of data as they grapple with it.</p>
<p>There are other potential pitfalls to using data science. But what unites these three – pseudo data science; unintelligent transparency; and context collapse – is that they relate to situations where data science rubs up against broader organisational dynamics, around communications, presentation and organisational strategy.</p>
<p>And the meta-message is this: for data scientists to thrive in organisations, they need to be good at more than data science. They need to be skilled at working alongside and influencing colleagues from other functions. Only through this form of <a href="https://osr.statisticsauthority.gov.uk/analytical-leadership/">data leadership</a> can the pitfalls be dealt with effectively.</p>
<div class="callout callout-style-simple callout-note">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-body-container">
<p>This article is based on a presentation at the <a href="https://www.datascienceforhealthequity.com/">Data Science for Health Equity</a> group in May 2023.</p>
</div>
</div>
</div>
<div class="article-btn">
<p><a href="../../../../../viewpoints/index.html">Discover more Viewpoints</a></p>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-12">
<dl>
<dt>About the author</dt>
<dd>
<strong>Ed Humpherson</strong> is head of the Office for Statistics Regulation, which provides independent regulation of all official statistics in the UK. The aim of OSR is to enhance public confidence in the trustworthiness, quality and value of statistics produced by government.
</dd>
</dl>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>Copyright and licence</dt>
<dd>
© 2023 Ed Humpherson
</dd>
</dl>
<p><a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> <img style="height:22px!important;vertical-align:text-bottom;" src="https://realworlddatascience.net/viewpoints/posts/2023/09/18/https:/mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://realworlddatascience.net/viewpoints/posts/2023/09/18/https:/mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"></a> This article is licensed under a Creative Commons Attribution 4.0 (CC BY 4.0) <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> International licence</a>.</p>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>How to cite</dt>
<dd>
Humpherson, Ed. 2023. “‘Pseudo data science’ and other pitfalls: lessons from the UK’s stats regulator on how not to be misleading.” Real World Data Science, September 18, 2023. <a href="https://realworlddatascience.net/viewpoints/posts/2023/09/18/pseudo-data-science.html">URL</a>
</dd>
</dl>
</div>
</div>
</div>


</section>

 ]]></description>
  <category>Communication</category>
  <category>Leadership</category>
  <category>Transparency</category>
  <guid>https://realworlddatascience.net/viewpoints/posts/2023/09/18/pseudo-data-science.html</guid>
  <pubDate>Mon, 18 Sep 2023 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/viewpoints/posts/2023/09/18/images/distorted-data.png" medium="image" type="image/png" height="105" width="144"/>
</item>
<item>
  <title>Contributors: check out the new Real World Data Science template repo on GitHub</title>
  <dc:creator>Brian Tarran</dc:creator>
  <link>https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/09/12/template.html</link>
  <description><![CDATA[ 




<p>Thinking of contributing to Real World Data Science but not sure how to get started? Help is at hand, thanks to <a href="https://github.com/finnoh">Finn-Ole Höner</a>. The Amsterdam-based business data science student has created <a href="https://github.com/finnoh/RWDS_post_template">a template repository on GitHub</a> that allows anyone to create Real World Data Science content in our house style and format.</p>
<p>In this repository you’ll find two example Quarto (.qmd) documents, which is the main file type we use for generating site content. The “content-brief.qmd” file is a template for developing article ideas to discuss with our site editors, and the “report.qmd” file is a standard article template. Within that article template you’ll find examples of the range of Quarto features that we use, as well as the code you need to make use of them yourself.</p>
<p>These documents can be edited using tools including Visual Studio Code and R Studio. For details on how to work with Quarto documents, see the <a href="https://quarto.org/">Quarto website</a>. Once article drafts are finished they can be rendered into HTML format, and the output files will be displayed in the Real World Data Science style, thanks to the inclusion of our stylesheets in the template repository. This is a great way for contributors to see what their content will look like on Real World Data Science before anything is published.</p>
<p>To get started, head on over to the <a href="https://github.com/finnoh/RWDS_post_template">RWDS_post_template repository</a> and click the “Use this template” button. Also, be sure to <a href="https://realworlddatascience.net/contributor-docs/contributor-guidelines.html">review our contributor guidelines</a> for advice on how to integrate the .qmd templates into the content development and submission workflow.</p>
<p>Huge thanks to Finn-Ole Höner for building this valuable resource for Real World Data Science contributors.</p>
<div class="article-btn">
<p><a href="../../../../../../viewpoints/editors-blog/index.html">Back to Editors’ blog</a></p>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-6">
<dl>
<dt>Copyright and licence</dt>
<dd>
© 2023 Royal Statistical Society
</dd>
</dl>
<p><a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> <img style="height:22px!important;vertical-align:text-bottom;" src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/09/12/https:/mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/09/12/https:/mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"></a> This article is licensed under a Creative Commons Attribution 4.0 (CC BY 4.0) <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> International licence</a>. Thumbnail photo by <a href="https://unsplash.com/@synkevych?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Roman Synkevych</a> on <a href="https://unsplash.com/photos/UT8LMo-wlyk?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Unsplash</a>.</p>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>How to cite</dt>
<dd>
Tarran, Brian. 2023. “Contributors: check out the new Real World Data Science template repository on GitHub.” Real World Data Science, September 12, 2023. <a href="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/09/12/template.html">URL</a>
</dd>
</dl>
</div>
</div>
</div>



 ]]></description>
  <category>Call for contributions</category>
  <category>Tools</category>
  <category>Updates</category>
  <guid>https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/09/12/template.html</guid>
  <pubDate>Tue, 12 Sep 2023 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/09/12/images/roman-synkevych-UT8LMo-wlyk-unsplash.png" medium="image" type="image/png" height="105" width="144"/>
</item>
<item>
  <title>For minorities, biased AI algorithms can damage almost every part of life</title>
  <dc:creator>Arshin Adib-Moghaddam</dc:creator>
  <link>https://realworlddatascience.net/viewpoints/posts/2023/09/06/biased-algorithms.html</link>
  <description><![CDATA[ 




<p>Bad data does not only produce bad outcomes. It can also help to suppress sections of society, for instance vulnerable women and minorities.</p>
<p>This is the argument of <a href="https://www.bloomsbury.com/us/is-artificial-intelligence-racist-9781350374423/">my new book</a> on the relationship between various forms of racism and sexism and artificial intelligence (AI). The problem is acute. Algorithms generally need to be exposed to data – often taken from the internet – in order to improve at whatever they do, such as <a href="https://www.theguardian.com/us-news/2022/may/11/artitifical-intelligence-job-applications-screen-robot-recruiters">screening job applications</a>, or underwriting mortgages.</p>
<p>But the training data often contains many of the biases that exist in the real world. For example, algorithms could learn that most people in a particular job role are male and therefore favour men in job applications. Our data is polluted by a set of myths from the age of <a href="https://en.wikipedia.org/wiki/Age_of_Enlightenment#:%7E:text=The%20Enlightenment%20included%20a%20range,separation%20of%20church%20and%20state.">“enlightenment”</a>, including biases that lead to <a href="https://www.gaytascience.com/transphobic-algorithms/">discrimination based on gender and sexual identity</a>.</p>
<p>Judging from the history in societies where racism has played a role in <a href="https://sk.sagepub.com/books/racism-from-slavery-to-advanced-capitalism">establishing the social and political order</a>, extending privileges to white males –- in Europe, North America and Australia, for instance –- it is simple science to assume that residues of racist discrimination feed into our technology.</p>
<p>In my research for the book, I have documented some prominent examples. Face recognition software <a href="https://www.washingtonpost.com/technology/2019/12/19/federal-study-confirms-racial-bias-many-facial-recognition-systems-casts-doubt-their-expanding-use/">more commonly misidentified black and Asian minorities</a>, leading to false arrests in the US and elsewhere.</p>
<p>Software used in the criminal justice system has predicted that black offenders would have <a href="https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing">higher recidivism rates</a> than they did. There have been false healthcare decisions. <a href="https://www.science.org/doi/10.1126/science.aax2342">A study found that</a> of the black and white patients assigned the same health risk score by an algorithm used in US health management, the black patients were often sicker than their white counterparts.</p>
<p>This reduced the number of black patients identified for extra care by more than half. Because less money was spent on black patients who have the same level of need as white ones, the algorithm falsely concluded that black patients were healthier than equally sick white patients. Denial of mortgages for minority populations is facilitated by biased data sets. The list goes on.</p>
<section id="machines-dont-lie" class="level2">
<h2 class="anchored" data-anchor-id="machines-dont-lie">Machines don’t lie?</h2>
<p>Such oppressive algorithms intrude on almost every <a href="https://www.newscientist.com/article/mg25033390-200-the-essential-guide-to-the-algorithms-that-run-your-life/">area of our lives</a>. AI is making matters worse, as it is sold to us as essentially unbiased. We are told that machines don’t lie. Therefore, the logic goes, no one is to blame.</p>
<p>This pseudo-objectiveness is central to the AI-hype created by the Silicon Valley tech giants. It is easily discernible from the speeches of Elon Musk, Mark Zuckerberg and Bill Gates, even if now and then they <a href="https://futureoflife.org/open-letter/pause-giant-ai-experiments/">warn us about the projects</a> that they themselves are responsible for.</p>
<p>There are various unaddressed legal and ethical issues at stake. Who is accountable for the mistakes? Could someone claim compensation for an algorithm denying them parole based on their ethnic background in the same way that one might for a toaster that exploded in a kitchen?</p>
<p>The <a href="https://umdearborn.edu/news/ais-mysterious-black-box-problem-explained#:%7E:text=This%20inability%20for%20us%20to,when%20they%20produce%20unwanted%20outcomes.">opaque nature of AI technology</a> poses serious challenges to legal systems which have been built around individual or human accountability. On a more fundamental level, basic human rights are threatened, as legal accountability is blurred by the maze of technology placed between perpetrators and the various forms of discrimination that can be conveniently blamed on the machine.</p>
<p>Racism has always been a systematic strategy to order society. It builds, legitimises and enforces hierarchies between the haves and have nots.</p>
</section>
<section id="ethical-and-legal-vacuum" class="level2">
<h2 class="anchored" data-anchor-id="ethical-and-legal-vacuum">Ethical and legal vacuum</h2>
<p>In such a world, where it’s difficult to disentangle truth and reality from untruth, our privacy needs to be legally protected. The right to privacy and the concomitant ownership of our virtual and real-life data needs to be codified as a human right, not least in order to harvest the real opportunities that good AI harbours for human security.</p>
<p>But as it stands, the innovators are far ahead of us. Technology has outpaced legislation. The ethical and legal vacuum thus created is readily exploited by criminals, as this brave new AI world is largely anarchic.</p>
<p>Blindfolded by the mistakes of the past, we have entered a wild west without any sheriffs to police the violence of the digital world that’s enveloping our everyday lives. The tragedies are already happening on a daily basis.</p>
<p>It is time to counter the ethical, political and social costs with a concerted social movement in support of legislation. The first step is to educate ourselves about what is happening right now, as our lives will never be the same. It is our responsibility to plan the course of action for this new AI future. Only in this way can a good use of AI be codified in local, national and global institutions.</p>
<!-- Below is The Conversation's page counter tag. Please DO NOT REMOVE. -->
<p><img src="https://realworlddatascience.net/viewpoints/posts/2023/09/06/https:/counter.theconversation.com/content/211778/count.gif?distributor=republish-lightbox-basic" alt="The Conversation" width="1" height="1" style="border: none !important; box-shadow: none !important; margin: 0 !important; max-height: 1px !important; max-width: 1px !important; min-height: 1px !important; min-width: 1px !important; opacity: 0 !important; outline: none !important; padding: 0 !important" referrerpolicy="no-referrer-when-downgrade"></p>
<!-- End of code. If you don't see any code above, please get new code from the Advanced tab after you click the republish button. The page counter does not collect any personal data. More info: https://theconversation.com/republishing-guidelines -->
<div class="article-btn">
<p><a href="../../../../../viewpoints/index.html">Discover more Viewpoints</a></p>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-12">
<dl>
<dt>About the author</dt>
<dd>
<a href="https://theconversation.com/profiles/arshin-adib-moghaddam-211780">Arshin Adib-Moghaddam</a> is professor in global thought and comparative philosophies, <a href="https://theconversation.com/institutions/soas-university-of-london-975">SOAS, University of London</a>.
</dd>
</dl>
</div>
<div class="g-col-12 g-col-md-12">
<dl>
<dt>Copyright and licence</dt>
<dd>
This article is republished from <a href="https://theconversation.com">The Conversation</a> under a Creative Commons license. Read the <a href="https://theconversation.com/for-minorities-biased-ai-algorithms-can-damage-almost-every-part-of-life-211778">original article</a>.
</dd>
<dd>
<p>Image by <a href="http://alanwarburton.co.uk/">Alan Warburton</a> / © BBC / <a href="https://www.betterimagesofai.org">Better Images of AI</a> / Quantified Human / <a href="https://creativecommons.org/licenses/by/4.0/">Licenced by CC-BY 4.0</a>.</p>
</dd>
</dl>
</div>
</div>
</div>


</section>

 ]]></description>
  <category>AI</category>
  <category>AI ethics</category>
  <category>Bias</category>
  <category>Ethics</category>
  <guid>https://realworlddatascience.net/viewpoints/posts/2023/09/06/biased-algorithms.html</guid>
  <pubDate>Wed, 06 Sep 2023 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/viewpoints/posts/2023/09/06/images/AlanWarburton-QuantifiedHuman-991x724.png" medium="image" type="image/png" height="105" width="144"/>
</item>
<item>
  <title>RSS Conference preview: Evaluating AI, machine learning, and data visualisation</title>
  <dc:creator>Brian Tarran</dc:creator>
  <link>https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/08/24/rss-conference.html</link>
  <description><![CDATA[ 




<p>The Royal Statistical Society International Conference takes place in Harrogate, England, this September (Monday 4 to Thursday 7). Real World Data Science will be in attendance, and we’ve helped organise a couple of sessions we’d like to tell you about.</p>
<section id="evaluating-ai-how-data-science-and-statistics-can-shape-the-uks-ai-strategy" class="level3">
<h3 class="anchored" data-anchor-id="evaluating-ai-how-data-science-and-statistics-can-shape-the-uks-ai-strategy">Evaluating AI: How data science and statistics can shape the UK’s AI strategy</h3>
<p><strong>Date:</strong> 6 September <strong>Time:</strong> 9:00 am - 10:20 am <strong>Room:</strong> Auditorium (moved from Queens Suite 8)</p>
<p>The launch of ChatGPT less than a year ago is a milestone moment in the story of artificial intelligence. Overnight, large language models were transformed from research projects into consumer products, now used by millions each month. <a href="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/07/19/code-interpreter.html">The capabilities are impressive</a>, <a href="https://realworlddatascience.net/careers/posts/2023/05/11/chatgpt-data-science-pt1.html">the productivity gains undeniable</a>. But, what of the downsides? These are issues <a href="https://realworlddatascience.net/viewpoints/interviews/posts/2023/04/28/stephanie-hare.html">societies, governments, and individuals are now starting to reckon with</a>.</p>
<p>In March 2023, <a href="https://www.gov.uk/government/publications/ai-regulation-a-pro-innovation-approach/white-paper">the UK government published a white paper promising a “pro-innovation approach” to AI regulation</a>, while also acknowledging the risks AI poses to “people’s privacy, their human rights or their safety” and “concerns about the fairness of using AI tools to make decisions which impact people’s lives”. <a href="https://rss.org.uk/RSS/media/File-library/Policy/2023/RSS-AI-white-paper-response-v2-2.pdf">The Royal Statistical Society, in response, has called for investment in a centre for AI evaluation methodology</a>, arguing that users of AI systems should be able to judge the trustworthiness of claims made by AI companies as well as the outputs of their systems.</p>
<p>What should AI evaluation look like? How will it work in practice? What metrics are most important, and – crucially – who gets to decide this? Join us for <a href="https://virtual.oxfordabstracts.com/#/event/4019/program?session=66677&amp;s=700">a special panel debate at the RSS International Conference</a>, where these questions, and more, will be discussed.</p>
</section>
<section id="best-practices-for-data-visualisation-how-to-make-data-outputs-more-readable-accessible-and-impactful" class="level3">
<h3 class="anchored" data-anchor-id="best-practices-for-data-visualisation-how-to-make-data-outputs-more-readable-accessible-and-impactful">Best Practices for Data Visualisation: How to make data outputs more readable, accessible, and impactful</h3>
<p><strong>Date:</strong> 5 September <strong>Time:</strong> 11:40 am - 1:00 pm <strong>Room:</strong> Auditorium</p>
<p>The Royal Statistical Society (RSS) has published a new guide, “<a href="https://royal-statistical-society.github.io/datavisguide/">Best Practices for Data Visualisation</a>”, containing insights, advice, and examples (with code) to make data outputs more readable, accessible, and impactful. The guide is written primarily for contributors to Royal Statistical Society publications – including <em>Significance</em> magazine, the <em>Journal of the Royal Statistical Society Series A</em>, and Real World Data Science – but the information and advice within is also of broad relevance and use for any data visualisation task.</p>
<p>In the first half of this conference session, authors Andreas Krause, <a href="https://nrennie.rbind.io/">Nicola Rennie</a>, and Brian Tarran will introduce the guide and its key recommendations, and there will be a short demo of how to use the new <a href="https://github.com/nrennie/RSSthemes">{RSSthemes} R package</a>. For the second half of the session, attendees will be invited to share feedback with the authors, propose ideas, and start developing new and expanded sections of the guide. Attendees will be shown how to work with the guide’s source files and collaborate via GitHub, so feel free to bring along a laptop and become a contributor!</p>
<p>For more information, see <a href="https://royal-statistical-society.github.io/datavisguide/">rss.org.uk/datavisguide</a> and the <a href="https://virtual.oxfordabstracts.com/#/event/4019/program?session=65937&amp;s=0">RSS Conference website</a>.</p>
</section>
<section id="discussion-meeting-probabilistic-and-statistical-aspects-of-machine-learning" class="level3">
<h3 class="anchored" data-anchor-id="discussion-meeting-probabilistic-and-statistical-aspects-of-machine-learning">Discussion Meeting: Probabilistic and statistical aspects of machine learning</h3>
<p><strong>Date:</strong> 6 September <strong>Time:</strong> 5:00pm - 7:00 pm <strong>Room:</strong> Auditorium</p>
<p>We haven’t helped organise this session, but we are interested to see it. Two papers will be presented for discussion and debate. Paper 1 is “Automatic Change-Point Detection in Time Series via Deep Learning” by Jie Li, Paul Fearnhead, Piotr Fryzlewicz, and Tengyao Wang, while Paper 2 is “From Denoising Diffusions to Denoising Markov Models” by Joe Benton, Yuyang Shi, Valentin De Bortoli, George Deligiannidis, and Arnaud Doucet. Preprints of both papers are available now via the <a href="https://rss.org.uk/training-events/events/discussion-papers/">RSS Discussion Meetings webpage</a>, and you can also hear more about the session in this interview with Adam Sykulski, RSS Discussion Papers editor.</p>
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/1UL1H21v-Q0?si=WPftzqltawRknPPM" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<div class="article-btn">
<p><a href="../../../../../../viewpoints/editors-blog/index.html">Back to Editors’ blog</a></p>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-6">
<dl>
<dt>Copyright and licence</dt>
<dd>
© 2023 Royal Statistical Society
</dd>
</dl>
<p><a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> <img style="height:22px!important;vertical-align:text-bottom;" src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/08/24/https:/mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/08/24/https:/mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"></a> This article is licensed under a Creative Commons Attribution 4.0 (CC BY 4.0) <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> International licence</a>. Thumbnail image by <a href="https://flic.kr/p/YzNWJw">jcw1967</a>, licenced under a Creative Commons Attribution 2.0 Generic (CC BY 2.0) <a href="https://creativecommons.org/licenses/by/2.0/">licence</a>.</p>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>How to cite</dt>
<dd>
Tarran, Brian. 2023. “RSS Conference preview: Evaluating AI, machine learning, and data visualisation.” Real World Data Science, August 24, 2023. <a href="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/08/24/rss-conference.html">URL</a>
</dd>
</dl>
</div>
</div>
</div>


</section>

 ]]></description>
  <category>AI</category>
  <category>Machine learning</category>
  <category>Data visualisation</category>
  <category>Events</category>
  <guid>https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/08/24/rss-conference.html</guid>
  <pubDate>Thu, 24 Aug 2023 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/08/24/images/harrogate-conference-centre.png" medium="image" type="image/png" height="105" width="144"/>
</item>
<item>
  <title>Where do AI, data science, and computer games intersect?</title>
  <dc:creator>Alice-Maria Toader and Liam Brierley</dc:creator>
  <link>https://realworlddatascience.net/viewpoints/posts/2023/08/17/data-science-and-games.html</link>
  <description><![CDATA[ 




<p>Game studios have cemented their place among the fastest-growing media industries. In recognition of this, we hosted an event in June through the <a href="https://rss.org.uk/membership/rss-groups-and-committees/groups/merseyside/">Royal Statistical Society (RSS) Merseyside Local Group</a> to explore AI and data science in computer game development. This was an amazing opportunity to engage with a different, in-vogue domain that has unique ties to data science. We showcased two fantastic presentations covering both academic and industry perspectives.</p>
<p>Stanley Wang, a data scientist at SEGA Europe, opened the event by showing the methods that SEGA uses to collect, process, and apply data on player decisions in-game. It was a revealing glimpse at how smoothly in-game data collection is integrated into SEGA’s digital platforms and the ways these data can be used to engage game-centred communities – for example, running special celebrations once milestones are hit for in-game events (revenue made, goals scored, etc.) or offering real-time integration with streaming platforms so viewers can see detailed statistics on in-game progress. Stanley showed one particular example where data collection fed directly into development decisions for <em>Endless Space</em>, a competitive strategy game where players vie for galactic conquest. During the beta (a period where a game is available to play but still considered in-testing before commercial release), SEGA were able to monitor how well-balanced the playable alien factions were based on real-time win rate data, which led to improvements to game mechanics for the final release.</p>
<p>We also learned how SEGA’s data science teams are using clustering methods to identify different game-playing behaviours in <em>Two Point Hospital</em>, a simulation game where players design, build, and manage a hospital through various scenarios. After compiling high-dimensional in-game data such as objectives achieved, treatment of staff, and even furniture choices, various clustering algorithms (including <a href="https://towardsdatascience.com/a-practical-guide-on-k-means-clustering-ca3bef3c853d">k-means clustering</a>) were used to identify common sets of player behaviour. Stanley highlighted that when using these sorts of <em>unsupervised learning methods</em>, it’s useful to get insights from multiple models to inform methodological decisions like number of clusters chosen or how to treat outliers. SEGA identified four distinct types of player from these analyses, which you can hear more about from Stanley in the video below. The approach allowed the company to better understand gamers’ motivations and experiences with a view to designing future game content.</p>
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/KAg3YDHvvqE" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<p>Our second speaker, Dr Konstantinos Tsakalidis, a lecturer in the Department of Computer Science at the University of Liverpool, presented exciting new ideas to teach computer games developers of the future. Dr Tsakalidis walked us through the curriculum for a dynamic new undergraduate program that reflects the latest software development technologies and the theory behind them. The course outline was designed around building knowledge and practice from the fundamentals upwards, starting from game physics as a prerequisite for game mechanics, game mechanics being a prerequisite for game content, and game content being a prerequisite for game AI. Combined with the continuous active involvement of students at each stage, this represented a great model of <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8049623/">constructivist teaching</a>. Dr Tsakalidis also proposed that practical game development (and subsequent assessments) should follow the latest <a href="https://www.datacamp.com/podcast/data-science-and-ai-in-the-gaming-industry">research on data science and AI in computer games</a>.</p>
<div class="article-btn">
<p><a href="../../../../../viewpoints/index.html">Discover more Viewpoints</a></p>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-12">
<dl>
<dt>About the author</dt>
<dd>
<strong>Alice-Maria Toader</strong> is a PhD student at the University of Liverpool and a committee member of the RSS Merseyside Local Group. <strong>Liam Brierley</strong> is a research fellow in health data science at the University of Liverpool and chair of the RSS Merseyside Local Group.
</dd>
</dl>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>Copyright and licence</dt>
<dd>
© 2023 Alice-Maria Toader and Liam Brierley
</dd>
</dl>
<p><a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> <img style="height:22px!important;vertical-align:text-bottom;" src="https://realworlddatascience.net/viewpoints/posts/2023/08/17/https:/mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://realworlddatascience.net/viewpoints/posts/2023/08/17/https:/mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"></a> This article is licensed under a Creative Commons Attribution 4.0 (CC BY 4.0) <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> International licence</a>. Thumbnail image by <a href="https://unsplash.com/@jezar?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Jezael Melgoza</a> on <a href="https://unsplash.com/photos/FOx3_4_2O1E?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Unsplash</a>.</p>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>How to cite</dt>
<dd>
Toader, Alice-Maria and Liam Brierley. 2023. “Where do AI, data science, and computer games intersect?” Real World Data Science, August 17, 2023. <a href="https://realworlddatascience.net/viewpoints/posts/2023/08/17/data-science-and-games.html">URL</a>
</dd>
</dl>
</div>
</div>
</div>



 ]]></description>
  <category>Events</category>
  <category>Video games</category>
  <category>Education</category>
  <guid>https://realworlddatascience.net/viewpoints/posts/2023/08/17/data-science-and-games.html</guid>
  <pubDate>Thu, 17 Aug 2023 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/viewpoints/posts/2023/08/17/images/sega-store.png" medium="image" type="image/png" height="105" width="144"/>
</item>
<item>
  <title>Live from Toronto: Real World Data Science at the Joint Statistical Meetings</title>
  <dc:creator>Brian Tarran</dc:creator>
  <link>https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/08/06/jsm-blog.html</link>
  <description><![CDATA[ 




<section id="sunday-august-6" class="level2">
<h2 class="anchored" data-anchor-id="sunday-august-6">Sunday, August 6</h2>
<section id="use-of-color-in-statistical-charts" class="level3">
<h3 class="anchored" data-anchor-id="use-of-color-in-statistical-charts">Use of color in statistical charts</h3>
<p><em>Haley Jeppson, Danielle Albers Szafir, and Ian Lyttle</em></p>
<p>JSM 2023 is underway, and the first session I attended today was this panel on the use of colour in statistical charts.</p>
<p>The topic appealed to me for two reasons:</p>
<ul>
<li>Before my trip to Toronto, I interviewed <a href="https://realworlddatascience.net/viewpoints/interviews/posts/2023/08/01/alberto-cairo.html">Alberto Cairo about the many “dialects” of data visualisation</a>.</li>
<li>I’ve recently been working with Andreas Krause and Nicola Rennie to create new guidance for improving statistical graphics, titled “<a href="https://royal-statistical-society.github.io/datavisguide/">Best Practices for Data Visualisation</a>”.</li>
</ul>
<p>The “Best Practices…” guide links to several useful data visualisation tools, and this session today has put a few more on my radar:</p>
<ul>
<li><p><a href="https://cmci.colorado.edu/visualab/ColorCrafting/">Color Crafting</a>, by Stephen Smart, Keke Wu, and Danielle Albers Szafir. The authors write: “Visualizations often encode numeric data using sequential and diverging color ramps. Effective ramps use colors that are sufficiently discriminable, align well with the data, and are aesthetically pleasing. Designers rely on years of experience to create high-quality color ramps. However, it is challenging for novice visualization developers that lack this experience to craft effective ramps as most guidelines for constructing ramps are loosely defined qualitative heuristics that are often difficult to apply. Our goal is to enable visualization developers to readily create effective color encodings using a single seed color.”</p></li>
<li><p><a href="https://observablehq.com/collection/@ijlyttle/color">Computing on color</a>, a collection of Observable notebooks by Ian Lyttle that allow users to see how different colour spaces and colour scales work with different types of colour vision deficiency.</p></li>
</ul>
</section>
</section>
<section id="monday-august-7" class="level2">
<h2 class="anchored" data-anchor-id="monday-august-7">Monday, August 7</h2>
<section id="astronomers-speak-statistics" class="level3">
<h3 class="anchored" data-anchor-id="astronomers-speak-statistics">Astronomers Speak Statistics</h3>
<p>Astrophysicist Joel Leja kicked off his JSM talk with a video of the launch of the James Webb Space Telescope – an inspiring way to start the day, and a prelude to a discussion of the statistical challenges involved in studying the deep universe.</p>
<p>James Webb, since launch, has “completely expanded our point of view”, said Leja, allowing astronomers to explore the first stars and galaxies at greater resolution than ever before.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/08/06/images/james-webb.png" class="img-fluid figure-img" alt="Image from the James Webb telescope showing two galaxies in the process of merging, twisting each other out of shape." width="500"></p>
<figcaption class="figure-caption">Image from the James Webb telescope showing two galaxies in the process of merging, twisting each other out of shape. Credit: ESA/Webb, NASA &amp; CSA, L. Armus, A. Evan, licenced under CC BY 2.0.</figcaption>
</figure>
</div>
<p>Already, after only 13 months of operation, the images and data sent back by the telescope have left observers astounded: for example, finding suspected early galaxies that are bigger than thought possible based on extreme value analysis.</p>
<p>But the big challenge facing those studying the early universe is trying to work out how early galaxies evolved over time. “We can’t watch this happen,” said Leja, joking that this process lasts longer than a typical PhD. So, instead, he said, “We need to use statistics to understand this, to figure out how they grow up.”</p>
</section>
<section id="teaching-statistics-in-higher-education-with-active-learning" class="level3">
<h3 class="anchored" data-anchor-id="teaching-statistics-in-higher-education-with-active-learning">Teaching statistics in higher education with active learning</h3>
<p>Great talk from Nathaniel T. Stevens of the University of Waterloo, explaining how a posting for a Netflix job inspired the creation of a final project for students to learn response surface methodology.</p>
<p>The job ad in question “really opened my eyes” to the use of online controlled experiments by companies, said Stevens. He told delegates how LinkedIn, the business social networking site, runs over 400 experiments per day, trying to optimise user experience and other aspects of site engagement.</p>
<p>Netflix’s job ad highlighted just how sophisticated these experiments are, said Stevens. People might hear companies refer to their use of A/B tests, but the term trivialises what’s involved, Stevens explained.</p>
<p>Having encountered a job ad from Netflix, looking for someone to design, run, and analyse experiments and support internal methodological research, Stevens was inspired to present students with a hypothetical business problem, based on the Netflix homepage. That homepage, for those not familiar, features rows and rows of movies and TV shows sorted by theme, each show presented as a tile that, when hovered over, leads to a pop-up with a video preview and a match score – a prediction of how likely a viewer is to enjoy the show.</p>
<p>Stevens explained the hypothetical goal as trying to minimise “browsing time” – the time it takes a Netflix user to pick something to watch. Browsing time was defined as time spent scrolling and searching, not including time spent watching previews.</p>
<p>Students were given four factors that might influence browsing time – tile size, match score, preview length, and preview type – and through a sequence of experiments based on data generated by a Shiny app, students sought to minimise browsing time.</p>
<p>The response from the students? Two Netflix-style thumbs up. Ta-dum!</p>
</section>
</section>
<section id="tuesday-august-8" class="level2">
<h2 class="anchored" data-anchor-id="tuesday-august-8">Tuesday, August 8</h2>
<section id="the-next-50-years-of-data-science" class="level3">
<h3 class="anchored" data-anchor-id="the-next-50-years-of-data-science">The Next 50 Years of Data Science</h3>
<p>Stanford University’s David Donoho wrestled with the question of whether a singularity is approaching in this post-lunch session on the future of data science.</p>
<p>Taking his cue from the 2005 Ray Kurzweil book, <em>The Singularity is Near</em>, Donoho reviewed recent – and sometimes rapid – advances in data science and artificial intelligence to argue that a singularity may have already arrived, just not in the way Kurzweil supposed.</p>
<p>Kurzweil’s book argues that at some point after the 2030s, machine intelligence will supersede human intelligence, leading to a takeover or disruption of life as we know it.</p>
<p>At JSM, Donoho argued that we have certainly seen a “massive scaling” of compute over the past decade, along with expanded communications infrastructure and the wider spread of information – all of which is having an impact on human behaviour.</p>
<p>That human behaviour can often now be directly measured thanks to the proliferation of digital devices with data collection capabilities, and this in turn is leading to a major scaling in datasets and performance scaling for machine learning models.</p>
<p>But does this mean that an AI singularity is near? Not according to Donoho. The notion of an AI singularity “is a kind of misdirection”, he said. Something very profound is happening, Donoho argued, and it is the culmination of three long-term initiatives in data science that have come together in recent years. “They constitute a singularity on their own.”</p>
<p>These three initiatives, as Donoho described, are: datafication and data sharing; adherence to the “challenge problem” paradigm; and documentation and sharing of code. These are solid achievements that came out of the last decade, said Donoho, and they are “truly revolutionary” when they come together to form what he refers to as “frictionless reproducibility.”</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="images/donoho-talk.png"><img src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/08/06/images/donoho-talk.png" class="img-fluid figure-img" alt="Slide text reads: Today's data scientists: typical interactions: What's your package name? What's your URL? QR Code? What's your stack? Today's data scientists: implicit demands: Data sharing, Specific numerical performance measures, Code sharing, Single-click access. Frictionless replications." width="500"></a></p>
<figcaption class="figure-caption">Photo of David Donoho’s slide, describing the scientific revolution of the “data science decade”. Photo by Brian Tarran, licenced under CC BY 4.0.</figcaption>
</figure>
</div>
<p>Frictionless reproducibility, when achieved, leads to a “reproducibility singularity” – the moment where it takes almost no time at all for an idea to spread. “If there is an AI singularity,” said Donoho, “it will be because this came first.”</p>
</section>
</section>
<section id="wednesday-august-9" class="level2">
<h2 class="anchored" data-anchor-id="wednesday-august-9">Wednesday, August 9</h2>
<section id="new-frontiers-of-statistics-in-trustworthy-machine-learning" class="level3">
<h3 class="anchored" data-anchor-id="new-frontiers-of-statistics-in-trustworthy-machine-learning">New frontiers of statistics in trustworthy machine learning</h3>
<p>Data, data everywhere, but is it safe to “drink”? A presentation this morning from Yaoliang Yu of the University of Waterloo looked at the issue of data poisoning attacks on algorithms and the effectiveness of current approaches.</p>
<p>Yu began by explaining how machine learning algorithms require a lot of data for training, and that large amounts of data can be obtained cheaply by scraping the web.</p>
<p>But, he said, when researchers download this cheap data, they are bound to worry about the quality of it. Drawing an analogy to food poisoning, Yu asked: What if the data we “feed” to algorithms is not clean? What is the impact of that?</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/08/06/images/data-hazards.png" class="img-fluid figure-img" alt="A person is illustrated in a warm, cartoon-like style in green. They are looking up thoughtfully from the bottom left at a large hazard symbol in the middle of the image. The hazard symbol is a bright orange square tilted 45 degrees, with a black and white illustration of an exclamation mark in the middle where the exclamation mark shape is made up of tiny 1s and 0s like binary code. To the right-hand side of the image a small character made of lines and circles (like nodes and edges on a graph) is standing with its ‘arms’ and ‘legs’ stretched out, and two antenna sticking up. It faces off to the right-hand side of the image." width="500"></p>
<figcaption class="figure-caption">Illustration by Yasmin Dwiputri &amp; Data Hazards Project / Better Images of AI / Managing Data Hazards / Licenced by CC-BY 4.0.</figcaption>
</figure>
</div>
<p>As a real-world example of a data poisoning attack, Yu pointed to TayTweets, the Microsoft Twitter chatbot that spewed racism within hours of launch <a href="https://www.theverge.com/2016/3/24/11297050/tay-microsoft-chatbot-racist">after Twitter users began engaging with it</a>.</p>
<p>Yu then walked delegates through some experiments showing how, generally, indiscriminate data poisoning attacks are ineffective when the ratio of poisoned data to clean data is small. A poisoning rate of 3%, for example, leads to model accuracy drops of 1.5%–2%, Yu said.</p>
<p>However, he then put forward the idea of “parameter corruption” – an attack that seeks to modify a model directly. Yu showed that this would be more effective in terms of accuracy loss, though – fortunately – perhaps less practical to implement.</p>
</section>
<section id="data-science-and-product-analysis-at-google" class="level3">
<h3 class="anchored" data-anchor-id="data-science-and-product-analysis-at-google">Data Science and Product Analysis at Google</h3>
<p>Our final session at JSM 2023, before heading home, was a whistle-stop tour of various data science projects at Google, covering YouTube, Google Maps, and Google Search.</p>
<p>Jacopo Soriano kicked us off with a brief intro to the role and responsibilities of statisticians and data scientists at Google, and within YouTube specifically – the main task being to make good decisions based on uncertain data.</p>
<p>Soriano also spoke about the key role randomised experiments play in product development – harking back to Nathaniel Stevens’ earlier talk on this subject. YouTube runs hundreds, if not thousands, of concurrent experiments, Soriano said; statisticians can’t, therefore, be involved in each one. As Soriano’s colleague, Angela Schoergendorfer, explained later in the session, the role of the data scientist is to build methodology and metrics that others in the business can use to run their own experiments.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/08/06/images/google-sign.png" class="img-fluid figure-img" alt="Google logo on top of building, against a blue sky." width="500"></p>
<figcaption class="figure-caption">Photo by Pawel Czerwinski on Unsplash.</figcaption>
</figure>
</div>
<p>For every experiment YouTube runs, a portion of its voluminous daily traffic will be assigned to control arms and treatment arms, with traffic able to be diverted to different groups based on user type, creators, videos, advertisers, etc. Once experiments are running, metrics such as search clickthrough rates, watch time using specific devices, or daily active user numbers are monitored. Teams tend to look at percentage change as the scale to measure whether something is working or not, said Soriano, rather than comparing treatment to control group.</p>
<p>Next up was Lee Richardson, who spoke about the use of proxy metrics. Technology companies like Google are often guided by so-called “<a href="https://www.forbes.com/sites/forbesbusinesscouncil/2022/11/11/what-is-your-startups-north-star-metric/">north star metrics</a>”, which executive leadership use to guide the overall strategy and priorities of an organisation. However, Richardson said, these can be hard to design experiments around, and so proxy metrics stand in for the north star metrics. Proxies need to be sensitive, he said, and move in the same direction as, e.g., a long-term positive user experience.</p>
<p>On the subject of user experience, Christopher Haulk then explained how YouTube measures user satisfaction through single-question surveys – typically asking a YouTube user to rate the video they just watched. The company doesn’t send out that many surveys, Haulk said, and response rates are in the single-digit percentage range, so it can be hard to evaluate whether changes YouTube makes to, e.g., its video recommendation algorithm are working to improve user satisfaction. Haulk then went on to explain a modelling approach the company uses to predict how users are likely to respond in order to “fill in” for missing responses.</p>
<p>Over at Google Search, user feedback is also regularly sought to help support the evolution of the product. Angela Schoergendorfer explained how, with so many people already using Google Search, statistically significant changes in top-line metrics like daily active users can take months to see. Decision metics should ideally capture user value quickly, said Schoergendorfer – within days. For this, Google has 10,000 trained “search quality” raters they can call on. Random samples of user search queries and results are sent to these raters, who are asked to evaluate the quality of the search results. Users can also be asked in the moment, or offline through the Google Rewards app.</p>
<p>In 2021, Schoergendorfer said, Google conducted approximately 800,000 experiments and quality tests. But perhaps the most impressive statistic of the day came from Sam Morris, who works on Google Maps. Something, somewhere, is always changing in the world, said Morris – be it a road closure or a change to business hours. The Maps team cannot evaluate every single piece of data – a lot of changes are automated or algorithmic, he explained. “So far this year, we have probably processed 16 billion changes to the map,” said Morris – a staggering figure!</p>
<div class="article-btn">
<p><a href="../../../../../../viewpoints/editors-blog/index.html">Back to Editors’ blog</a></p>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-6">
<dl>
<dt>Copyright and licence</dt>
<dd>
© 2023 Royal Statistical Society
</dd>
</dl>
<p><a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> <img style="height:22px!important;vertical-align:text-bottom;" src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/08/06/https:/mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/08/06/https:/mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"></a> This article is licensed under a Creative Commons Attribution 4.0 (CC BY 4.0) <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> International licence</a>.</p>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>How to cite</dt>
<dd>
Tarran, Brian. 2023. “Live from Toronto: Real World Data Science at the Joint Statistical Meetings.” Real World Data Science, August 6, 2023, updated August 15, 2023. <a href="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/08/06/jsm-blog.html">URL</a>
</dd>
</dl>
</div>
</div>
</div>


</section>
</section>

 ]]></description>
  <category>Conferences</category>
  <category>Events</category>
  <guid>https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/08/06/jsm-blog.html</guid>
  <pubDate>Tue, 15 Aug 2023 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/08/06/images/google-sign.png" medium="image" type="image/png" height="105" width="144"/>
</item>
<item>
  <title>The many ‘dialects’ of data visualization: Alberto Cairo and ‘The Art of Insight’</title>
  <dc:creator>Brian Tarran</dc:creator>
  <link>https://realworlddatascience.net/viewpoints/interviews/posts/2023/08/01/alberto-cairo.html</link>
  <description><![CDATA[ 




<p>Alberto Cairo is Knight Chair in Visual Journalism at the School of Communication of the University of Miami (UM). He’s also the director of visualization at UM’s Institute for Data Science and Computing. He joins Real World Data Science to discuss his upcoming book, <em>The Art of Insight: How Great Visualization Designers Think</em>, in which Cairo reflects on his conversations with data artists, data journalists, and information designers.</p>
<p>“If we can conceptualise data visualization as language, this language can have multiple dialects,” says Cairo. “And these dialects – let’s say the statistical dialect, the data journalism dialect, the art dialect – they are not mutually exclusive. They exist, or they should exist, ideally, in constant conversation with each other. So, we can borrow ideas from each other, learn from each other.”</p>
<p>Listen to the full interview below or on <a href="https://www.youtube.com/watch?v=htUWWVzYTUI">YouTube</a>.</p>
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/htUWWVzYTUI" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<p>Find out more about Cairo’s work and his upcoming book at <a href="http://www.thefunctionalart.com/">thefunctionalart.com</a>.</p>
<section id="transcript" class="level2">
<h2 class="anchored" data-anchor-id="transcript">Transcript</h2>
<div class="callout callout-style-simple callout-warning" style="margin-top: 0.75rem;">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-body-container">
<p>This transcript has been produced using <a href="https://otter.ai/">speech-to-text transcription software</a>. It has been only lightly edited to correct mistranscriptions and remove some repetitions.</p>
</div>
</div>
</div>
<p><strong>Brian Tarran</strong><br>
Hello, and welcome to Real World Data Science. I’m Brian Tarran. And today I’m joined by Alberto Cairo, Knight chair in visual journalism at the School of Communication of the University of Miami. He’s also the director of visualization at UM’s Institute for data science and computing. Alberto, welcome. Thanks for joining us.</p>
<p><strong>Alberto Cairo</strong><br>
Hi, Brian. Very nice to be here. Thank you for inviting me.</p>
<p><strong>Brian Tarran</strong><br>
No worries. Well, today we’re excited to be discussing your new book, The Art of Insight: How Great Visualization Designers Think. I think it’s a really– I’ve not read all of it yet. I’ve dipped in and out of some chapters that you kindly sent me ahead of time. I think it’s really interesting and unique. I think the thing that struck me was often when we talk about visualization design, we tend to concentrate on what designers do, not necessarily about how they think about what they do, or how they think generally. And so, that was to be my first question for you is like, what aspects of their thought processes, these experts, what were you really trying to understand and why?</p>
<p><strong>Alberto Cairo</strong><br>
Yeah, yeah, this latest book of mine is very different to the previous one that I– that I wrote. The book is not out yet, by the way, the book will be out in November of 2023. I am in the process of copy editing it, getting rid of typos. But as you said, I mean the book focuses not so much on the– on the work itself, but more on the people who produce the work and the motivations and values that lie behind the work that they do. It is also, in comparison to my previous books, it is also a shift of perspective, I would say because my previous books, particularly The Truthful Art and How Charts Lie which came out in 2019, focus mostly on statistical visualization. Right, so it has a very strong, they both have a very strong statistical focus – how to make sure that your graphs and your data maps don’t deceive people. I teach elementary principles of visualization, of communication through visualization. But visualization is much more than that. And that is what I wanted to convey with this book. More and more throughout the years, I have come to understand data visualization not so much as a representation of data for insight or for communication, but as a language, a language that can be used for many different purposes. And I try to reflect that in the book. Obviously, a great part of the book is devoted to people who come from the same world where I come from, the professional world where I come from, the world of data journalism, so plenty of them are data journalists. Many of them are data analysts and statisticians and researchers. But a good portion of the book is devoted to people who use– who use visualization for other purposes such as self expression, self discovery, art in some cases. I wanted to provide a sort of like a broader understanding of the language of visualization and I also talk about– I also discussed the fact that if we can conceptualize data visualization as language, this language can have multiple dialects. And that is what I wanted to convey in the book. And these are not, these dialects – let’s say the statistical dialect, the data journalism dialect, the art dialect – they are not mutually exclusive. They exist, or they should exist, ideally, in constant conversation with each other. So we can borrow ideas from each other, learn from each other. So I wanted to provide sort of like an overview of the huge diversity that exists in the world of visualization – in terms of people, in terms of race, in terms of gender, but also in terms of the dialects that people use.</p>
<p><strong>Brian Tarran</strong><br>
Yeah, and is that almost pushing back a little bit at this idea that, you know, if visualization is a language in the same way that English is or Spanish is or whatever it might be, that there are– there must be rules that people have to follow?</p>
<p><strong>Alberto Cairo</strong><br>
Yeah, I push back against that a little bit in the book because obviously, I mean, what I have taught and what I continue talking– talking about at the– talking about at the University of Miami, what I teach my classes, is what you could call let’s say standard data visualization, right? Data visualization for communication. I discuss a lot about, you know, cognitive science, you know, perception, you know, how to apply that, colour palettes – I just do standard data visualization. But that is just one of the dialects that data visualization has, right? Data visualization can be used for journalism, for business analytics, for statistics, for art, for expression, for self discovery – some of the people who I interviewed, plot their own data, for example, their own health metrics, as a way to reduce their own anxiety. So I interviewed, for example, a person who has gone through– who in the past went through very serious health problems like cancer, brain cancer and other health problems, and he discovered that the process of designing visualizations based on his own data was similar to– had similar effects as meditating about your own thoughts, right. It was a way to pour your anxiety and your dark feelings onto the graphic, so they will not overburden your mind. I find that absolutely fascinating. And it shows you that, I believe, that’s what I– what I reflect in the book, that there are really no universal rules in data visualization. There are parochial rules that are applicable to different– to the different dialects. But it is it is wrong, it is a mistake, to apply the standards of one of the dialects of data visualization to a completely different dialect of data visualization. Every visualization, I feel or I think, should be judged according to their own terms, to the terms in which they were created.</p>
<p><strong>Brian Tarran</strong><br>
The book is essentially set out as a series of discussions with these visualization designers, right. And then it’s your interspersed reflections on the conversations and things that you’re sort of taking away from them. And when you were saying in the introduction about why you wanted to have these conversations, you say you were kind of looking to, or needing to, rekindle your love for the design of information. So I wanted to ask you, maybe I’ve misjudged that sentence, but you know, had you fallen out of love with the design of information? Or did you just kind of get to that point where you thought, oh, there must be more to it than this, the way I– the way I work. What was the– what was the motivating force driving you down this path?</p>
<p><strong>Alberto Cairo</strong><br>
It’s not that I stopped, you know, being in love with data visualization, or more broadly with information design, because I teach information design – data visualization is one of the branches of information design. So I also teach, you know, illustration driven visual explanations – how an airplane works, and you do a cutaway of the airplane and you show the engines and how they work. I also do that type of information design. So it’s not that I ever stopped being in love with– with the work that I do. As I explain, by the way, in the conclusions of the book, in the epilogue of the book, which circles back to the themes in the prologue, information design and data visualization are a great part of who I am as a person. To me, it’s a way of life. I use visualization not only to communicate with other people, I use visualization also to study. When I am reading a book, I am probably producing a visualization of the book, like some sort of network diagram, in which I plot all the ideas from the book. That’s a technique, a mnemonic technique, that I learned from my– from my father, who is a medical doctor, but also a humanist. He taught me this technique to study: when you’re reading a book, just write down the concepts that you’re learning about, and then connect them with arrows make little comments on the side. Indirectly he was teaching me to make data visualization. So data visualization, information design has permeated my life since I was very, very young – since I– since I didn’t have the language to talk about what I was doing. But at the same time, in the past three or four years, many personal circumstances led me to feel, let’s say, my morale went down quite a lot, the pandemic also and then some personal problems and stuff. And I started feeling a little bit disillusioned with my own– with my own work, like having self doubts, right? Am I doing the right thing? Am I in the right career? Should I be doing something else? Have I written everything that I wanted to write about this field? Have I designed every graphic that was worthy to be designed? And I felt the need to connect with other people. Because something that I discovered throughout the years is that we human beings, we don’t think well when we are alone, we think better when we are in connection with others. So my conversations with the many friends that are showcased in the book, obviously I wanted to give their work and their lives and their values visibility because I believe that they are worthy to be explored and understood by readers. But it was also a way for me to sort of like recover a little bit of the passion that I had about information design in the past – and I was successful. I mean, I went out of– The process of writing a book can be grueling. So, while you’re writing a book, you’re always thinking, you know, this is crap. What is it that I’m doing? I don’t know where I’m going. But in hindsight, now that the book is written, and I am reviewing it, I am thinking, hmm, this is not bad. This is not bad, right? And I discovered that I was– I felt energized, thanks to all these conversations with tons of inspiring people from all over the world.</p>
<p><strong>Brian Tarran</strong><br>
I think I can sort of sympathize with that, you know, the process of creating – I don’t do data visualization myself – but creating content, it can be quite a lonely process sometimes. And you do have that, I always talk about the roller coaster of emotions – of the peaks, were you think you’re doing a great job, and then the troughs where you’re like, Oh, my God, why or I should just throw it all in. So actually being able to sit down and talk to people and share ideas does inspire you, does sort of bring you back up again, doesn’t it? But I was worried, actually, that because the last time we spoke was, I think, around the time that How Charts Lie had come out, and you were interviewed by one of our freelance writers on Significance magazine – where I was at the time – and I thought, oh, no, maybe– maybe all that encountering the dark side of data visualization and all that misinformation that was out there…</p>
<p><strong>Alberto Cairo</strong><br>
That I felt depressed, right, because the book was useless, or not useless. But I mean, it was not read by the people – How Charts Lie, I mean – it was not read by the people who needed to read the book.</p>
<p><strong>Brian Tarran</strong><br>
That is always the case with these books, isn’t it? So they– they’re really valuable, if only you could get them in the hands of the right people. That’s the challenge.</p>
<p><strong>Alberto Cairo</strong><br>
We preach– We preach to the choir a little bit with these type of books, unfortunately, yeah.</p>
<p><strong>Brian Tarran</strong><br>
Well, I still enjoyed it anyway. And it’s always valuable to, to listen to experts like yourself and take learnings from those. So the, the things that– the interviews I’ve read, I’ve not read all of them, but I think the things that jumped out for me – the interviews with people like Ed Hawkins, talking about the Warming Stripes, you know, talking about how their focus is less about – and tell me if I’m mischaracterizing this – it’s less about direct communication of information or data, it’s more about conveying like a feeling or an intuitive understanding of something. And obviously, warming stripes, most people have seen those, you know – the kind of plots of changes in temperature against a baseline over time and the kind of rapid shift to deeper, darker shades of red as we get closer to the present, you know – I think they do create a sense of the urgency of the climate crisis when you just look at them. But what lessons do you as a kind of, you know, as a data visualization designer, a journalistic data visualization designer, what do you take from those sorts of examples, where it isn’t direct communication, of information or data, it’s about feeling? What can you– what can you take from that and bring to your own work?</p>
<p><strong>Alberto Cairo</strong><br>
Well, the fact, as I was saying before, that not all visualizations are alike, as I explained in that chapter. Hawkins got a little bit of pushback, because that visualization broke some rules – and I’m doing sort of like scare quotes with my fingers right now, right? It broke some rules because it doesn’t have axes, it doesn’t have scales. It’s just a beautiful picture. But that is valuable, that is valuable, and it’s proven that it is valuable. It’s one of the most popular data visualizations in history already. And he, it’s a perfect example of a match between purpose and outcomes. And that is what needs to be explored when evaluating a data visualization. So, Hawkins told me when I interviewed him that he didn’t want to create an analytical data visualization. If he wanted to do that, he will do a line chart with like error bars or whatever, right? Something that you could publish in a paper. He has done thousands of those types of graphs. But this graphic was originally designed to bring to a festival, to be displayed in the background while there was a conversation going on about climate change. So it was designed with the specific and explicit purpose not to provide an analytical tool to explore the data but as something that brought attention to the information, something that ignited curiosity in the viewers. And I think that if that is the purpose, the outcomes actually match really well what he had in mind, and therefore the visualization works. That’s a visualization that works. So that’s just one of the many examples that appear in the book, of graphics that somehow defy conventions but at the same time, according to their own predefined purposes, work pretty well. So we have the example, for example, from Jaime Serra, who is a designer from Spain who is a– he’s a data visualization designer, he has worked for many, many years for newspapers. But the type of graphics that he creates blend the artistic with the– with the statistical and the analytical. He uses objects, for example, to create data visualizations to– he comes up with these beautiful pieces that sometimes he has showcased in exhibits all over the– all over the world. But then I also talked to people who produce what we could call more conventional data visualizations, right – people who work in public health, right, people who work in data journalism, people who live in countries where, you know, producing accurate and truthful data visualization can be dangerous to your career, right? I talk, for example, to Attila Bátorfy, who is a data journalist working in Hungary, and obviously Hungary, right now, considering the Viktor Orban regime, it’s not very friendly to journalists who want to be accurate and truthful. And he tries to be, and he’s very successful in Hungary right now, right? He’s a, he’s a voice against authoritarianism in his country. Or Anatoly Bondarenko, who is a data journalist and data visualization designer from Ukraine, who years ago created an organization called Texty, which is an investigative reporting newsroom in Ukraine, a nonprofit in Ukraine, to investigate corruption in the Ukrainian government but also Russian interference in Ukraine prior to the war. And, and that is one of my favorite chapters, because I’m Anatoly is a good friend of mine, and he’s, he’s fighting. He’s part of the Ukrainian army. And I think about him on a regular basis. And I am in touch with him just to make sure that he’s– that he’s safe, that he’s doing good. That chapter begins with a sentence that says that I sometimes wake up in shock thinking about, you know, my friend is at war, right? That’s such a strange thought and his work is so valuable, it’s so impressive. Again, what I find inspiring in all the people I talk to, I talk with, in the book is not just the work itself, it’s the values and the motivations behind the work and sometimes the resilience of the people producing that work. That’s what I find inspiring.</p>
<p><strong>Brian Tarran</strong><br>
Yeah, yeah, I was– when you were talking there about the Hawkins warming stripes examples, the– the idea of evaluating visualizations, you know, on their own terms, on their kind of their stated purposes, I think is quite important. But do you think people creating data visualizations, do they spend enough time thinking through generally – not the experts you’ve talked to, obviously, they’re the maybe the exception – but about what the purpose– what is it that I want to achieve with this data visualization? Is that kind of one of the things that all your interviewees have in common, a very clear sense of purpose?</p>
<p><strong>Alberto Cairo</strong><br>
They do. They do have that sense of purpose. That doesn’t mean that they don’t sometimes create these great visualizations out of a whim – say, I’m gonna just create a pretty graphic based on that, no purpose whatsoever. And that’s perfectly fine. Again, the analogy with writing. Not all writing can be technical writing. That’s just one of the types of writing that we could use. And conventional, traditional visualization is analogous to technical writing – you want to communicate something effectively, clearly, and therefore you try to create something that doesn’t use too many words, or too many, you know, verbal flourishes, you just go directly to the point and try to communicate directly. But that’s not the only way you can use writing. You can write poetry, so why not using data visualization to create visual poetry? That’s perfectly, perfectly fine. Again, every visualization needs to be judged based on their own– on their own stated purposes. As to the question of whether people in general – like, not the people I talked to in the book, for the book – but, you know, people in general think about purpose when designing data visualizations, that’s a question that I cannot answer. But that’s the core of my classes and workshops. It’s like my classes and workshops outline, both at the university but also as a consultant, put a lot of emphasis on the purpose part. I mean, just list what do you want to communicate? What do you want to achieve? Create an actually a bullet point list of what you want to communicate, and based on that list, then you can make choices. The way that I teach data visualization these days is not about teaching rules, right? Like, you know, use a bar graph to compare, use this graphic for that, use a scatterplot to show associations between, you know, continuous variables or whatever. No, that’s not the way I teach visualization. I teach visualization based on a process of reasoning, right? Reason that takes you from the purpose to the outcome. And every decision down the road in between those two points needs to be somehow justified. You need to justify every decision that you make in the visualization in a way that is– that can be persuasive to other people who may be in your team. I use this colour palette because, and what comes after the because is the important part. I use this type of graphic because, and what comes after the because is the important part, and so on and so forth.</p>
<p><strong>Brian Tarran</strong><br>
Yeah, there’s something that struck me. I think it was a podcast producer who came up this idea of the XY story formula – that’s how you assess the value of a kind of an article pitch. Now, I’m writing a story about X, and it is interesting because Y – and it’s the bit that follows after the “because” that determines– you have to work on that and refine that, and that’s what shapes your story and your outputs. I’m glad you brought up teaching as well, because I was reading through the epilogue, and it said about you having “anarchic leanings and sympathies” and I was kind of curious about how those sympathies and leanings manifest in your work or in your teaching. And obviously, you said you don’t teach rules. So maybe that’s part of it. But…</p>
<p><strong>Alberto Cairo</strong><br>
What sympathies are you referring to?</p>
<p><strong>Brian Tarran</strong><br>
I don’t know. It was just that phrase jumped out: I have, I have anarchic– I think it’s “despite my anarchic leanings and sympathies”, and I was kind of curious as to what are those, and how do they– how do they manifest?</p>
<p><strong>Alberto Cairo</strong><br>
Well, one of the points that I make, particularly in the epilogue, which I think that is the most important part of the book, because it’s where I lay out my own thinking – is that, one of the points that I make is that you cannot really separate the work from the people. And I make the analogy with philosophy, I read a lot of philosophy. There is this book that I absolutely love about philosophy, titled “What is Ancient Philosophy?” by Pierre Hadott, who was, I think that he was French – wonderful book, absolutely wonderful book if you’re interested in the ancient history of philosophy, that book is amazing. Talks about the Hellenistic tradition of philosophy. I could go on and on and talk about that book. I absolutely love it. I think that I read it four times, something like that. And the point that Hadott makes in “What is Ancient Philosophy?” is that it takes you a long way to understand the philosophy of the, you know, the classics – Plato, Aristotle, and then the Hellenists like the Epicureans, or the Stoics, or whatever – it takes you a long way if you sort of like understand the temperament of those people, and their lived experiences, what they went through in their lives, right? If you understand, for example, what Plato lived, his times and his temperament, and also the history of the times when he lived, you can understand the Republic better, his best book, right? You, you sort of like guess where it comes from, right, where his thinking comes from. And I think that’s something similar can be said about visualization, right? I have my own temperament. I have a– I have a very driven temperament. So I’m quite a strong will – when I decide that I’m going to do something, I usually put the energy to do it. But at the same time, I’m quite anarchic, not in the sense of being disorganized, but in the sense that I don’t deal with authority well. I just want to be left alone, right? Just leave me alone. I will figure things out on my own. I work well with other people, right. But in horizontal organizations, I enjoy horizontal teams, rather than hierarchical teams, right. I work really well in horizontal teams. And that is somehow reflected, I think, in the way that I think about data visualization. I somehow rebelled against, you know, the 1980s, 1990s tradition of data visualization teaching around what I call the Tuftean – after Edward Tufte – the Tuftean tradition of saying, this is the only way to do visualization well, these are the rules of data visualization. Well, why? Why are those the rules? Tell me what is this based on, or is it just your own opinion? I mean, I enjoy reading Tufte and I enjoy reading, you know, people like Steven Few, who is a friend of mine, etc. But at the same time I rebelled against that tradition, because in many cases, as I explain in The Art of Insight, many of those so called rules are merely the opinions of people. This is just my opinion. I like this stuff. I like this style, and therefore, I’m going to try to pass my own opinion as if it were a rule of design. I think that we need to be a little bit more honest about what we are doing. Many of those rules are not really grounded on any sort of empirical evidence, and therefore they are still valuable – I think that people should keep reading Tufte, they should keep reading [unclear] and many of the, we should keep reading them. But always with a pinch of salt, taking everything that we read with a pinch of salt, and this applies to my own books as well. We need to be a little bit more skeptical, a little bit more flexible in some sense, knowing that we are on these together and what really matters, I think, is the conversation between people in the field. Conversation is a word that appears a lot in The Art of Insight. I see my work, and I see the work of everybody else who writes or thinks or makes data visualizations as part of an ongoing conversation between people in which we can learn from each other, borrow from each other – always understanding that our opinions can be strongly stated, but sometimes they have very, very shaky foundations.</p>
<p><strong>Brian Tarran</strong><br>
What you’re saying about the importance of still reading these kinds of texts, where the rules – again, in inverted commas – are set, the importance of doing that, that kind of reminded me of like in my, in my own world of, you know, the written word, people like James Ellroy, the author of American Tabloid, you know, about understanding the rules of grammar so that you know how to break them for effect and for impact and things like that. So I can see how that applies to data visualization.</p>
<p><strong>Alberto Cairo</strong><br>
It is, yeah, that’s sort of like already has become a cliche, right: learn the rules, so you can break them. I think that that is valuable. But at the same time, I think that we need to go beyond that and say, there are really no rules. I mean, there are a few things that could be considered rules. For example, we know that, you know, if you want to compare numbers, a bar graph is usually superior to a pie chart, for example. We know that, there is empirical evidence behind that, so you can sort of like derive a principle out of that, right? But beyond those very basic things, there are really not many rules. What there are is a lot of conventions, inherited conventions, right, that historically have developed and we have– we have inherited. So we could say, you know, it’s good to learn the conventions. It is still good to learn about perception and cognition to guide your decisions. But after you do that, all that matters is the choices that you make with the knowledge that you have, and with the guesses that you can make. Right? So it’s not that you’re breaking the rules, you’re creating your own path, based on the inherited knowledge that you have under your belt.</p>
<p><strong>Brian Tarran</strong><br>
Yeah. My last question for you – because I don’t want to take up too much of your time, I know you are very busy, Alberto – is, you mentioned, again, going back to the previous question, or two, the people that you work with, and one of those sometime collaborators is Shirley Wu, who you refer to in your introduction, and I was really struck by the description of the installation, the number of COVID deaths each week, and this this dripping valve. I think what struck me most was that, you know, obviously, Shirley had this idea that the drips would represent the number of COVID deaths each week, these drips into a bowl, but that this wasn’t explicitly stated to people viewing the installation, right? She created space for viewers to bring their own interpretations, and they did. And again, it’s one of these things that I think is a beautiful idea – being able to, to withhold some information – but I don’t know, how does that manifest if you’re, you know, a data scientist or whatever, and you’re trying to create visualizations for, you know, an internal client or whatever it might be. How do you kind of bring some of that, that flavor and that interpretation and that space, to a graphic? I think that’s something that I was thinking about when reading that book, that part of the book.</p>
<p><strong>Alberto Cairo</strong><br>
There are many examples like that in the book. For example, in the chapter about Jaime Serra, Jaime created once a graphic in which– he drinks a lot of coffee, and he wanted to – remember that one – he wanted to, he wanted to see how much coffee he was actually drinking throughout a year. And if I have to do that, I will, you know, I will get my mug, the mug that I use every day to drink my coffee, I will draw a scale on top of that, and then I will measure the number of ounces of coffee that I’m drinking. At the end of the year, I will probably design a line graph, a time series line graph, to see whether there is any seasonality in my coffee consumption. I will design an analytical chart or so to speak, right, a graphic to analyze my own data. But he wanted to design something a little bit more fun, a little bit more expressive, a little more artistic and what he did was to create a graphic in which he plotted the amount of coffee that he drinks throughout a year through coffee stains. He got 12 pieces of paper, each one of them corresponding to a month. He folded those pieces of paper to subdivide them into quadrants, each one corresponding to a day. And then whenever he was drinking coffee, he tried to leave a coffee stain on the corresponding quadrant of the corresponding paper. And the result was sort of like it was a physic– it’s a physical data visualization. And it is amazing. Now, does that mean that you can insert that type of graphic, let’s say, in a business dashboard, or on a quarterly report in a company? No, that’s not the purpose of that type of visualization. The way that I usually explain the value of that type of visualization is to create this sort of like hypothetical scenario. And I have used these many times with clients when presenting you know, Shirley’s work or Jaime’s work. I say this is not the type of graphic that you use for analysis, right. For analysis, you need to use line graphs, bar graphs, scatter plots, traditional conventional data visualizations. But let’s suppose that you, for some reason, one year you conduct a survey internally in your company to analyze how much coffee people drink in the company, right? And you do sort of like this beautiful report that you print out as a hardcover book to give to your own clients as a gift when they come to visit you. What do you put inside of the book? The analytical graphics, right? The analytical charts that slice and dice the data by gender, by location, by whatever? You put all the conventional traditional graphics? What do you put on the cover? What you put on the cover is the beautiful artistic data visualization, which is still a data visualization. And same thing with Shirley’s work, right. Shirley’s installation about COVID: true, it’s not a graphic. It’s not a visualization. It’s not really a graphic because it’s physical. It’s a physical installation. But it is not a visualization that is intended to communicate the data in any sort of like, with accuracy or anything, it just tries to create a feeling. So again, imagine that you work for let’s say, a company focusing on public health or whatever. And every day, what you produce will be conventional charts and graphs and maps. That’s what we need to use to analyze data. But let’s suppose that you want to create some sort of like beautiful piece of artwork to display in your headquarters. That will be an amazing piece to display in your headquarters. It will get people– it will get visitors curious about what you do, it may drive– it may lead you to conversations about the data that they deal with everyday, the same way that Ed Hawkins’s warming stripes graphic did. It’s just a different type of data visualization that needs to be judged according to its own purposes, under its own terms.</p>
<p><strong>Brian Tarran</strong><br>
Yeah, fantastic. Well, that’s a really nice idea to end on. Hope some people take it forward, and future visits to offices will be more visually appealing as we get to explore those spaces. So, Alberto, thank you very much. So the book is out in November, yes?</p>
<p><strong>Alberto Cairo</strong><br>
November the 15th. Yeah.</p>
<p><strong>Brian Tarran</strong><br>
Is there a website yet that people can go and find out more details?</p>
<p><strong>Alberto Cairo</strong><br>
No, still working on it. For now, there is some information in my weblog, which is the title of my first book, The Functional Art. So, it’s thefunctionalart.com. That’s my web blog. And there’s some information about The Art of Insight there, including some, you know, some sneak peeks.</p>
<p><strong>Brian Tarran</strong><br>
Excellent. Well, we’ll put a link to that in the in the show notes. So, Alberto, thank you for joining us today. Best of luck finishing up the book and the website. And I hope you can join us again soon because there’s so much more that I could discuss about the book with you, but it’s been great talking to you today.</p>
<p><strong>Alberto Cairo</strong><br>
Thank you, Brian.</p>
<div class="article-btn">
<p><a href="../../../../../../viewpoints/interviews/index.html">Find more Interviews</a></p>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-6">
<dl>
<dt>Copyright and licence</dt>
<dd>
© 2023 Royal Statistical Society
</dd>
</dl>
<p><a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> <img src="https://realworlddatascience.net/viewpoints/interviews/posts/2023/08/01/https:/mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1" style="height:22px!important;vertical-align:text-bottom;"><img src="https://realworlddatascience.net/viewpoints/interviews/posts/2023/08/01/https:/mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1" style="height:22px!important;margin-left:3px;vertical-align:text-bottom;"></a> This interview is licensed under a Creative Commons Attribution 4.0 (CC BY 4.0) <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> International licence</a>. Images are not covered by this licence. Photo of Alberto Cairo is copyright JCA Photography.</p>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>How to cite</dt>
<dd>
Tarran, Brian. 2023. “The many ‘dialects’ of data visualization: Alberto Cairo and ‘The Art of Insight.’” Real World Data Science, August 1, 2023. <a href="https://realworlddatascience.net/viewpoints/interviews/posts/2023/08/01/alberto-cairo.html">URL</a>
</dd>
</dl>
</div>
</div>
</div>


</section>

 ]]></description>
  <category>Data visualisation</category>
  <category>Communication</category>
  <guid>https://realworlddatascience.net/viewpoints/interviews/posts/2023/08/01/alberto-cairo.html</guid>
  <pubDate>Tue, 01 Aug 2023 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/viewpoints/interviews/posts/2023/08/01/images/alberto-cairo.png" medium="image" type="image/png" height="105" width="144"/>
</item>
<item>
  <title>‘Go out and talk about data science, particularly to schoolchildren’</title>
  <dc:creator>Brian Tarran</dc:creator>
  <link>https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/07/27/schools-outreach.html</link>
  <description><![CDATA[ 




<p>Rachel Hilliam, statistics professor at The Open University, used her inaugural lecture this month to make “a real plea” to the data science community “for outreach into schools”, to help build excitement and awareness of the promise and potential for careers in data science.</p>
<p>“We have a plethora of jobs that we cannot fill in data science at the moment,” said Hilliam. “We’ve had all sorts of initiatives in terms of trying to retrain people, and that’s great, and those are gaps that we need to plug. But unless we get that pipeline coming through, we’re always going to have this problem at the top.”</p>
<p>Hilliam, who is chair of the <a href="https://alliancefordatascienceprofessionals.co.uk">Alliance for Data Science Professionals</a>, wants schoolchildren and teachers to be made more aware of the benefits of, and opportunities for, data science careers. “Let me tell you,” she said, “if you go out into a school and say, ‘Do your kids want to be a data scientist?’, the teachers will look at you and go, ‘A what?’. They have no idea, generally, that data science actually exists, which is a shame.”</p>
<p>But there are plentiful opportunities to introduce data science to children, Hilliam suggests. She began her talk by saying that: “Data is everywhere – in every single thing that we do, in all of our walks of life.” And she concluded by saying: “Whatever it is that these kids are interested in, […] there is lots of data out there, so there is absolutely no reason why we can’t excite children in a career in data science. So, that’s where I’d like to finish. Go out and talk about data science, particularly to schoolchildren!”</p>
<p>Watch the lecture in full below or on YouTube. Skip to <a href="https://www.youtube.com/live/tCQhU4yP0OU?feature=share&amp;t=1024">17:04</a> for the start of the talk.</p>
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/tCQhU4yP0OU" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<div class="article-btn">
<p><a href="../../../../../../viewpoints/editors-blog/index.html">Back to Editors’ blog</a></p>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-6">
<dl>
<dt>Copyright and licence</dt>
<dd>
© 2023 Royal Statistical Society
</dd>
</dl>
<p><a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> <img style="height:22px!important;vertical-align:text-bottom;" src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/07/27/https:/mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/07/27/https:/mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"></a> This article is licensed under a Creative Commons Attribution 4.0 (CC BY 4.0) <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> International licence</a>. Thumbnail photo by <a href="https://unsplash.com/@neonbrand?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Kenny Eliason</a> on <a href="https://unsplash.com/photos/zFSo6bnZJTw?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Unsplash</a>.</p>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>How to cite</dt>
<dd>
Tarran, Brian. 2023. “‘Go out and talk about data science, particularly to schoolchildren.’” Real World Data Science, July 27, 2023. <a href="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/07/27/schools-outreach.html">URL</a>
</dd>
</dl>
</div>
</div>
</div>



 ]]></description>
  <category>Education</category>
  <category>Data literacy</category>
  <category>Outreach</category>
  <guid>https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/07/27/schools-outreach.html</guid>
  <pubDate>Thu, 27 Jul 2023 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/07/27/images/kenny-eliason-zFSo6bnZJTw-unsplash.png" medium="image" type="image/png" height="105" width="144"/>
</item>
<item>
  <title>Testing out ChatGPT’s new Code Interpreter</title>
  <dc:creator>Lee Clewley</dc:creator>
  <link>https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/07/19/code-interpreter.html</link>
  <description><![CDATA[ 




<p>On July 6, 2023, <a href="https://twitter.com/OpenAI/status/1677015057316872192?s=20">OpenAI began rolling out the Code Interpreter plugin</a> to users of its ChatGPT Plus service. But what exactly is this, and what functionality does it offer?</p>
<p>Code Interpreter runs code and allows for uploading data so you can use ChatGPT for data cleaning, preprocessing, analysis, visualisation and predictive modelling tasks, among other things. This tool holds great promise for programmers and analysts alike, with the potential to streamline coding workflows as well as having an automated data analyst at your fingertips.</p>
<p>To use Code Interpreter, you need to enable it in the ChatGPT settings (at time of writing this only works with a paid ChatGPT Plus subscription).</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="images/pic1.png"><img src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/07/19/images/pic1.png" class="img-fluid figure-img" alt="Screenshot of ChatGPT Plus setting, showing Code Interpreter plugin option." width="700"></a></p>
</figure>
</div>
<p>Now, let’s take it for a bit of a spin by uploading the <a href="https://www.kaggle.com/datasets/fedesoriano/stroke-prediction-dataset">stroke prediction dataset from Kaggle</a>.</p>
<section id="the-stroke-prediction-dataset" class="level2">
<h2 class="anchored" data-anchor-id="the-stroke-prediction-dataset">The stroke prediction dataset</h2>
<p>The World Health Organization (WHO) identifies stroke as the second leading cause of death worldwide, accounting for roughly 11% of all fatalities.</p>
<p>Kaggle’s stroke prediction dataset is used to forecast the likelihood of a patient suffering a stroke, taking into account various input parameters such as age, gender, presence of certain diseases, and smoking habits. Each row in the dataset offers pertinent information about an individual patient.</p>
<p>Loading this dataset into ChatGPT Code Interpreter, one is treated with:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="images/pic2.png"><img src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/07/19/images/pic2.png" class="img-fluid figure-img" alt="Screenshot from ChatGPT, showing Code Interpreter's initial review of an uploaded stroke prediction dataset." width="700"></a></p>
</figure>
</div>
<p>The user is asked: “Please let me know what analysis or operations you’d like to perform on this dataset. For instance, we can perform exploratory data analysis, data cleaning, data visualization, or predictive modelling.”</p>
<p>It seems quite a bold claim. So, I asked it to do all of the above.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="images/pic3.png"><img src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/07/19/images/pic3.png" class="img-fluid figure-img" alt="Screenshot from ChatGPT, showing Code Interpreter's overview explanation of planned analysis steps." width="700"></a></p>
</figure>
</div>
<section id="exploratory-data-analysis" class="level3">
<h3 class="anchored" data-anchor-id="exploratory-data-analysis">Exploratory Data Analysis</h3>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="images/pic4.png"><img src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/07/19/images/pic4.png" class="img-fluid figure-img" alt="Screenshot of ChatGPT Code Interpreter's exploratory data analysis outputs." width="700"></a></p>
</figure>
</div>
<p>This is a good, useful summary. The missing values in <code>bmi</code> are set to the median, which the user can later decide to change for themselves as the code is available to do so.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="images/pic5.png"><img src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/07/19/images/pic5.png" class="img-fluid figure-img" alt="Screenshot of code output from ChatGPT Code Interpreter, showing how to set missing values in dataset to the median value." width="700"></a></p>
</figure>
</div>
</section>
<section id="data-visualisation" class="level3">
<h3 class="anchored" data-anchor-id="data-visualisation">Data visualisation</h3>
<p>Next, the visualisations of the variables are shown along with a correlation heatmap. Users can toggle between the visualisations and the code. The outputs are pretty useful, except for one mistake: <code>id</code> shouldn’t be included as part of the heatmap.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="images/pic6.png"><img src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/07/19/images/pic6.png" class="img-fluid figure-img" alt="Screenshot of ChatGPT Code Interpreter's description of visualisations it will create, along with partial code for doing so." width="700"></a></p>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="images/pic7.png"><img src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/07/19/images/pic7.png" class="img-fluid figure-img" alt="Histograms and bar plots created by ChatGPT Code Interpreter for variables in the Kaggle stroke prediction dataset." width="700"></a></p>
</figure>
</div>
<div class="figure-caption" style="text-align: center;">
<p>Histograms and bar plots created by ChatGPT Code Interpreter for variables in the Kaggle stroke prediction dataset.</p>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="images/pic8.png"><img src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/07/19/images/pic8.png" class="img-fluid figure-img" alt="Correlation heatmap for variables in the Kaggle stroke prediction dataset." width="700"></a></p>
</figure>
</div>
<div class="figure-caption" style="text-align: center;">
<p>Correlation heatmap for variables in the Kaggle stroke prediction dataset.</p>
</div>
<p>Things start to go seriously awry when Code Interpreter tries to create a predictive model.</p>
</section>
<section id="the-predictive-model-is-garbage" class="level3">
<h3 class="anchored" data-anchor-id="the-predictive-model-is-garbage">The predictive model is garbage</h3>
<p>From the screenshot below, you can see that lumping all the data into a predictive model creates some highly spurious results. Age is a factor, as it should be, as is hypertension – indeed, those with hypertension in this dataset are around three times more likely to have a stroke than those without. In reality, there are also significant effects from glucose level and smoking, and also a slight BMI effect in this small, unbalanced dataset. However, <code>work_type_children</code> having a large positive effect is alarming and plainly wrong.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="images/pic9.png"><img src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/07/19/images/pic9.png" class="img-fluid figure-img" alt="Screenshot showing ChatGPT Code Interpreter's most important features for predicting stroke. The inclusion of 'work_type_children' is wrong: it says that 'individuals who are children are more likely to have a stroke', but goes on to explain that 'this might be the result of an imbalance in the dataset or noise, as in reality, children generally have a lower risk of stroke." width="700"></a></p>
</figure>
</div>
<p>It is very evident from the table below that the positive coefficient on children is spurious.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="images/pic10.png"><img src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/07/19/images/pic10.png" class="img-fluid figure-img" alt="Screenshot of table from ChatGPT code interpreter, showing 'number of individuals' and 'number of strokes' for each 'work type'. Figures for children are 687 individuals and 2 strokes." width="700"></a></p>
</figure>
</div>
<p>So, where does this leave our thinking about Code Interpreter?</p>
</section>
</section>
<section id="discussion" class="level2">
<h2 class="anchored" data-anchor-id="discussion">Discussion</h2>
<p>My test case is possibly an unfair one. The sort of study presented to Code Interpreter is one that requires careful analysis, and it uses a relatively small, tricky dataset whose difficulties are compounded by missing data. It’s therefore not surprising that, in this context, an automated analysis fails to shine in all respects.</p>
<p>To be fair, OpenAI themselves describe the plugin as an “<a href="https://openai.com/blog/chatgpt-plugins">eager junior programmer</a>”. And as would be the case with a real junior programmer or junior data scientist, you’d expect a more experienced hand to be guiding an analysis like the one I asked for – someone who can sense-check results, point out errors, and offer suggestions for fixes and improvements.</p>
<p>Despite some stumbles in this demo, OpenAI’s “junior programmer” presents a real step forward in the ChatGPT offering, and it is particularly impressive that one can toggle between code and charts without having to worry about coding at all.</p>
<p>At this stage, I would argue that Code Interpreter may be useful for quick summaries, visualisations and a little basic data cleaning and some preliminary investigations. However, based on what I’ve seen so far, it is clear to me that highly trained statisticians won’t be replaced anytime soon.</p>
<div class="article-btn">
<p><a href="../../../../../../viewpoints/editors-blog/index.html">Back to Editors’ blog</a></p>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-12">
<dl>
<dt>About the author</dt>
<dd>
<strong>Lee Clewley</strong> is a member of the <a href="https://realworlddatascience.net/viewpoints/editors-blog/posts/2022/10/18/meet-the-team.html">editorial board of Real World Data Science</a> and head of applied AI in GSK’s AI and Machine Learning Group, R&amp;D.
</dd>
</dl>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>Copyright and licence</dt>
<dd>
© 2023 Lee Clewley
</dd>
</dl>
<p><a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> <img style="height:22px!important;vertical-align:text-bottom;" src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/07/19/https:/mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/07/19/https:/mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"></a> This article is licensed under a Creative Commons Attribution 4.0 (CC BY 4.0) <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> International licence</a>. Thumbnail image by <a href="https://unsplash.com/@charlesdeluvio?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">charlesdeluvio</a> on <a href="https://unsplash.com/photos/pjAH2Ax4uWk?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Unsplash</a>.</p>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>How to cite</dt>
<dd>
Clewley, Lee. 2023. “Testing out ChatGPT’s new Code Interpreter.” Real World Data Science, July 19, 2023. <a href="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/07/19/code-interpreter.html">URL</a>
</dd>
</dl>
</div>
</div>
</div>


</section>

 ]]></description>
  <category>AI</category>
  <category>Large language models</category>
  <category>Coding</category>
  <category>Data analysis</category>
  <guid>https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/07/19/code-interpreter.html</guid>
  <pubDate>Wed, 19 Jul 2023 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/07/19/images/charlesdeluvio-pjAH2Ax4uWk-unsplash.png" medium="image" type="image/png" height="105" width="144"/>
</item>
<item>
  <title>Teaching a chatbot about love, and other adventures from London Data Week</title>
  <dc:creator>Brian Tarran</dc:creator>
  <link>https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/07/07/LDW.html</link>
  <description><![CDATA[ 




<p><a href="https://www.londondataweek.org/">London Data Week</a> wraps up on Sunday, and what a week it’s been! Kudos to organisers <a href="https://realworlddatascience.net/viewpoints/interviews/posts/2023/06/08/london-data-week.html">Sam Nutt and Jennifer Ding</a> for the huge amount of energy and passion they invested in making this idea a reality, and I’m looking forward to seeing what they have in store for us next year.</p>
<p>My highlights of the week? Well, of course, I really enjoyed being part of the event that was hosted at the Royal Statistical Society on Tuesday. The <a href="https://rss.org.uk/membership/volunteering-and-promoting/statisticians-for-society-initiative/">Statisticians for Society</a> workshop brought together charities and statisticians to explore ways in which data and statistics can support third sector organisations to deliver on their charitable aims as well as demonstrate to communities and funders the impact they are having. There’s a nice selection of <a href="https://rss.org.uk/membership/volunteering-and-promoting/statisticians-for-society-initiative/case-studies/">case studies of successful past projects on the RSS website</a>, and hopefully the London Data Week event will result in several new additions to this collection in due course.</p>
<p>I wasn’t able to attend this event myself, but I’m really looking forward to viewing the outputs of the <a href="https://betterimagesofai.org/images">Better Images of AI</a> workshop, which was also held on Tuesday. Real World Data Science has used several of the group’s images to illustrate past articles (<a href="https://realworlddatascience.net/viewpoints/editors-blog/posts/2022/11/23/LLM-content-warning.html#qa">here</a>, <a href="https://realworlddatascience.net/viewpoints/posts/2023/06/05/no-AI-probably-wont-kill-us.html">here</a> and <a href="https://realworlddatascience.net/ideas/posts/2023/07/03/trusted-AI.html">here</a>), so I’m excited to see what gets added to the image gallery in the coming weeks.</p>
<p>Sticking with the AI theme, I also got to explore the <a href="https://london.sciencegallery.com/ai-season">“AI: Who’s Looking After Me?” exhibition</a> at the Science Gallery, where I found myself unexpectedly moved by one installation in particular – <a href="https://london.sciencegallery.com/ai-artworks/newly-forgotten-technologies">an artificial landfill of broken and discarded tablets and smart speakers</a>, explaining matter-of-factly, but with an unmistakable air of mournfulness, that they had been replaced “by a newer model that is better because it is lighter, or heavier, or bigger, or smaller…”. Fortunately I was able to cheer myself up with another exhibit, which tasks visitors with <a href="https://london.sciencegallery.com/ai-artworks/looking-for-love">helping a chatbot to define and understand love</a>.</p>
<p>Later on in my visit to the Science Gallery (which was actually last Thursday, before London Data Week officially began), I listened to a panel debate on “Building Better AI in the Open”, featuring Margaret Mitchell of HuggingFace, Lara Groves of the Ada Lovelace Institute, and Irini Papadimitriou of FutureEverything, facilitated by artist and machine learning design researcher Caroline Sinders. A recording of the panel is below, and well worth a watch for discussion of:</p>
<ul>
<li>the advantages of open source versus closed source</li>
<li>the role of public participation in AI</li>
<li>what transparency in AI development should look like</li>
<li>issues of accountability in AI applications.</li>
</ul>
<p>Jennifer Ding followed up the panel with <a href="https://loti.london/blog/building-better-ai-in-the-open/">a thoughtful post on the benefits of open source AI</a>, and for more on trustworthy AI – and the need for transparency, explainability, and fairness – check out Maxine Setiawan and Mira Pijselman’s recent Real World Data Science article, <a href="https://realworlddatascience.net/ideas/posts/2023/07/03/trusted-AI.html">“Trusted AI: translating AI ethics from theory into practice”</a>.</p>
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/xddQq3opSzU" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<div class="article-btn">
<p><a href="../../../../../../viewpoints/editors-blog/index.html">Back to Editors’ blog</a></p>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-6">
<dl>
<dt>Copyright and licence</dt>
<dd>
© 2023 Royal Statistical Society
</dd>
</dl>
<p><a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> <img style="height:22px!important;vertical-align:text-bottom;" src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/07/07/https:/mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/07/07/https:/mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"></a> This article is licensed under a Creative Commons Attribution 4.0 (CC BY 4.0) <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> International licence</a>. Thumbnail image by <a href="https://unsplash.com/it/@bendavisual?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Benjamin Davies</a> on <a href="https://unsplash.com/photos/Oja2ty_9ZLM?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Unsplash</a>.</p>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>How to cite</dt>
<dd>
Tarran, Brian. 2023. “Teaching a chatbot about love, and other adventures from London Data Week.” Real World Data Science, July 7, 2023. <a href="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/07/07/LDW.html">URL</a>
</dd>
</dl>
</div>
</div>
</div>



 ]]></description>
  <category>AI</category>
  <category>Open source</category>
  <category>Accountability</category>
  <category>Public opinion</category>
  <guid>https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/07/07/LDW.html</guid>
  <pubDate>Fri, 07 Jul 2023 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/07/07/images/benjamin-davies-Oja2ty_9ZLM-unsplash.png" medium="image" type="image/png" height="105" width="144"/>
</item>
</channel>
</rss>
