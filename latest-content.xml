<?xml version="1.0" encoding="UTF-8"?>
<rss  xmlns:atom="http://www.w3.org/2005/Atom" 
      xmlns:media="http://search.yahoo.com/mrss/" 
      xmlns:content="http://purl.org/rss/1.0/modules/content/" 
      xmlns:dc="http://purl.org/dc/elements/1.1/" 
      version="2.0">
<channel>
<title>Real World Data Science</title>
<link>https://realworlddatascience.net/latest-content.html</link>
<atom:link href="https://realworlddatascience.net/latest-content.xml" rel="self" type="application/rss+xml"/>
<description></description>
<image>
<url>https://realworlddatascience.net/images/rwds-logo-150px.png</url>
<title>Real World Data Science</title>
<link>https://realworlddatascience.net/latest-content.html</link>
<height>83</height>
<width>144</width>
</image>
<generator>quarto-1.4.555</generator>
<lastBuildDate>Wed, 05 Jun 2024 15:22:05 GMT</lastBuildDate>
<item>
  <title>Forecasting the Health Needs of a Changing Population</title>
  <dc:creator>Luke Shaw (BNSSG ICB), Rich Wood (BNSSG ICB, University of Bath), Christos Vasilakis (University of Bath), Zehra Onen Dumlu (University of Bath)</dc:creator>
  <link>https://realworlddatascience.net/case-studies/posts/2024/05/08/dpm.html</link>
  <description><![CDATA[ 





<section id="background" class="level2">
<h2 class="anchored" data-anchor-id="background">Background</h2>
<p>Decisions around medium and long-term allocation of healthcare resources are fraught with challenges and uncertainties, which explains the use of blunt resource allocations based on across-the-board annual percentage uplifts.</p>
<p>The Bristol, North Somerset, South Gloucestershire Integrated Care Board (BNSSG ICB - we love elaborate acronyms in the National Health Service!), in the south west of England, is part of the local NHS apparatus responsible for planning the current and future health needs of the one million resident population.</p>
<div id="fig-bnssg-map" class="quarto-figure quarto-figure-center quarto-float anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-bnssg-map-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="tv-iframe-container">
  <iframe class="responsive-iframe" src="images/bnssg-map.html" title="fig-bnssg-map" width="80%" height="500"></iframe>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-bnssg-map-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;1: A map of the area covered by BNSSG, a space covered by three local authorities, with about 1 million people living inside it.
</figcaption>
</figure>
</div>
</section>
<section id="population-segmentation" class="level2">
<h2 class="anchored" data-anchor-id="population-segmentation">Population Segmentation</h2>
<p>Before tackling the complex problem of forecasting healthcare resources into the future, we first need to understand the current situation regarding the distribution of health needs.</p>
<p>While every individual has a unique set of circumstances, population segmentation is an approach used to help understand overall need by combining individuals into different groups, based on certain criteria.</p>
<p>We use the <a href="https://pubmed.ncbi.nlm.nih.gov/32015079/">Cambridge Multimorbidity Score</a> which is a metric designed to summarise the presence of multiple health conditions, known as multimorbidity. Using that score, which applies different weights to different health conditions, we <a href="https://www.tandfonline.com/doi/full/10.1080/20479700.2023.2232980">previously</a> found a way of splitting the adult (17+) population into five Core Segments, with <span style="color:#77A033;"><strong>Core Segment 1</strong></span> patients having the lowest score and being the least ill and <span style="color:#FF6C53;"><strong>Core Segment 5</strong></span> being those with the most multimorbidity.</p>
<p>Applied to the BNSSG adult population (of around 750K individuals), the following interesting properties were found:</p>
<ol type="1">
<li><strong>Halving</strong>: Going up one segment results in roughly half the number of people in that segment</li>
<li><strong>Doubling</strong>: Going up one segment results in roughly twice the NHS monetary spend per person per year</li>
</ol>
<p>We can see this in Figure&nbsp;2.</p>
<div id="fig-halving-doubling" class="quarto-figure quarto-figure-center quarto-float anchored" alt="Table showing the 5 Core Segments with CS1 having a Cambridge Score of <0.09, 52% of the population and £300 mean annual spend per person as the first row. This then changes by row through to CS1 having a Cambridge Score of >2.94 with 3% of the population and £5600 mean annual spend per person as the last row. The propoportion of population column roughly halved row-by-row, the mean annual spend per person roughly doubled row by row.">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-halving-doubling-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="https://realworlddatascience.net/case-studies/posts/2024/05/08/images/halving-doubling-no-arrows.png" class="img-fluid figure-img" alt="Table showing the 5 Core Segments with CS1 having a Cambridge Score of <0.09, 52% of the population and £300 mean annual spend per person as the first row. This then changes by row through to CS1 having a Cambridge Score of >2.94 with 3% of the population and £5600 mean annual spend per person as the last row. The propoportion of population column roughly halved row-by-row, the mean annual spend per person roughly doubled row by row.">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-halving-doubling-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2: Halving-Doubling Effect of the Core Segments
</figcaption>
</figure>
</div>
</section>
<section id="sec-creating-the-model" class="level2">
<h2 class="anchored" data-anchor-id="sec-creating-the-model">Creating The Model</h2>
<p>To forecast health needs of the population, in terms of how many people will be in which Core Segment in what future year, the Dynamic Population Model (DPM) takes information from two different sources:</p>
<ol type="1">
<li><p>The Office for National Statistics <a href="https://www.ons.gov.uk/peoplepopulationandcommunity/populationandmigration/populationprojections/datasets/localauthoritiesinenglandtable2">projections</a> for our area. From this, we get yearly projections for not just the total 17+ population, but also the predicted number of people turning 17 (and so entering our model), deaths, and in- and out-ward migration.</p></li>
<li><p>NHS patient attribute and activity data, stored in the <a href="https://bnssghealthiertogether.org.uk/population-health-management/">System Wide Dataset</a> (SWD). This gives us: past and current information on the adult population’s NHS healthcare usage; the Core Segment breakdown of our current and past populations; the proportion of those turning 17, migrating, and dying that are in each Core Segment. From this, we estimate the historical rates of transition within Core Segments, which is essentially the yearly number of people getting sicker or healthier.</p></li>
</ol>
<p>By synthesising these pieces of data, we create our DPM forecast. Starting from the most up to date Core Segment population breakdown, the model takes yearly time steps into the future, at each time step using the inputs to estimate how many people are to be in each Core Segment. This modelling approach of having discrete time steps and different movements between states can be set up as a Markov chain, although here we have formulated it as a set of difference equations - through which the outflow of each Core Segment population at each time step is deterministic. The design was led by <a href="https://researchportal.bath.ac.uk/en/persons/zehra-onen-dumlu">Zehra</a> and <a href="https://researchportal.bath.ac.uk/en/persons/christos-vasilakis">Christos</a>, through a collaboration between the NHS and the <a href="https://www.bath.ac.uk/research-centres/centre-for-healthcare-innovation-and-improvement-chi2/">Centre for Healthcare Innovation and Improvement (CHI2)</a> at the University of Bath.</p>
<p>The model can be thought of as having the following inputs:</p>
<table class="caption-top table">
<colgroup>
<col style="width: 31%">
<col style="width: 59%">
<col style="width: 8%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">Model Input</th>
<th style="text-align: left;">Description</th>
<th style="text-align: left;">Data Source</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">initial population</td>
<td style="text-align: left;">The starting number of people in each Core Segment</td>
<td style="text-align: left;">SWD</td>
</tr>
<tr class="even">
<td style="text-align: left;">inner transition matrix</td>
<td style="text-align: left;">The yearly proportions of people moving from one Core Segment to another</td>
<td style="text-align: left;">SWD</td>
</tr>
<tr class="odd">
<td style="text-align: left;">births, net migration, deaths - numbers</td>
<td style="text-align: left;">The yearly number of people moving in and out of the area</td>
<td style="text-align: left;">ONS</td>
</tr>
<tr class="even">
<td style="text-align: left;">births, net migration, deaths - proportions</td>
<td style="text-align: left;">The proportion of births/migrations/deaths that come from each Core Segment group</td>
<td style="text-align: left;">SWD</td>
</tr>
</tbody>
</table>
<p>From these inputs, it deterministically outputs the yearly forecasts for the number of people in each Core Segment. From these yearly Core Segment population figures, we can also forecast use by point of delivery by taking historic SWD information on the activity used by current Core Segment breakdown, under the assumption that stays the same into the future.</p>
<p>We combine these population health segment projections – i.e., how many people will be in which Core Segment in what future year – with recent NHS healthcare usage data to yield forecasted changes for various delivery points, like Emergency Department (ED) visits or maternity service appointments.</p>
</section>
<section id="findings" class="level2">
<h2 class="anchored" data-anchor-id="findings">Findings</h2>
<p>The first output of the model is the population forecast for each Core Segment, as plotted in Figure&nbsp;3. The visualisation is a type of sankey diagram called an alluvial plot, which shows the proportion of people moving between the Core Segments each year. As it is to be expected, the majority of individuals stay in the same Core Segment year-on-year as the process of acquiring conditions and developing multimorbidity takes places over many years and decades.</p>
<p>The concerning insight shown in Figure&nbsp;3 is that all Core Segments apart from (the most healthy) <span style="color:#77A033;"><strong>Core Segment 1</strong></span> are due to increase in size, with <span style="color:#FF6C53;"><strong>Core Segment 5</strong></span> having the largest percentage increase over the next 20 years. While, at first glance, this could be attributed to the effect an ageing population, in which people are staying alive for longer we will see in the next set of results that this itself does not wholly explain the forecasted Core Segment changes.</p>
<div id="fig-sankey" class="quarto-figure quarto-figure-center quarto-float anchored" alt="over 20 years when scaled to 1000 population initially we have that population changes in the following ways: CS1 decreases from 520 to 490, CS2 increases from 240 to 310, CS3 increased from 130 to 180, CS4 increases from 70 to 110, CS5 increases from 40 to 60.">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-sankey-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="https://realworlddatascience.net/case-studies/posts/2024/05/08/images/dpm-sankey-no-title.png" class="img-fluid figure-img" alt="over 20 years when scaled to 1000 population initially we have that population changes in the following ways: CS1 decreases from 520 to 490, CS2 increases from 240 to 310, CS3 increased from 130 to 180, CS4 increases from 70 to 110, CS5 increases from 40 to 60.">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-sankey-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;3: All Core Segments, except the most healthy (CS1), are forecast to increase in size. BNSSG Population rescaled to have an initial population of 1,000.
</figcaption>
</figure>
</div>
<p>In applying the typical NHS healthcare usage per Core Segment to the projections of Figure&nbsp;3, we derive the expected future healthcare usage for various healthcare settings (Figure&nbsp;4). In overlaying to these the equivalent projections due solely to demographic factors (both for total population size and capturing the effect of Age and Sex), we see that the DPM projections for increased resource use are not solely attributable to an ageing and growing population, but also to a population becoming gradually less healthy over time.</p>
<p>Specifically, from Figure&nbsp;4 we can glean the following insights:</p>
<ol type="a">
<li><p>In all areas except Maternity, the DPM forecasts an increased use beyond just the growing, aging population. The reason that Maternity can be explained as the exception is due to it closely following the demographic changes forecast, specifically for numbers of women of child bearing age.</p></li>
<li><p>For Community contacts, with the highest proportion of use from <span style="color:#FF6C53;"><strong>Core Segment 5</strong></span> patients, the DPM forecasts the highest increase into the future. This is because, relative to current size, the number of <span style="color:#FF6C53;"><strong>Core Segment 5</strong></span> patients is set to increase the largest and so that has the largest impact on Community contacts, which include home visits to patients to support rehabilitation and services to manage long-term mobility issues such as physiotherapy.</p></li>
<li><p>Whilst Secondary Elective and Non-Elective activity is forecast to grow at similar rates, the Carbon and Cost values are forecast to grow more for Secondary Non-Elective due to the average Carbon and Cost usage per person in Core Segment 5 being higher. In this context ‘Secondary’ is a hospital stay, with ‘Elective’ being planned and ‘Non-Elective’ being unplanned. For example, a hip replacement is elective whereas an admission following a road traffic accident is non-elective.</p></li>
</ol>
<div id="fig-pod-forecasts" class="quarto-figure quarto-figure-center quarto-float anchored" alt="the image shows 15 separate graphs, with the columns being Community, Maternity, Secondary Elective, Secondary Non-Elective and Total, and the rows being Activity, Carbon, and Cost. All graphs have similar overall shape of increase into the future, but with different gradients.">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-pod-forecasts-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="https://realworlddatascience.net/case-studies/posts/2024/05/08/images/dpm-pod-forecasts.png" class="img-fluid figure-img" alt="the image shows 15 separate graphs, with the columns being Community, Maternity, Secondary Elective, Secondary Non-Elective and Total, and the rows being Activity, Carbon, and Cost. All graphs have similar overall shape of increase into the future, but with different gradients.">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-pod-forecasts-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4: Forecasts by activity, carbon, and cost for four different points of delivery.
</figcaption>
</figure>
</div>
</section>
<section id="limitations" class="level2">
<h2 class="anchored" data-anchor-id="limitations">Limitations</h2>
<blockquote class="blockquote">
<p>It’s difficult to make predictions, especially about the future.</p>
<p>– <cite>Danish Proverb</cite></p>
</blockquote>
<p>As with any modelling / forecasting method, there are limitations to be mindful of.</p>
<ol type="1">
<li><p>The cost and activity usage estimates are made under the assumption that we will continue to deliver services as they are currently being delivered. We know this isn’t going to be true, as healthcare-seeking behaviour evolves over time, with younger people accessing healthcare in different ways to previous generations. On top of that, healthcare advances can result in significant changes in healthcare provision, in ways unaccounted for within this model.</p></li>
<li><p>The model is tied to ONS forecasts for population change, and robust forecasting is hard. It is difficult to estimate what the population will look like in 20 years’ time, and the influence of uncertain and unknown future local development and housing plans. Having said this, population forecasts tend to be robust, one way to consider this is that everyone who will be an adult by the end of the forecast in 20 years’ time has already been born.</p></li>
<li><p>The DPM does not explicitly account for the interaction of demand and capacity: it simply predicts future healthcare resource requirement assuming that health needs of a given Core Segment patient are met in the same way they are met now. This is an essential assumption to help ensure legitimate use of the empirically derived Core Segment transition rates. However, it inevitably limits practical use, as flexing demand and capacity assumptions is of importance to planners and service managers.</p></li>
<li><p>It is not possible to validate the model on historic data, firstly because of point 3. above but also because we only have good quality SWD information for the past two years, so cannot reliably look further back into the past and create a forecast that we can check against what actually happened.</p></li>
<li><p>Whilst it is possible to use the model in other healthcare systems and geographic areas, the underlying data required to generate the Core Segments is non-trivial, so significant data pipelining may be required to get to create local model inputs, as explained above in Section&nbsp;3.</p></li>
</ol>
</section>
<section id="what-next" class="level2">
<h2 class="anchored" data-anchor-id="what-next">What Next</h2>
<p>We have already generated local use cases for the DPM in forecasting different geographical areas or specific hospital trusts. We envisage the DPM becoming a standard tool in most forward planning initiatives and will continue to refine the model as more information becomes available both for calibration and validation.</p>
<p>Outside of BNSSG, we are keen to disseminate our modelling approach to others who may be interested, as well as expanding our collaboration. There are also other innovative approaches in this space, such as the <a href="https://www.health.org.uk/publications/health-in-2040">Health in 2040</a> report by the Health Foundation which looks at England-level and uses the same ONS forecasts, but using a different ‘micro simulation’ modelling approach.</p>
<blockquote class="blockquote">
<p>If long-term forecasting in the NHS is of interest to you and your work, we’d love to chat! Please get in touch at <a href="mailto:bnssg.analytics@nhs.net">bnssg.analytics@nhs.net</a></p>
</blockquote>
</section>
<section id="summary" class="level2">
<h2 class="anchored" data-anchor-id="summary">Summary</h2>
<p>Reliably forecasting longer-term population health needs and healthcare resource requirements is essential if the NHS is to effectively plan for tomorrow’s problems today.</p>
<p>While this is undoubtedly a difficult problem – both conceptually and statistically – our modelling, undertaken through an academic-NHS collaboration, demonstrates that there are alternatives beyond the commonly-used but simplistic approaches based only on demographic factors.</p>
<div class="article-btn">
<p><a href="../../../../../case-studies/index.html">Find more case studies</a></p>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-12">
<dl>
<dt>About the authors</dt>
<dd>
<strong>Luke Shaw</strong> is a Data Scientist working in the NHS.
</dd>
<dd>
<strong>Rich Wood</strong> is Head of Modelling Analytics at BNSSG ICB and Senior Visiting Research Follow at University of Bath School of Management.
</dd>
<dd>
<strong>Christos Vasilakis</strong> is Director of the Centre for Healthcare Innovation and Improvement (CHI2), and Professor at the University of Bath School of Management.
</dd>
<dd>
<strong>Zehra Onen Dumlu</strong> is a Research Associate at CHI2 and Lecturer at the University of Bath.
</dd>
</dl>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>Copyright and licence</dt>
<dd>
© 2024 Luke Shaw
</dd>
</dl>
<p><a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> <img style="height:22px!important;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"></a> This article is licensed under a Creative Commons Attribution 4.0 (CC BY 4.0) <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> International licence</a>.</p>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>How to cite</dt>
<dd>
Shaw, Luke et al 2024. “Forecasting the Health Needs of a Changing Population” Real World Data Science, May 08, 2024. <a href="https://realworlddatascience.net/case-studies/posts/2024/05/08/dpm.html">URL</a>
</dd>
</dl>
</div>
</div>
</div>


</section>

 ]]></description>
  <category>Health and Wellbeing</category>
  <category>Forecasting</category>
  <guid>https://realworlddatascience.net/case-studies/posts/2024/05/08/dpm.html</guid>
  <pubDate>Wed, 05 Jun 2024 15:22:05 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/case-studies/posts/2024/05/08/images/doctor-patient-thumbnail.png" medium="image" type="image/png" height="105" width="144"/>
</item>
<item>
  <title>AI series: What is “best practice” when working with AI in the real world?</title>
  <dc:creator>Anna Demming</dc:creator>
  <link>https://realworlddatascience.net/ideas/posts/2024/06/04/ai-series-6.html</link>
  <description><![CDATA[ 





<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/SoOoj9iUTM0" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<p>Over the course of the Real World Data Science AI series, we’ve had articles laying out the nitty gritty of what AI is, how it works, or at least how to get an explanation for its output as well as burning issues around the data involved, evaluating these models, ethical considerations, and gauging societal impacts such as changes in workforce demands. The ideas in these articles give a firm footing for establishing what best practice with AI models should look like but there is often a divide between theory and practice, and the same pitfalls can trip people up again and again. Here we discuss how to wrestle with real world limitations and flag these common hazards.</p>
<p>Our interviewees, in order of appearance, are:</p>
<p><strong>Ali Al-Sherbaz</strong>, academic director in digital skills at the University of Cambridge in the UK</p>
<p><strong>Janet Bastiman</strong>, Napier chief data scientist and chair of the Royal Statistical Society Data Science &amp; AI Section</p>
<p><strong>Jonathan Gillard</strong>, professor of statistics/data science at Cardiff University, and a member of the Real World Data Science Board</p>
<p><strong>Fatemeh Torabi</strong>, senior research officer and data scientist, health data science at Swansea University, and also a member of the Real World Data Science board</p>
<p><strong>It is often said that while almost everybody is now trying to leverage AI in their projects, most AI projects fail. What nuggets of wisdom do the panel have for swelling that minority that succeed with their AI projects, and what should you do before you start doing anything?</strong></p>
<p><strong>Ali Al-Sherbaz</strong>: It’s not easy to start, especially for people who are not aware how AI works. My advice is, first, they have to understand the basics of how AI works because the expectation could be overpromising, and that is a danger. Just 25 years ago, a master dissertation might be about developing a simple – we call it simple now but it was a master’s project 25 years ago – a simple model with a neural network of a combination of nodes to classify data. Whatever the data is – it could be drawing shapes, simple shapes, square, circle triangle – just classifying them was worth an MSc. Now, kids can do it. But that is not the same as understanding what the neural network or the AI is. It’s a matrix of numbers, and actually, for the learning process each does multiple iterations to find the best combination of these numbers – product of sum; sum of product – to classify, to do something, and train them for a certain situation, and that is a supervised learning. Over the last 25 years – especially in the last 10 years – the computational power is getting better, so AI is now working better.</p>
<p>There are other things people have to learn. There’s the statistics as well, and of course people who would like to work in AI and data science must understand the data, and they should also be experts in the data itself. For instance, I can talk about cybersecurity, I can talk about networking and other things, but if it comes to something regarding health data, or financial services, or stock markets, I’m not an expert in the data. So I’m not going to be actively working on those things even if I use the same AI tools. This is in a nutshell why I think some people fail sometimes using AI, or they succeed using AI. And we should emphasise the human value. The AI is there, and it exists to help us to make a better more accurate decision, but the human value is still there. We have to insist on that.</p>
<p><strong>Janet Bastiman</strong>: I would just like to build on all of that great stuff that Ali’s just said. When you look at basically the non-data scientist side of it, you often get businesses who think AI can solve a certain problem. They might go out and hire a team – whether that’s directly or indirectly – and get them to try and solve a problem that, as Ali said, they may not have the domain expertise for. The business might not even have the right data for it, and AI might not even be the right way of solving that problem. I think that’s one of the fundamental things to think about – really understanding what you’re trying to solve, and how you’re going to solve it before you start throwing complex tools, and potentially very expensive teams at the problem.</p>
<p>When you look at a lot of the failures, it’s been because businesses have just gone, we can solve this problem, I’m just going to hire a team and let these intelligent people look at something. And then they’re restricted on the data that they’ve got, which won’t even answer the question; they’re restricted on the resources they have; and even restricted in terms of wider buy in from the company. So really understanding what is it that you want to solve? What are you trying to do? Is AI the right thing? And can you even do it with the resources you have available? And I think that’s, that’s a fundamental starting point. Because, you can have wonderful experts, who have that domain knowledge, who understand the statistics, and all that essential stuff that Ali just said. But then if from a business point of view, if you don’t give them the right data to work on, or you don’t let them do their job and tell you when they can’t do their job, then again, you’re going to be doomed to failure.</p>
<p><strong>Jonathan Gillard</strong>: Explainability is a big issue when it comes to AI models, as well. They are at the moment, very largely “black box” – data goes in, then these models get trained on dumb data and answers get popped out. And when it works, well, it works fabulously well. And we’ve seen lots of examples of that happening. But often for business, industry or real life, we want to learn. We want to understand the laws of the universe, and to understand the reasons why this answer came about. Because this explainability piece is missing – because everything is hidden away almost – I think that’s a big issue in successful execution. And particularly when it comes to industries where there’s a degree of regulation there as well, if you can’t explain how a particular input arose to a particular output, then how can you justify to regulatory bodies that what you’ve got is satisfactory, ethical, and that you’re learning and you’re doing things in the right way?</p>
<p><strong>There have been efforts at trying to get explanations from these models. How do you think things are progressing there?</strong></p>
<p><strong>JG</strong>: Yeah, that’s a good question. I think where we are with explainability is in very simple scenarios, very simple models. This is where traditional statistical models do very well. There’s an explicit model which says if you put these things inside then you’ll get this output. So [for today’s AI] I think we’re actually very far away from having that complete explainability picture, particularly as we fetishise more and more grand models. The AI models are only getting bigger, more complex, and that makes the explainability per se even more challenging. And that’s why I think, as Ali says, at the moment, the human in the loop is absolutely crucial.</p>
<p>What AI does share with classical statistics (or classical data science if you want to call it that) is it can still only be as good as the data that’s put into it, that’s still a fundamental truth. I think a lot of the assumptions currently with AI models – and this is where there could be a few trip ups is that it can create something from nothing. It’s “artificial intelligence” – almost the wording suggested it’s artificial. But fundamentally, we still need a robust and reliable comprehensive source of data there in order to train these models in the first place.</p>
<p><strong>In terms of having outsourced expertise for these projects– does that make more problems if you’re then trying to understand what this AI has done?</strong></p>
<p><strong>JB</strong>: Oh, hugely. Let’s say that domain expertise – that’s something Ali touched on –you’ve got to understand your data. Because even that fundamental initial preparation of data before you try and train anything is absolutely crucial – really looking at where are the gaps? Where are the assumptions? How is this data even being collected? Has it been manipulated before you got to it? If you don’t understand your industry, well enough you won’t know where those pitfalls might be – and a lot of teams do this, they just take the data, and then they just put it in, turn the handle and out comes something and it looks like it’s okay. What they’re really missing there – because they’re not putting that effort in to really understand those inputs, what the models are doing, they’re just turning the handle until they get something that feels about right – what they miss out is where it goes wrong. And there are some industries, where the false positives and false negatives from classification or the bad predictions from running things really have a severe human impact. And if you don’t understand what’s going in, and the potential impact of what comes out, then it’s very, very easy to just churn these things out and go, “it’s 80% accurate, but that’s fine” without really understanding the human impact of the 20% [that it gets wrong].</p>
<p>Going back to what Jon said about that explainability, it’s so crucial. It is challenging, and it is difficult, but going from these opaque systems to more transparent systems – we need that for trust. As humans, we divulge our trust very differently, depending on the impact. One of the examples I use all the time is, you know, sort of weather prediction stuff, you know, we don’t really care too much, because it’s not got a huge impact. But when you look at sort of financials or medicals, we really, really want to know that that output is good, and how we got to that output. The Turing Institute’s come out with some great research that says, as humans, if we want to understand why when another human has told us something, then we want the same thing from the models, and that can vary from person to person. So building that explainable level into everything we do, has to be one of the things we think about upfront. But you’ve got to really, truly deeply understand that data. And it’s not just a question of offloading a data set to a generalist who can turn that handle, otherwise you will end up with huge, huge problems.</p>
<p><strong>Fatemeh Torabi</strong>: I very much agree with all the points that my colleagues raised. I also think it’s very important that we know why we are doing things. Having those incremental stages in our planning for any project, and then having a vision of where we see AI can contribute into this process and can give us further efficiency – and how – is very important. If we don’t have defined measures to see how this AI algorithm is contributing to this specific element of the project, we can get really lost bringing these capabilities on board. Yes, it might generate something, but how we are going to measure that something is very important. I think, as members of the scientific community, we must all view AI as a valuable tool. However, it has its own risks and benefits.</p>
<p>For example, in healthcare when we use AI for risk predictions, it can be a really great tool to aid clinicians to save time. However, in each stage, we need to assess the data quality, how these data are fed into the algorithm, what procedures, what models, and how we generate those models. And then which discriminative models do we use to balance the risk and eventually predict the risk of outcomes in patients? It’s very much a balance between risks and benefits for usefulness of these tools in practice. We have all these brilliant ideas of what best practice is. But in real terms, sometimes it’s a little bit tricky to follow through.</p>
<p><strong>Could you give us some thoughts on the sort of best practice with data, for example, that doesn’t quite turn out to be quite so easy to follow in practice, and what you might do about it?</strong></p>
<p><strong>FT</strong>: We always call these AI algorithms, data hungry algorithms, because the models that we fit require us to see patterns in the data that we feed into them so that the learning happens. And then the discriminative functions come in place to balance and kind of give a score to wherever the learning is happening and give an evaluation of each step. However, the data that we put into these algorithms comes first – the quality of that data. Often in healthcare, because of its sensitivity, the data is held within a secure environment. So we cannot, at this point in time, expose an AI algorithm to a very diverse example, specifically for investigating rare diseases or rare conditions. And above that, there is also complexities in the data itself. We need to evaluate and clean the data before we feed it into these algorithms. We need to evaluate the diversity of the data itself – for example, the tabular data, the imaging data, the genomic data – and each one requires its own specific or tailored approach in data cleaning stages.</p>
<div id="fig-1" class="quarto-figure quarto-figure-center quarto-float anchored" data-fig-align="center" alt="The panel. Clockwise from top left: Ali Al-Sherbaz, Janet Bastiman, Fatemeh Torabi and Jonathan Gillard">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="https://realworlddatascience.net/ideas/posts/2024/06/04/images/panel-991.jpg" class="img-fluid quarto-figure quarto-figure-center figure-img" alt="The panel. Clockwise from top left: Ali Al-Sherbaz, Janet Bastiman, Fatemeh Torabi and Jonathan Gillard">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;1: The panel. Clockwise from top left: Ali Al-Sherbaz, Janet Bastiman, Fatemeh Torabi and Jonathan Gillard
</figcaption>
</figure>
</div>
<p>We also have another level that is now being discovered in the health data science community, which is the generation of synthetic data. We can give AI models access to these synthetic versions of the data that we hold. However, that also has its own challenges because it requires reading the patterns from real data, and then creating those synthetic versions of data.</p>
<p>For example, Dementia Platforms UK is one of the pioneers in developing this. We hold a range of cohort data, patients’ data, genomics data and imaging data. In each one of these when we try to develop those processing algorithms, there are specific tailored approaches that we need to consider to ensure we are actually creating a low fidelity level of data that is holding some of the patterns in it for the AI algorithm to allow the learning to happen. However, we also need to consider whether it is safe enough so that we can ensure the data provided are secure to be released for use at a lower governance level compared to the actual data. So there are quite a lot of challenges, and we captured a lot of it in our <a href="https://realworlddatascience.net/ideas/posts/2024/05/07/ai-series-3.html">article</a>.</p>
<p><strong>A A-S</strong>: I can talk about the cybersecurity and other relevant data network security, the point being the amount of data we receive to analyse. It’s really huge. And when I say huge I mean about one gigabyte, probably in a couple of hours, or one terabyte in a week – that’s huge. One gigabyte of a text file – if I printed out this file with A4 – that would leave me with a stack of A4 paper, three times the Eiffel Tower.</p>
<p>Now, if I have cyber traffic, and try to detect any cyber attack, AI helps with that. However, if we train this model properly, they have to detect cyber attacks in real time – when I say real time, we’re talking about within microseconds or a millisecond – and the decision has to be correct. AI alone doesn’t work, doesn’t help. Humans should also intervene, but rather than having 100,000 records to check for a suspected breach, AI can reduce that to 100. A human can interact with that. And then in terms of the authentication or verification, humans alongside AI can learn whether this is a false positive, or a real attack or a false negative. This is a challenge in the cybersecurity area.</p>
<p><strong>JB</strong>: I just wanted to dive in from the finance side – again the data is critical, and we have very large amounts of data. However in addition – and I think we probably suffer from the same sort of problem that Ali does in this – when I’m trying to detect things, there are people on the other side actively working against what I’m trying to detect, which I suppose is a problem that maybe Fatemeh doesn’t have in healthcare.</p>
<p>When you’re trying to build models to look for patterns, and those patterns are changing underneath you, it can be incredibly difficult. I have an issue that all of my client’s data legally has to be kept separated – some of it has to be kept in certain parts of the world so we can’t put that into one place. We can try and create synthetic data that has the same nuances of the snapshots that we can see at any one point in time, and we can try and put that together in one place, but what we can detect now will very quickly not be what we need to detect in a month’s time. As soon as transactions start getting stopped, as soon as suspicious activity reports are raised, and banks are fined, everything switches and how all of that financial crime occurs, changes. And it’s changing, on a big scale worldwide, but also subtly because, there are a team of data scientists on the other side trying desperately to circumvent the models that me and my team are building. It’s absolutely crazy. So while I would love to be able to pull all of the data that I have access to in one place and get that huge central visual view, legally I can’t do that because of all the worldwide jurisdictional laws around data and keeping it in certain places.</p>
<p>Then I’ve also got the ethical side of it, which is something that Fatemeh touched on. If I get it wrong, that can have a material impact on usually some of the most marginalised in society. The profile of some of the transactions that are highly correlated with financial crime are also highly correlated with people in borderline poverty, even in Western countries. So false positives in my world have a huge, huge ethical impact. But at the same time, we’re trying really hard to minimise those false negatives – that balance is critical, and the data side of it is such a problem.</p>
<p>Fatemeh mentioned the synthetic side of it. There’s a huge push, particularly in the UK to get good synthetic data to really showcase some of these things that we’re trying to detect. But by the time you get that pooling, and the synthesising of data that you can ethically use and share around without fear of all the legal repercussions, what we’re trying to detect has already moved on. So we’re constantly several steps behind.</p>
<p>I imagine Ali has similar problems in the cybercrime space in that as soon as things are detected, the ways in which they work move on. So there’s an awful lot I think that, as an industry, although we have different verticals, we can share best practices on.</p>
<p><strong>Is there a demand for new types of expertise?</strong></p>
<p><strong>A A-S</strong>: There is a huge gap in the in the UK, at least and worldwide about finding people working as a data scientist or working with the data. So we created a course in Cambridge, which we call the data science career accelerator for people who work in data, and would like to move on and learn more. We did market research, and we interviewed around 50 people between CEO and head of security and head of data scientists, in science departments and in industry, to tell us – what kind of skills are you after? What problems do you currently have? And then we designed this course.</p>
<p>We found that first of all there are people who don’t know from where to start – what kind of data they need, what tools they have to learn with… Even if they learn the tools, they still need to learn what kind of machine learning process to use. And then suddenly, we have ChatGPT turned out, and the LLM [large language model] development – all of that in one course, it is a real challenge.</p>
<p>The course has started now, the first cohort. The big advice from industry we have is that during the course they have to work on real world case studies, on scenarios with data that nobody has touched before – that is, it’s new, not public. We teach them on a public data, but companies also have their own data, and we get consent from them to use that data for the students so we can test the skills they learned on virgin data that nobody has touched before.</p>
<p>We just started this month, and the students are going to start with the first project now. They are enjoying the course but that is the challenge we have now. How did we handle that? It’s to work together with the industry side by side, even during the delivery. We have an academic from Cambridge, and we have experts from the industry to support the learners to learn to get the best of both worlds.</p>
<p><strong>The industry has changed so much in the last couple of years. Does that mean that the expertise and demands are also changing very quickly or is there a common thread that you can work with?</strong></p>
<p><strong>A A-S</strong>: Well, there is a common thread, but having new tools – I mean, Google just released Gemini, and that’s a new skill they have learnt and been tested on, and looked into how others feel about it and compared it to ChatGPT, or Claude 3 or Copilot. That’s all happened in the last 12 months. And then, of course, reacting on that, reflecting on the material, teaching the material – it’s a challenge. It’s not easy and you need to find the right person. Of course, people who have this kind of experience are in demand, and it’s hard to secure these kinds of human resources as well as to deliver the course. So there are challenges and we have to act dynamically and be adaptive.</p>
<p><strong>What are your thoughts on the evaluation of these models, and how to manage the risk of something that you haven’t thought of before, and the role of regulation.</strong></p>
<p><strong>JG</strong>: I think a lot of our discussions at the moment are assuming that we’ve got well meaning, well intentioned people and well meaning, well intentioned companies and industries, who are trying to seek to do their best ethically and regulatorily and with appropriate data, and so on. But there is a space here for bad actors in the system.</p>
<p>Unfortunately, digital transformation of human life will happen in a good and bad way – unfortunately, I think there are going to be those two streams to this. Individuals are very capable now of making their own large language models by following a video guide if they wanted to, and having that data is, of course going to enable them maybe to do bad things with it.</p>
<p>Data is already a commodity in quite a strong way, but I do think we have to visit data security, and even the risks of open data as well. We live in a country, which I think does very well in producing lots of publicly available data. But that could be twisted in a way that we might not expect. And when I speak of those things, we’re usually thinking of groundwork – writing and implementing your own large language models – but there were recent examples of where just by using very clever prompting of existing large language models, you could get quite dangerous material, shall we say, which circumnavigated inbuilt existing safeguards. Again, that’s an emerging thing that we have to have to try and address as it comes on.</p>
<p>I think my final point with ethics and regulation is it will rapidly evolve, and it will rapidly change. And a story which I think can illustrate that is, when the first motorcar was introduced into the UK, it was law for a human to walk in front of the motorcar with a large red flag to warn passers-by of the incoming car because people weren’t really familiar with it. Now, of course, that’s in distant memory, right? We don’t have people with red flags, walking in front of cars. I do wonder, in 20 years or 50 years, what will the ethical norms regarding AI and its use be? Likewise, will we have deregulation? That seems to be the common theme in history that when we get more familiar with things, we deregulate because we’re more comfortable with their existence. That makes me quite curious about what the future holds.</p>
<p><strong>FT</strong>: Jon raised a very interesting point and Janet touched upon keeping financial data in silos but we are facing this in healthcare as well. Data has to be checked within a trusted research environment or secure data environment that’s making the data silos. However, efforts at this point in time are on enhancing these digital platforms to bring data and federal data together. Alongside what is happening in terms of our progression towards development of a new ethical or legal requirement, is documenting what is being practised at the moment, because at the moment there are quite a lot of bubbles. Each institution has their own data and applies their own rules to it. So understanding what it is that we are currently working on – the data flows that are flowing into the secure environments – is building the basis of developments that are going on in terms of developing standardisation and common frameworks. A lot of projects have been focused on understanding the current to develop on it for the future.</p>
<p>We know for example, the Data Protection Act, put forward some specific requirements, but that was developed in 2018, before we had this massive AI consideration. In my academic capacity as well, we are facing what Jon mentioned, in terms of the diversity of assessments for students. For example, when we ask these questions, even if the data is provided within the course and within this defined governance, we know that the answers can possibly be aided by AI – a model. So we are defining more diverse assessment methods in academic practice to ensure that we have a way to evaluate the outcome that we are receiving by the human eye, rather than being blinded by what we receive from AI, and then calling it high quality output, whether in research practice or in academic practice. So there’s quite a lot of consideration of these issues, I think that is bringing our past knowledge to the current point where we now have to balance between human and machine interactions in every single process that we are facing.</p>
<p><strong>How does this change the skill set required of data scientists, as AI is getting more and more developed?</strong></p>
<p><strong>A A-S</strong>: Regarding the terminology of data scientists, when we talk about data we immediately link that with statistics, and statistics is an old topic. There has been an accumulation of expertise for 100 years, to the best of my knowledge or more in statistics, and people who are new to data analysis or data, have to learn about this legacy. And when we develop the course, we should mention these skills in statistics and build this knowledge on top, that is, when we reach the right point, then we talk about learning or machine learning, supervised and unsupervised, and about LLM – these are the new skills they have to learn. As I mentioned, it’s tricky when we teach learners about it, we have to provide them with simple datasets to teach them something complex in statistics because it’s a danger to teach both [data and statistics at the same time] – we will lose them, they will lose concentration and it’s hard to follow up. So, a little bit of statistics – they have to learn the basics like normal distribution, the distribution, the type, and what does it mean when we have these distributions, the meaning of the data – and that is the point I made earlier about how people should have a sense for the numbers. What does it mean, when I say 0.56 in healthcare? Is that a danger? 60% – is that OK? In cybersecurity, if the probability of attack today is 60% should I inform the police? Should I inform someone; is that important? Or for example, for the stock market? Say we have dropped off 10% – Is that something we have to worry about? So making sense of the numbers is part of it.</p>
<p>That is part of personalised learning because it depends on their background or what they have learned – it’s not straightforward, and it has to be personalised not just for people taking the course now, for instance for someone who is 18 years old coming from their A levels. No, it’s for a wide range. People from diverse courses like to approach this data science course. And now we are in the era of people who are in social science, and engineering, doctors, journalism, art, they are all interested in learning a little bit of data science, and utilising AI for their benefit. So there is no one answer.</p>
<p><strong>You emphasise that people still need to be able to make sense of numbers. We’re often told that AI will devalue knowledge and devalue experience – it sounds like you don’t feel that’s the case.</strong></p>
<p><strong>A A-S</strong>: I have to stick with the following: human value is just that – value. AI without humans is worth nothing. I have one example: In 1997, some software was developed for chess, to play against a human, and for the first time, that computer programme (called AI now) beat Kasparov. Guess what happened? Did chess disappear? No, we still value human to human competition. The value of the human is the same for art and for music. So we still have human value, and we have to maintain that for the next generation. They shouldn’t lose this human value, and handover to AI value, which I feel is zero without the human.</p>
<p><strong>J B</strong>: I think one of the things we are seeing is that diversity in people’s backgrounds coming into data science, which is fantastic, because I think that really helps with the understanding of when things can go wrong, and how things can be misused. If you have this cookie cutter set of people that have all got a degree from the same place and all had the same experience, which is very similar – this happens a lot in the financial industry where there’s like five universities that all feed into the banks – they all think and solve problems in the same way because that’s how they’ve been trained. But as soon as you start bringing in people with different backgrounds, they’re the ones that say, hang on, this is a problem. So having those different backgrounds is really useful.</p>
<p>But then as Ali said there’s so many people who call themselves a data scientist that don’t understand data, or science. And I think he was absolutely right. If you’ve got a probability of 60%, or you’ve got a small standard deviation, when is that an issue? What do you really understand about that based on your industry, and based on your statistical knowledge? That’s so so key. And it’s something that a lot of people who are self-trained and call themselves data scientists have missed out on. So coming back to your original question about is it harder or is it easier, in some respects, it’s a lot harder, because someone who calls himself a data scientist now needs to do everything from basically fundamental research, trying to make models better, you’ve got to understand statistics, you’ve got to understand machine learning, engineering, production, isolation, efficiencies, effectiveness, ethics – it’s this huge, huge sphere. And it’s too much for one person. So you’ve really got to have well balanced teams and support. Because you can’t keep on top of your game across all of those. It’s just not possible. So I think that becomes really difficult. When I look at how things have changed, there’s so many basic principles from, you know, the 80s and 90s, in standard, good quality computer programming and testing. And I think the one thing that we’re really missing as an industry is a specialist AI testing role. Someone who understands enough about how models work and how they can go wrong and can do the same thing for AI solutions, as good QA analysts can do for standard software engineering models. Someone who can really test them to extremes with what happens when I put the wrong data in.</p>
<p>We saw this – there were a couple of days under COVID, where all the numbers went wrong, because the data hadn’t been delivered correctly, or not enough of it had been delivered. There were no checks in place to say, actually, we’ve only got 10% of what we were expecting, so don’t automatically publish these results. It’s things like that, that we really need to make sure are built into the systems because those are the things that, again, could cause problems. As soon as you get a model that’s not doing the right thing – going back to our original question – when they do go wrong, you can then find a company pulls that model even though it could be easily fixed. And then they’re disillusioned with AI, and won’t use it. That’s that whole project, and all of the expense and investment on that just thrown away when a bit more testing and understanding could have saved it.</p>
<div class="article-btn">
<p><a href="../../../../../ideas/index.html">Explore more data science ideas</a></p>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-12">
<dl>
<dt>About the authors</dt>
<dd>
<strong>Anna Demming</strong> is a freelance science writer and editor based in Bristol, UK. She has a PhD from King’s College London in physics, specifically nanophotonics and how light interacts with the very small, and has been an editor for Nature Publishing Group (now Springer Nature), IOP Publishing and New Scientist. Other publications she contributes to include The Observer, New Scientist, Scientific American, Physics World and Chemistry World..
</dd>
</dl>
</div>
<div class="g-col-12 g-col-md-6">
<!-- copyright goes to the author, or to Royal Statistical Society if written by staff -->
<dl>
<dt>Copyright and licence</dt>
<dd>
© 2024 Royal Statistical Society
</dd>
</dl>
<!-- confirm licence terms with contributor before publishing - must be Creative Commons licence, but different types of CC licences might be preferred -->
<p><a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> <img src="https://mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1" style="height:22px!important;vertical-align:text-bottom;"><img src="https://mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1" style="height:22px!important;margin-left:3px;vertical-align:text-bottom;"></a> This article is licensed under a Creative Commons Attribution 4.0 (CC BY 4.0) <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> International licence</a>. <!-- Add thumbnail image credit and any licence terms here --></p>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>How to cite</dt>
<dd>
Demming, Anna. 2024. “What is “best practice” when working with AI in the real world?.” Real World Data Science, June 4, 2024. <a href="https://realworlddatascience.net/ideas/posts/2024/05/20/ai-series-6.html">URL</a>
</dd>
</dl>
</div>
</div>
</div>
<!-- Make sure to update main site homepage (index.qmd) before publishing. See README for details -->



 ]]></description>
  <category>AI</category>
  <category>large language models</category>
  <category>machine learning</category>
  <guid>https://realworlddatascience.net/ideas/posts/2024/06/04/ai-series-6.html</guid>
  <pubDate>Tue, 04 Jun 2024 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/ideas/posts/2024/06/04/images/panel-991.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>AI series: Meeting the unprecedented challenges AI poses in the labour market</title>
  <dc:creator>Julia Lane, Lesley Hirsch, and Adam Leonard</dc:creator>
  <link>https://realworlddatascience.net/ideas/posts/2024/05/28/ai-series-5.html</link>
  <description><![CDATA[ 





<p>Roughly $280 billion of new funding was authorized to boost research and production of semiconductors in the US under the CHIPS and Science Act in 2022 - an amount greater than the inflation-adjusted initial spending to create the US Interstate Highway System. The legislation was just one of multiple acts engineered to subsidise and support emerging technologies in the US that are bound to have seismic impacts on the labor market. It signifies how swift changes in new and emerging technologies have the potential to profoundly change the demand for skills and the structure of work. Here AI has the potential to be more disruptive than any other technological development since the industrial revolution.</p>
<p>The US is not alone. Countries across the globe are trying to understand the potential for AI to affect their workforce and economic activity. IPSOS, Group SA, a multinational market research company with headquarters in France, recently attempted to gauge people’s feelings towards AI across the world through a survey across 31 countries and interviews with a small cohort of AI leaders (<a href="https://www.ipsos.com/sites/default/files/ct/news/documents/2023-07/Ipsos%20Global%20AI%202023%20Report-WEB_0.pdf">Global Views on AI 2023</a>). However although extensive, the data retrieved shares the limitations common to all surveys. The OECD’s most recent <a href="https://www.oecd-ilibrary.org/sites/08785bba-en/index.html?itemId=/content/publication/08785bba-en">Employment Outlook</a> devotes six out of seven chapters to understanding the impact of AI on the workforce. But the OECD also notes that “No comprehensive method exists by which to track and compare AI R&amp;D funding across countries and agencies.” <sup>1</sup> Not surprisingly, the inability to track, let alone compare AI R&amp;D funding, means that it is difficult to make predictions about the R&amp;D induced global labor market consequences.</p>
<p>The lack of a comprehensive method, and the resultant uncertainty about impact, is a clarion call to action. There are many challenges that need to be addressed. A partial list would include the following: a) a lack of a common definition of AI; b) a lack of information about the needed AI capabilities and how they will change; c) mapping AI capabilities to occupational skillls; and d) an inability to measure the impact of AI on job replacement or job augmentation.</p>
<p>Fortunately, there is hope, with new partnerships being established in the US by universities, federal, and state agencies. A new data infrastructure is being developed at the Institute for Research on Innovation and Science (IRIS) at the University of Michigan, joint with Ohio State University, in the United States, funded by the federal US National Science Foundation (NSF). The pilot joins up existing data using university and state sources to trace how scientific innovation translates to the labor market <sup>2</sup>. The NSF, which was been charged with the regional implementation of the CHIPS and Science investments, is funding the pilot precisely because it needs “innovative tools to accurately assess the impact of these investments across the U.S. <sup>3</sup></p>
<section id="how-bad-is-the-problem" class="level2">
<h2 class="anchored" data-anchor-id="how-bad-is-the-problem">How bad is the problem?</h2>
<p>The lack of data results in conflicting information. Some reports have warned of apocalyptic takeovers of the job market for many professions. Indeed, a heavily cited report by Goldman Sachs <sup>4</sup> predicted that AI could replace 300 million jobs. But the same BBC report that cited the Goldman Sachs prediction quoted the future-of-work director at Oxford University, Carl Benedikt Frey as saying “The only thing I am sure of is that there is no way of knowing how many jobs will be replaced by generative AI”. Simply put, as the former US Federal CIO, Suzette Kent, said “we lack useful information for informing strategic decisions for national workforce matters.”</p>
<p>So just how much of a problem is it that there is no information on how investments in science and technology affect the labor market? Why should we worry if we cannot accurately predict the impact of AI on workers, firms, and jobs? One reason is to avoid the mistakes of the past, in which both workers and firms have borne the consequences of bad information. Just in recent history, digitization and globalization resulted in a devastating loss of jobs in many countries. And geographic inequality soared as jobs in the midwestern and northeastern urban centers were lost and a service economy on the coasts burgeoned. Efforts to reduce the loss of jobs and earnings came too little, too late <sup>5</sup> <sup>6</sup>. Another reason is to make evidence based policy recommendations. For example, the US National AI Research Resources Taskforce, which was directly charged by the President and Congress with recommending ways to invest in AI research to strengthen and democratize the U.S. AI innovation ecosystem did not have joined up data between science investment and the workforce to inform their final recommendations. <sup>7</sup></p>
<p>In other words, governments need more timely, local, and actionable data so that they can understand changes in the tasks that employers need performed, which types of jobs and firms will be affected, and where. Concomitantly, data will be needed about the effects of AI on different population groups and different geographic areas so that the costs of change are not unfairly distributed. Armed with such information, policy makers can make investments that mitigate or counteract negative impacts and workers can be trained in the new necessary skills and matched with the firms that need them. But the swift pace of change in AI means that the urgency to create timely, local, and actionable labor market information to guide these investments has never been greater.</p>
</section>
<section id="a-new-approach" class="level2">
<h2 class="anchored" data-anchor-id="a-new-approach">A new approach</h2>
<p>The IRIS approach, called the “Industry of Ideas” builds on the “economics of ideas” framework for which Paul Romer received the 2018 Nobel Prize in Economics”. <sup>8</sup> <sup>9</sup>. People who create ideas – new technologies – that can be reused, form the foundations of new industries. In other words, “the discovery of new ideas lie at center of economic growth…” (Charles Jones describing Paul Romer’s conceptual framework) <sup>10</sup>.</p>
<p>The project recognizes that, as Robert Oppenheimer said “the best way to transmit knowledge is to wrap it up in a human being”. <sup>11</sup> It uses people-centric methods for following the movement of ideas from investments in research into the marketplace. The approach identifies businesses that employ people with deep skills in AI and other emerging technology areas and developing early, never-before-available indicators that can provide alerts associated with potential impacts on current and future workforce. Initially focused on the artificial intelligence and electric vehicle industries in Ohio, the pilot is creating a data system that can be expanded and applied to other industries and other states across the country.</p>
<p>The new tools are innovative because they build on new opportunities to produce usable information that is local, about relevant industries, and that directly tie investments in new technologies, such as AI, to labor market impacts.</p>
<p>Another key aspect of the NSF piloted “Industry of Ideas” is the focus on tying innovation at its source - individual data on university research activities - to the local workforce data reported by firms to their state departments of labor. The need for local data is critical because so many labor markets are local, not national in scope. Even in a global economy, many businesses and workers are locally based – as are the training providers that work to ensure that labor demand and supply are well matched. Thus the Industry of Ideas pilot provides policy makers, workers, firms, and educational institutions with access to an array of local, timely, granular, actionable resources to help them make decisions. That way, local leaders who need labor market data don’t need to rely on national unemployment figures, which are reported once a month.</p>
</section>
<section id="connecting-science-investments-with-jobs" class="level2">
<h2 class="anchored" data-anchor-id="connecting-science-investments-with-jobs">Connecting science investments with jobs</h2>
<p>The Industry of Ideas approach directly connects investment in science and the labor market, moving beyond the current approach for evaluating investment by studying scientific papers and publications <sup>12</sup> <sup>13</sup> which are disconnected from workers and jobs. The data seeds were sown almost two decades ago. President Bush’s Science Advisor, John Marburger III, who, quite sensibly was unconvinced of the scientific and practical value of relying primarily on document-based, bibliometric approaches to studying science to understand its practical effects, called for a “Science of Science Policy” <sup>14</sup> <sup>15</sup>.</p>
<p>The Industry of Ideas is testing the potential to securely combine university and state data to measure the link between federal investments on local and regional economies for AI. It uses people-centric data generated by the administrative processes at universities and firms. With this data the Industry of Ideas project can capture the organization of people in science at multiple levels (e.g.&nbsp;individuals, teams, projects, and institutions), their multiple sources of funding (federal scientific and programmatic agencies, philanthropic foundations, industry, and state and local government), inputs into science from vendors (such as computing services, instruments, biological specimens), as well as the dynamics of their careers across time (individual career earnings and employment trajectories).</p>
<div id="fig-1" class="quarto-figure quarto-figure-center quarto-float anchored" data-fig-align="center" alt="The Industry of Ideas Infrastructure (provided by Jason Owen-Smith, IRIS, University of Michigan)">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="https://realworlddatascience.net/ideas/posts/2024/05/28/images/Industry-of-ideas991-724.png" class="img-fluid quarto-figure quarto-figure-center figure-img" alt="The Industry of Ideas Infrastructure (provided by Jason Owen-Smith, IRIS, University of Michigan)">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;1: The Industry of Ideas Infrastructure (provided by Jason Owen-Smith, IRIS, University of Michigan)
</figcaption>
</figure>
</div>
<p>The IRIS infrastructure, developed over the past decade, provides administrative records on more than 41% of U.S. total R &amp; D spending at universities <sup>16</sup>. The infrastructure also provides links to survey data, as well as data from private sector suppliers <sup>17</sup>, and can trace the flows of university funded researchers into the private sector <sup>18</sup> by joining up the university administrative data with state workforce data.</p>
</section>
<section id="tying-information-about-ai-to-skills-needs" class="level2">
<h2 class="anchored" data-anchor-id="tying-information-about-ai-to-skills-needs">Tying information about AI to skills needs</h2>
<p>How is it possible to tie changes in AI to changing needs for skills? State leaders in workforce and education agencies have identified new ways to collaborate, build staff capacity, and develop solutions, services, and products that respond to local need. An example of how to use data to get better information that more accurately connects workers with firms in the swiftly changing labor market is the New Jersey Career Navigator. It provides job seekers recommendations on new careers, available job postings, and relevant training programs based on skills similarity, labor market demand, and wage impacts observed in the underlying data. These recommendations, which are in themselvers generated by AI, show how AI technology can be used to navigate the changes in the labour market AI may cause. The New Jersey Career Navigator draws on millions of wage records, providing earnings and industry information on all workers covered by unemployment insurance in New Jersey firms; employment and wage outcomes from hundreds of thousands of graduates of occupational skills training programs in New Jersey; several years of online job postings from the National Labor Exchange Research Hub (NLx); and the resumes of 400,000 New Jersey residents.</p>
<p>In other words, as the Industry of Ideas pilot evolves, new ideas from states like New Jersey can be used not only to trace the flows of ideas from academia to the workplace but also to develop a new system that targets reskilling efforts once the type and location of skills needs have been identified. The new joined up data and evidence can be used to address challenges such as low labor force participation, and supplies education and training providers the data they need to align their programs with the needs of the labor market. Such a system would help government, business, educators, and workers adjust regional talent pipelines continuously in response to the changes in AI and enable workers to successfully navigate the changes that it brings.</p>
</section>
<section id="new-approaches-to-classifying-industries-industries-of-ideas" class="level2">
<h2 class="anchored" data-anchor-id="new-approaches-to-classifying-industries-industries-of-ideas">New approaches to classifying industries: “Industries of Ideas”</h2>
<p>An important outcome of the new NSF pilot is the potential to transform the way in which we classify firms into industries. The current industry classifications are rule based. They are designed for the economy as it was organized 40 years ago, so are not designed to describe AI. A case in point is the state of Texas – a state that anecdotally has generated a lot of high tech jobs. Current industry data for Texas is limited because firms are grouped into industries that are defined by what they produce, or how they produce it, rather than describing what new technology is being developed or utilized by those firms. As a result, the main source of labor market data in Texas provides an implausibly low picture of AI activity <sup>19</sup>.</p>
<p>The Industries of Ideas approach could provide states with a new way to classify firms, based on clever new ideas of how firms can do their business, and by grouping firms by the people who created and use the technologies they will adopt <sup>20</sup>. Examples just for Ohio include funding to use AI to improve the ways in which medicine is delivered, and advancing digital agricuture , which includes things like precision livestock farming, or precision agriculture that reduces waste and improves productivity more generally. As they interact with farmers, the clustering of university researchers and the ideas embodied in them alongside the farms that adopt those ideas represents this new type of industry cluster . Such a classification framework is a sea change from earlier industrial classifications based on what goods are physically produced - like manufacturing and agriculture <sup>21</sup>.</p>
</section>
<section id="the-future" class="level2">
<h2 class="anchored" data-anchor-id="the-future">The Future</h2>
<p>Such a bottom-up classification and analysis system, based on local links between researchers and firms, could be designed locally but scaled nationally. It could address the challenges identified at the beginning of this piece. The definition of AI firms could evolve and be defined by the links between AI researchers and the firms with which they work. The lack of information about the needed AI capabilities would be resolved by the direct mapping of firm skill demand and their hiring patterns, as exemplified in New Jersey. The same New Jersey mapping could tie AI capabilities to occupational skills. And the direct impact of AI on job replacement or job augmentation could be mapped from the joined up university and workforce data.</p>
<p>Of course, much needs to be done. The implementation will depend on the success of the pilot, and the ability to build on existing assets. Not all states and universities have the capacity to build a similar system, but the fact that 30 universities and 15 state agencies are participating in advisory boards for the NSF Industry of Ideas pilot is grounds for hope. Indeed, a new generation of data leaders is leading the way, not only at the local and regional government level but also at universities and professional associations (Advisory Committee on Data for Evidence Building) <sup>22</sup>.</p>
<p>We began this paper by noting that the urgency to create timely, local, and actionable labor market information has never been greater. We close by arguing that our capacity to fundamentally change the way in which we can use data and information to understand the demand for skills and the structure of work has also never been greater. The opportunity is ours for the taking.</p>
<!-- article text to go here -->
<div class="article-btn">
<p><a href="../../../../../ideas/index.html">Explore more data science ideas</a></p>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-12">
<dl>
<dt>About the authors</dt>
<dd>
<strong>Julia Lane</strong> is a Professor at New York University’s Wagner Graduate School of Public Service. She was a senior advisor in the Office of the Federal CIO at the White House, supporting the implementation of the Federal Data Strategy. She recently served on two White House committees: the Advisory Committee on Data for Evidence Building and the National AI Research Resources Task Force.
</dd>
<dd>
<p><strong>Adam Leonard</strong> is the Chief Analytics Officer &amp; Director of the Division of Information Innovation &amp; Insight (I|3) for the Texas Workforce Commission (TWC). Adam envisioned and founded I|3 to help TWC leverage its most important untapped resource - its data – to help the agency and its partners better help employers, individuals, families, and communities achieve &amp; maintain prosperity.</p>
</dd>
<dd>
<p><strong>Lesley Hirsch</strong> is the Assistant Commissioner of Research and Information at the New Jersey Department of Labor and Workforce Development. Her vision for the department is to bring cutting-edge digital tools to bear to deliver labor market intelligence to the department’s internal and external customers where, when, and how they need it and to mine every data source so it can tell its full story.</p>
</dd>
</dl>
</div>
<div class="g-col-12 g-col-md-6">
<!-- copyright goes to the author, or to Royal Statistical Society if written by staff -->
<dl>
<dt>Copyright and licence</dt>
<dd>
© 2024 Royal Statistical Society
</dd>
</dl>
<!-- confirm licence terms with contributor before publishing - must be Creative Commons licence, but different types of CC licences might be preferred -->
<p><a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> <img src="https://mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1" style="height:22px!important;vertical-align:text-bottom;"><img src="https://mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1" style="height:22px!important;margin-left:3px;vertical-align:text-bottom;"></a> This article is licensed under a Creative Commons Attribution 4.0 (CC BY 4.0) <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> International licence</a>. <!-- Add thumbnail image credit and any licence terms here --></p>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>How to cite</dt>
<dd>
Lane, J., Hirsch, L. and Leonard, A. 2024. “Meeting the unprecedented challenges AI poses in the labour market.” Real World Data Science, May 28, 2024. <a href="https://realworlddatascience.net/ideas/posts/2024/05/13/ai-series-5.html">URL</a>
</dd>
</dl>
</div>
</div>
</div>
<!-- Make sure to update main site homepage (index.qmd) before publishing. See README for details. -->


</section>


<div id="quarto-appendix" class="default"><section id="footnotes" class="footnotes footnotes-end-of-document"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p>A new approach to measuring government investment in AI-related R&amp;D. Galindo-Rueda, F. &amp; Cairns, S. <em>oecd.ai</em> (2021)↩︎</p></li>
<li id="fn2"><p><a href="https://www.aei.org/research-products/report/the-industry-of-ideas-measuring-how-artificial-intelligence-changes-labor-markets/">The Industry of Ideas: Measuring How Artificial Intelligence Changes Labor Markets</a> Lane, J. AEI (2023)↩︎</p></li>
<li id="fn3"><p><a href="https://www.aei.org/research-products/report/the-industry-of-ideas-measuring-how-artificial-intelligence-changes-labor-markets/">NSF launches pilot to assess the impact of strategic investments on regional jobs</a> *new.nsf.gov (2023)↩︎</p></li>
<li id="fn4"><p><a href="https://www.bbc.co.uk/news/technology-65102150">AI could replace equivalent of 300 million jobs - report</a> Vallance, C. <em>BBC news</em> (2023)↩︎</p></li>
<li id="fn5"><p><a href="https://www.aeaweb.org/articles?id=10.1257/aer.103.5.1553">The Growth of Low-Skill Service Jobs and the Polarization of the US Labor Market</a> Autor, D. H. &amp; Dorn, D. <em>American Economic Review</em> <strong>103</strong> pp.&nbsp;1553-97 (2013)↩︎</p></li>
<li id="fn6"><p><a href="https://www.aeaweb.org/articles?id=10.1257/aer.104.8.2509">Explaining Job Polarization: Routine-Biased Technological Change and Offshoring</a> Goos, M., Manning, A. &amp; Salomons, A. <em>American Economic Review</em> <strong>104</strong> 2509-26 (2014)↩︎</p></li>
<li id="fn7"><p><a href="https://www.ai.gov/wp-content/uploads/2023/01/NAIRR-TF-Final-Report-2023.pdf">Strengthening and Democratizing the U.S. Artificial Intelligence Innovation Ecosystem</a> Office of Science and Technology Policy (2023)↩︎</p></li>
<li id="fn8"><p><a href="https://paulromer.net/deep_structure_growth/">The Deep Structure of Economic Growth</a> Romer, P. <em>paulromer.net</em> (2019)↩︎</p></li>
<li id="fn9"><p><a href="https://hdsr.mitpress.mit.edu/pub/zgu2u8y6/release/2">Interview With Paul Romer</a> Romer, P. &amp; Lane, J. (2022)↩︎</p></li>
<li id="fn10"><p><a href="https://onlinelibrary.wiley.com/doi/abs/10.1111/sjoe.12370">Paul Romer: Ideas, nonrivalry, and endogenous growth</a>(Jones, C. I. <em>The Scandinavian Journal of Economics</em> <strong>121</strong> 859-883 (2019)↩︎</p></li>
<li id="fn11"><p><a href="https://www.science.org/doi/10.1126/science.aac5949">Wrapping it up in a person: Examining employment and earnings outcomes for Ph.D.&nbsp;recipients</a> Zolas, N. <em>et al.</em> <em>Science</em> **350 1367-1371 (2015)↩︎</p></li>
<li id="fn12"><p><a href="https://www.nature.com/articles/464488a">Let’s make science metrics more scientific</a> Lane, J. <em>Nature</em> <strong>464</strong> 488–489 (2010)↩︎</p></li>
<li id="fn13"><p><a href="https://issues.org/democratizing-government-data-lane/">A Vision for Democratizing Government Data</a> Lane, J. <em>Issues in Science and Technology</em> <strong>XXXIX</strong> (2022)↩︎</p></li>
<li id="fn14"><p><a href="https://www.nature.com/articles/464488a">Let’s make science metrics more scientific</a> Lane, J. <em>Nature</em> <strong>464</strong> 488–489 (2010)↩︎</p></li>
<li id="fn15"><p><a href="https://www.science.org/doi/10.1126/science.1114801">Wanted: Better Benchmarks</a> Marburger III, J. H. <em>Science</em> <strong>308</strong> p1087(2005)↩︎</p></li>
<li id="fn16"><p><a href="https://iris.isr.umich.edu/research-data/2022datarelease-summarydoc/">The Institute for Research on Innovation &amp; Science (IRIS). Summary Documentation for the IRIS UMETRICS 2022 Data Release</a> Nicholls, N., Brown, C. A., Ku, R. L. and Owen-Smith, J. D. <em>Ann Arbor, MI: The Institute for Research on Innovation &amp; Science</em> (2022) doi: 10.21987/df2a-ha30↩︎</p></li>
<li id="fn17"><p><a href="https://hdsr.mitpress.mit.edu/pub/u073rjxs/release/3">A Linked Data Mosaic for Policy-Relevant Research on Science and Innovation: Value, Transparency, Rigor, and Community</a> Chang, W.-Y., Garner, M., Basner, J., Weinberg, B. and Owen-Smith, J. <em>Harvard Data Science Review</em> (2022) doi: 10.1162/99608f92.1e23fb3f↩︎</p></li>
<li id="fn18"><p><a href="https://www.aei.org/research-products/report/the-industry-of-ideas-measuring-how-artificial-intelligence-changes-labor-markets/">The Industry of Ideas: Measuring How Artificial Intelligence Changes Labor Markets</a> Lane,J. <em>American Enterprise institute</em> (2023)↩︎</p></li>
<li id="fn19"><p>[Outside of the Box Use of Administra4ve and Wage Data in Texas] (https://digitaleconomy.stanford.edu/wp-content/uploads/2024/03/Adam-Leonard.pdf) Leonard, A. <em>digitaleconomy.standford.edu</em> (2024)↩︎</p></li>
<li id="fn20"><p><a href="https://www.aei.org/research-products/report/the-industry-of-ideas-measuring-how-artificial-intelligence-changes-labor-markets/">The Industry of Ideas: Measuring How Artificial Intelligence Changes Labor Markets</a> Lane,J. <em>American Enterprise institute</em> (2023)↩︎</p></li>
<li id="fn21"><p><a href="https://www.bea.gov/system/files/papers/P2007-7.pdf">Converting historical industry time series data from SIC to NAICS. The Federal Committee on Statistical Methodology</a> Yuskavage, R. <em>Federal Committee on Statistical Methodology</em> (2007)) – or by how services and goods are produced – like the delivery of health, financial, and investment services <a href="https://www.jstor.org/stable/23487551">The Statistics Corner: The NAICS Is Coming. Will We Be Ready?</a> Haver, M. A. <em>Business Economics</em> <strong>32</strong> 63-65 (1997)↩︎</p></li>
<li id="fn22"><p><a href="https://www.bea.gov/system/files/2022-10/supplemental-acdeb-year-2-report.pdf">Year 2 Report Supplemental Information</a> Advisory Committee on Data for Evidence Building (ACDEB) (2022)↩︎</p></li>
</ol>
</section></div> ]]></description>
  <category>AI</category>
  <category>Data management</category>
  <category>Forecasting</category>
  <guid>https://realworlddatascience.net/ideas/posts/2024/05/28/ai-series-5.html</guid>
  <pubDate>Tue, 28 May 2024 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/ideas/posts/2024/05/28/images/Industry-of-ideas991-724.png" medium="image" type="image/png" height="105" width="144"/>
</item>
<item>
  <title>AI series: Evaluation essentials for safe and reliable AI model performance</title>
  <dc:creator>Isabel Sassoon</dc:creator>
  <link>https://realworlddatascience.net/ideas/posts/2024/05/21/ai-series-4.html</link>
  <description><![CDATA[ 





<p>It took just sixteen hours for <a href="https://blogs.microsoft.com/blog/2016/03/25/learning-tays-introduction/">Microsoft’s shiny new chatbot</a> Tay to be shut down for profanity. The chatbot had been released on the social media platform, X, then known as Twitter, following extensive evaluation and stress testing under different conditions to ensure that interacting with the chatbot would be a positive experience. Unfortunately, the testing plan had not bargained on a coordinated attack exploiting the chatbot’s vulnerability when exposed to a torrent of offensive material. Tay soon began tweeting wildly inappropriate words and images and was taken offline within hours.</p>
<p>The chatbot’s failure highlights just how hard yet imperative it can be to test and evaluate a model before real world deployment. With the recent flux of accessible “off-the-shelf” machine learning algorithms, building AI models, in particular generative AI models is now relatively straight forward. However, the simplicity with which models are deployed undermines the complexity of evaluating them. Nonetheless, deploying the model anywhere outside the data and context it has been trained on can be risky if its performance is not evaluated. The evaluation process requires clear definitions for good performance as well as highlighting the potential risks, and can throw up unexpected requirements in the test data. Not only are the subtle nuances in the initial evaluation requirements important, but once deployed a process needs to be in place so that the algorithm can be monitored over time.</p>
<section id="know-your-goals" class="level2">
<h2 class="anchored" data-anchor-id="know-your-goals">Know your goals</h2>
<p>The first point to note is that checking how well the output from an AI model matches the data in the training set is not an adequate indication of how well it will perform once deployed on other data. The problem can be exemplified by considering a simple model based on an equation that best fits a training data set. Data values are inevitably subject to measurement uncertainties and local conditions that add various types of noise, so taking the line defined by the equation identified as best matching the training data and measuring how good that match is falls short of adequate evaluation - the more perfectly a model matches this noisy data, the less perfectly it will fit an alternative set of data, a scenario described as “overfitting”. Similarly, what a machine learning or AI algorithm or model learns when it optimises its fit to the training data may not be generalisable.</p>
<div id="fig-1" class="quarto-figure quarto-figure-center quarto-float anchored" data-fig-align="center" alt="Reliable deployment of an algorithm requires identifying metrics, risks and rigorous, ongoing evaluation. Image created by Isabel Sassoon using firefly to show a technical report process flow of statistical model performance and a huge numbers chart.">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="https://realworlddatascience.net/ideas/posts/2024/05/21/images/Evaluation_thumbnail.jpg" class="img-fluid quarto-figure quarto-figure-center figure-img" alt="Reliable deployment of an algorithm requires identifying metrics, risks and rigorous, ongoing evaluation. Image created by Isabel Sassoon using firefly to show a technical report process flow of statistical model performance and a huge numbers chart.">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;1: Evaluation plots. The kinds of charts of monitored performance and risk metrics that are plotted to evaluate an AI model. Reliable deployment of an algorithm requires identifying appropriate metrics for performance and risk as well as rigorous, ongoing evaluation. Image created by Isabel Sassoon using Adobe Firefly to show a technical report process flow of statistical model performance and a huge numbers chart.
</figcaption>
</figure>
</div>
<p>There are a number of possible approaches and factors to take into account when sourcing test data but the first thing to consider when drawing up a process for evaluating an AI model is its objective. With this objective in mind it is then possible to pin down an appropriate measure of performance, which will shape how to use the test data to evaluate the model performance. Among the distinguishing factors between different measures used to evaluate how a model performs on test data, some will be suitable when the objective is to classify (e.g high or low risk based on health data?) while others are useful for models that estimate or predict (e.g What is the estimated height of a child given their parents’ heights).</p>
<p>Classification model performance can be measured using accuracy, confusion matrices, sensitivity, specificity and the receiver operating characteristic (ROC). Classification accuracy summarises the performance of a classification model as the number of cases in which the model correctly classifies divided by the total number of cases used in the test set. However, this can be a blunt tool as there are cases where there is a different cost or consequence depending on the direction of the error. Confusion matrices are helpful to explore how the model performs in correctly classifying the different classes. The confusion matrix sums up the number of cases the model classifies correctly within each of the classes, for example how many actual high-risk cases are correctly classified as high risk by the model. The number of cases the model classifies as high risk, for example, that are not high risk is referred to as the False Positives. In the context of medical tests (e.g the covid lateral flow tests) testing positive for a condition that is not actually there is potentially less damaging than testing negative when the condition is there.</p>
<div id="fig-2" class="quarto-figure quarto-figure-center quarto-float anchored" data-fig-align="center" alt="The receiver operating characteristic can provide a helpful means of visualising performance. Credit: shutterstock .">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="https://realworlddatascience.net/ideas/posts/2024/05/21/images/shutterstock_2377152411.jpg" class="img-fluid quarto-figure quarto-figure-center figure-img" alt="The receiver operating characteristic can provide a helpful means of visualising performance. Credit: shutterstock .">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2: The receiver operating characteristic can provide a helpful means of visualising performance. Credit: shutterstock
</figcaption>
</figure>
</div>
<p>Additionally, the sensitivity and specificity can provide a more detailed look at model performance. The sensitivity refers to the proportion of cases labelled as positive that are classified as positive by the model, whereas specificity refers to the proportion labelled as negative that it classifies as negative. It is useful to visualise model performance and the receiver operating characteristic (ROC) provides a method to do just that. The ROC plots the True Positive rate against the False Positive rate for the model. This can be further summarised in one value as the area under the curve (AUC). The larger the AUC the better the model is performing.</p>
<p>Deciding whether accuracy is enough or whether there is a need to delve into the directions of the errors depends on the context of the model’s deployment. Other examples in medicine include the risk models that were developed to assess an individual’s risk of a specific medical condition, such as <a href="https://qrisk.org/">QRISK</a> <sup>1</sup> which calculates a person’s risk of developing a heart attack or stroke over the next 10 years. Here model performance needs to go beyond accuracy and consider the direction of the errors it makes. A good overview of performance evaluation is outlined by Flach (2019) <sup>2</sup>. Is it better to tell someone they may be at risk of disease X, run a blood test and rule it out (False Positive) than to tell them they are not at risk and not check (False Negative)? All this needs to be considered and factored into the validation of the model. It is worth noting that a systematic direction for its errors can also cause an algorithm to hit <a href="https://realworlddatascience.net/ideas/posts/2024/05/14/ai-series-2.html">ethical problems</a>.</p>
<p>When evaluating the performance of models that are estimating a numerical value (e.g height of child from height of parents) the measures used are based on how far off the model’s estimate is from the actual value (which is known for testing data). There are then a multitude of ways of summarising that quantity. The mean square error (MSE) is computed by taking the average squared difference between the estimated values from the model and the actual value in the data. Other variations include root mean square error (RMSE) and mean absolute error (MAE). The RMSE is computed in the same way as the MSE but the value is square rooted. The MAE takes a different approach by summing up the absolute errors (i.e.&nbsp;the error magnitude). Each of these three measures involve dividing the value obtained by the number of rows in the data. Depending on the context one of these measures may be better suited than others. For example the MSE is sensitive to outliers so can be easily skewed by a small number of extreme values, which may be useful to highlight them, whereas the RMSE has the advantage of being measured in the same units as the original variable the model is designed to estimate.</p>
<p>Large Language Models (LLMs, e.g.&nbsp;Gemini, ChatGPT) are also models trained on a data set and as such also need to be evaluated and monitored. Whereas in the models discussed so far there are some standard metrics, evaluating LLMs is more challenging as there are a multitude of benchmarks and metrics<sup>3</sup>. When LLMs are used to answer questions (when you ask a chatbot a question) then monitoring the performance of the model (the trained LLM) can involve anything. Is the answer correct? Is the answer clear? Is the answer biased? The possible metrics are varied and not as simple to capture in one measure. It is also possible to use a LLM to evaluate or score another LLMs’ answer to a question. However this adds its own risk as LLMs are not 100% accurate or consistent themselves, and they can <a href="https://realworlddatascience.net/viewpoints/editors-blog/posts/2022/11/23/LLM-content-warning.html">hallucinate</a>.</p>
</section>
<section id="getting-data-right" class="level2">
<h2 class="anchored" data-anchor-id="getting-data-right">Getting data right</h2>
<p>Not only is separate test data needed for an evaluation, but care is needed to ensure the test data is suitably representative. Similar requirements apply for test data as for the original training data to ensure the dataset is representative of the context the model will be deployed in. For instance, if an algorithm is being developed to handle photos from the UK, training and testing it on photos where the sun always shines may cause problems. The model needs to be trained and tested on a set of photos that include rain and clouds otherwise it cannot be assumed it will reliably classify such photos if they appear during deployment in the real world. Getting the training and test data set right may mean using a smaller more curated set than simply one that contains everything available.</p>
<p>These data sets also need to have reliable labelling i.e.&nbsp;the rows of data need to be accurate so that the model’s performance can be assessed objectively against a trusted “ground truth”. For example, if we want to evaluate the performance of a fraud transaction classification model using accuracy as the performance metric, then we need a reliable training data set with true fraud transactions to evaluate how good the model is at detecting them. A data set with a list of transactions that are not accurately identified (or labelled) as fraud or not is not helpful. Thinking about how some commercial LLMs are trained on all the data in the “internet” it is worth asking whether a smaller more curated and specific training set would be better for model performance as well as being more ethical and safer.</p>
<p>Several approaches for generating test data sets take training and test data as distinct subsets from the same initial data set <sup>4</sup>. There are different ways of doing this to make the most of the data to evaluate the model as systematically and exhaustively as possible. Perhaps the simplest example is using a hold-out set, which involves taking all the data available and taking a random subset of the data to use for testing the model. Depending on how much data is available then this can be 50% or less.</p>
<p>A slightly more sophisticated approach is k-fold cross validation, which involves splitting all the data you have available into k subsets and then doing k iterations where in each iteration a different kth of the data is used as the testing data for evaluation of the model built by training it on the remaining (k-1/k) of the data. This is repeated k times each time using a different one of the k subsets for testing. The performance of the model can then be averaged over the k iterations. (The measure of performance can be, say, accuracy or sensitivity depending on the context). For example, if k is 3 then the data is split into 3, and each iteration will take a different 2/3 of the data as training data to build the model, and the remaining 1/3 as testing data to evaluate the model.</p>
<div id="fig-1" class="quarto-figure quarto-figure-center quarto-float anchored" data-fig-align="center" alt="K fold cross validation can indicate how sensitive a model is to the test data. Credit: Fabian Flöck CC-BY-AS-3.0">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="https://realworlddatascience.net/ideas/posts/2024/05/21/images/k-fold-cross-validation.png" class="img-fluid quarto-figure quarto-figure-center figure-img" alt="K fold cross validation can indicate how sensitive a model is to the test data. Credit: Fabian Flöck CC-BY-AS-3.0">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;3: K fold cross validation can indicate how sensitive a model is to the test data. Credit: Fabian Flöck CC-BY-AS-3.0
</figcaption>
</figure>
</div>
<p>Bootstrap is a more computationally intensive approach and it involves creating multiple samples by randomly sampling with replacement from the original data. Typically, hundreds or thousands of and such samples are generated, each will be different. These multiple samples provide multiple versions of the training and testing data so the model can be evaluated on all these variations. As bootstrap relies on sampling with replacement this means that each row of data in the original data can appear multiple times in a sample training or test data during each iteration, or not appear in other samples. As with k-fold cross validation the performance of the model can be then averaged over these multiple iterations. It is important that bootstrap does not rely on only a handful of iterations. Both bootstrap and cross validation offer an opportunity to see how sensitive the model’s performance is to the characteristics of the test data, but when the data sets available are small, the use of the bootstrap approach provides a more robust way of estimating the model’s performance.</p>
<p>An approach that can be useful to test whether the performance of the model is sensitive to time is time-based splits. This involves taking a “sliding window” ensuring that data is split into back-to-back time periods. Using a back-to-back (sliding window) further ensures that the data the model is trained on is separate from the one it is tested on.</p>
</section>
<section id="maintained-monitoring" class="level2">
<h2 class="anchored" data-anchor-id="maintained-monitoring">Maintained monitoring</h2>
<p>Once an algorithm has been let loose it can be challenging to maintain any rigorous monitoring, but it is worth highlighting the importance of taking on the challenge of ongoing monitoring and promising approaches to it. Some of the same metrics will apply to keep a handle on the myriad of issues that could arise. These range from the banal, such as data input errors, to the complex as is the case in model drift.</p>
<p>In the first case, if a model makes use of data that is fed into it from another system (e.g.&nbsp;a billing system) any update to this other system can affect model performance. Identifying this involves checking that the characteristics of the data used to train the model and the latest data fed into the model are not too dissimilar, since a difference in the data such as an increase by a factor of 10 or a hundred can cause the algorithm to fail. The magnitude of acceptable change in the data will depend on the context. Such a step change (due to source system update) in one of the model inputs can be identified and can potentially be an easy fix.</p>
<p>Model drift is more complex as real-world data evolves over time. There are two types of model drift: data drift and concept drift. Data drift refers to the change that can occur to data over time, whilst concept drift<sup>5</sup> is a deterioration or change in the relationship between the target variable and input variables of a model. An example of data drift could be in the context of billing data the addition of new price plans or phones to the data, whilst an example of concept drift can arise when there is a change in the relationship between the effect (for instance, leaving one mobile phone provider for another) and underlying factors changes. In the context of the mobile phone provider market, a concept drift may mean that leaving for another provider is no longer dictated so much by price sensitivity as the type of network. Both types of drift lead to a deterioration in performance of the model as time goes by. Performance monitoring of the model is key to detecting model drift but differentiating between data or concept drift requires additional specialist approaches. Some of these are outlined in (Rotalinti, 2022)<sup>6</sup> and (Davis, 2020)<sup>7</sup>.</p>
<p>In some cases, refreshing a model to account for the change in the underlying data (both training and test) can be quick and easy. However, if concept drift is detected, then it may take more than just a model refresh as the relationships between the variable we are trying to model, and the explanatory data has changed. This may involve finding new data sources and could lead to significant changes in the model, for example moving from a regression model to a neural network. Deciding to rebuild or retrain a model can also in some cases have environmental impact (particularly for the more resource intensive models such as deep learning and LLMs). Either way, where models are subject to peer review or some form of governance this can be a more onerous task.</p>
<p>Even with each step in a model’s evaluation stringently adhered to it is also important to assess the context for its deployment for risks and rogue scenarios that might break or in the case of Tay despoil it. And like all other stages of the evaluation this should not just be at the time of deployment but also over time. When models (machine learning or other) are used to inform or make important decisions providing information on how and when the model was evaluated, and how it is monitored should be standard practice not just to avoid the wasted expense of another broken AI model (algorithm) left on the shelf but more importantly to safeguard the welfare of those who come into contact with it.</p>
<div class="article-btn">
<p><a href="../../../../../ideas/index.html">Explore more data science ideas</a></p>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-12">
<dl>
<dt>About the author</dt>
<dd>
<strong>Isabel Sassoon</strong> is senior lecturer in the Department of Computer Science, Brunel University London.
</dd>
</dl>
</div>
<div class="g-col-12 g-col-md-6">
<!-- copyright goes to the author, or to Royal Statistical Society if written by staff -->
<dl>
<dt>Copyright and licence</dt>
<dd>
© 2024 Royal Statistical Society
</dd>
</dl>
<!-- confirm licence terms with contributor before publishing - must be Creative Commons licence, but different types of CC licences might be preferred -->
<p><a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> <img src="https://mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1" style="height:22px!important;vertical-align:text-bottom;"><img src="https://mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1" style="height:22px!important;margin-left:3px;vertical-align:text-bottom;"></a> This article is licensed under a Creative Commons Attribution 4.0 (CC BY 4.0) <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> International licence</a>. <!-- Add thumbnail image credit and any licence terms here --></p>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>How to cite</dt>
<dd>
Sassoon, Isabel. 2024. “Evaluation essentials for safe and reliable AI model performance .” Real World Data Science, May 21, 2024. <a href="https://realworlddatascience.net/ideas/posts/2024/05/06/ai-series-4.html">URL</a>
</dd>
</dl>
</div>
</div>
</div>
<!-- Make sure to update main site homepage (index.qmd) before publishing. See README for details. -->


</section>


<div id="quarto-appendix" class="default"><section id="footnotes" class="footnotes footnotes-end-of-document"><h2 class="anchored quarto-appendix-heading">References</h2>

<ol>
<li id="fn1"><p>Hippisley-Cox, J., Coupland, C. and Brindle, P. Development and validation of QRISK3 risk prediction algorithms to estimate future risk of cardiovascular disease: prospective cohort study.<em>BMJ</em> (2017) <a href="https://www.bmj.com/content/357/bmj.j2099">doi: https://doi.org/10.1136/bmj.j2099</a>.↩︎</p></li>
<li id="fn2"><p>Flach, P. (2019). Performance evaluation in machine learning: the good, the bad, the ugly, and the way forward. <em>Proceedings of the AAAI conference on artificial intelligence</em> pp.&nbsp;9808-9814 (2019) <a href="https://ojs.aaai.org/index.php/AAAI/article/view/5055">doi: https://doi.org/10.1609/aaai.v33i01.33019808</a>.↩︎</p></li>
<li id="fn3"><p>Chang, Y. <em>et al.</em> A survey on evaluation of large language models. <em>ACM Transactions on Intelligent Systems and Technology</em> (2023) <a href="https://dl.acm.org/doi/10.1145/3641289">doi: https://doi.org/10.1145/3641289</a>.↩︎</p></li>
<li id="fn4"><p>Witten, I. H., Frank, E. and Hall, M. A. Data mining: Practical machine learning tools and techniques. Morgan Kaufmann (2011).↩︎</p></li>
<li id="fn5"><p>Bayram, F., Ahmed, B. S. and Kassler A. From concept drift to model degradation: An overview on performance-aware drift detectors. <em>Knowledge-Based Systems</em> (2022) <a href="https://www.sciencedirect.com/science/article/pii/S0950705122002854">doi: https://doi.org/10.1016/j.knosys.2022.108632</a>.↩︎</p></li>
<li id="fn6"><p>Rotalinti, Y., Tucker, A., Lonergan, M., Myles, P. and Branson, R. Detecting drift in healthcare AI models based on data availability. <em>Joint European Conference on Machine Learning and Knowledge Discovery in Databases</em> 243-258 (2022) Springer Nature Switzerland. <a href="https://link.springer.com/chapter/10.1007/978-3-031-23633-4_17">doi: https://doi.org/10.1007/978-3-031-23633-4_17</a>↩︎</p></li>
<li id="fn7"><p>Davis, S. E., Greevy Jr, R. A., Lasko, T. A., Walsh, C. G. and Matheny, M. E. Detection of calibration drift in clinical prediction models to inform model updating. <em>Journal of biomedical informatics</em> (2020) <a href="https://www.sciencedirect.com/science/article/pii/S1532046420302392">doi: https://doi.org/10.1016/j.jbi.2020.103611</a>.↩︎</p></li>
</ol>
</section></div> ]]></description>
  <category>AI</category>
  <category>Machine Learning</category>
  <category>Large Language Models</category>
  <guid>https://realworlddatascience.net/ideas/posts/2024/05/21/ai-series-4.html</guid>
  <pubDate>Tue, 21 May 2024 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/ideas/posts/2024/05/21/images/Evaluation_thumbnail.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>AI series: On AI ethics - influencing its use in the delivery of public good</title>
  <dc:creator>Olivia Varley-Winter</dc:creator>
  <link>https://realworlddatascience.net/ideas/posts/2024/05/14/ai-series-2.html</link>
  <description><![CDATA[ 





<!-- article text to go here -->
<p>Criminal <a href="https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing">sentencing biased by race</a> in the US, <a href="https://www.theguardian.com/education/2021/feb/18/the-student-and-the-algorithm-how-the-exam-results-fiasco-threatened-one-pupils-future">students systematically downgraded</a> in UK public examinations with no process for appeal, and <a href="https://orientblackswan.com/details?id=9789352875429#:~:text=Dissent%20on%20Aadhaar%20argues%20that,surveillance%20and%20commercial%20data%2Dmining">decisions to rescind food welfare</a> in India riddled with errors and discrepancies are all instances where AI algorithms have hit the headlines. When Bill Gates wrote that the age of <a href="https://www.linkedin.com/pulse/age-ai-has-begun-bill-gates/">AI has begun</a> and “will change the way people work, learn, travel, get health care, and communicate with each other,” those probably weren’t the changes he had in mind. Nor need they be an inevitable side effect of living with AI.</p>
<p>A number of points require consideration to work safely with AI, from the potential for bias in input and training data, and consent over data use, to the transparency and fairness of applying an algorithm – who has decided the problem, or set of problems, it is to solve? The steps that are taken to explain and involve an organisation’s stakeholders in the conclusions that AI reaches also require ethical consideration, as does ethical development of AI. Its use for social policies and services highlights an additional set of problems.</p>
<p>As AI becomes more active in society, AI ethics involves not only defining the objectives for data scientists, researchers and technologists to work on. It involves governing bodies, regulators, policy makers, businesses and organisations, the media, and civil society, working to handle and communicate AI’s benefits and mitigate its harms. Organisations with international clout – such as the United Nations Educational, Scientific and Cultural Organization (<a href="https://www.unesco.org/en/artificial-intelligence/recommendation-ethics">UNESCO</a>) and the Organisation for Economic Co-operation and Development (<a href="https://www.oecd.org/gov/ethics/ethicscodesandcodesofconductinoecdcountries.htm">OECD</a>) – have prominently set out ethical principles that can broadly apply. Nonetheless, a lot can go wrong.</p>
<section id="bias-in-bias-out" class="level2">
<h2 class="anchored" data-anchor-id="bias-in-bias-out">Bias in bias out</h2>
<p>In 2016 when ProPublica launched an investigation into potential biases in a ‘risk assessment’ algorithm used by the US criminal justice system, it was the first independent investigation of its kind. This was despite the widespread use of the algorithm and its power to influence a judge’s sentence, in one instance <a href="ttps://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing">doubling the duration while increasing the severity</a> of the imprisonment. On examining 7000 risk assessment scores and the records detailing whether the subjects of those scores had reoffended in the subsequent two years, Propublica found “Only 20 percent of the people predicted to commit violent crimes actually went on to do so”. Even when the full range of crimes was taken into account “the algorithm was somewhat more accurate than a coin flip” at 61%. Part of the enthusiasm for these algorithms had been the expectation that they might bypass the prejudices and unconscious biases of human judges, enabling fairer justice. However, while many might baulk at the thought of tossing a coin to determine someone’s prison sentence, it turns out this might be a fairer approach than the algorithm, which was found to “falsely flag black defendants as future criminals” at twice the rate of white defendants.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://realworlddatascience.net/ideas/posts/2024/05/14/images/Eleanor_Roosevelt-991724.jpg" class="img-fluid figure-img" alt="Eleanor Roosevelt reads the Universal Declaration of Human Rights in 1949; FDR Presidential Library &amp; Museum 64-165 CC-BY-2.0"></p>
<figcaption>Eleanor Roosevelt reads the Universal Declaration of Human Rights in 1949; FDR Presidential Library &amp; Museum 64-165 CC-BY-2.0</figcaption>
</figure>
</div>
<p>Since Propublica’s investigation there have been multiple reports highlighting problems with algorithms trained on historic data for use in the criminal justice system. The risk illustrated here, which can be generalised, is that such algorithms will tend to propagate social biases. In this case it means that those from ethnic minorities and lower socioeconomic backgrounds are awarded harsher sentences. Compounding the problem was the proprietary nature of the algorithms involved, which made it difficult to launch independent investigations. However, in the case of the algorithm investigated by Propublica, the input data, which is taken from questions put to the defendant and their prison records, did provide clues as to the scope for unfair outcomes. Although race is not explicitly identified, it likely correlates with other data that is used as input. This meant that the outcomes would be biased with respect to race all the same. A lot more work is needed to mitigate the effects of historical social injustices in how the criminal justice system uses data. Innovators in this area need to have confidence in what will be affected by their evidence base, as well as support from independent legal and ethical reviewers, and from regulators, to determine what will make a good innovation, and what will not.</p>
</section>
<section id="consent-human-rights-and-data-provenance" class="level2">
<h2 class="anchored" data-anchor-id="consent-human-rights-and-data-provenance">Consent, human rights, and data provenance</h2>
<p>The testing and training of AI algorithms can also run into other ethical questions about the ratio of public to private benefits from data and who governs those benefits. On the eve of the UK’s AI Summit in 2023, <a href="https://www.linkedin.com/pulse/ai-beneath-surface-pivotal-role-data-smart-data-research-uk-betwe/">Joe Cuddeford of Smart Data Research UK wrote</a>: “Many AI systems rely on data collected passively from individuals, raising questions about transparency, privacy, and who benefits from these data-driven advancements.”</p>
<p>Large scale AI models, such as generative AI models, are <a href="https://www.washingtonpost.com/technology/2023/10/25/data-provenance/">often trained on web-scraped data</a> from online platforms. This leads to questions about the fairness of internet data, the ownership of it (e.g.&nbsp;<a href="https://www.nytimes.com/2024/04/06/technology/tech-giants-harvest-data-artificial-intelligence.html">potential violation of copyright law</a>), and methods for users’ consent and human rights to be embedded and respected. There are, once again, questions about accuracy and bias: what do algorithms “learn” from data scraped from the internet, and is the information appropriately curated for use?</p>
<p>Civil liberties concerns also similarly arise when people are compelled to give up data about themselves by powerful arms of the state. For example, the national Facial Verification Testing program run by the National Institute of Standards and Technology, a part of the U.S. Department of Commerce, has held and <a href="https://slate.com/technology/2019/03/facial-recognition-nist-verification-testing-data-sets-children-immigrants-consent.html">made use of images of vulnerable individuals</a> to test and validate the performance of commercialised AI technologies. The data used by the agency for testing include ‘mugshots’ or facial images from arrests or from other encounters with law enforcement. <sup>1</sup> An additional programme focuses on testing the performance of facial recognition algorithms against an image database of sexually exploited children (<a href="https://www.nist.gov/programs-projects/chexia-face-recognition">CHEXIA-FACE</a>). Having statistics from this kind of agency testing has clear commercial benefit: it helped win the case for the vendors who could match those statistics when the <a href="https://www.met.police.uk/SysSiteAssets/media/downloads/force-content/met/advice/lfr/other-lfr-documents/lfr-accuracy-and-demographic-differential.pdf">London Metropolitan police purchased live facial recognition technology</a>. However, the interests of the people that have been documented do not come up for discussion in this form of data governance. There are many participatory methods that could be used for more ethical stewardship of the data that people are compelled to give. <sup>2</sup></p>
<p>To address the scope for minorities and vulnerable groups to play their part in data collection, it should be possible for data scientists to adopt strategies that consciously address the bias in data collection. Eun Seo Jo (from Stanford University) and Timnit Gebru (formerly at Google) have suggested library and archival approaches. In Strategies for Collecting Sociocultural Data in Machine Learning, <sup>3</sup> they note that internet data is subject to historical and representative biases. Recognising and mitigating biases will “start with a statement of commitment to collecting the cultural remains of certain concepts, topics, or demographic groups.” A public mission statement, which highlights the interests of communities and minorities they plan to support, “forces [archival] researchers to reckon with their data composition.”</p>
<p>These strategies also need to be supported by good management of data collection and curation. A report by the Royal Academy of Engineering (2021) <a href="https://reports.raeng.org.uk/datasharing/implications-for-policy">Towards trusted data sharing: implications for policy and practice</a> has highlighted that, to support the use of data for research, good data management must exist among the data owners. Strong relationships with data owners predicated on data quality and ethics will help researchers to specify what data sets they are looking for and how they can best be curated for AI purposes. Good data management will not only help AI developers but also all potential users (as well as the public) to understand the scope and the quality of what’s being shared. “Defining the requirements for data quality, and ensuring these requirements are delivered, remains a central challenge.” (<a href="https://reports.raeng.org.uk/datasharing/implications-for-policy">RAE report</a>)</p>
<p>Advocates for accurate and fair data and machine learning have worked hard to clarify what good data management and sharing looks like, which is cause for optimism. However there is the sense that this is the area in which AI has the furthest to go, as data sets currently available fall far wide from the standards recommended by their work. Nonetheless the rise of Trusted Research Environments, Data Safe Havens and other methods of open-source transparency enable more AI innovators to disclose their sources without placing any of the personal information they use at further risk, as <a href="https://realworlddatascience.net/ideas/posts/2024/05/07/ai-series-3.html">discussed previously in the AI series</a>. Leadership on ethical standards for data sharing may yet help to improve the <a href="https://oecd.ai/en/dashboards/ai-principles/P8">robustness, security, safety, and fairness of AI tools</a>, which the OECD advocates as key principles for AI.</p>
</section>
<section id="openness-explainability-and-the-scope-to-challenge-ai-decisions" class="level2">
<h2 class="anchored" data-anchor-id="openness-explainability-and-the-scope-to-challenge-ai-decisions">Openness, explainability, and the scope to challenge AI decisions</h2>
<p>A principle that many data science communities have been working on, is towards ensuring transparency and explainability of AI (<a href="https://oecd.ai/en/dashboards/ai-principles/P7">OECD AI Principle</a>). In OECD parlance that is in part “to ensure that people understand when they are engaging with [artificial intelligence] and can challenge outcomes.” In acknowledgement that some AI applications make this disclosure harder and more unappealing, the OECD suggests that the fact that AI is in use should be disclosed “with proportion to the importance of the outcome … so that consumers, for example, can make more informed choices”. The OECD emphasises the importance of the “explainability” of the algorithms, which it defines as “enabling people affected by the outcome of an AI system to understand how it was arrived at. … notably – to the extent practicable – the factors and logic that led to an outcome.”</p>
<p>The <a href="https://www.oii.ox.ac.uk/research/projects/a-fairwork-foundation-towards-fair-work-in-the-platform-economy/">tens of millions of digital ‘platform workers’</a> that now live all over the world are a case in point for where explainability is needed. They perform short-term, freelance, or temporary work through digital platforms or apps in the “gig economy”. There is little transparency about how algorithms and AI influence outcomes for gig workers, and whether platform algorithms are contributing systematically to unfair outcomes. <a href="https://www.oii.ox.ac.uk/research/projects/a-fairwork-foundation-towards-fair-work-in-the-platform-economy/">Platform workers themselves have come together</a> to share their data to understand more about the outcomes of the algorithms, or AI, which is shaping their lives.</p>
<p>It follows that where the use of an AI system does not affect outcomes for people, there may be less of a demand to publicly justify how AI arrived at its outcomes. For example, where AI is used to simulate something, or to research a decision, rather than to make a decision, there could be less weight placed on explaining the model publicly.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://realworlddatascience.net/ideas/posts/2024/05/14/images/Aerial_view_of_Silicon_Valley991.jpg" class="img-fluid figure-img" alt="Aerial view of tech cluster in Silicon Valley, taken on 29 March 2013, courtesy of Patrick Nouhaillier CC-BY-3.0"></p>
<figcaption>Aerial view of tech cluster in Silicon Valley, taken on 29 March 2013, courtesy of <a href="Patrick Nouhaillier">https://www.flickr.com/photos/patrick_nouhailler/</a> CC-BY-3.0</figcaption>
</figure>
</div>
<p>François Candelon, Theodoros Evgeniou, and David Martens, writing for the Harvard Business Review have outlined that their preference is for <a href="https://hbr.org/2023/05/ai-can-be-both-accurate-and-transparent">accuracy as well as explainability</a>. Often, to strike this balance, they will prefer ‘white box’ models which are transparent and interpretable. But not always. “In [complex] applications such as face-detection for cameras, vision systems in autonomous vehicles, facial recognition, image-based medical diagnostic devices, illegal/toxic content detection, and most recently, generative AI tools like ChatGPT and DALL-E, a black box approach may be advantageous or even the only feasible option.”</p>
<p>Even where the algorithm is too large and complicated to be interpretable, work like that conducted by the Alan Turing Institute in <a href="https://www.turing.ac.uk/research/research-projects/project-explain">Project ExplAIn</a> finds ways of extracting some kind of explanation, for instance by embedding layers in the coding. The case for opening up AI in this way has to be balanced against concerns for intellectual property, information security and privacy. There can be <a href="https://www.tripwire.com/state-of-security/ai-transparency-why-explainable-ai-essential-modern-cybersecurity">cybersecurity issues</a> with making the different layers of an AI model more open to interrogation. Nonetheless, experiments with transparent and explainable models enable developers to advance their understanding of AI, as well as to consider whether its use for decision-making is ethically sound. The OECD principles make clear that it is important that AI doesn’t elude human insight, checks and balances. As Andrew Ng highlighted in the <a href="https://youtu.be/nIIPMmZaK-s?si=T6ahpP6R1QjuUIsq">RSS fireside chat in 2021</a>: “AI is increasing concentration of power like never before…governments and regulators need to look at that and think of what to do.”</p>
</section>
<section id="appropriate-human-centred-governance" class="level2">
<h2 class="anchored" data-anchor-id="appropriate-human-centred-governance">Appropriate, human-centred governance</h2>
<p>When school exams in England were cancelled during the Covid-19 pandemic, the government’s Department for Education decided that an algorithm should be used to allot grades to A-Level students, partly as a measure to counter grade inflation (a trend in which the grades awarded for the same standard of work will tend to rise, year on year). Algorithms had been used before in previous years to adjust the marks that were awarded for exams and coursework. Here instead of exams and coursework, the input data was gathered from Ofqual’s historical records about how particular schools’ pupils had performed in previous years, and some was generated by teachers. Efforts had been made at transparency in terms of how the new algorithm would arrive at these decisions (it was a relatively simple, white box algorithm). But there were ‘outliers’ acknowledged in the model even prior to deployment. Coupled with the widespread downgrading of teacher-estimated grades to fit a curve that would avoid grade inflation, there was not a clear process by which students and schools could appeal to change their grades. <a href="https://www.theguardian.com/education/2021/feb/18/the-student-and-the-algorithm-how-the-exam-results-fiasco-threatened-one-pupils-future">Dissatisfaction with the grades awarded</a> in the absence of exams or coursework was rife, as young people regarded as academically talented by their schools fell short of the grades their teachers had predicted, and lost university places.</p>
<p>In the resulting furore, the Department for Education determined that its original policy was wrong and adopted the teacher estimated grades with an appeal process in place. The incident demonstrates that achieving the functional transparency of an algorithm is only one step in due process. Controversial policies could be using an algorithm to apportion losses across the population (e.g.&nbsp;to try to reduce grade inflation) in ways that are abhorred by individuals.</p>
<p>Vested interests also surfaced during investigation of an algorithm brought into use to <a href="https://orientblackswan.com/details?id=9789352875429#:~:text=Dissent%20on%20Aadhaar%20argues%20that,surveillance%20and%20commercial%20data%2Dmining.">tackle fraud in India’s welfare system</a>. “From 2014 to 2019, the government of Telangana “<a href="https://www.aljazeera.com/economy/2024/1/24/how-an-algorithm-denied-food-to-thousands-of-poor-in-indias-telangana">cancelled more than 1.86 million existing food security cards</a> and rejected 142,086 fresh applications without any notice.” reported Al Jazeera in January of this year. Despite the government’s initial claims that the cancelled food security cards were fraudulent, critical data scholarship in India and elsewhere has established discrepancies and errors in the algorithms used, such as, confusing the records of a valid claimant with a car-owning citizen by the same name. (Under the government’s policies, SUV owners cannot receive food aid.) Further investigations revealed that at least 7.5 per cent of the food security cards were wrongly cancelled. The investigations highlight what can be a common problem: a focus on reducing the costs of welfare programmes tends to lead services to identify false positives - wrongful claimants – rather than false negatives. Thus efforts to correct sloppy data may meet resistance if this leads to fewer “frauds” being identified, even when citizens bring evidence to challenge it.</p>
<p>There is a similar type of example in the <a href="https://www.computerweekly.com/feature/Post-Office-Horizon-scandal-explained-everything-you-need-to-know">UK’s Post Office scandal</a>, in which many sub-postmasters were wrongfully prosecuted for false accounting, after the Post Office adopted accounting software that contained significant bugs, which were covered up for many years. This similarly goes to show how far organisations can pursue wrongful judgements, and the life-changing consequences.</p>
<p>The <a href="https://digital-strategy.ec.europa.eu/en/policies/regulatory-framework-ai">EU’s new AI Act</a> advocates a risk-based approach, to balance the desire to minimise the burden of compliance while ensuring the safety of people who may be affected by the implementation of AI algorithms. Systems assessed as <a href="https://digital-strategy.ec.europa.eu/en/policies/regulatory-framework-ai">high risk according to specific criteria</a> are then “subject to strict obligations before they can be put on the market”.</p>
<p>Governments across the industrialised world have raised their hopes for AI that will help to drive increases in productivity, and do so safely in ways that are fairly constructed, making use of legitimate data sources, and with fair outcomes for society. The work of data scientists is integral to the foundations by which AI can be used for social good, from establishing protocols for data management and sharing, to understanding the workings of complex algorithms, and the use of large and unstructured data sources. Data scientists and researchers are getting closer to understanding what good looks like, not just in terms of the ethical values to uphold but the technicalities of the code and data involved. However, a great deal of not only data work but also other work also needs to be maintained to uphold the ideal of ‘AI ethics’. Support for well-established ethical and legal rights and principles, to meaningfully involve people in policies that will be affected by AI use, and to develop data governance and infrastructure. It is always possible that when we’re working on AI ethics, we find that there are fairer and more ethical approaches that should precede the use of AI.</p>
<p>“AI development raises a range of ethical questions for data practitioners, whether they are data scientists, econometricians, analysts, or statisticians,” Daniel Gibbons, Vice Chair of the Royal Statistical Society’s Data Ethics and Governance Section told <em>Real World Data Science</em>. Today, many data scientists would urge that ethical considerations precede the development of an AI algorithm and must inform its design and use, particularly for processes that significantly affect people, to ensure it does not propagate errors and injustices.</p>
<div class="article-btn">
<p><a href="../../../../../ideas/index.html">Explore more data science ideas</a></p>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-12">
<dl>
<dt>About the author</dt>
<dd>
<strong>Olivia Varley-Winter</strong> Olivia is an experienced policy manager who has worked for the Royal Statistical Society, the Open Data Institute, Open Data Charter, the Nuffield Foundation, and the Alan Turing Institute. She was part of the Ada Lovelace Institute’s founding team in 2018 to 2020 and has since supported the development of other policy-related programmes and partnerships relating to data, AI and ethics. She is presently working for Smart Data Research UK on matters pertaining to ethics and responsible data governance. She has an MSc. in Nature, Society, and Environmental Policy from University of Oxford.
</dd>
</dl>
</div>
<div class="g-col-12 g-col-md-6">
<!-- copyright goes to the author, or to Royal Statistical Society if written by staff -->
<dl>
<dt>Copyright and licence</dt>
<dd>
© 2024 Royal Statistical Society
</dd>
</dl>
<!-- confirm licence terms with contributor before publishing - must be Creative Commons licence, but different types of CC licences might be preferred -->
<p><a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> <img src="https://mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1" style="height:22px!important;vertical-align:text-bottom;"><img src="https://mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1" style="height:22px!important;margin-left:3px;vertical-align:text-bottom;"></a> This article is licensed under a Creative Commons Attribution 4.0 (CC BY 4.0) <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> International licence</a>. <!-- Add thumbnail image credit and any licence terms here --></p>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>How to cite</dt>
<dd>
Varley-Winter, O., Author. 2024. “On AI ethics - influencing its use in the delivery of public good.” Real World Data Science, May 14, 2024. <a href="https://realworlddatascience.net/ideas/posts/2024/04/22/ai-series-2.html">URL</a>
</dd>
</dl>
</div>
</div>
</div>
<!-- Make sure to update main site homepage (index.qmd) before publishing. See README for details. -->


</section>


<div id="quarto-appendix" class="default"><section id="footnotes" class="footnotes footnotes-end-of-document"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p>Grother, P., Ngan, M. &amp; Hanaoka K. Face Recognition Vendor Test (FRVT) Part 3: Demographic Effects NISTIR 8280 (2019) https://nvlpubs.nist.gov/nistpubs/ir/2019/NIST.IR.8280.pdf↩︎</p></li>
<li id="fn2"><p>Participatory data stewardship (2021) Ada Lovelace Institute https://www.adalovelaceinstitute.org/wp-content/uploads/2021/11/ADA_Participatory-Data-Stewardship.pdf ↩︎</p></li>
<li id="fn3"><p>Jo, E. S. &amp; Gebru T. Lessons from Archives: Strategies for Collecting SocioculturalData in Machine Learning Proceedings of the 2020 Conference on Fairness, Accountability, and Transparency (2020) https://dl.acm.org/doi/epdf/10.1145/3351095.3372829↩︎</p></li>
</ol>
</section></div> ]]></description>
  <category>AI</category>
  <category>AI ethics</category>
  <guid>https://realworlddatascience.net/ideas/posts/2024/05/14/ai-series-2.html</guid>
  <pubDate>Tue, 14 May 2024 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/ideas/posts/2024/05/14/images/Eleanor_Roosevelt-991724.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>AI series: Healthy datasets for optimised AI performance</title>
  <dc:creator>Fatemeh Torabi, Lewis Hotchkiss, Emma Squires, Prof. Simon E. Thompson and Prof. Ronan A. Lyons</dc:creator>
  <link>https://realworlddatascience.net/ideas/posts/2024/05/07/ai-series-3.html</link>
  <description><![CDATA[ 





<!-- article text to go here -->
<p>In Charles Babbage’s <a href="https://www.gutenberg.org/files/57532/57532-h/57532-h.htm">Passages from the Life of a Philosopher</a> he recalls two incidents where he is asked, “Pray, Mr.&nbsp;Babbage, if you put into the machine wrong figures, will the right answers come out?” Reflecting on these incidents he comments, “I am not able rightly to apprehend the kind of confusion of ideas that could provoke such a question.” Similarly, accurate and clean data is at the core of a functional AI model. However, ensuring accuracy of input data to avoid any “wrong figures” creeping into training datasets used to train AI models, demands meticulous attention during the stages of data wrangling, cleaning, and curation.</p>
<p>This necessity is particularly pronounced when dealing with the vast datasets used for training machine learning algorithms which are at the core of AI models. The predictive power of these models are highly dependent on the quality of the training data. <sup>1</sup> The most obvious errors which often require meticulous attention at data processing stages are duplication, missingness and data imbalance (Figure&nbsp;1). The presence of any of these errors can exert multifaceted impacts both in the training and testing stage of machine learning algorithms that are at the core of any AI models, and the challenge does not end there. The provenance, content, format and structure of the data require attention as well. Even data that is essentially correct may be “wrong” for a particular data set.</p>
<section id="obviating-the-obvious-errors" class="level2">
<h2 class="anchored" data-anchor-id="obviating-the-obvious-errors">Obviating the obvious errors</h2>
<p>Duplicated records can mask existing diversities within the data, diminishing the representativeness of important subgroups and leading to a biased training set and model outcomes. If duplication originates from data labelling issues, it can lead to fundamental challenges during the training of supervised models. <sup>2</sup> In healthcare data, this issue can arise when linking data across multiple sources where each source holds different labels for the same data. <sup>3</sup></p>
<p>Missingness directly leads to loss of information required for training the algorithms on various real-world scenarios. It is typically addressed via two primary routes: deletion of missing rows or imputation. Deleting missing rows results in a reduction of the sample size and bias. For instance, when it comes to health data, using electronic medical records from a single health provider such as general practice may give rise to a lot of missingness in other aspects of an individual’s health such as their hospital records, pathology testing data or medical imaging. On the one hand, structured missingness can serve as an informative feature to explore within the data. However in cases where missing data causes pixelation in the comprehensive health picture we are attempting to construct, it often conceals an underlying narrative. <sup>4</sup> For instance, the COVID-19 response involved many initiatives across the AI community, however, during the early stages of the pandemic partial availability of data pixelated the picture and impacted models predictive ability which resulted in a minimal improvement according to the UK’s national centre for data science and AI report. <sup>5</sup></p>
<p>Imputing missing values can preserve the whole sample. However, the introduction of noise during the imputation process may compromise the quality of fitted models, contingent upon the proportion of missing records. One way to offset this may be to use larger and larger data sets that might inevitably include a fuller training picture to the algorithm, just as adding dots to a pixelated image makes it more and more clear what is depicted.</p>
<p>It is often perceived that for certain instances, particularly in the context of deep learning models, such as neural networks, the model itself is capable of handling missing values without explicit imputation or deletion procedures. <sup>6</sup> Is this really true in a real-world scenario? Are these models advanced enough to achieve an optimised performance even when data quality is not at an optimised level? <sup>7</sup> Köse et al.&nbsp;(2020) investigated the effect of two conventional imputation approaches: Multiple imputation (MICE) <sup>8</sup> and Factor analysis of mixed data (FAMD) <sup>9</sup> on performance of deep learning models. Their study endorsed the use of such explicit imputation approaches, showing an enhancement in model performance. <sup>10</sup></p>
<p>Data imbalance issues, arise within datasets where there is a disproportionate amount of information pertaining to a specific aspect. When imbalanced data, rich in focused information, is used to train an AI model, the model becomes adept at learning about the specific aspect but may struggle to generalise its findings to diverse scenarios, thus fostering overfitting where the model achieves accurate prediction on the training data but loses accuracy for any new test dataset.</p>
<div id="fig-1" class="quarto-figure quarto-figure-center quarto-float anchored" alt="Stages involved in AI model development" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="https://realworlddatascience.net/ideas/posts/2024/05/07/images/Stages-of-model-development-724.png" class="img-fluid quarto-figure quarto-figure-center figure-img" alt="Stages involved in AI model development">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;1: Stages involved in AI model development.
</figcaption>
</figure>
</div>
<p>Overfitting severely undermines the predictive performance of AI models on data beyond their training set, defeating the primary purpose of these models. For instance, out of all strokes that occur, approximately 85% are ischaemic, caused by blockage of blood supply to part of the brain, and 15% are haemorrhagic, caused by bleeding into the brain. Development of machine-learning and AI-based stroke predictive models are therefore being affected by this natural imbalance in the two types of stroke. <sup>11</sup> This type of imbalance also exists in population wide studies where stroke itself is only present in a minority subsection of a healthy population. <sup>12</sup></p>
<p>The circumstances of data collection can lead to bias, so care is needed at early stages to ensure that datasets are representative of the real world. These types of error can be picked up at an initial Quality Assurance (QA) stage conducted to reveal any unexpected errors in data used by AI models. QA checks often involve principle checks on presented values to ensure they are the right data type and within the expected range and have the expected temporal coverage.</p>
<p>Finally the choice of features included in a data set requires consideration since this can also have implications on an algorithm. Taking another example from the COVID-19 pandemic, a group of researchers trained an algorithm on radiological imaging of COVID-19 patients where the position of the patient during radiology was present as a feature in the dataset. However, since more severe cases were lying down and less severe cases were standing up, the existence of this feature resulted in an algorithm that predicted COVID-19 risk based on the position of the patients. Here although the data included was correct, its inclusion in the dataset proved to be “wrong”.</p>
</section>
<section id="things-get-complicated" class="level2">
<h2 class="anchored" data-anchor-id="things-get-complicated">Things get complicated</h2>
<p>When AI algorithms encounter complex, unstructured data, the task of quality assurance suddenly balloons beyond tackling the three main errors highlighted above. Such circumstances require some kind of quality enhancement procedure, where datasets in the form of images or unstructured text go through a curation process which involves enhancement of the quality and standardisation of the format to the level required for integration into AI algorithms. This process of standardization of data is paramount across various domains, especially in healthcare where complex, unstructured health data holds transformative potential for AI driven advances that revolutionise diagnosis, treatment, and prognosis of diseases. From electronic health records to magnetic resonance imaging (MRI) scans and genetic sequences, this data offers a wealth of insights for AI models to learn from. Adopting standardised formats not only facilitates seamless integration of diverse datasets but also streamlines the development and deployment of AI models. However, unlocking this potential requires a strong foundation in high-quality, processed data which begins with standardisation.</p>
<p>One category of complex health data is neuroimaging of which a prime example is MRI. Different institutions will often employ different acquisition protocols and different ways of collecting and storing neuroimaging data. Above all, this can make it very difficult to integrate into existing workflows and processing pipelines, but it also makes it challenging to understand, compare and combine with other datasets. To address these challenges, the neuroimaging community has adopted the Brain Imaging Data Structure (BIDS) <sup>13</sup> – a standardised format for organising and naming MRI data which allows compliant data to integrate smoothly with existing workflows and AI models, streamlining processing and analysis. By embracing standardisation, we can pave the way for common processing tools to enable the generation of AI-ready data.</p>
<p>Next, comes pre-processing. Sticking with the neuroimaging example, MRI scans are susceptible to various forms of noise and artifacts, which can appear as blurring or distortions which, without proper processing, can be misinterpreted by AI models. Pre-processing typically includes steps for spatial normalisation and image registration, involving alignment of brain images from different individuals into a common reference model and alignment of different images of the same subject to a common template. This standardisation facilitates inter-subject and inter-study comparisons, enabling AI models to generalise effectively across diverse datasets. However, the multi-layer aspect of this process means that aligning data to a common template is dependent on the choice of template which itself can introduce bias if the template brain doesn’t accurately reflect the patient’s anatomy (due to age, ethnicity, or disease for example).</p>
<div id="fig-2" class="quarto-figure quarto-figure-center quarto-float anchored" alt="Neuroimaging data" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="https://realworlddatascience.net/ideas/posts/2024/05/07/images/neuroimaging.jpg" class="img-fluid quarto-figure quarto-figure-center figure-img" alt="Neuroimaging data">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2: Neuroimaging data.
</figcaption>
</figure>
</div>
<p>Once pre-processing is complete, you may want to combine datasets to increase sample sizes for your AI model. This is where harmonisation techniques <sup>14</sup> <sup>15</sup> come in to deal with inconsistencies and variations in acquisition which can add noise and bias into a model. A typical technique for harmonisation in neuroimaging, known as ComBat <sup>16</sup>, works by modelling data using a hierarchical Bayesian model and followed by empirical Bayes to infer the distribution of the unknown factors. The method is actually borrowed from genomics data but is applicable to situations where multiple features of the same type are collected for each participant, whether that be expression levels for genes, or imaging derived measures such as volumes from different regions. This is a crucial step for combining datasets to enable AI models to focus on learning the actual relationships within the data rather than struggling with inconsistencies across datasets. It also leads to models which can generalise better on unseen data.</p>
</section>
<section id="feeding-hungry-algorithms" class="level2">
<h2 class="anchored" data-anchor-id="feeding-hungry-algorithms">Feeding hungry algorithms</h2>
<p>The public good is at the heart of AI driven approaches and indeed, the aim is to develop models with optimised predictive ability that can be generalised to many scenarios. For this to be achieved a large and diverse training source is required. This is often referred to as data hungry algorithms. To provide a large amount of enriched training data for optimised model development two main approaches have been explored: federated analytics and synthetic data.</p>
<p>Federation is when data from multiple sources is made available for training and analysis of models designed to run on data that is not held in a single place, nominally called distributed models. It provides the opportunity to test algorithms in different populations/settings to ensure generalisability. In the context of patient-level health data, the data is often held institutionally. Enabling federation and trustworthy sharing of these datasets requires extensive attention to governance models and a common model between multiple organisations is a known catalyst of this process <sup>17</sup> <sup>18</sup></p>
<p>Generating synthetic data <sup>19</sup> from original data sources is a resource intensive mechanism. It requires the development of models on the real data to learn existing patterns, formats, and statistical properties within the original data from which it is possible to generate further synthetic versions of these data. When working with sensitive data such as health records, ensuring patient data is safe and secure is covered by information governance. Depending on how close the synthetic data source is to the original data, the same governance level may still be applicable when trying to bring individual/patient data from multiple sources together. A suggested solution to overcome the governance challenges in the context of synthetic data is to use a <a href="https://www.adruk.org/news-publications/news-blogs/accelerating-public-policy-research-with-easier-safer-synthetic-data/">low-fidelity version</a> of the original data which means a level of bias has been added throughout the synthesisation process to ensure safety and security of individual level data. <sup>20</sup> While the low fidelity data sources are generated based on real data, it is worth noting that the rise in generative AI also poses a concern for data pollution, particularly where AI tools such as Gretel.ai <sup>21</sup> are used to generate synthetic data which may also be used to train AI models – the problematic case of AI training AI!</p>
<p>When using sensitive health data of patients a further layer is in place to ensure security of access. These are called Trusted Research Environments (<a href="https://www.hdruk.ac.uk/access-to-health-data/trusted-research-environments/">TREs</a>), secure technology infrastructures which play a crucial role in consolidating disparate data collections into a centralised repository, facilitating researcher access to data for scientific exploration. However, integrating data from various sources into AI models poses challenges due to differences in data collection methods and formats, hindering computational analysis. In response, the FAIR (Findable, Accessible, Interoperable, Reusable) data principles were introduced in 2016 to enhance the reusability of scientific datasets by humans and machines. <sup>22</sup> Adoption of FAIR principles within TREs ensures well-documented, curated, and harmonised datasets, addressing issues raised above such as duplicated records and missing data. <sup>23</sup> Additionally, preprocessing pipelines within TREs streamline data standardisation, creating “AI research-ready” datasets. <sup>24</sup></p>
<p>Access to real-world healthcare data remains challenging, prompting the development of AI models on open-source or synthetic datasets. However, these models often exhibit performance discrepancies when applied to real world data <sup>25</sup> It is therefore imperative to provide researchers with secure access to real-world healthcare data within TREs, bolstered by robust governance and support mechanisms. Initiatives like the GRAIMATTER study <sup>26</sup> and AI risk evaluation workshops <sup>27</sup> exemplify efforts to facilitate AI model development and translation from TREs to clinical settings. By establishing governance guidelines and promoting FAIR datasets, TREs aim to become important resources for the AI research community. Providing standardised and curated data rich repositories that AI models can be developed on is a top priority in UK-TREs. Given the well-defined and secure governance environments of TREs they may also provide the basis for federated data analysis allowing researchers to combine datasets across TREs/data environments. In this way they can provide the large numbers that data hungry algorithms require, while avoiding the wide-ranging and myriad ways that data for a specific dataset can be “wrong”.</p>
</section>
<section id="also-in-the-ai-series" class="level2">
<h2 class="anchored" data-anchor-id="also-in-the-ai-series">Also in the AI series:</h2>
<p><a href="https://realworlddatascience.net/ideas/posts/2024/04/22/ai-series-1.html">What is AI? Shedding light on the method and madness in these algorithms</a> <a href="https://realworlddatascience.net/ideas/posts/2024/04/29/gen-ai-human-intel.html">Generative AI models and the quest for human-level artificial intelligence</a></p>
<div class="article-btn">
<p><a href="../../../../../ideas/index.html">Explore more data science ideas</a></p>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-12">
<dl>
<dt>About the authors</dt>
<dd>
<strong>Fatemeh Torabi</strong> is Senior Research Officer and Data Scientist, at Swansea University and works on Health Data Science and Population Data Science for the Dementias Platform UK.
</dd>
<dd>
<p><strong>Lewis Hotchkiss</strong> is a Research Officer in Neuroimaging at Swansea University and works on Population Data Science for the Dementias Platform UK.</p>
</dd>
<dd>
<p><strong>Emma Squires</strong> is the Data Project Manager for Dementias Platform UK based at Swansea University and works on Population Data Science</p>
</dd>
<dd>
<p><strong>Prof.&nbsp;Simon E. Thompson</strong> is Deputy Associate Director of the Dementias Platform UK</p>
</dd>
<dd>
<p><strong>Prof.&nbsp;Ronan A. Lyons</strong> is the Associate Director of the Dementias Platform UK based at Swansea University and works on Population Data Science.</p>
</dd>
</dl>
</div>
<div class="g-col-12 g-col-md-6">
<!-- copyright goes to the author, or to Royal Statistical Society if written by staff -->
<dl>
<dt>Copyright and licence</dt>
<dd>
© 2024 Royal Statistical Society
</dd>
</dl>
<!-- confirm licence terms with contributor before publishing - must be Creative Commons licence, but different types of CC licences might be preferred -->
<p><a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> <img src="https://mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1" style="height:22px!important;vertical-align:text-bottom;"><img src="https://mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1" style="height:22px!important;margin-left:3px;vertical-align:text-bottom;"></a> This article is licensed under a Creative Commons Attribution 4.0 (CC BY 4.0) <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> International licence</a>. <!-- Add thumbnail image credit and any licence terms here --></p>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>How to cite</dt>
<dd>
Torabi, Fatemeh, Hotchkiss, Lewis, Squires, Emma, Thompson, Simon E. and Lyons, Ronan A. 2024. “Getting the data right for optimised AI performance.” Real World Data Science, May 7, 2024. <a href="https://realworlddatascience.net/ideas/posts/2024/05/07/ai-series-3.html">URL</a>
</dd>
</dl>
</div>
</div>
</div>
<!-- Make sure to update main site homepage (index.qmd) before publishing. See README for details. -->


</section>


<div id="quarto-appendix" class="default"><section id="footnotes" class="footnotes footnotes-end-of-document"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p>Li, P. et al.&nbsp;CleanML: A Benchmark for Joint Data Cleaning and Machine Learning [Experiments and Analysis]↩︎</p></li>
<li id="fn2"><p>Azeroual, O. et al.&nbsp;A Record Linkage-Based Data Deduplication Framework with DataCleaner Extension. Multimodal Technol. Interact. 2022, Vol. 6, Page 27 6, 27 (2022).↩︎</p></li>
<li id="fn3"><p>Rajpurkar, P., Chen, E., Banerjee, O. &amp; Topol, E. J. AI in health and medicine. Nat. Med. 2022 281 28, 31–38 (2022).↩︎</p></li>
<li id="fn4"><p>Mitra, R. et al.&nbsp;Learning from data with structured missingness. (2023).↩︎</p></li>
<li id="fn5"><p>Alan Turing Institution. Data science and AI in the age of COVID-19. 2020 https://www.turing.ac.uk/sites/default/files/2021-06/data-science-and-ai-in-the-age-of-covid_full-report_2.pdf↩︎</p></li>
<li id="fn6"><p>Han, J. &amp; Kang, S. Dynamic imputation for improved training of neural network with missing values. Expert Syst. Appl. 194, 116508 (2022).↩︎</p></li>
<li id="fn7"><p>Köse, T. et al.&nbsp;Effect of Missing Data Imputation on Deep Learning Prediction Performance for Vesicoureteral Reflux and Recurrent Urinary Tract Infection Clinical Study. Biomed Res. Int. 2020, (2020).↩︎</p></li>
<li id="fn8"><p>Azur, M. J., Stuart, E. A., Frangakis, C. &amp; Leaf, P. J. Multiple imputation by chained equations: what is it and how does it work? Int. J. Methods Psychiatr. Res. 20, 40–49 (2011).↩︎</p></li>
<li id="fn9"><p>Audigier, V., Husson, F. &amp; Josse, J. A principal component method to impute missing values for mixed data. Adv. Data Anal. Classif. 10, 5–26 (2016).↩︎</p></li>
<li id="fn10"><p>Köse, T. et al.&nbsp;Effect of Missing Data Imputation on Deep Learning Prediction Performance for Vesicoureteral Reflux and Recurrent Urinary Tract Infection Clinical Study. Biomed Res. Int. 2020, (2020).↩︎</p></li>
<li id="fn11"><p>Liu, T., Fan, W. &amp; Wu, C. A hybrid machine learning approach to cerebral stroke prediction based on imbalanced medical dataset. Artif. Intell. Med. 101, 101723 (2019).↩︎</p></li>
<li id="fn12"><p>Kokkotis, C. et al.&nbsp;An Explainable Machine Learning Pipeline for Stroke Prediction on Imbalanced Data. Diagnostics 2022, Vol. 12, Page 2392 12, 2392 (2022).↩︎</p></li>
<li id="fn13"><p>Gorgolewski, K. J. et al.&nbsp;BIDS apps: Improving ease of use, accessibility, and reproducibility of neuroimaging data analysis methods. PLoS Comput. Biol. 13, (2017).↩︎</p></li>
<li id="fn14"><p>Bauermeister, S. et al.&nbsp;Research-ready data: the C-Surv data model. Eur. J. Epidemiol. 38, 179–187 (2023).↩︎</p></li>
<li id="fn15"><p>Abbasizanjani, H. et al.&nbsp;Harmonising electronic health records for reproducible research: challenges, solutions and recommendations from a UK-wide COVID-19 research collaboration. BMC Med. Inform. Decis. Mak. 23, 1–15 (2023).↩︎</p></li>
<li id="fn16"><p>Orlhac, F. et al.&nbsp;A Guide to ComBat Harmonization of Imaging Biomarkers in Multicenter Studies. J. Nucl. Med. 63, 172 (2022).↩︎</p></li>
<li id="fn17"><p>Toga, A. W. et al.&nbsp;The pursuit of approaches to federate data to accelerate Alzheimer’s disease and related dementia research: GAAIN, DPUK, and ADDI. Front. Neuroinform. 17, 1175689 (2023).↩︎</p></li>
<li id="fn18"><p>Torabi, F. et al.&nbsp;A common framework for health data governance standards. Nat. Med. 2024 1–4 (2024) doi:10.1038/s41591-023-02686-w.↩︎</p></li>
<li id="fn19"><p>Tucker, A., Wang, Z., Rotalinti, Y. &amp; Myles, P. Generating high-fidelity synthetic patient data for assessing machine learning healthcare software. npj Digit. Med. 2020 31 3, 1–13 (2020)↩︎</p></li>
<li id="fn20"><p>Tucker, A., Wang, Z., Rotalinti, Y. &amp; Myles, P. Generating high-fidelity synthetic patient data for assessing machine learning healthcare software. npj Digit. Med. 2020 31 3, 1–13 (2020)↩︎</p></li>
<li id="fn21"><p>Noruzman, A. H., Ghani, N. A. &amp; Zulkifli, N. S. A. Gretel.ai: Open-Source Artificial Intelligence Tool To Generate New Synthetic Data. MALAYSIAN J. Innov. Eng. Appl. Soc. Sci. 1, 15–22 (2021).↩︎</p></li>
<li id="fn22"><p>Wilkinson, M. D. et al.&nbsp;The FAIR Guiding Principles for scientific data management and stewardship. Sci. Data 2016 31 3, 1–9 (2016).↩︎</p></li>
<li id="fn23"><p>Chen, Y. et al.&nbsp;A FAIR and AI-ready Higgs boson decay dataset. Sci. Data 9, (2021).↩︎</p></li>
<li id="fn24"><p>Esteban, O. et al.&nbsp;fMRIPrep: a robust preprocessing pipeline for functional MRI. Nat. Methods 16, 111–116 (2018).↩︎</p></li>
<li id="fn25"><p>Alkhalifah, T., Wang, H. &amp; Ovcharenko, O. MLReal: Bridging the gap between training on synthetic data and real data applications in machine learning. Artif. Intell. Geosci. 3, 101–114 (2022).↩︎</p></li>
<li id="fn26"><p>Jefferson, E. et al.&nbsp;GRAIMATTER Green Paper: Recommendations for disclosure control of trained Machine Learning (ML) models from Trusted Research Environments (TREs). doi:10.5281/ZENODO.7089491.↩︎</p></li>
<li id="fn27"><p>DARE UK Community Working Group - DARE UK. https://dareuk.org.uk/dare-uk-community-working-groups/dare-uk-community-working-group-ai-risk-evaluation-working-group/.↩︎</p></li>
</ol>
</section></div> ]]></description>
  <category>AI</category>
  <category>Data management</category>
  <category>Data science education</category>
  <guid>https://realworlddatascience.net/ideas/posts/2024/05/07/ai-series-3.html</guid>
  <pubDate>Tue, 07 May 2024 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/ideas/posts/2024/05/07/images/Stages-of-model-development-724.png" medium="image" type="image/png" height="105" width="144"/>
</item>
<item>
  <title>AI series: Generative AI models and the quest for human-level artificial intelligence</title>
  <dc:creator>Diego Miranda-Saavedra</dc:creator>
  <link>https://realworlddatascience.net/ideas/posts/2024/04/29/gen-ai-human-intel.html</link>
  <description><![CDATA[ 





<p>Generative artificial intelligence (AI) models have taken the world by storm over the past year. The human-like outputs of these systems, and the recent publication of a guideline to determine the degree of consciousness of machines, have again raised the question of whether machines will soon be able to replicate human intelligence. In this article, we discuss some of the merits and limitations of modern machine learning models, and also provide a general view of human intelligence and the position of “intelligent” systems in the constellation of human capabilities.</p>
<p>Large language models (LLMs) such as ChatGPT are designed to process and understand natural language, and to generate human-like text in response to prompts and questions. This is achieved thanks to a specific type of deep learning architecture called the <em>Transformer</em>, which consists of an encoder and a decoder, each made up of some number <em>N</em> of blocks. Here the input text is eventually transformed into predicted (and contextualised) output text (Figure&nbsp;1).<sup>1</sup> LLMs are trained on complex and large bodies of text so that they can learn complex patterns and relationships between words in sentences, in different contexts.</p>
<div id="fig-1" class="quarto-figure quarto-figure-center quarto-float anchored" alt="Architecture of the Transformer. The left-hand block is the Encoder, whereas the right-hand block represents the decoder" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="https://realworlddatascience.net/ideas/posts/2024/04/29/images/fig1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" alt="Architecture of the Transformer. The left-hand block is the Encoder, whereas the right-hand block represents the decoder">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;1: Architecture of the Transformer. The left-hand block is the Encoder, whereas the right-hand block represents the decoder.
</figcaption>
</figure>
</div>
<p>The two main types of LLMs are autoregressive models and autoencoding models. Autoregressive models such as OpenAI’s GPT (Generative Pre-trained Transformer) generate text by predicting the next word in a sequence given the previously emitted words. Autoencoding models such as Google’s BERT (Bidirectional Encoder Representations from Transformers) also aim to produce coherent and contextually relevant text, but they do so by attempting to predict missing words (from a corrupted version of the text) while considering the surrounding context.</p>
<p>LLMs are engineering marvels capable of producing syntactically flawless, coherent, and remarkable responses to complex requests such as question answering, text summarisation, computer code generation, document classification, text generation and sentiment analysis. We tend to associate linguistic skills with intelligence because communication via an elaborate language system is largely synonymous with the human intellect. So, do the linguistic skills of tools like ChatGPT mean these systems are close to displaying human-level intelligence? Proponents of the Turing test might well argue “yes”. Most would still say “no”.</p>
<section id="speaking-and-understanding" class="level2">
<h2 class="anchored" data-anchor-id="speaking-and-understanding">Speaking and understanding</h2>
<p>The Turing test was proposed by Alan Turing in the 1950s. It operates on the basis that if a person is unable to tell whether the entity they are interacting with over typed messages is a human or a machine (irrespective of the answers being correct), the machine is said to have achieved human-level intelligence.<sup>2</sup> There’s some debate over whether ChatGPT could pass this test; it has been specifically trained not to impersonate humans and will frequently preface its responses with the phrase, “As a large language model…”, thus giving the game away. But <a href="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/01/27/talking-chatgpt.html">others are impressed at what developers like OpenAI have been able to achieve</a> in terms of building artificial models that can sustain realistic-sounding conversations.</p>
<p>This, though, is where the Turing test falls apart as a means of assessing machine intelligence. The ability to “<a href="https://www.nature.com/articles/d41586-023-02361-7">mimic human chatter</a>” does not by itself suggest that a machine understands what it is ‘reading’ or ‘writing’ in the same way a human would. Consider a different set of tests, called the Winograd schemas – puzzles that differ by one or two words and whose solutions cannot be determined using statistics but instead require common sense and an understanding of the physical world.<sup>3</sup> For example, the following sentence:</p>
<blockquote class="blockquote">
<p>The trophy would not fit in the suitcase because it was too <strong>small/large</strong>.</p>
</blockquote>
<p>Humans would infer that if the last word of that sentence is <em>small</em>, then <em>suitcase</em> is the object being described, whereas if the word is <em>large</em> then we are referring to the <em>trophy</em>. ChatGPT v3.5 was unable to make this inference when the question was first put to it (see Figure&nbsp;2), although a later test finds it now can – as can other LLMs. Some suggest that this type of improvement comes from training ChatGPT to do better on some of the tasks that are routinely used to highlight model limitations on social media at the expense of <a href="https://www.searchenginejournal.com/chatgpt-quality-worsened/492145/">giving worse answers in other contexts</a>. But could this improvement be due to ChatGPT and other models suddenly having acquired common sense and an understanding of the physical world? A more complex set of Winograd schema questions, the WinoGrande dataset, suggests not: humans still outperform computers on these tests.<sup>4</sup></p>
<div id="fig-2" class="quarto-figure quarto-figure-center quarto-float anchored" alt="Screenshot of author's ChatGPT conversation, prompting the AI chatbot to solve a WinoGrad schema question" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="https://realworlddatascience.net/ideas/posts/2024/04/29/images/fig2.png" class="img-fluid quarto-figure quarto-figure-center figure-img" alt="Screenshot of author's ChatGPT conversation, prompting the AI chatbot to solve a WinoGrad schema question">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2: GPT-3.5’s inconclusive answer to a typical WinoGrad schema question.
</figcaption>
</figure>
</div>
<p>Machines will likely beat us all at these puzzles one day, in the same way that they already beat the world champions of chess and Go, can translate across multiple languages, and diagnose rare forms of cancer that escape well-trained doctors. These <em>narrow AI</em> applications that spectacularly outperform humans at very specific tasks will become more and more common. But will a multiplicity of narrow AI soon lead to general AI that can compete or beat humans at <em>all</em> tasks? Will human-level linguistic capabilities inevitably result in machines acquiring human-level intelligence in the not-too-distant future? Some developers and researchers certainly believe or hope so. Others remain sceptical.</p>
</section>
<section id="thinking-and-learning" class="level2">
<h2 class="anchored" data-anchor-id="thinking-and-learning">Thinking and learning</h2>
<p>What is “intelligence”, anyway? More than 70 working definitions currently exist.<sup>5</sup> One that focuses specifically on human-level intelligence while excluding lower types of animal intelligence is this: “intelligence can be understood as the ability to generate a range of plausible scenarios about how the world around you may unfold and then base sensible actions on those predictions”.<sup>6</sup> Does this come anywhere close to describing the way LLMs work, or indeed any other machine learning algorithm?</p>
<p>In my view, part of the reason why attaining human-level intelligence remains a distant goal has to do with how machines think differently from us.</p>
<p>The goal of a machine learning algorithm is always to optimise a particular function – whether the machine is playing chess (the goal is to win) or classifying images (the goal is to correctly classify as many images as possible). The majority of problems that human intelligence has to “solve”, however, do not always have a clear goal. Consider a simple chatbot standing in for a human on a customer helpline: What scalar quantity should it look to optimise? Is it ensuring that engagement with the customer is informative and supportive? Or, perhaps the goal is to build a recurrent relationship. In either case, how will these quantities be measured? Dealing with this type of real-world problem, where the variable to optimise is not well-defined, represents a formidable obstacle for the development of machine learning algorithms whose behaviour must approximate human intelligence.</p>
<p>Moreover, machines can be surprisingly easy to fool. For example, placing an object next to the one we are trying to classify can confuse image classification algorithms – a <a href="https://www.youtube.com/watch?v=i1sp4X57TL4">well-known example shows a patch being placed next to a banana</a>, which makes the deep neural network (DNN) classify the banana as a toaster with a high degree of confidence. We can also fool image classification networks <a href="https://arxiv.org/abs/1811.11553">by showing the same object under different lighting conditions and orientations</a>, such as when we flip a school bus on its side (as in an accident). The reason why a DNN cannot do this trivial mental rotation is because learning algorithms cannot generalise knowledge to unseen (or “out of distribution”) examples – imbuing them with no small amount of “brittleness”.<sup>7</sup> Compare this to the human mind, which learns in a semi-supervised manner: we need only be shown a few guiding examples to be able to extrapolate knowledge. This is a clear evolutionary adaptation since most real-world learning is semi-supervised: we do not need to explore every road to learn to drive, nor do every possible differentiation exercise to become confident at calculus. Likewise, we do not need to become fully bilingual in a language before we start combining newly learned words to try to explain complex concepts.</p>
<p>Next to GPT-4’s <a href="https://arxiv.org/abs/2303.08774">100-trillion parameter model</a>, the human brain seems <a href="https://www.wired.com/story/cerebras-chip-cluster-neural-networks-ai/">much more</a> <a href="https://arxiv.org/pdf/2005.14165">parsimonious</a>. Therefore, progress in AI would perhaps come faster if we could teach machines to learn from a few (or no) labelled examples instead of being so heavily dependent on terabytes of labelled data (supervised learning) and on our own interpretation of the world.<sup>8</sup></p>
<p>Another major limitation of algorithms for achieving human-like adaptive learning in changing environments is the fact that they cannot keep learning without forgetting previously learned training data. This phenomenon is called <em>catastrophic forgetting</em>,<sup>9</sup> and it occurs because of the <em>stability-plasticity dilemma</em>: this states that a certain degree of plasticity is required for the integration of new knowledge, but also radically new knowledge (e.g.&nbsp;large weight changes in a DNN) disrupts the stability necessary for retaining the previously learned representations (Figure&nbsp;3). In other words, weight stability is synonymous with knowledge retention, but it also introduces the rigidity that prevents the learning of new tasks.<sup>10</sup></p>
<div id="fig-3" class="quarto-figure quarto-figure-center quarto-float anchored" alt="Illustration of catastrophic forgetting and ideal learning in a two-class classifier" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-3-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="https://realworlddatascience.net/ideas/posts/2024/04/29/images/fig3.png" class="img-fluid quarto-figure quarto-figure-center figure-img" alt="Illustration of catastrophic forgetting and ideal learning in a two-class classifier">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-3-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;3: Illustration of catastrophic forgetting and ideal learning in a two-class classifier.
</figcaption>
</figure>
</div>
<p>Although some ingenious approaches have been developed for mitigating catastrophic forgetting (and which are much smarter than simply building a new network for each new task), it has also been shown that no single method can solve catastrophic forgetting while allowing incremental learning in every possible situation.<sup>11</sup> The problem with catastrophic forgetting is not only that it contradicts a fundamental characteristic of human intelligence – the ability to learn within, and adapt to, changing environments;<sup>12</sup> catastrophic forgetting is also a major bottleneck for the development of adaptable systems that learn incrementally from the constant flow of data in the real world, such as autonomous vehicles, recommender systems, anomaly detection methods and, in general, any device embedded with sensors. Moreover, the development of continual learning methods is key not just for machine intelligence, but also for learning scalability: by 2025 the world will be <a href="https://www.seagate.com/files/www-content/our-story/trends/files/idc-seagate-dataage-whitepaper.pdf">producing some 175 zettabytes of data annually</a>, of which we will only be able to <a href="https://www.uber.com/en-GB/blog/uber-big-data-platform/">store between 3% and 12%</a>. Thus, for learning to be scalable in the future, continual learning methods will need to be able to process data faster and in real time, learn on the fly and then discard the data, much like humans do.</p>
</section>
<section id="how-are-we-wired" class="level2">
<h2 class="anchored" data-anchor-id="how-are-we-wired">How are we wired?</h2>
<p>One further bottleneck for machines emulating human-level intelligence is that we do not yet understand the circuitry of the brain well enough to be able to reproduce it, and therefore we have been working with misleading models. For instance, the realisation of the “all-or-nothing” nature of action potentials (i.e.&nbsp;there is no such thing as the partial firing of a neuron) led McCulloch and Pitts to propose the concept of the artificial neuron and suggest that networks of neurons could equally be modelled as (all-or-nothing) logical propositions.<sup>13</sup> From this point onwards, the dominant idea over most of the past century has been that the brain is essentially a computer. But even on a superficial level of analysis, brains and computers have very different architectures and behaviour, with computers specifically making optimal use of virtually unlimited memory as well as an extraordinary capacity for brute-force searching. On the microscopic level, networks of neurons cannot possibly be modelled as logical propositions because they do not really operate in this manner: a single neuronal synapse is an environment that harbours hundreds of proteins that specifically interact with other proteins in complex networks that possess clear time-space coordinates. Neurons process information and generate not just electrical signals but also discrete biochemical changes that occur in cycles instead of linearly. Moreover, a system like the brain responds to stimuli over long periods of time, which can effect changes in its own behaviour. Understanding at least how some cognitive tasks are performed at an algorithmic level would likely translate into major progress towards emulating human-level intelligence.<sup>14</sup></p>
<p>GPT-4’s impressive capabilities can make people believe that some AI systems are conscious on a human level (since animals display limited consciousness), but this is an illusion. Consciousness is another essential quality that we can easily recognise when we see it, but which (like intelligence) is extraordinarily difficult to define – other than consciousness simply being everything you experience, or, more formally put, the “awareness of internal and external existence”.<sup>15</sup> Could machines eventually achieve consciousness? This is a controversial and key question because, besides intelligence, having a degree of consciousness on the level exercised by humans is believed to be necessary for displaying goal-directed behaviour.<sup>16</sup> Recall that machine learning algorithms do have the general goal of optimising functions but these goals are determined by human programmers, not the machines themselves.</p>
<p>A fundamental question regarding the development of consciousness is this: if an AI system were close to consciousness, how would we know? Butlin and colleagues recently explored the question in a groundbreaking paper where they compiled a list of “indicator properties” drawn from various neuroscientific theories of consciousness (since no theory is clearly superior). The idea is that the more boxes an AI system ticks, <a href="https://arxiv.org/pdf/2308.08708.pdf">the more likely it is close to being conscious</a>. The authors argue that a failure to identify artificial consciousness has important moral implications because an entity that exhibits consciousness invariably influences how we feel it should be treated. While this is likely true, humans do not necessarily need to feel that an entity is conscious in order to develop empathy. Emotional attachment is a basic human instinct, and we have a tendency to anthropomorphise. You may remember the story of hitchBOT, a clearly unconscious yet friendly robot invented by David Smith of McMaster University. <a href="https://twitter.com/hitchbot">HitchBOT</a> could barely speak and its only mission was to autostop. It ended up travelling throughout Europe and North America thanks to the sympathy it generated. The “beheading” of the robot in Philadelphia in 2015 had huge repercussions across the planet because thousands of strangers had developed empathy and become <a href="https://www.gq.com/story/americans-murder-friendly-canadian-hitchhiking-robot">emotionally attached to hitchBOT</a> despite never having met it.<sup>17</sup> Do you think that a machine is likely to develop a degree of human-like empathy anytime soon?</p>
<p>Finally, another fundamental human trait that is absent from machines, and which is particularly important in these trying times, is our capacity for remaining <em>hopeful</em>, which can be seen as a post-hoc rationalisation of our survival instinct. Being hopeful means that we think things will improve beyond what would be reasonable to predict for the immediate or medium-term future given the most recently available data points. Jane Goodall defines hope as “a crucial survival trait that enables us to keep going in the face of adversity”. Desmond Tutu gave an equally ethereal definition: “Hope is being able to see that there is light despite all the darkness”.<sup>18</sup> One fundamental aspect of hope is its undeniable association with <em>agency</em>, i.e.&nbsp;our capacity to <em>voluntarily</em> act in a given environment: even when we are at odds with the desired outcome, hope makes us take action, which in turn fuels more hope, thus establishing a dynamic form of self-stimulation over thousands of ethical actions without necessarily having a clear variable to optimise, which machines are incapable of doing. And, one very interesting thing about hope is that its effects can be quantified in the short term: hope is much better than intelligence and personality at predicting academic performance,<sup>19</sup> as well as performance in the workplace, with hopeful workers being reported as 14% more productive.<sup>20</sup></p>
</section>
<section id="closing-thoughts" class="level2">
<h2 class="anchored" data-anchor-id="closing-thoughts">Closing thoughts</h2>
<p>Generative language-based models have reignited much interest in the possibility of artificially recreating human-level intelligence. Despite being seminal breakthroughs, we must not forget that LLMs are, essentially, just very sophisticated pattern recognition systems which, when trained on even larger datasets, may become even better at predicting the most appropriate responses to different prompts. LLMs are incomplete models of thought, though, plagued by practical problems that we have not discussed here, such as giving incorrect answers, security breaches, privacy concerns regarding personal data used in their training datasets, algorithmic opacity and an inability to meet the EU’s General Data Protection Regulation (GDPR), and their amplification of web <em>bias</em> which can result in answers that discriminate against different groups.<sup>21</sup> Even if these limitations are fixed one day, the capabilities of LLMs still do not approximate general human intelligence.</p>
<p>Generative models are just one type of narrow AI application. Such applications will continue to evolve at a very fast pace and produce breakthroughs of paramount importance. Some of the latest breakthroughs in the biomedical field include the discovery of new antibiotics against deadly antibiotic-resistant bacteria<sup>22</sup> and <a href="https://deepmind.google/discover/blog/alphafold-using-ai-for-scientific-discovery-2020/">AlphaFold’s</a> accurate prediction of a protein’s structure from its amino acid sequence.<sup>23</sup> <sup>24</sup> The number of ways an amino acid sequence may fold is astronomical. Thus being able to predict a protein’s structure as accurately as experimental measurements (by X-ray crystallography or cryo-electron microscopy) represents a gigantic step towards understanding a protein’s likely function and its regulation, how it may be drugged to combat diseases and for antibiotic development, and its manipulation to guide vaccine design as was done during the <a href="https://www.biorxiv.org/content/10.1101/2021.05.10.443524v1">coronavirus pandemic</a>.<sup>25</sup> Most impressively, AlphaFold is able to predict the structural effects of single amino changes (mutations), which is essential for engineering new proteins as well as for understanding evolutionary history and mechanistic aspects of diseases.<sup>26</sup></p>
<p>Being able to harness the power of narrow AI applications and delegate some tasks to machines will allow humans to focus on those tasks at which we do better than machines. <em>Augmented intelligence</em> is the name given to the close collaboration between humans and machines, which was first proposed in the 1950s, and is now <a href="https://pz.harvard.edu/sites/default/files/Intelligence%20Augmentation-%20Upskilling%20Humans%20to%20Complement%20AI.pdf">finally within reach</a>.<sup>27</sup> <sup>28</sup> Current examples of devices that are a functional extension of human beings are virtual reality headsets that expand the users’ senses and perceptions, implantable technologies that substitute access cards, and, in general, any software that automates research and data analysis. Since such technological developments might make us more “intelligent” or at least more productive, will we then still need machines that display human-like intelligence?</p>
<p>The official position of some major players like Microsoft is to not even attempt to replicate human intelligence but to produce “AI centred on assisting human productivity in a responsible way”.<sup>29</sup> Still, a recent paper that reported GPT-4’s impressive performance at solving a number of difficult tasks (in the fields of mathematics, coding, vision, medicine, law and psychology) suggests that GPT-4 displays “<a href="https://arxiv.org/abs/2303.12712">sparks of artificial general intelligence</a>”. This is in line with OpenAI’s <a href="https://openai.com/blog/planning-for-agi-and-beyond">clearly stated goal</a> of developing human-level intelligence. However, the debate over whether we are getting any closer to replicating intelligence with just a few impressive generative models that simply recombine and duplicate data on which they have been trained is self-limiting because it takes a very narrow view of human intelligence. For one thing, mindlessly generating text (“speaking”) and thinking are <a href="https://nymag.com/intelligencer/article/ai-artificial-intelligence-chatbots-emily-m-bender.html">two very different things</a>. It has been shown that while LLMs may excel at formal linguistic competence (understanding language rules and patterns), their performance on tasks that evaluate human thought in the real world (functional linguistic competence) is <a href="https://arxiv.org/abs/2301.06627">very limited</a>. Moreover, GPT-4 is unable to reason. We can define reasoning as the process of drawing justifiable conclusions from a set of premises, which is also a key component of intelligence. When given a set of 21 distinct problems ranging from simple arithmetic and logic puzzles to spatial and temporal reasoning, and medical common sense, <a href="https://medium.com/@konstantine_45825/gpt-4-cant-reason-2eab795e2523">GPT-4 proved incapable of applying elementary reasoning techniques</a>.</p>
<p>OpenAI’s newest headline-grabbing development, <a href="https://openai.com/sora">Sora</a>, shares many of the limitations of GPT-4. Sora is a model that can generate video clips from text prompts – but while it may prove useful for content creation, it seems incapable of understanding the real world. OpenAI’s defence is that Sora still struggles with “simulating the physics of a complex scene” but that it “represents a foundation for models that can understand and simulate the real world”. This is, OpenAI believes, key for training models that will help solve problems that require simulating the physical world (e.g.&nbsp;rescue missions), and eventually for achieving general AI. However, it is suspected that Sora’s limitations in understanding the physical world have nothing to do with physics. For example, in <a href="https://twitter.com/sama/status/1758249750909096142?s=61">a generated video of a monkey playing chess in a park</a>, we see a 7x7 board and three kings. This is likely not an error of insufficient training data or of computational power. This is an error that reveals a failure to discern the cultural regularity of the world by making wrong generalisations despite having ample evidence of the existence of universal 8x8 chess boards and one king per player. A video of <a href="https://twitter.com/openai/status/1758192965703647443?s=61">a stylish woman wandering in Tokyo</a> is also incorrect for the same reason: nobody takes two consecutive left steps in a row (about 30s into the video). Sora also does not appear to understand cause and effect; for example, in a video of a basketball that makes a hoop explode, the net appears to be restored automatically following the explosion. Sora uses arrangements of pixels to predict new pixel configurations, but without trying to understand the cultural context of the images. This is why the images and videos generated by Sora <a href="https://garymarcus.substack.com/p/sora-cant-handle-the-truth">seem correct at the pixel level</a> but <em>globally</em> wrong. Thus, OpenAI’s claim that “<a href="https://openai.com/research/video-generation-models-as-world-simulators">scaling video generation models is a promising path towards building general purpose simulators of the physical world</a>” is open to doubt.</p>
<p>LLMs do not yet approximate the human brain; generative video models do not approximate the physical world; and human intelligence is so much more than combining formal linguistic competence with complete models of thought, or making creative videos that respect the physical constraints of the world. Human intelligence is not limited to specific domains either but exists in the open to challenge currently held views. Ask Noam Chomsky and he will respond that generative models like ChatGPT are essentially “<a href="https://www.nytimes.com/2023/03/08/opinion/noam-chomsky-chatgpt-ai.html">high-tech plagiarism</a>”. Human consciousness includes a sense of self which machines will not be able to replicate anytime soon – or perhaps never will, since a human brain and a computer are <a href="https://www.wired.com/story/artificial-intelligence-consciousness/#:~:text=Pondering%20this%20question%2C%20it's%20important,necessary%20nor%20sufficient%20for%20consciousness.">not the same</a>. Human consciousness is coupled with curiosity, imagination, intuition, emotions, desires, purpose, objectives, wisdom and even humour. If we think about humour, a good sense of humour means thinking outside of the box and connecting concepts and situations in novel ways, which is something that machines are unable to do. Also, by thinking outside the box, humans are able to <em>consciously</em> ask a variety of questions – the most <em>extraordinary</em> of which have led to major leaps in our understanding of the world around us.</p>
<p><em>Reasonable</em> questions can be posed by many and answered logically (some even by machines) using the standard scientific process of experimental design, controls and hypothesis validation. In this context, the faster and more efficient exploration of search space by learning methods, complemented by the delegation of repetitive tasks to machines, will <a href="https://www.technologyreview.com/2023/07/05/1075865/eric-schmidt-ai-will-transform-science/">allow scientists to conduct experiments at greater scale</a> while focusing on designing optimal solutions. Beyond reasonable questions and expected results is the concept of <em>serendipity</em> that machines cannot yet be made to grasp. Some of the greatest discoveries in the history of science are indeed serendipitous (accidental), including the discovery of insulin, penicillin, smallpox vaccination, the anti-malarial drug quinine, X-rays, nylon and the anaesthetic effects of ether and nitrous oxide.<sup>30</sup> Turning accidents into discoveries requires having a questioning mind that can view data from several perspectives and connect seemingly unrelated pieces of information instead of discarding unusual results right away.</p>
<p>And yet beyond serendipitous discoveries we have <em>extraordinary</em> questions, which machines are as yet incapable of asking. Extraordinary questions lie outside of our current frame of knowledge and require an illogical step that is often the product of letting one’s mind wander freely.<sup>31</sup> A classical example here is when Einstein was trying to modify Maxwell’s equations so that they were no longer in contradiction with the constant speed of light that had been observed. After trying to modify these equations for years, Einstein eventually realised that it was not Maxwell’s fault. Rather, our notion of time was incorrect. Einstein thus stumbled upon the very question that led to the idea that the rate at which time passes depends on one’s frame of reference. While machines follow rules, the revolutionary ideas of Einstein, Newton, Darwin, Galileo, Wittgenstein and many others did not follow any rules established at the time. Therefore, the real danger in thinking that we can rely on “intelligent” machines to achieve a human level of imagination, intuition, wisdom or purpose anytime soon is that the world will become an even more statistically predictable place.</p>
</section>
<section id="also-in-the-ai-series" class="level2">
<h2 class="anchored" data-anchor-id="also-in-the-ai-series">Also in the AI series:</h2>
<p><a href="https://realworlddatascience.net/ideas/posts/2024/04/22/ai-series-1.html">What is AI? Shedding light on the method and madness in these algorithms</a> <a href="https://realworlddatascience.net/ideas/posts/2024/05/07/ai-series-3.html">Healthy datasets for optimised AI performance</a></p>
<div class="article-btn">
<p><a href="../../../../../ideas/index.html">Explore more data science ideas</a></p>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-12">
<dl>
<dt>About the author</dt>
<dd>
<strong>Diego Miranda-Saavedra</strong>, PhD, is a data scientist and a financial investor. His book <em>How To Think About Data Science</em> (Chapman &amp; Hall / CRC Press) was published in December, 2022.
</dd>
</dl>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>Copyright and licence</dt>
<dd>
© 2024 Diego Miranda-Saavedra
</dd>
</dl>
<p><a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> <img style="height:22px!important;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"></a> Text, code, and figures are licensed under a Creative Commons Attribution 4.0 (CC BY 4.0) <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;">International licence</a>, except where otherwise noted. Thumbnail image by <a href="https://www.jemimahknightstudio.com/work/ai">Jamillah Knowles</a> / <a href="https://www.betterimagesofai.org">Better Images of AI</a> / Data People / <a href="https://creativecommons.org/licenses/by/4.0/">Licenced by CC-BY 4.0</a>.</p>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>How to cite</dt>
<dd>
Miranda-Saavedra, Diego. 2024. “Generative AI models and the quest for human-level artificial intelligence.” Real World Data Science, April 29, 2024. <a href="https://doi.org/10.5281/zenodo.11237253"><img src="https://zenodo.org/badge/DOI/10.5281/zenodo.11237253.svg" class="img-fluid" alt="DOI"></a>
</dd>
</dl>
</div>
</div>
</div>


</section>


<div id="quarto-appendix" class="default"><section id="footnotes" class="footnotes footnotes-end-of-document"><h2 class="anchored quarto-appendix-heading">References</h2>

<ol>
<li id="fn1"><p>Vaswani A, Shazeer N, Parmar N, Uszkoreit J, Jones L, Gomez AN, Kaiser L, Polosukhin I. <em>Attention is All you Need</em>. In Advances in Neural Information Processing Systems 30 (NIPS 2017), Long Beach, California (USA), 2017. ISBN: 9781510860964.↩︎</p></li>
<li id="fn2"><p>Turing A. <em>Computing Machinery and Intelligence</em>. Mind, LIX(236):433-460, 1950.↩︎</p></li>
<li id="fn3"><p>Levesque HJ, Davis E, Morgenstern L. <em>The Winograd Schema Challenge</em>. In KR’12: Proceedings of the Thirteenth International Conference on Principles of Knowledge Representation and Reasoning, June 2012, Rome, Italy. AIII Press, Palo Alto (CA), USA, 2012. ISBN: 9781577355601.↩︎</p></li>
<li id="fn4"><p>Sakaguchi K, Le Bras R, Bhagavatula C, Choi Y. <em>WinoGrande: An Adversarial Winograd Schema Challenge at Scale</em>. In Proceedings of the Thirty-Fourth AAAI Conference on Artificial Intelligence, 34(05), 8732–8740. February 2020, New York (NY), USA. AIII Press, Palo Alto (CA), USA, 2020. ISSN: 2159–5399.↩︎</p></li>
<li id="fn5"><p>Legg S, Hutter M. <em>A Collection of Definitions of Intelligence</em>. Proceedings of the 2007 Conference on Advances in Artificial General Intelligence: Concepts, Architectures and Algorithms: Proceedings of the AGI Workshop 2006, 17-24. IOS Press, Amsterdam, the Netherlands, 2007. ISBN: 978-1-58603-758-1.↩︎</p></li>
<li id="fn6"><p>Suleyman M, Bhaskar M. <em>The Coming Wave</em>. Bodley Head, London, UK, 2023. ISBN-10: 1847927483.↩︎</p></li>
<li id="fn7"><p>McCarthy J. <em>From Here to Human-Level AI</em>. Artificial Intelligence, 171(18):1174–1182, 2007.↩︎</p></li>
<li id="fn8"><p>LeCun Y, Bengio Y, Hinton G. <em>Deep Learning</em>. Nature, 521(7553):436–444, 2015.↩︎</p></li>
<li id="fn9"><p>McCloskey M, Cohen NJ. <em>Catastrophic Interference in Connectionist Networks: The Sequential Learning Problem</em>. Psychology of learning and motivation, 24:109–165, 1989.↩︎</p></li>
<li id="fn10"><p>Abraham WC, Robins A. <em>Memory Retention - the Synaptic Stability Versus Plasticity Dilemma</em>. Trends in Neurosciences, 28(2):73–78, 2005.↩︎</p></li>
<li id="fn11"><p>Kemker R, McClure M, Abitino A, Hayes T, Kanan C. <em>Measuring Catastrophic Forgetting in Neural Networks</em>. In Proceedings of the AAAI Conference on Artificial Intelligence, 32(1). AAAI Press, Palo Alto (CA), USA, 2018. ISBN: 9781577358008.↩︎</p></li>
<li id="fn12"><p>Hadsell R, Rao D, Rusu AA, Pascanu R. <em>Embracing Change: Continual Learning in Deep Neural Networks</em>. Trends in Cognitive Sciences 24(12): 1028–1040, 2020.↩︎</p></li>
<li id="fn13"><p>McCulloch W, Pitts W. <em>A Logical Calculus of Ideas Immanent in Nervous Activity</em>. Bulletin of Mathematical Biophysics, 5(4):115–133, 1943.↩︎</p></li>
<li id="fn14"><p>Brooks R, Hassabis D, Bray D, Shashua A. <em>Is the Brain a Good Model for Machine Intelligence?</em> Nature 482: 462-463, 2012.↩︎</p></li>
<li id="fn15"><p>Koch C. <em>What Is Consciousness?</em> Nature, 557:S8–S12, 2018.↩︎</p></li>
<li id="fn16"><p>DeWall C, Baumeister R, Masicampo R. <em>Evidence that Logical Reasoning Depends on Conscious Processing</em>. Consciousness and Cognition 17(3): 628, 2008.↩︎</p></li>
<li id="fn17"><p>Darling K, Nandy P, and Breazeal C. <em>Empathic Concern and the Effect of Stories in Human-Robot Interaction</em>. 24th IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN) 2015, Kobe, Japan, August 31 - September 4, pp.&nbsp;770-775. IEEE, Washington (DC), USA, 2015. ISBN: 9781467367042.↩︎</p></li>
<li id="fn18"><p>Goodall J, Abrams D. <em>The Book of Hope: A Survival Guide for an Endangered Planet (1st Edition)</em>. Viking Press, New York (NY), USA, 2021. ISBN-10: 024147857X.↩︎</p></li>
<li id="fn19"><p>Day L, Hanson K, Maltby J, Proctor C, Wood A. <em>Hope Uniquely Predicts Objective Academic Achievement Above Intelligence, Personality, and Previous Academic Achievement</em>. Journal of Research in Personality 44(4): 550-553, 2010.↩︎</p></li>
<li id="fn20"><p>Reichard RJ, Avey JB, Lopez S, Dollwet M. <em>Having the Will and Finding the Way: A Review and Meta-Analysis of Hope at Work</em>. The Journal of Positive Psychology 8(4): 292-304, 2013.↩︎</p></li>
<li id="fn21"><p>Baeza-Yates R. <em>Bias on the Web</em>. Communications of the ACM, 61(6):54–61, 2018.↩︎</p></li>
<li id="fn22"><p>Liu G et al.&nbsp;<em>Deep learning-guided discovery of an antibiotic targeting Acinetobacter baumannii</em>. Nature Chemical Biology 19: 1342-1350, 2023.↩︎</p></li>
<li id="fn23"><p>Senior AW et al.&nbsp;<em>Protein structure prediction using multiple deep neural networks in the 13th Critical Assessment of Protein Structure Prediction (CASP13)</em>. Proteins: Structure, Function and Bioinformatics 87(12):1141–1148, 2019.↩︎</p></li>
<li id="fn24"><p>Senior AW et al.&nbsp;<em>Improved protein structure prediction using potentials from deep learning</em>. Nature 577:706–710, 2020.↩︎</p></li>
<li id="fn25"><p>Higgins MK. <em>Can We AlphaFold Our Way Out of the Next Pandemic?</em> Journal of Molecular Biology 433(20):1–7, 2021.↩︎</p></li>
<li id="fn26"><p>McBride JM, Polev K, Abdirasulov A, Reinharz V, Grzybowski BA, Tlusty T. <em>AlphaFold2 Can Predict Single-Mutation Effects</em>. Phys. Rev.&nbsp;Lett. 121:218401, 2023.↩︎</p></li>
<li id="fn27"><p>Zheng NN, Liu ZY, Ren PJ, Ma YQ, Chen ST, Yu SY, Xue JR, Chen BD, Wang FY. <em>Hybrid-Augmented Intelligence: Collaboration and Cognition</em>. Frontiers of Information Technology &amp; Electronic Engineering 18:153-179, 2017.↩︎</p></li>
<li id="fn28"><p>Bryant PT. <em>Augmented Humanity: Being and Remaining Agentic in a Digitalized World</em>. Palgrave Macmillan, Cham, Switzerland. ISBN: 9783030764449.↩︎</p></li>
<li id="fn29"><p>Lenharo M. <em>If AI Becomes Conscious: Here’s How Researchers Will Know</em>. Nature, 24 August 2023.↩︎</p></li>
<li id="fn30"><p>Roberts RM. <em>Serendipity: Accidental Discoveries in Science (1st Edition)</em>. Wiley-VCH, Weinheim, Germany, 1989. ISBN: 0471602035.↩︎</p></li>
<li id="fn31"><p>Yanai I, Lercher M. <em>What Is The Question?</em> Genome Biology 20(1):289, 2019.↩︎</p></li>
</ol>
</section></div> ]]></description>
  <category>AI</category>
  <category>Large language models</category>
  <category>Machine learning</category>
  <category>Deep neural networks</category>
  <guid>https://realworlddatascience.net/ideas/posts/2024/04/29/gen-ai-human-intel.html</guid>
  <pubDate>Mon, 29 Apr 2024 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/ideas/posts/2024/04/29/images/data-people.png" medium="image" type="image/png" height="105" width="144"/>
</item>
<item>
  <title>AI series: What is AI? Shedding light on the method and madness in these algorithms</title>
  <dc:creator>Anna Demming</dc:creator>
  <link>https://realworlddatascience.net/ideas/posts/2024/04/22/ai-series-1.html</link>
  <description><![CDATA[ 





<!-- article text to go here -->
<p>What do <a href="https://www.simmons-simmons.com/en/publications/clq2gkar900fcu2ewb904uhrj/inappropriate-use-of-chatgpt-exposed-in-tax-case">defence cases in litigation</a>, statistical analyses, book summaries and a description of <a href="https://twitter.com/jimalkhalili/status/1621454981097209857/photo/1">Young’s double slit experiment in the manner of poet Robert Burns</a> have in common? They are all tasks that people have rightly or wrongly attempted to delegate to large language models.</p>
<p>The playground of generative AI algorithms based on large language models extends well beyond the space of generating text-based language but includes creating images, videos and even music from prompts. The capabilities of these algorithms, and the ubiquity of tasks that large language models like OpenAI’s Generative Pre-trained Transformer (GPT) models can have a go at is striking. These large language models and the chatbots and so on based on them have also been catapulted into the centre of mainstream public attention with huge success – who has not heard of ChatGPT? The net result has been something akin to a feeding frenzy as individuals and businesses alike strive to be among the first to benefit from them.</p>
<p>Like others, many data scientists closely familiar with these kinds of algorithms share some enthusiasm for their potential utility, but many also advocate an element of caution. There are some obvious caveats, including accuracy and cost – not just financially but also in terms of the huge energy costs to run these algorithms, a real world consequence that is affecting the planet in the present day but is often eclipsed by fears that AI might take over the world some time in the future. Another concern is security. Should you be sharing the information you are working from with a third party anyway? However, while a lot of attention has focused on what these algorithms can do, fewer have been asking what they actually do – what we know about the initial programming, the training data, the final algorithm and the range of possible outputs, all of which provide useful pointers as to whether a particular algorithm is appropriate for the task in hand, and how best to benefit from it.</p>
<section id="demystifying-machine-learning" class="level2">
<h2 class="anchored" data-anchor-id="demystifying-machine-learning">Demystifying machine learning</h2>
<p>Definitions of artificial intelligence vary, often circling around the theme of a system reaching an “intelligent” decision or output based on multiple inputs, although how “intelligent” might be defined can be hairier still. Nonetheless, there is currently largely a consensus that some kind of machine learning is a route to achieving it. Through machine learning “you are letting the computer adjust the importance of its inputs, and their relationships, to determine an appropriate output” as Napier chief data scientist and chair of the Royal Statistical Society DS &amp; AI Section <a href="https://www.linkedin.com/in/janetbastiman/?originalSubdomain=uk">Janet Bastiman</a> describes it. The term “machine learning” was first proposed by IBM scientist Arthur Samuel in 1952, and it has largely been achieved by two approaches. One is “random forests”, based on constructing multiple decision trees. The other is the neural networks first devised by American psychologist Frank Rosenblatt and simulated at IBM in 1957. Here, a set of artificial neurons – components closer to a capacitor than a biological neuron – is connected to another layer of neurons, which is connected to another layer of neurons, and so on (Figure 1). Crucially the connections are strengthened or not through “learning” based on training data that allows the network to recognise patterns and extract meaningful features.</p>
<div id="fig-neuralnetworks" class="quarto-figure quarto-figure-center quarto-float anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-neuralnetworks-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="https://realworlddatascience.net/ideas/posts/2024/04/22/images/neuralnetworks.jpg" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-neuralnetworks-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;1: A <a href="https://commons.wikimedia.org/wiki/File:Visualizing_Artificial_Neural_Networks_%28ANNs%29_with_python_library-ANN_Visualizer.jpg">schematic of a neural network</a> depicted with circles connected with lines or arrows.
</figcaption>
</figure>
</div>
<p>“Machine learning is just like linear regression with tonnes of bells and whistles,” says <a href="https://www.danielawitten.com/">Daniela Witten</a>, professor of mathematical statistics at the University of Washington in the US, referring to a statistical method for fitting a line to a set of data points that dates back over a hundred years. There are many other traditional approaches to statistical learning that may be nonlinear and so on, but as an example of the “bells and whistles” Witten describes, whereas a traditional regression model might have 5 inputs or variables, the machine learning version might have 15 million, and instead of assuming it is linear the fit is allowed to be more flexible and so on. However, the fundamental statistical ideas underlying both sets of models are the same. For this reason, although some may beg to differ, she feels doing machine learning before you understand statistics is like trying to jump rope before you can walk. “It’s not that you can’t do it but why would you?” she adds.</p>
<p>Broadly speaking, machine learning can be classified two ways. One is “supervised”, which means that the training data is somehow labelled, for instance with a known output collected from real world records. The alternative is “unsupervised” where the algorithm is set the task of finding a way to learn relationships between input data itself. There are also neural network approaches that fall somewhere between the two, such as reinforcement learning where an algorithm may generate outputs for a task at random such that its performance is initially poor but improves with feedback to reinforce generation of outputs that are closer to those desired. An approach that enjoyed great popularity for a time used another machine learning algorithm to provide this feedback, which would initially also be a poor judge but improve as pitted against the algorithm learning to do the task – generative adversarial networks (<a href="https://proceedings.neurips.cc/paper_files/paper/2014/file/5ca3e9b122f61f8f06494c97b1afccf3-Paper.pdf">GANs</a>). GANs are still used a lot, but usually in a pipeline and may be pre-trained so they are not starting from scratch like they used to.</p>
<p>As the number of layers increased from just a few, the term “deep learning” was adopted along with alternative structures. The first models operated with every neuron in each layer connected to every neuron in the previous layer. “This is very wasteful because not every part of your input relates to each other that much,” says <a href="https://petar-v.com/">Petar Veličković</a>, staff research scientist at Google DeepMind and affiliated lecturer at the University of Cambridge. He cites images as among the first scenarios where people began to implement a tweak to the approach in what is called a convolutional neural network. Based on the assumption that the pixels for each object in an image sit adjacent to each other rather than at opposing corners of the image, the neurons in a convolutional neural network connect only with the neurons in the next layer that are nearby in the image space. In this way the convolutional neural network assumes a kind of structure in the input data – that the image is contiguous, so the pixels for edges and so on are in contact.</p>
<div id="fig-Attentionfigure2" class="quarto-figure quarto-figure-center quarto-float anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-Attentionfigure2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="https://realworlddatascience.net/ideas/posts/2024/04/22/images/Attentionfigure2.jpg" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-Attentionfigure2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2: Schematics for (left) Scaled Dot-Product Attention and (right) Multi-Head Attention, which consists of several attention layers running in parallel.
</figcaption>
</figure>
</div>
<p>“Transformers are also a neural network but they encode a different kind of structure,” Veličković tells Real World Data Science, as he describes the data architecture at the heart of the large language models creating such a buzz at present. Language has structure too – the letters make up words, which then make up sentences and so on. So it makes sense to program some of that structure into the algorithm rather than leaving it to work it all out. “You would need a lot more training data than there is on the internet to train a system without such structure by itself,” adds Veličković. Transformers structure the training data into tokens, and a key component first reported in 2017 is the way each token then connects with or <a href="https://papers.nips.cc/paper_files/paper/2017/hash/3f5ee243547dee91fbd053c1c4a845aa-Abstract.html">“attends” to all other similar tokens</a> . Here whether they are “similar” is determined by their dot products, a multiplication technique for the kind of vector format of input numbers used for these tokens (Figure 2). Exploiting this “dot product attention” significantly improves the efficiency of the training process.</p>
</section>
<section id="taking-the-world-by-storm" class="level2">
<h2 class="anchored" data-anchor-id="taking-the-world-by-storm">Taking the world by storm</h2>
<p>The transformer architecture proved very powerful as has been seen in the surge to prominence of various AI systems based on generative pre-trained transformer algorithms, such as ChatGPT, BERT and PaLM, although this likely has at least as much to do with the marketing of the recent releases as it does with the algorithm itself. “It was a small evolution rather than a revolution,” says Bastiman in reference to recent GPT releases, explaining that there was an increase in parameter size and the amount of data used for training that gave rise to something that could provide broader answers and was ready for mass market. Nonetheless she adds, “There had been GPT2, GPT1 and all the other previous ones had been released quietly and had all been quite good.”</p>
<p>The marketing spin has not stopped with the product releases as terms like “<a href="https://realworlddatascience.net/viewpoints/editors-blog/posts/2022/11/23/LLM-content-warning.html">hallucination</a>” have entered the lexicon to describe instances when the output is wrong and potentially dangerous. (Figure 3) “The language we are using to describe these models is different to how we describe human intelligence to deliberately instil the sense this is better,” adds Bastiman. “So even if the model is incorrect these terms imply that it is still doing something amazing.”</p>
<div id="fig-hallucinatedreferences" class="quarto-figure quarto-figure-center quarto-float anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-hallucinatedreferences-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="https://realworlddatascience.net/ideas/posts/2024/04/22/images/hallucinatedreferences.jpg" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-hallucinatedreferences-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;3: “Hallucinated” references. A study found that out of the 178 references cited by ChatGPT, 69 did not have a DOI. Upon extensive internet search, 41 out of these 69 reference articles were found to exist.
</figcaption>
</figure>
</div>
<p>The success of this marketing does have its advantages as Veličković points out, thrusting AI in the spotlight, inviting people to try the algorithms, which thanks to a growth in web-based user interfaces like ChatGPT can reach a much broader audience. This is not only encouraging developers they are doing something potentially useful but prompting important discussions around the potential bias and ethics issues, which many would argue ought to be considered before anything else. Nonetheless Veličković also doubts whether the current AI fanfare can be attributed to advances in the algorithms they use alone, pointing out that neural networks have been around since the 1950s, and the 1980s and 1990s saw the invention of most of the building blocks we need to scale such systems up: the backpropagation algorithm, convolutional and recurrent neural networks, long-short term memory networks, and early variants of linear self-attention and graph neural networks. “It’s just that we needed gamers,” he tells <em>Real World Data Science</em>, suggesting that hardware and engineering have been key to the recent successes of AI. “We needed people to drive the development of graphics cards which are really good hardware for training these things.”</p>
<p>Clearly advances in processing power and the hardware such as GPUs to manage it so that it is possible to compute these algorithms massively affects their potential impact. Although the field no longer relies on GPUs developed for gamers, GPUs are still widely used, as they offer such a good return on investment and are easier to get hold of than alternatives like tensor processing units. Certainly a significant development over the past decade or so is the increase in size of not just the data sets but the algorithms themselves. Implementing algorithms at such colossal scales that require data centres imposes incredibly challenging requirements on the hardware and the electrical and computational engineering involved to set them running and keep them from failure. “When you have a data centre, failure is a common thing,” says Veličković, listing multiple vulnerabilities that balloon at scale such as hardware failures, electrical failures, even apparently exotic events like solar flares can flip bits and scramble data leading to nonsense output. “People underestimate this but good engineering is now the bread and butter of how these systems work.”</p>
</section>
<section id="managing-expectations" class="level2">
<h2 class="anchored" data-anchor-id="managing-expectations">Managing expectations</h2>
<p>The explosion in scale has also created fundamental distinctions from how people work with machine learning algorithms versus statistical methods. Witten highlights “the ability to gauge uncertainty” by quantifying parameters such as confidence intervals and error bars as a key contribution of statistics. “Often with these machine learning models things get very complicated and we do not yet have a way to quantify that uncertainty.”</p>
<p>This quantifying of finite parameters contrasts with the kind of output achieved with the generative AI applications that have grabbed media focus recently. For instance, asking a large language model to describe Young’s double slit experiment in the style of Robert Burns may sound quite a specific prompt, and it may seem impressive if the algorithm returns something akin to what was asked, but the number of possible responses that could be deemed “correct” are infinite. A lot of applications of generative AI – many with more real world impact than describing iconic experiments in archaic scotch rhyme – similarly have a vast set of reasonable outputs.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://realworlddatascience.net/ideas/posts/2024/04/22/images/Gamers.jpg" class="img-fluid figure-img"></p>
<figcaption>Gamers drove the development of GPUs which have proven invaluable for training machine learning algorithms</figcaption>
</figure>
</div>
<p>“We shouldn’t be surprised if ChatGPT does well with a question that has a million reasonable answers,” says Witten, contrasting these scenarios with questions that she suggests might have more real-world importance, like whether a patient with breast cancer will respond to a particular treatment. “Actually ChatGPT often gets into trouble if there is a problem with just one answer, and that answer is not part of the training set.”</p>
<p>For predictive AI there is often only one useful answer – the outcome that will come to pass. This has implications if machine learning is used for predictions, particularly if it is in real world settings that affect real people. “If you are deploying an AI model for some healthcare application like what breast cancer treatment you are going to respond best to, we really better make sure that the model works, and that we understand the uncertainty of those predictions,” says Witten. She feels that over the past few years, the machine learning community has increasingly recognized the importance of bringing statistical thinking to bear within the context of complex machine learning/AI algorithms: in particular, interpretability and uncertainty quantification have become major areas of interest in machine learning. Witten suggests that statistics is making progress here citing as an example conformal inference, “which allows recalibration of the predictions of a machine learning model in order to quantify uncertainty appropriately.”</p>
</section>
<section id="explain-yourself" class="level2">
<h2 class="anchored" data-anchor-id="explain-yourself">Explain yourself</h2>
<p>Understanding the uncertainties of output is one thing, but many of these algorithms have now reached the kind of scale that totally obfuscates what they are doing with the input data to reach their outputs. There may be specialists who understand how they are programmed but there are just too many variables to track so that even for them, the final process the algorithm lands on for generating its output from the various inputs is a black box with no neat mathematical description, unlike statistical techniques like regression.</p>
<p>“You can draw a picture with circles and arrows, and arrows cross in a certain way, but you don’t have a clear idea of how one feature that you started with maps to the output,” says Witten. “On an actual quantitative level of scientific understanding we don’t have that.” If decisions are being made for and about people based on AI, people will also sometimes want to know how that conclusion was drawn. “When we want to make decisions there’s a level of deferred trust,” says Bastiman citing a <a href="https://www.turing.ac.uk/research/research-projects/project-explain#:~:text=This%20gap%20in%20AI%20explainability,robust%2C%20reliable%2C%20and%20safe">work by the Alan Turing Institute</a> that began in the late 2010s. “We as humans want explanations from machines in the same scenarios that we want them from humans but that’s not going to be the same for all people.” For example, a person who has had a bad experience in the past will need more convincing than one who has not. Janet suggests that a very normal cognitive bias can be generalised as most people wanting more explanation if the model output is not in their favour. “Similarly, a person accepted for a job where AI is used, may not require any explanation, while another candidate the AI rejected may challenge the decision and want to know why.”</p>
<p>Hybrid implementations including a human in the loop may help to a degree. However, to get a handle on the workings of the algorithm itself, Bastiman points out that it is possible to introduce layers in the algorithm that will help extract how the output is reached even for unsupervised neural networks. “That’s where a lot of effort goes from data scientists and machine learning engineers to make sure the model has that level of transparency and makes sense,” she adds, emphasising the need to ensure a model has these features before it is released and put in use. The process is far from straightforward as the explanation needs to be at the right level and with the right terminology for a range of audiences, be they data scientists, quality assurance professionals, decision makers, end users or impacted individuals. “People say you can’t explain things when what they really mean is that it’s difficult.”</p>
<p>Veličković suggests a lot could be gained in terms of being able to analyse AI algorithms by marrying them with elements of classical algorithms, which are “nicely implemented and interpretable.” Classical algorithms are also impervious to changes in the input data such as an increase by a factor of 10, which can completely throw an algorithm based on machine learning. “The problem is they are trained to be really useful and give you an answer at all times so they won’t even give you a confidence estimate, they will just try to answer even if the answer is completely broken,” he adds. A lot of his research has focused on “<a href="https://www.sciencedirect.com/science/article/pii/S2666389921000994">out-of-distribution generalisation</a>” – the way classical algorithms work with any input data – to see how these features might be sewn into AI to extract the best of both worlds. “There’s a lot of research to be done still but our findings so far indicate that if you want out-of-distribution generalisation you need to look at what makes your problem special and put some of those properties inside your neural network model.”</p>
<p>Even what we know about the way the algorithm reaches a decision has caused concern when it comes to critical real-world applications – for example, <a href="https://www.bu.edu/articles/2023/do-algorithms-reduce-bias-in-criminal-justice/">to determine the likelihood that someone convicted of a crime will reoffend</a>. (More on this to come in the special issue article on ethics). With many commercial algorithms the details of the training data are unknown or essentially constitute the whole internet, which as Witten points out is “a pretty bad place a lot of the time.” While ChatGPT may seem an unlikely choice for anything like gauging risk for recidivism or cancer treatments, concerns remain over biases propagating in AI generated content we might consume through marketing campaigns and other activities. “Even just thinking about deploying AI/machine learning models in critical real-world settings without the associated statistical understanding is just very deeply problematic,” says Witten, emphasising the importance of not just statisticians but also ethicists for tackling these challenges.</p>
<p>The fact is many of us are already interacting with multiple machine learning/AI models on a daily basis through recommendations, search engines and predictive text. “If we are going to deploy these [machine learning algorithms] at scale in a way that will affect human lives, then we first need to understand the implications for humans of these models,” says Witten. “This includes both statistical and ethical considerations.”</p>
<p>Coming up: Forthcoming articles in this special issue will look at machine learning and human-level intelligence, issues around data, techniques for evaluation, gauging workforce impact, governance, best practice and living with AI</p>
</section>
<section id="also-in-the-ai-series" class="level2">
<h2 class="anchored" data-anchor-id="also-in-the-ai-series">Also in the AI series</h2>
<p><a href="https://realworlddatascience.net/ideas/posts/2024/04/29/gen-ai-human-intel.html">Generative AI models and the quest for human-level artificial intelligence</a> <a href="https://realworlddatascience.net/ideas/posts/2024/05/07/ai-series-3.html">datasets for optimised AI performance</a></p>
<div class="article-btn">
<p><a href="../../../../../ideas/index.html">Explore more data science ideas</a></p>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-12">
<dl>
<dt>About the authors</dt>
<dd>
<strong>Anna Demming</strong> is a freelance science writer and editor based in Bristol, UK. She has a PhD from King’s College London in physics, specifically nanophotonics and how light interacts with the very small, and has been an editor for Nature Publishing Group (now Springer Nature), IOP Publishing and New Scientist. Other publications she contributes to include The Observer, New Scientist, Scientific American, Physics World and Chemistry World.
</dd>
</dl>
</div>
<div class="g-col-12 g-col-md-6">
<!-- copyright goes to the author, or to Royal Statistical Society if written by staff -->
<dl>
<dt>Copyright and licence</dt>
<dd>
© 2024 Anna Demming
</dd>
</dl>
<!-- confirm licence terms with contributor before publishing - must be Creative Commons licence, but different types of CC licences might be preferred -->
<p><a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> <img src="https://mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1" style="height:22px!important;vertical-align:text-bottom;"><img src="https://mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1" style="height:22px!important;margin-left:3px;vertical-align:text-bottom;"></a> This article is licensed under a Creative Commons Attribution 4.0 (CC BY 4.0) <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> International licence</a>. <!-- Add thumbnail image credit and any licence terms here -->Thumbnail image courtesy of Serenechan3 reproduced under a Creative Commons Attribution 4.0 (CC BY 4.0) <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> International licence</a></p>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>How to cite</dt>
<dd>
Demming Anna. 2024. “What is AI? Shedding light on the method and madness in these algorithms .” Real World Data Science, April 22, 2024. <a href="https://realworlddatascience.net/ideas/posts/2024/04/22/ai-series-1.html">URL</a>
</dd>
</dl>
</div>
</div>
</div>
<!-- Make sure to update main site homepage (index.qmd) before publishing. See README for details. -->


</section>

 ]]></description>
  <category>AI</category>
  <category>algorithms</category>
  <category>statistics</category>
  <guid>https://realworlddatascience.net/ideas/posts/2024/04/22/ai-series-1.html</guid>
  <pubDate>Mon, 22 Apr 2024 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/ideas/posts/2024/04/22/images/neuralnetworks.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>Data science and AI in the public sector: An interview with ONS’s Penny Holborn</title>
  <dc:creator>Jonathan Gillard</dc:creator>
  <link>https://realworlddatascience.net/careers/posts/2024/03/27/pholborn-interview.html</link>
  <description><![CDATA[ 





<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/NcpHUGaV_WI?si=XAjVdwV29zS0IX8Z" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<div class="g-col-12 g-col-sm-6">
<div class="nav-btn">
<p><a href="../../../../../careers/index.html">Back to Careers</a></p>
</div>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-12">
<dl>
<dt>About the author</dt>
<dd>
<strong>Jonathan Gillard</strong> is a professor of statistics and data science at Cardiff University and a member of the <a href="https://realworlddatascience.net/viewpoints/editors-blog/posts/2022/10/18/meet-the-team.html">editorial board</a> of Real World Data Science.
</dd>
</dl>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>Copyright and licence</dt>
<dd>
© 2024 Royal Statistical Society
</dd>
</dl>
<p><a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> <img src="https://mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1" style="height:22px!important;vertical-align:text-bottom;"><img src="https://mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1" style="height:22px!important;margin-left:3px;vertical-align:text-bottom;"></a> This interview is licensed under a Creative Commons Attribution 4.0 (CC BY 4.0) <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> International licence</a>. Thumbnail background by <a href="https://unsplash.com/@m_skalij?utm_content=creditCopyText&amp;utm_medium=referral&amp;utm_source=unsplash">Marcin Skalij</a> on <a href="https://unsplash.com/photos/laptop-turned-on-nXGw951o3Hk?utm_content=creditCopyText&amp;utm_medium=referral&amp;utm_source=unsplash">Unsplash</a>.</p>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>How to cite</dt>
<dd>
Gillard, Jonathan. 2024. “Data science and AI in the public sector: An interview with ONS’s Penny Holborn.” Real World Data Science, March 27, 2024. <a href="https://realworlddatascience.net/careers/posts/2024/03/27/pholborn-interview.html">URL</a>
</dd>
</dl>
</div>
</div>
</div>



 ]]></description>
  <category>AI</category>
  <category>Data</category>
  <category>Skills</category>
  <category>Public sector</category>
  <guid>https://realworlddatascience.net/careers/posts/2024/03/27/pholborn-interview.html</guid>
  <pubDate>Wed, 27 Mar 2024 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/careers/posts/2024/03/27/images/pholborn-laptop.png" medium="image" type="image/png" height="105" width="144"/>
</item>
<item>
  <title>Data science and AI in financial services: An interview with Nationwide’s Matthew Jones</title>
  <dc:creator>Jonathan Gillard</dc:creator>
  <link>https://realworlddatascience.net/careers/posts/2024/03/21/mjones-interview.html</link>
  <description><![CDATA[ 





<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/3ZlnGsaAj0Q?si=w7W9quAm0drMWWqL" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<div class="g-col-12 g-col-sm-6">
<div class="nav-btn">
<p><a href="../../../../../careers/index.html">Back to Careers</a></p>
</div>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-12">
<dl>
<dt>About the author</dt>
<dd>
<strong>Jonathan Gillard</strong> is a professor of statistics and data science at Cardiff University and a member of the <a href="https://realworlddatascience.net/viewpoints/editors-blog/posts/2022/10/18/meet-the-team.html">editorial board</a> of Real World Data Science.
</dd>
</dl>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>Copyright and licence</dt>
<dd>
© 2024 Royal Statistical Society
</dd>
</dl>
<p><a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> <img src="https://mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1" style="height:22px!important;vertical-align:text-bottom;"><img src="https://mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1" style="height:22px!important;margin-left:3px;vertical-align:text-bottom;"></a> This interview is licensed under a Creative Commons Attribution 4.0 (CC BY 4.0) <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> International licence</a>. Thumbnail background by <a href="https://unsplash.com/@nextiva?utm_content=creditCopyText&amp;utm_medium=referral&amp;utm_source=unsplash">Devin Pickell</a> on <a href="https://unsplash.com/photos/black-and-gray-laptop-computer-p0UwQ-Wd8TM?utm_content=creditCopyText&amp;utm_medium=referral&amp;utm_source=unsplash">Unsplash</a>.</p>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>How to cite</dt>
<dd>
Gillard, Jonathan. 2024. “Data science and AI in financial services: An interview with Nationwide’s Matthew Jones.” Real World Data Science, March 21, 2024. <a href="https://realworlddatascience.net/careers/posts/2024/03/21/mjones-interview.html">URL</a>
</dd>
</dl>
</div>
</div>
</div>



 ]]></description>
  <category>AI</category>
  <category>Communication</category>
  <category>Skills</category>
  <category>Financial services</category>
  <guid>https://realworlddatascience.net/careers/posts/2024/03/21/mjones-interview.html</guid>
  <pubDate>Thu, 21 Mar 2024 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/careers/posts/2024/03/21/images/mjones-laptop.png" medium="image" type="image/png" height="105" width="144"/>
</item>
<item>
  <title>Democratizing Data: Using natural language processing and machine learning to capture dataset usage</title>
  <dc:creator>Brian Tarran</dc:creator>
  <link>https://realworlddatascience.net/viewpoints/interviews/posts/2024/03/11/democratizing-data.html</link>
  <description><![CDATA[ 





<p>Figuring out how much money is spent annually on collecting and publishing datasets is a challenge. According to the World Bank, it is <a href="https://blogs.worldbank.org/opendata/how-much-should-governments-spend-data">“painfully hard to obtain”</a> information just on government spending on data, never mind all the other bodies and organisations who invest in the creation of data assets. But there’s an even more challenging figure to pin down: How much value does all this data provide? By and large, there is very little data – or systematic collection of data – on dataset usage. There’s no easy way to find all the users of a particular dataset and to see how the data has been used, or what research topics it may have contributed to.</p>
<p>Writing in the <a href="https://hdsr.mitpress.mit.edu/pub/g6e8noiy/release/2">Harvard Data Science Review in April 2022</a>, <a href="https://julialane.org/">Julia Lane</a> and others explained that “the current approach to finding what data sets are used to answer scientific questions … is largely manual and ad hoc.” They went on to argue: “Better information on the use of data is likely to have at least two results: (i) government agencies might use the information to describe the return on investment in data sets and (ii) scientists might use the information to reduce the time taken to search and discover other empirical research.”</p>
<p>This hope for a better understanding of how datasets are used and the value they provide underpins the creation of “Democratizing Data: A Search and Discovery Platform for Public Data Assets.”</p>
<p>As described on <a href="https://democratizingdata.ai/">the platform’s homepage</a>, Democratizing Data “describes how datasets identified by federal agencies have been used in scientific research. It uses machine learning algorithms to search over 90 million documents and find how datasets are cited, in what publications, and what topics they are used to study.”</p>
<p>But this is just the start of what Lane thinks the project could eventually achieve, as she explains in this interview.</p>
<div class="keyline">
<hr>
</div>
<p><strong>How did the Democratizing Data platform come about?</strong><br>
It emerged from three things, really, and I can trace the start of it back to 2016, when I was asked to build a secure environment that could host confidential microdata in order to inform the work of the <a href="https://obamawhitehouse.archives.gov/omb/management/commission_evidence">Commission on Evidence-Based Policymaking</a>.<sup>1</sup> They asked me to lead on this because I had built the <a href="https://www.norc.org/services-solutions/data-enclave.html">NORC remote access Data Enclave at the University of Chicago</a> 10 years before that.</p>
<p>This was the first step towards Democratizing Data.</p>
<p>The second step was figuring out how to create value from the data in the secure environment, because we knew that if we couldn’t create value, government agencies weren’t going to put their data into it.</p>
<p>But how do you figure out what agencies are going to want to do with the data in a secure environment? It’s difficult to get them to tell you what they want, so I thought, well, why don’t we build training classes, put people in these training classes and have them work on problems with their own data? That way, we’re going to know what problems they have so that we can address them.</p>
<p>So, step 1 was build secure environment. Step 2 was build capacity and identify the questions that are of interest to agencies so that they would put data into the secure environment. That led to the training classes that Frauke Kreuter, Rayid Ghani, and I put together, which are described here.</p>
<p>But then what happened was, people kept coming to me in the classes and asking, “Who else has worked with these data, and who can I go to and ask questions?”</p>
<p>I could give them a list of people, but that list would be biased by my age and race and sex and the people I know. What about those people who are doing really interesting stuff with these data that I happen not to know about?</p>
<p>So, that’s how Democratizing Data got started. I thought, really the best way to give a full answer to those sorts of questions is to figure out what datasets are being used in research publications.</p>
<p>Now, how was I going do that? I could read all the publications and manually write notes about who the authors were, and what the topics were, and what datasets they used. But that’s not realistic. So, I thought, well, maybe we could combine natural language processing techniques with machine learning so that you could “read” all these publications and find out how datasets are cited.</p>
<div class="pullquote-container">
<div class="grid">
<div class="g-col-12 g-col-lg-4">
<div class="quarto-figure quarto-figure-left">
<figure class="figure">
<p><img src="https://realworlddatascience.net/viewpoints/interviews/posts/2024/03/11/images/julia-lane-sq.png" class="img-fluid figure-img" alt="Photo of Julia Lane, professor at the NYU Wagner Graduate School of Public Service and visiting fellow at RTI International."></p>
<figcaption>Julia Lane, professor at the NYU Wagner Graduate School of Public Service and visiting fellow at RTI International. Image supplied, used with permission.</figcaption>
</figure>
</div>
</div>
<div class="g-col-12 g-col-lg-8 pullquote-grid pullquote">
<p><img src="https://realworlddatascience.net/images/pullquote-purple.png" class="img-fluid" width="50"></p>
<p>We’re searching for ways to measure how datasets are used, how they’re valued, and so on. Federal statistical data and Elsevier’s Scopus have been a great starting point for us, but the broader vision is to incorporate other datasets and other publication databases.</p>
</div>
</div>
</div>
<p><strong>Would this have been a problem that needed solving if there were common, established citation standards and practices for datasets?</strong><br>
There <em>are</em> great citation practices for datasets, and we’ve had them for 15 years. Back when I was a National Science Foundation (NSF) program officer, everyone was saying, well, if we just get the plumbing right, people will come and use it. Well, they don’t. Even when there are DOIs available and they’re relatively easy to cite, people don’t. The plumbing’s there, we built it, but they didn’t come.</p>
<p>So, I think there has to be a demand-side piece, and we talk about that in one of the papers in an upcoming special issue of the <a href="https://hdsr.mitpress.mit.edu/">Harvard Data Science Review</a>: How do you create an incentive structure so that people do provide information about how they’ve used data? My thinking was that, suppose we can find out who’s using what data. Then the incentive structure to an academic is “your name in lights”: you are the world’s living expert in orange carrots with green stripes, or whatever. So, we would read the publications, find the datasets, and then you could have a leaderboard of the people who have done the most work in a particular field, and then people would have an incentive both to cite datasets and to let you know when you miss things. And that was when I thought, well, let’s put all this information up in a dashboard.</p>
<p><strong>So, is the grand vision for this to create a platform that, essentially, any data owner – anyone who publishes datasets – could plug into, connect to, and understand how other people are using their datasets?</strong><br>
That’s right. The grand vision is basically to set up a search and discovery portal. Originally, my thinking was that would be super helpful for people just starting out in a field; for a new graduate student or a postdoc to say, “I want to figure out what work has been done on recidivism of welfare recipients relative to access to jobs and neighborhood characteristics,” for example, and for them to see what datasets are available and how they have been used.</p>
<p>But from the data producer side it’d also be useful to know: Who’s using the datasets? Where are the gaps? Where are we maybe not reaching as many people as we thought we were, and how can we change that?</p>
<p>So, while the original idea was to build a platform for researchers, plans changed when the <a href="https://www.govinfo.gov/content/pkg/PLAW-115publ435/pdf/PLAW-115publ435.pdf">Evidence Act</a> passed, and agencies were required to produce usage statistics for their datasets.<sup>2</sup></p>
<p>We started a pilot with the US Department of Agriculture’s (USDA) Economic Research Service (ERS). They have been a huge supporter and helped us work through a lot of the issues. Then, when we began showing around the ERS wireframes and ideas, the NSF National Center for Science and Engineering Statistics joined in, and so did USDA’s National Agricultural Statistics Service and the National Center for Education Statistics and the National Oceanic and Atmospheric Administration.</p>
<p>So, we have these agencies involved and they’ve really been the drivers, the intellectual partners, pushing the design and the structure forward.</p>
<p><strong>I’ve had a chance to play around with some of the <a href="https://democratizingdata.ai/tools/dashboards/">public dashboards you’ve released on Tableau</a>, and I really like the way you can explore dataset usage from different start points and end up with a list of publications that use those datasets. My question is, though, how have you connected all this up – datasets and publications?</strong><br>
Our start point was scientific publications because these are pretty well curated. We ended up working with Elsevier because Scopus [Elsevier’s abstract and citation database] is a well-curated corpus and they’ve got the associated publication metadata well curated.</p>
<p>So, we have the Scopus corpus, and we then ran <a href="https://www.kaggle.com/c/coleridgeinitiative-show-us-the-data">a Kaggle competition</a> to develop machine learning models to identify candidate snippets of text from scientific papers that seem like they might be referring to a dataset.</p>
<p>Human researchers would then validate those snippets as either referring to a dataset or not, and once they’ve validated the publication-to-dataset dyad, we then pull in all the metadata associated with the publication: authors, institutions, key topics, publication year, countries, etc. – all this information gets piped over to the dashboards.</p>
<p><strong>You published <a href="https://hdsr.mitpress.mit.edu/pub/g6e8noiy/release/2">a Harvard Data Science Review article about this competition a couple of years ago</a>, and from that I understand that you can actually get quite far with a simple string-matching method for finding datasets, but you would still miss a lot of citations using this approach because of the variability in the way people refer to datasets.</strong><br>
That’s right. There were three different models that were developed, and each one picks up different aspects of how authors mention data in publications, and all three have been extremely useful. We learned a lot about the variety of ways in which researchers cite the data that they use.</p>
<p>It turns out that more people do cite datasets in references than we had originally thought, but usually they don’t cite a DOI, they cite the URL or they cite the exact name of the dataset, so string search of references and URLs pulls out quite a lot of information that the DOIs, <em>per se</em>, don’t.</p>
<p><strong>What are the next steps for scaling up the Democratizing Data work?</strong><br>
I think it is more of a sociotechnical issue than a technical one. We have the plumbing, but really what we need to do is to figure out the incentives for researchers. We need to build a community around the data, which is what’s happened with code and the sharing of code on platforms like GitHub.</p>
<p>Obviously, our initial focus has been on federal statistical data, but there’s also a lot of interest in how administrative data or streaming data are being used.</p>
<p>The advantage of starting with statistical data is that they have names. As we learn more about citation patterns, though, it may be that we don’t need precise names. What may happen is that the community starts converging on common terminologies for datasets. That happens in a lot of fields.</p>
<p>At the moment, it feels a little bit like the Wild West. We’re searching for ways to measure how datasets are used, how they’re valued, and so on. Federal statistical data and Elsevier’s Scopus have been a great starting point for us, but the broader vision is to incorporate other datasets and other publication databases like arXiv and Semantic Scholar. But all those other datasets that are out there, they need to be curated and documented in some way and that’s a huge task, so the solution has got to be community curation and sharing, right?</p>
<p>If we don’t build a community around the data, we’re just going to have really bad information, really bad analysis, and really bad statistics on the value that our datasets – all these data assets – provide. My colleague <a href="https://www.rti.org/event/rti-fellow-program-distinguished-lecture-series-democratizing-data">Nancy Potok gave a talk a couple of days ago</a> in which she said that our future depends on this – and it really does.</p>
<div class="article-btn">
<p><a href="../../../../../../viewpoints/interviews/index.html">Find more Interviews</a></p>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-6">
<dl>
<dt>Copyright and licence</dt>
<dd>
© 2023 Royal Statistical Society
</dd>
</dl>
<p><a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> <img style="height:22px!important;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"></a> This article is licensed under a Creative Commons Attribution 4.0 (CC BY 4.0) <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> International licence</a>. Photo of Julia Lane is not included in this licence.</p>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>How to cite</dt>
<dd>
Tarran, Brian. 2023. “Democratizing Data: Using natural language processing and machine learning to capture dataset usage.” Real World Data Science, March 11, 2024. <a href="https://realworlddatascience.net/viewpoints/interviews/posts/2024/03/11/democratizing-data.html">URL</a>
</dd>
</dl>
</div>
</div>
</div>




<div id="quarto-appendix" class="default"><section id="footnotes" class="footnotes footnotes-end-of-document"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p>The Commission on Evidence-Based Policymaking was “charged with examining all aspects of how to increase the availability and use of government data to build evidence and inform program design, while protecting privacy and confidentiality of those data.”↩︎</p></li>
<li id="fn2"><p>Specifically, the act requires federal agencies to identify and implement methods “for collecting and analyzing digital information on data asset usage by users within and outside of the agency.”↩︎</p></li>
</ol>
</section></div> ]]></description>
  <category>AI</category>
  <category>Data</category>
  <category>Machine learning</category>
  <category>Natural language processing</category>
  <guid>https://realworlddatascience.net/viewpoints/interviews/posts/2024/03/11/democratizing-data.html</guid>
  <pubDate>Mon, 11 Mar 2024 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/viewpoints/interviews/posts/2024/03/11/images/julia-lane-thumb.png" medium="image" type="image/png" height="105" width="144"/>
</item>
<item>
  <title>Editor’s note: Not saying goodbye, just saying…</title>
  <dc:creator>Brian Tarran</dc:creator>
  <link>https://realworlddatascience.net/viewpoints/editors-blog/posts/2024/03/editors-note.html</link>
  <description><![CDATA[ 





<p>It’s not easy to leave a brilliant group of people you’ve worked with for almost a decade, but in a month’s time I’ll be moving on from the Royal Statistical Society (RSS).</p>
<p>When I joined RSS in June 2014 I was looking for new challenges. I wanted to find out more about the ways statistics and data are used to understand and solve problems and inform decisions in science, business and industry, public policy, health… I could go on! Working for the RSS certainly delivered on that front: as editor of <a href="https://significancemagazine.com/">Significance</a> for eight years and of Real World Data Science more recently, I have had many opportunities to learn.</p>
<p>Pretty much every day of my working life for the past nine years, eight months or so involved speaking with expert statisticians and data scientists or reading about their work. When there were things I didn’t understand, they were always happy to explain. When I shared my ideas for how to make their articles clearer or more readable, they took the time to listen. Together, we worked to create accessible, engaging stories about statistics and data. There have been hundreds of these collaborations over the years – too many to namecheck individually – but I have enjoyed them all, and I’ve learned something from each of them.</p>
<p>Before I head off to pursue a new set of challenges and learning opportunities, I want to say a big thank you to all the RSS staff and members, past and present, that I’ve been lucky to call my colleagues. Thank you also to the staff and members of the American Statistical Association who have been valued partners on Significance over the years and now RWDS too. It’s been a privilege to work with you all.</p>
<p>The chance to launch RWDS has been a particular highlight of my time at RSS, and I am grateful to have had the support and input of The Alan Turing Institute and many of its wonderful staff and researchers on this project. I’m excited to see the site continue to grow and develop into a valuable resource for the data science community, and I look forward to reading an upcoming series of articles that will explore the statistical and data science perspectives on AI – stay tuned for more on this soon.</p>
<p>Statistics and data will continue to be a big part of my life, so this isn’t “goodbye.” Instead, I’ll just say, let’s keep in touch – and thank you for reading!</p>
<div class="article-btn">
<p><a href="../../../../../viewpoints/editors-blog/index.html">Back to Editors’ blog</a></p>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-6">
<dl>
<dt>Copyright and licence</dt>
<dd>
© 2024 Royal Statistical Society
</dd>
</dl>
<p><a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> <img style="height:22px!important;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"></a> This article is licensed under a Creative Commons Attribution 4.0 (CC BY 4.0) <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> International licence</a>. Thumbnail photo by <a href="https://unsplash.com/@peet818?utm_content=creditCopyText&amp;utm_medium=referral&amp;utm_source=unsplash">Pete Pedroza</a> on <a href="https://unsplash.com/photos/thank-you-text-VyC0YSFRDTU?utm_content=creditCopyText&amp;utm_medium=referral&amp;utm_source=unsplash">Unsplash</a>.</p>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>How to cite</dt>
<dd>
Tarran, Brian. 2024. “Editor’s note: Not saying goodbye, just saying…” Real World Data Science, March 6, 2024. <a href="https://realworlddatascience.net/viewpoints/editors-blog/posts/2024/03/06/editors-note.html">URL</a>
</dd>
</dl>
</div>
</div>
</div>



 ]]></description>
  <category>People</category>
  <category>Updates</category>
  <guid>https://realworlddatascience.net/viewpoints/editors-blog/posts/2024/03/editors-note.html</guid>
  <pubDate>Wed, 06 Mar 2024 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/viewpoints/editors-blog/posts/2024/03/images/thank-you.png" medium="image" type="image/png" height="105" width="144"/>
</item>
<item>
  <title>What is data science? A closer look at science’s latest priority dispute</title>
  <dc:creator>Jonathan Auerbach, David Kepplinger, and Nicholas Rios</dc:creator>
  <link>https://realworlddatascience.net/ideas/posts/2024/02/19/what-is-data-science.html</link>
  <description><![CDATA[ 





<p>What is data science, and where did it come from? Is data science a new and exciting set of skills, necessary for analyzing 21st century data? Or is it (as some have claimed) a rebranding of statistics, which has carefully developed time-honored methods for data analysis over the past century?</p>
<p>Priority disputes – disagreements over who deserves credit for a new scientific theory or method – date back to the beginning of science. Famous examples include the invention of <a href="https://en.wikipedia.org/wiki/Leibniz–Newton_calculus_controversy">calculus</a> and <a href="https://projecteuclid.org/journals/annals-of-statistics/volume-9/issue-3/Gauss-and-the-Invention-of-Least-Squares/10.1214/aos/1176345451.full">ordinary least squares</a>. But this latest dispute calls into question the novelty of an entire discipline.</p>
<p>In this article, we use two popular data science algorithms to examine the difference between data science, statistics, and other occupations. We find that in terms of the preparation required to become a data scientist, data science reflects both the work of natural sciences managers – individuals who oversee research operations in the natural sciences – and statisticians and mathematicians. This suggests that data science is a shared enterprise among science and math, and thus those trained in the natural sciences have as much claim to data science as those trained in mathematics and statistics.</p>
<p>In terms of the role a data scientist serves relative to other occupations, however, we find that data science is closest to statistics by far. Both occupations are fast growing and central among the occupations that work with data, suggesting a data scientist serves the same function as a statistician. But this function may be changing. While the centrality of statistics has declined over the past decade relative to other occupations, the centrality of data science has grown. In fact, data science has now surpassed statistics as the most central fast-growing occupation.</p>
<section id="we-examine-the-role-of-data-science-using-data-science" class="level2">
<h2 class="anchored" data-anchor-id="we-examine-the-role-of-data-science-using-data-science">We examine the role of data science using data science</h2>
<p>Everyone seems to agree that data science requires skills traditionally associated with a variety of different occupations. <a href="http://drewconway.com/zia/2013/3/26/the-data-science-venn-diagram">Drew Conway</a>, for example, describes data science as a combination of math and statistics, substantive (domain) expertise, and “hacking” skills (see Figure&nbsp;1). In dispute is the relative importance of those skills. <a href="https://www.statisticsviews.com/article/nate-silver-what-i-need-from-statisticians/">Some</a> <a href="https://imstat.org/2014/10/01/ims-presidential-address-let-us-own-data-science/">have</a> <a href="https://magazine.amstat.org/blog/2013/07/01/datascience/">argued</a> that data science is basically statistics – and that 20th century statisticians like <a href="https://imstat.org/2023/09/30/hand-writing-john-tukey-the-first-data-scientist/">John Tukey</a> have long possessed the data science skills traditionally associated with computer science and the natural sciences. <a href="http://drewconway.com/zia/2013/3/26/the-data-science-venn-diagram">Others</a> <a href="https://statmodeling.stat.columbia.edu/2013/11/14/statistics-least-important-part-data-science/">have</a> <a href="https://web.archive.org/web/20211219192027/http://www.dataists.com/2010/09/a-taxonomy-of-data-science/">argued</a> that data science is truly interdisciplinary, and statistical thinking only plays a small role. But while opinions on data science abound, few appear to be based on data or science.<sup>1</sup></p>
<div id="fig-conway" class="quarto-figure quarto-figure-center quarto-float anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-conway-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="https://images.squarespace-cdn.com/content/v1/5150aec6e4b0e340ec52710a/1364352051365-HZAS3CLBF7ABLE3F5OBY/Data_Science_VD.png?format=2500w" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-conway-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;1: <a href="http://drewconway.com/zia/2013/3/26/the-data-science-venn-diagram">Drew Conway</a> describes data science as a combination of math and statistics, substantive (domain) expertise, and “hacking” skills. Conway’s data science venn diagram, reproduced here, is Creative Commons licensed as <a href="https://creativecommons.org/licenses/by-nc/3.0/legalcode">Attribution-NonCommercial</a>.
</figcaption>
</figure>
</div>
<p>To that end, we use two popular data science algorithms, naïve Bayes and eigen centrality (eigen decomposition), to investigate the question: What is data science? Both algorithms use data listing the training a worker must generally complete to work in an occupation, such as data science. Specifically, we use the <a href="https://nces.ed.gov/ipeds/cipcode/resources.aspx?y=56">CIP SOC Crosswalk</a> provided by the US Bureau of Labor Statistics and US National Center for Education Statistics, which links the <a href="https://nces.ed.gov/ipeds/cipcode/Default.aspx?y=56">Classification of Instructional Programs</a> – the standard classification of educational fields of study into roughly 2,000 instructional programs – with the <a href="https://www.bls.gov/soc/">Standard Occupational Classification</a> – the standard classification of professions into roughly 700 occupations.</p>
<p>Our main assumption is that the skills required to work in an occupation can be represented by the instructional programs that prepare students to work in that occupation. For example, the occupation “data scientists” is associated with 35 instructional programs, such as data science, statistics, artificial intelligence, computational science, mathematical biology, and econometrics. The occupation “statisticians” is associated with 26 instructional programs, including data science, statistics, and econometrics, but not artificial intelligence, computational science, or mathematical biology.</p>
<p>The algorithms we employ consider occupations to be similar if they have many instructional programs in common. Data scientists and statisticians share 14 degrees, suggesting they are similar: Half the programs that prepare students to be a statistician also prepare students to be a data scientist. In contrast, data scientists and computer programmers share six degrees in common, suggesting they are less similar; computer programmers have 17 degrees overall so only a third of the programs that prepare students to be a computer programmer also prepare students to be a data scientist.<sup>2</sup></p>
<div class="callout callout-style-simple callout-note">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-body-container">
<p>Data and code to reproduce the analysis and figures are available through <a href="https://github.com/jauerbach/what-is-data-science">GitHub</a>.</p>
</div>
</div>
</div>
</section>
<section id="data-science-is-a-shared-enterprise-among-science-and-math" class="level2">
<h2 class="anchored" data-anchor-id="data-science-is-a-shared-enterprise-among-science-and-math">Data science is a shared enterprise among science and math</h2>
<p>We use <a href="https://en.wikipedia.org/wiki/Naive_Bayes_classifier#Multinomial_naive_Bayes">naïve Bayes</a> to measure the similarity between each occupation and data science in terms of the preparation required to work in that occupation. Specifically, we first pretend that the occupation “data scientist” did not exist and then use Bayes’ rule to calculate the probability that a hypothetical group of workers with the 35 degrees associated with data science could have come from one of the roughly 700 other occupations. The higher the measure, the more consistent that occupation is with data science.</p>
<p>The use of Bayes’ rule is appealing because the similarity between a given occupation and data science takes into account the similarities between every other occupation and data science. Our use of Bayes’ rule is naïve in the sense that – before collecting the data – we assume these workers are equally likely to have come from any occupation.</p>
<p>The occupations with the largest probabilities, and thus most related to data science, are summarized in Figure&nbsp;2. We find that the hypothetical workers have a 50% chance of being natural sciences managers and a 50% chance of being statisticians or mathematicians.<sup>3</sup> We conclude that data science is a shared enterprise among science and math, and thus those trained in natural sciences have as much claim to data science as those trained in mathematics and statistics.</p>
<div id="fig-naive-bayes" class="quarto-figure quarto-figure-center quarto-float anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-naive-bayes-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="https://realworlddatascience.net/ideas/posts/2024/02/19/images/fig-naive-bayes-1.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-naive-bayes-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2: We use <a href="https://en.wikipedia.org/wiki/Naive_Bayes_classifier#Multinomial_naive_Bayes">naïve Bayes</a> to measure the similarity between each occupation and data science in terms of the preparation required to work in that occupation. We find that in terms of the preparation required to become a data scientist, data science is a shared enterprise among science and math.
</figcaption>
</figure>
</div>
</section>
<section id="data-science-is-closest-to-statistics-in-its-role-among-other-occupations" class="level2">
<h2 class="anchored" data-anchor-id="data-science-is-closest-to-statistics-in-its-role-among-other-occupations">Data science is closest to statistics in its role among other occupations</h2>
<p>We use <a href="https://en.wikipedia.org/wiki/Centrality#Eigenvector_centrality">eigen centrality</a> (eigen decomposition) to measure the similarity of each occupation in terms of its role relative to other occupations. Specifically, we calculate the principal right singular vector of the adjacency matrix denoting whether an instructional program (row) is associated with an occupation (column).<sup>4</sup> An occupation has high eigen centrality when the instructional programs that prepare a worker for that occupation also prepare that worker for many other occupations as well. This suggests that the higher the measure, the more central the role of the occupation relative to other occupations.</p>
<p>The eigen centrality of each occupation is displayed in Figure&nbsp;3. Each point represents an occupation, the x-axis denotes the centrality of the occupation, and the y-axis denotes the percent growth of the occupation as <a href="https://www.bls.gov/emp/">predicted</a> by the US Bureau of Labor Statistics over the next decade. The figure demonstrates that data scientists and statisticians occupy nearly identical positions: Both are fast growing and central to the other occupations that work with data. In contrast, natural sciences managers are central but growing much more slowly, suggesting a role closer to managers. We conclude that – though data scientists are prepared similarly to natural sciences managers – a data scientist serves the same function as a statistician.</p>
<div id="fig-centrality-growth" class="quarto-figure quarto-figure-center quarto-float anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-centrality-growth-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="https://realworlddatascience.net/ideas/posts/2024/02/19/images/fig-centrality-growth-1.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-centrality-growth-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;3: We use <a href="https://en.wikipedia.org/wiki/Centrality#Eigenvector_centrality">eigen centrality</a> (eigen decomposition) to measure the similarity of each occupation in terms of its role relative to other occupations. We find that in terms of the role a data scientist serves relative to other occupations, a data scientist functions like a statistician.
</figcaption>
</figure>
</div>
<p>But this function may be changing. Figure&nbsp;4 shows the centrality (x-axis) of each occupation (y-axis) in 2010 and 2020. Green bars denote increases from 2010 to 2020 while yellow bars denote decreases. We find that the centrality of statisticians has declined over the past decade relative to other occupations, while the centrality of data scientists has grown. In fact, data science has now surpassed statistics as the most central fast-growing occupation. We conclude that though a data scientist and a statistician serve similar roles today, those roles may change as the workforce changes. Note that the occupation classifications changed in 2018, and we used the <a href="https://www.bls.gov/soc/2018/crosswalks_used_by_agencies.htm">crosswalk</a> provided by the US Bureau of Labor Statistics to make these comparisons.</p>
<div id="fig-centrality-change" class="quarto-figure quarto-figure-center quarto-float anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-centrality-change-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="https://realworlddatascience.net/ideas/posts/2024/02/19/images/fig-centrality-change-1.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-centrality-change-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4: We use <a href="https://en.wikipedia.org/wiki/Centrality#Eigenvector_centrality">eigen centrality</a> (eigen decomposition) to measure the similarity of each occupation in terms of its role relative to other occupations. We find that the centrality of statisticians has declined over the past decade relative to other occupations, while the centrality of data scientists has grown. Data science has now surpassed statistics as the most central fast-growing occupation. (Occupations predicted to grow more than 20% over the next decade shown.)
</figcaption>
</figure>
</div>
<p>The findings in this section are based on the adjacency matrix that encodes whether an instructional program (row) is associated with an occupation (column). A more detailed summary of the matrix is provided in Figure&nbsp;5, which depicts the matrix as a network graph. Larger nodes represent occupations that are growing faster, while nodes closer to the center of the network represent more central occupations. The figure is interactive. You can zoom in to see the similar positions between data scientists and statisticians, which are both large (fast growing) and central.</p>
<div id="fig-interactive-plot" class="quarto-figure quarto-figure-center quarto-float anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-interactive-plot-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="tv-iframe-container">
  <iframe class="responsive-iframe" src="images/network.html" title="fig-interactive-plot"></iframe>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-interactive-plot-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;5: A visualization of occupations as a network: Occupations are placed according to the instructional programs that train students for that occupation, with occupations closer together sharing more instructional programs in common. We find data scientists and statisticians occupy nearly identical positions at the center of the network. Occupations are colored according to the primary classification of instructional programs that train students for that occupation. Larger nodes represent occupations that are growing faster.
</figcaption>
</figure>
</div>
</section>
<section id="is-data-science-statistics" class="level2">
<h2 class="anchored" data-anchor-id="is-data-science-statistics">Is data science statistics?</h2>
<p>We conclude that individuals trained in managing natural sciences research – a slow growing occupation – are turning to data science – a much faster growing occupation, and one which currently serves a role like that of a statistician. But if present trends continue, data science is poised to eclipse the historic role of the statistician as central to the occupations that work with data.</p>
<p>This suggests that while data science may be new and exciting, the role served by the data scientist is not particularly new. This does not mean that data scientists necessarily use the same time-honored methods for data analysis as statisticians. It is the authors’ experience, however, that many data science tools are in fact statistical. Indeed, the two data science algorithms we used in this article are both taught to students as new and exciting, but in reality are centuries-old methods steeped in statistical history.</p>
<p>Regardless of whether data science is or is not statistics, the occupation “data scientist” has proven immensely popular, capturing a zeitgeist that has eluded statistics. This is best evidenced by the fact that data science – and not statistics – has been crowned the <a href="https://hbr.org/2012/10/data-scientist-the-sexiest-job-of-the-21st-century">sexiest</a> job of the 21st century. But if statistics has not enjoyed the popularity of data science, perhaps the real question in need of answering is: What is statistics?</p>
<div class="article-btn">
<p><a href="../../../../../ideas/index.html">Explore more data science ideas</a></p>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-12">
<dl>
<dt>About the author</dt>
<dd>
<strong>Jonathan Auerbach</strong> is an assistant professor in the Department of Statistics at George Mason University. His research covers a wide range of topics at the intersection of statistics and public policy. His interests include the analysis of longitudinal data, particularly for data science and causal inference, as well as urban analytics, open data, and the collection, evaluation, and communication of official statistics.
</dd>
<dd>
<strong>David Kepplinger</strong> is an assistant professor in the Department of Statistics at George Mason University. His research revolves around methods for robust and reliable estimation and inference in the presence of aberrant contamination in high-dimensional, complex data. He has active collaborations with researchers from the medical, biological, and life sciences.
</dd>
<dd>
<strong>Nicholas Rios</strong> is an assistant professor of statistics at George Mason University. He earned his PhD in statistics 2022 from Penn State University, where his dissertation focused on designing optimal mixture experiments. His primary research interests are experimental design and methods for intelligent data collection in the presence of real-world constraints. He is also interested in functional data analysis, computational statistics, compositional data analysis, and the analysis of high-dimensional data.
</dd>
</dl>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>Copyright and licence</dt>
<dd>
© 2023 Jonathan Auerbach, David Kepplinger, and Nicholas Rios
</dd>
</dl>
<p><a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> <img style="height:22px!important;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"></a> Text, code, and figures are licensed under a Creative Commons Attribution 4.0 (CC BY 4.0) <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;">International licence</a>, except where otherwise noted. Thumbnail photo by <a href="https://unsplash.com/@marcsm?utm_content=creditCopyText&amp;utm_medium=referral&amp;utm_source=unsplash">Marc Sendra Martorell</a> on <a href="https://unsplash.com/photos/closeup-photo-of-two-bubbles-2BrdNFxW0UY?utm_content=creditCopyText&amp;utm_medium=referral&amp;utm_source=unsplash">Unsplash</a>.</p>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>How to cite</dt>
<dd>
Auerbach, Jonathan, David Kepplinger, and Nicholas Rios. 2023. “What is data science? A closer look at science’s latest priority dispute.” Real World Data Science, February 19, 2024. <a href="https://doi.org/10.5281/zenodo.10679962"><img src="https://zenodo.org/badge/DOI/10.5281/zenodo.10679962.svg" class="img-fluid" style="vertical-align:text-bottom;" alt="DOI"></a>
</dd>
</dl>
</div>
</div>
</div>



</section>


<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0">
<div id="ref-donoho201750" class="csl-entry">
Donoho, David. 2017. <span>“50 Years of Data Science.”</span> <em>Journal of Computational and Graphical Statistics</em> 26 (4): 745–66.
</div>
<div id="ref-stigler1981gauss" class="csl-entry">
Stigler, Stephen M. 1981. <span>“Gauss and the Invention of Least Squares.”</span> <em>The Annals of Statistics</em>, 465–74.
</div>
</div></section><section id="footnotes" class="footnotes footnotes-end-of-document"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p>Descriptions of occupations by government agencies are not particularly helpful in differentiating between data science, statistics, and related occupations. For example, according to the Bureau of Labor Statistics, data scientists use “analytical tools and techniques to extract meaningful insights from data.” This description is similar to mathematicians/statisticians, who “analyze data and apply computational techniques to solve problems,” and operations research analysts who use “mathematics and logic to help solve complex issues.”↩︎</p></li>
<li id="fn2"><p>Our analysis treats all instructional programs as equal and independent. We do not consider, for example, the number of workers who hold a degree from an instructional program or whether two instructional programs are similar or offered by similar academic departments. Our analysis could be adjusted to account for this or related information, although it is unclear to the authors whether such an adjustment would make the results more accurate.↩︎</p></li>
<li id="fn3"><p>Note that natural sciences managers share 18 instructional programs with data scientists, while statisticians share 14.↩︎</p></li>
<li id="fn4"><p>Or alternatively, the principal eigenvector of the adjacency matrix denoting the number of instructional programs each occupation (row) has in common with each other occupation (column).↩︎</p></li>
</ol>
</section></div> ]]></description>
  <category>Algorithms</category>
  <category>Data science education</category>
  <category>Skills</category>
  <category>Training</category>
  <guid>https://realworlddatascience.net/ideas/posts/2024/02/19/what-is-data-science.html</guid>
  <pubDate>Mon, 19 Feb 2024 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/ideas/posts/2024/02/19/images/bubbles.png" medium="image" type="image/png" height="105" width="144"/>
</item>
<item>
  <title>£10m for UK regulators to ‘jumpstart’ AI capabilities, as government commits to white paper approach</title>
  <dc:creator>Brian Tarran</dc:creator>
  <link>https://realworlddatascience.net/viewpoints/editors-blog/posts/2024/02/08/llms-whitepaper-response.html</link>
  <description><![CDATA[ 





<p>The UK government this week announced a £10 million investment to “jumpstart regulators’ AI capabilities” as part of its commitment to a “pro-innovation approach to AI regulation.” But will this be sufficient to answer criticisms that it has so far been “too slow” to give regulators the tools they need to police the growing usage of AI?</p>
<p>It was March last year when a Department for Science, Innovation and Technology (DSIT) white paper first set out the government’s <a href="https://www.gov.uk/government/publications/ai-regulation-a-pro-innovation-approach/white-paper">principles- and context-based approach to regulating artificial intelligence</a>. This proposed to focus regulatory attention on “the context in which AI is deployed” rather than target specific technologies. Under this model, existing regulators, including the Information Commissioner’s Office, Ofcom, and the Competition and Markets Authority, would be responsible for ensuring that technologies deployed within their domains adhered to established rules – e.g., data protection regulation – and a common set of principles:</p>
<ul>
<li>Safety, security and robustness.</li>
<li>Appropriate transparency and explainability.</li>
<li>Fairness.</li>
<li>Accountability and governance.</li>
<li>Contestability and redress.</li>
</ul>
<p>The approach was broadly well received, as was clear from a debate at techUK’s <a href="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/12/08/digital-ethics-summit.html">Digital Ethics Summit</a> last December. However, concerns were expressed about whether regulators would be funded sufficiently to meet the expectations set out in the March white paper. Also, the Royal Statistical Society, in <a href="https://rss.org.uk/RSS/media/File-library/Policy/2023/RSS-AI-white-paper-response-v2-2.pdf">its response to the white paper</a>, worried that “splitting responsibilities for regulating the use of AI between existing regulators does not meet the scale of the challenge,” and that “central leadership is required to give a clear, coherent and easily communicable framework that can be applied to all sectors.”</p>
<p>While the DSIT white paper proposed that a range of “central functions” be created to support regulators, <a href="https://committees.parliament.uk/committee/170/communications-and-digital-committee/news/199728/uk-will-miss-ai-goldrush-unless-government-adopts-a-more-positive-vision/">evidence presented to a House of Lords inquiry</a> last November suggested that regulators “did not appear to know what was happening” with these mooted teams and were “keen to see progress” on this front.</p>
<p>In reporting the outcomes of its inquiry last week, the House of Lords Communications and Digital Committee concluded that government was being “too slow” to give regulators the tools required to meet the objectives set out in the white paper, and that “speedier resourcing of government‑led central support teams is needed.”</p>
<p>“Relying on existing regulators to ensure good outcomes from AI will only work if they are properly resourced and empowered,” the committee said.</p>
<p>The £10 million funding for regulators announced this week is therefore likely to be welcomed. Money is earmarked to “help regulators develop cutting-edge research and practical tools to monitor and address risks and opportunities in their sectors, from telecoms and healthcare to finance and education,” according to <a href="https://www.gov.uk/government/news/uk-signals-step-change-for-regulators-to-strengthen-ai-leadership">a DSIT press release</a>. Speaking on February 6 at <a href="https://parliamentlive.tv/event/index/68ecee17-2896-4002-8736-1608229db364?in=15:27:41">a hearing of the Lords Communications and Digital Committee</a>, Michelle Donelan, Secretary of State for Science, Innovation and Technology, said that the government would “stay on top” of what regulators need to be able to fulfil their responsibilities for regulating the use of AI in their sectors.</p>
<section id="consultation-response" class="level2">
<h2 class="anchored" data-anchor-id="consultation-response">Consultation response</h2>
<p>News of the funding for regulators came as part of <a href="https://www.gov.uk/government/consultations/ai-regulation-a-pro-innovation-approach-policy-proposals/outcome/a-pro-innovation-approach-to-ai-regulation-government-response">a long-awaited response by the government to the consultation on its AI regulation white paper</a>. The response essentially confirmed that the government was proceeding with its principles- and context-based approach to regulating AI, having received “strong support from stakeholders across society.”</p>
<p>This approach is right for today, the government said, “as it allows us to keep pace with rapid and uncertain advances in AI.” However, it acknowledged that “the challenges posed by AI technologies will ultimately require legislative action in every country once understanding of risk has matured.”</p>
<p>“Highly capable general-purpose AI systems” would, for example, present a particular challenge to the government’s current approach. It explained: “Even though some regulators can enforce existing laws against the developers of the most capable general-purpose systems within their current remits, the wide range of potential uses means that general-purpose systems do not currently fit neatly within the remit of any one regulator, potentially leaving risks without effective mitigations.”</p>
<p>As a next step in delivering on the white paper approach, the government is asking key regulators to publish an update on their strategic approach to AI by the end of April. This was welcomed by Royal Statistical Society (RSS) president Andrew Garrett, who said:</p>
<blockquote class="blockquote">
<p>“Urgency is certainly warranted, and the directive for key regulators to disclose their approach in the coming months is a positive development. Ensuring consistency and coherence not only among key regulators but also those who follow is crucial.”</p>
</blockquote>
<p>Garrett also <a href="https://realworlddatascience.net/viewpoints/interviews/posts/2023/10/25/evaluating-ai.html">reiterated the need for government to engage with statisticians and data scientists</a>, particularly through its <a href="https://realworlddatascience.net/viewpoints/posts/2023/12/06/ai-fringe.html">new AI Safety Institute</a> (AISI). In the white paper consultation response, AISI is billed as being “fundamental to informing the UK’s regulatory framework”: it will “advance the world’s knowledge of AI safety by carefully examining, evaluating, and testing new frontier AI systems” and will also “research new techniques for understanding and mitigating AI risk.” Garrett said:</p>
<blockquote class="blockquote">
<p>“As always, fostering diversity of representation within government and regulatory bodies remains paramount; it cannot solely rely on input from major tech companies. It is especially important that the AI Safety Institute engages with a diverse array of voices, including statisticians and data scientists who play a pivotal role in both the development of AI systems and novel evaluation methodologies.”</p>
</blockquote>
</section>
<section id="risks-and-opportunities" class="level2">
<h2 class="anchored" data-anchor-id="risks-and-opportunities">Risks and opportunities</h2>
<p>Calls for a “diversity of representation within government and regulatory bodies” certainly chime with a warning bell sounded by the Lords Communications and Digital Committee last week, in the February 2 release of its <a href="https://committees.parliament.uk/committee/170/communications-and-digital-committee/news/199728/uk-will-miss-ai-goldrush-unless-government-adopts-a-more-positive-vision/">inquiry report into large language models and generative AI</a>. “Regulatory capture” by big commercial interests was highlighted as a danger to be avoided, amid concern that “the AI safety debate is being dominated by views narrowly focused on catastrophic risk, often coming from those who developed such models in the first place” and that “this distracts from more immediate issues like copyright infringement, bias and reliability.”<sup>1</sup></p>
<p>The committee called for enhanced governance and transparency measures in DSIT and AISI to guard against regulatory capture, and for a rebalancing away from a “narrow focus on high-stakes AI safety” toward a “more positive vision for the opportunities [of AI] and a more deliberate focus on near-term risks” including cyber security and disinformation.</p>
<p>It also wants to see greater action by the government in support of copyright. “Some tech firms are using copyrighted material without permission, reaping vast financial rewards,” reads the report. “The legalities of this are complex but the principles remain clear. The point of copyright is to reward creators for their efforts, prevent others from using works without permission, and incentivise innovation. The current legal framework is failing to ensure these outcomes occur and the Government has a duty to act. It cannot sit on its hands for the next decade and hope the courts will provide an answer.”</p>
<p>Again, here’s RSS president Andrew Garrett’s take on the Lords committee report:</p>
<center>
<iframe src="https://www.linkedin.com/embed/feed/update/urn:li:share:7159583475350585344" height="1091" width="504" frameborder="0" allowfullscreen="" title="Embedded post">
</iframe>
</center>
<div class="article-btn">
<p><a href="../../../../../../viewpoints/editors-blog/index.html">Back to Editors’ blog</a></p>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-6">
<dl>
<dt>Copyright and licence</dt>
<dd>
© 2024 Royal Statistical Society
</dd>
</dl>
<p><a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> <img style="height:22px!important;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"></a> This article is licensed under a Creative Commons Attribution 4.0 (CC BY 4.0) <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> International licence</a>. Thumbnail photo by <a href="https://unsplash.com/@yaopey?utm_content=creditCopyText&amp;utm_medium=referral&amp;utm_source=unsplash">Yaopey Yong</a> on <a href="https://unsplash.com/photos/white-concrete-building-near-body-of-water-during-night-time-flmPTUCjkto?utm_content=creditCopyText&amp;utm_medium=referral&amp;utm_source=unsplash">Unsplash</a>.</p>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>How to cite</dt>
<dd>
Tarran, Brian. 2024. “£10m for UK regulators to ‘jumpstart’ AI capabilities, as government commits to white paper approach.” Real World Data Science, February 8, 2024. <a href="https://realworlddatascience.net/viewpoints/editors-blog/posts/2024/02/08/llms-whitepaper-response.html">URL</a>
</dd>
</dl>
</div>
</div>
</div>


</section>


<div id="quarto-appendix" class="default"><section id="footnotes" class="footnotes footnotes-end-of-document"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p>See, for example, <a href="https://realworlddatascience.net/viewpoints/posts/2023/06/05/no-AI-probably-wont-kill-us.html">“No, AI probably won’t kill us all – and there’s more to this fear campaign than meets the eye.”</a>↩︎</p></li>
</ol>
</section></div> ]]></description>
  <category>AI</category>
  <category>Large language models</category>
  <category>Public policy</category>
  <category>Risk</category>
  <category>Regulation</category>
  <guid>https://realworlddatascience.net/viewpoints/editors-blog/posts/2024/02/08/llms-whitepaper-response.html</guid>
  <pubDate>Thu, 08 Feb 2024 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/viewpoints/editors-blog/posts/2024/02/08/images/parliament-and-thames.png" medium="image" type="image/png" height="105" width="144"/>
</item>
<item>
  <title>UK government sets out 10 principles for use of generative AI</title>
  <dc:creator>Brian Tarran</dc:creator>
  <link>https://realworlddatascience.net/viewpoints/editors-blog/posts/2024/01/22/gen-ai-framework.html</link>
  <description><![CDATA[ 





<p>The UK government has published <a href="https://www.gov.uk/government/publications/generative-ai-framework-for-hmg/generative-ai-framework-for-hmg-html">a framework for the use of generative AI</a>, setting out 10 principles for departments and staff to think about if using, or planning to use, this technology.</p>
<p>It covers the need to understand what generative AI is and its limitations, the lawful, ethical and secure use of the technology, and a requirement for “meaningful human control.”</p>
<p>The focus is on large language models (LLMs) as, according to the framework, these have “the greatest level of immediate application in government.”</p>
<p>It lists a number of promising use cases for LLMs, including the synthesise of complex data, software development, and summaries of text and audio. However, the document cautions against using generative AI for fully automated decision-making or in contexts where data is limited or explainability of decision-making is required. For example, it warns that:</p>
<blockquote class="blockquote">
<p>“although LLMs can give the appearance of reasoning, they are simply predicting the next most plausible word in their output, and may produce inaccurate or poorly-reasoned conclusions.”</p>
</blockquote>
<p>And on the issue of explainability, it says that:</p>
<blockquote class="blockquote">
<p>“generative AI is based on neural networks, which are so-called ‘black boxes’. This makes it difficult or impossible to explain the inner workings of the model which has potential implications if in the future you are challenged to justify decisioning or guidance based on the model.”</p>
</blockquote>
<p>The framework goes on to discuss some of the practicalities of building generative AI solutions. It talks specifically about the value a multi-disciplinary team can bring to such projects, and emphasises the role of data scientists:</p>
<blockquote class="blockquote">
<p>“data scientists … understand the relevant data, how to use it effectively, and how to build/train and test models.”</p>
</blockquote>
<p>It also speaks to the need to “understand how to monitor and mitigate generative AI drift, bias and hallucinations” and to have “a robust testing and monitoring process in place to catch these problems.”</p>
<p>What do you make of the <a href="https://www.gov.uk/government/publications/generative-ai-framework-for-hmg/generative-ai-framework-for-hmg-html">Generative AI Framework for His Majesty’s Government</a>? What does it get right, and what needs more work?</p>
<div class="callout callout-style-simple callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
And in case you missed it…
</div>
</div>
<div class="callout-body-container callout-body">
<p>New York State issued a policy on the <a href="https://its.ny.gov/acceptable-use-artificial-intelligence-technologies">Acceptable Use of Artificial Intelligence Technologies</a> earlier this month. Similar to the UK government framework, it references the need for human oversight of AI models and rules out use of “automated final decision systems.” There is also discussion of fairness, equity and explainability, and AI risk assessment and management.</p>
</div>
</div>
<div class="article-btn">
<p><a href="../../../../../../viewpoints/editors-blog/index.html">Back to Editors’ blog</a></p>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-6">
<dl>
<dt>Copyright and licence</dt>
<dd>
© 2024 Royal Statistical Society
</dd>
</dl>
<p><a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> <img style="height:22px!important;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"></a> This article is licensed under a Creative Commons Attribution 4.0 (CC BY 4.0) <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> International licence</a>. Thumbnail photo by <a href="https://unsplash.com/@therawhunter?utm_content=creditCopyText&amp;utm_medium=referral&amp;utm_source=unsplash">Massimiliano Morosinotto</a> on <a href="https://unsplash.com/photos/brown-tower-clock-under-cloudy-sy-paINk01G8Xk?utm_content=creditCopyText&amp;utm_medium=referral&amp;utm_source=unsplash">Unsplash</a>.</p>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>How to cite</dt>
<dd>
Tarran, Brian. 2024. “UK government sets out 10 principles for use of generative AI.” Real World Data Science, January 22, 2024. <a href="https://realworlddatascience.net/viewpoints/editors-blog/posts/2024/01/22/gen-ai-framework.html">URL</a>
</dd>
</dl>
</div>
</div>
</div>



 ]]></description>
  <category>AI ethics</category>
  <category>Large language models</category>
  <category>Monitoring</category>
  <category>Public policy</category>
  <category>Risk</category>
  <guid>https://realworlddatascience.net/viewpoints/editors-blog/posts/2024/01/22/gen-ai-framework.html</guid>
  <pubDate>Mon, 22 Jan 2024 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/viewpoints/editors-blog/posts/2024/01/22/images/uk-parliament.png" medium="image" type="image/png" height="105" width="144"/>
</item>
<item>
  <title>When will the cherry trees bloom? Get ready to make and share your predictions!</title>
  <dc:creator>Brian Tarran</dc:creator>
  <link>https://realworlddatascience.net/viewpoints/editors-blog/posts/2024/01/18/cherry-blossom.html</link>
  <description><![CDATA[ 





<p>The <a href="https://competition.statistics.gmu.edu/">2024 International Cherry Blossom Prediction Competition</a> will open for entries on February 1, and Real World Data Science is once again proud to be a sponsor.</p>
<p>Contestants are invited to submit predictions for the date cherry trees will bloom in 2024 at five different locations – Kyoto, Japan; Liestal-Weideli, Switzerland; Vancouver, Canada; and Washington, DC and New York City, USA.</p>
<p>The competition organisers will provide all the publicly available data they can find for the bloom dates of cherry trees in these locations, and contestants will then be challenged to use this data “in combination with any other publicly available data (e.g., climate data) to provide reproducible predictions of the peak bloom date.”</p>
<p>“For this competition, we seek accurate, interpretable predictions that offer strong narratives about the factors that determine when cherry trees bloom and the broader consequences for local and global ecosystems,” say the organisers. “Your task is to predict the peak bloom date for 2024 and to estimate a prediction interval, a lower and upper endpoint of dates during which peak bloom is most probable.”</p>
<p>So that organisers can reproduce the predictions, entrants must submit all data and code in a <a href="https://quarto.org/">Quarto document</a>.</p>
<p>There’s cash and prizes on offer for the best entries, including having your work featured on Real World Data Science. <a href="https://competition.statistics.gmu.edu/">Head on over to the competition website for full details and rules</a>.</p>
<p>And, if you are looking for some inspiration, check out this <a href="https://realworlddatascience.net/ideas/tutorials/posts/2023/04/13/flowers.html">tutorial on the law of the flowering plants</a>, written by Jonathan Auerbach, a co-organiser of the prediction competition.</p>
<p>Good luck to all entrants!</p>
<div class="article-btn">
<p><a href="../../../../../../viewpoints/editors-blog/index.html">Back to Editors’ blog</a></p>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-6">
<dl>
<dt>Copyright and licence</dt>
<dd>
© 2024 Royal Statistical Society
</dd>
</dl>
<p><a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> <img style="height:22px!important;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"></a> This article is licensed under a Creative Commons Attribution 4.0 (CC BY 4.0) <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> International licence</a>. Photo by <a href="https://unsplash.com/@ajny?utm_content=creditCopyText&amp;utm_medium=referral&amp;utm_source=unsplash">AJ</a> on <a href="https://unsplash.com/photos/pink-flowers-McsNra2VRQQ?utm_content=creditCopyText&amp;utm_medium=referral&amp;utm_source=unsplash">Unsplash</a>.</p>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>How to cite</dt>
<dd>
Tarran, Brian. 2024. “When will the cherry trees bloom? Get ready to make and share your predictions!” Real World Data Science, January 18, 2024. <a href="https://realworlddatascience.net/viewpoints/editors-blog/posts/2024/01/18/cherry-blossom.html">URL</a>
</dd>
</dl>
</div>
</div>
</div>



 ]]></description>
  <category>Coding</category>
  <category>Prediction</category>
  <category>Reproducible research</category>
  <category>Statistics</category>
  <guid>https://realworlddatascience.net/viewpoints/editors-blog/posts/2024/01/18/cherry-blossom.html</guid>
  <pubDate>Thu, 18 Jan 2024 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/viewpoints/editors-blog/posts/2024/01/18/images/cherry-blossom.png" medium="image" type="image/png" height="105" width="144"/>
</item>
<item>
  <title>‘We absolutely have to transform and modernise our operation’ – US Census Bureau director Robert Santos</title>
  <dc:creator>Brian Tarran (with Anna Britten)</dc:creator>
  <link>https://realworlddatascience.net/viewpoints/interviews/posts/2024/01/15/census-bureau.html</link>
  <description><![CDATA[ 





<p>A month ago now, Real World Data Science published <a href="https://realworlddatascience.net/viewpoints/interviews/posts/2023/12/15/ian-diamond.html">an interview with UK national statistician Professor Sir Ian Diamond</a>. In the process of preparing the text of that interview for publication, I found myself reflecting on a conversation I’d been part of earlier in the year with Robert Santos, director of the US Census Bureau.</p>
<p>I met Santos in Toronto, Canada, in August – a few hours before his <a href="https://www.youtube.com/watch?v=SmljZLfqIbI">President’s Invited Address at the 2023 Joint Statistical Meetings</a>. The meeting was arranged as a joint interview with Anna Britten, editor of our sister publication <em>Significance</em> magazine, and Santos was joined by Sallie Ann Keller, the Census Bureau’s chief scientist and associate director for research and methodology, and Michael Hawes, senior advisor for data access and privacy.</p>
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/SmljZLfqIbI?si=QEAN6QpbTlwPs20" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<p>The interview with Santos, Keller, and Hawes was published in <a href="https://academic.oup.com/jrssig/article/20/5/40/7296065">the October issue of <em>Significance</em></a>, so you may have already read it. But, following on from our Sir Ian Diamond interview, I thought it worth highlighting some of what Santos <em>et al.</em> had to say, particularly where key themes, challenges, and opportunities seem to resonate across both the US Census Bureau and the UK Office for National Statistics.</p>
<p>I’ve also gone back to the original interview recording to pick out some previously unpublished comments.</p>
<div class="keyline">
<hr>
</div>
<section id="on-the-scale-of-the-challenge-santos-inherited-on-becoming-director-of-the-us-census-bureau-in-january-2022" class="level3">
<h3 class="anchored" data-anchor-id="on-the-scale-of-the-challenge-santos-inherited-on-becoming-director-of-the-us-census-bureau-in-january-2022">On the scale of the challenge Santos inherited on becoming director of the US Census Bureau in January 2022</h3>
<p><strong>Robert Santos:</strong> Certainly it was formidable – although I’m comforted in knowing, after a year and a half, that the career staff [of the Census Bureau] were well positioned to accept this challenge anyway, and were working on it. But the challenge was real. We had the pandemic. We had to, basically, not redesign but scramble and adapt to a really threatening situation where the entirety of the 2020 census was conducted before there was a vaccine, and when people didn’t know the nature of the beast. A huge chunk of this operation was conducted when society was shut down. And not only did the Census Bureau need to rethink, nimbly and quickly, how to do its operation, but so did all of the different community partners – which was really enlightening because we realised that, at the end of the day, we could not have completed this job alone. And now our position is that we cannot complete our mission without the external community. They’re the extra folks we need in order to understand better what the needs are, and therefore improve our methods and data and the relevance of what we’re doing.</p>
<p>So, we see our role now as having a continuous engagement with the entire country at all levels – be it elected officials, universities and professors and the research community, or data users like policy users and policy researchers, or local community organisations that are doing neighbourhood stuff. And so we’re actively working between censuses to engage them and show them the value of the data that we’ve collected – not just decennial [census data], but also our flagship American Community Survey and our Current Population Study and all the 130 other business, economic as well as household types of studies that we’re doing.</p>
</section>
<section id="on-the-need-to-transform-census-bureau-operations" class="level3">
<h3 class="anchored" data-anchor-id="on-the-need-to-transform-census-bureau-operations">On the need to transform Census Bureau operations</h3>
<p><strong>Robert Santos:</strong> We absolutely have to transform and modernise our operation, from what was historically this transactional survey type of data collection – where we go to somebody that’s randomly sampled and we say, “Please give me your information” – and realise the value of taking that information, blending it with existing data, administrative data, even third-party private sector data, into a huge data pool and linking it together, and that will create new data products that will serve the public in ways that we never imagined before. And we already have some great examples of that. So, that transformation process is an incredible priority that we have to do, regardless of what our funding situation is. If we don’t do that, we’re not going to be able to serve the public in the way that we need to.</p>
</section>
<section id="on-laying-the-groundwork-for-the-2030-census-and-an-increased-use-of-administrative-data" class="level3">
<h3 class="anchored" data-anchor-id="on-laying-the-groundwork-for-the-2030-census-and-an-increased-use-of-administrative-data">On laying the groundwork for the 2030 census and an increased use of administrative data</h3>
<p><strong>Robert Santos:</strong> There are a couple of things going on. One is that we’re obliged, because of our values of scientific integrity, objectivity, transparency, and independence, to let folks know what we’re doing in terms of our use of administrative records, and we’ve done that and we will continue doing that. The big lift was really in preparing for the last decennial [census], where we took the use of administrative records to new heights in terms of their utility – not only to help us for some enumeration of households, but, more importantly, to help us predict which households were occupied or not, or to predict which households would benefit from the use of administrative record enumeration versus which ones wouldn’t, or how many times should we knock on the door before we do something else. And now, with that knowledge, we’re looking back at 2020 and saying, what worked? What didn’t? How can we exploit it? And we’re kind of moving the dial to say, “What can we take more advantage of for 2030?”, with full recognition that there were some subpopulations, there’s some segments of society, that we really need to focus and hone in on to make sure we get a good count.</p>
<div class="pullquote-container">
<div class="grid">
<div class="g-col-12 g-col-lg-4">
<div class="quarto-figure quarto-figure-left">
<figure class="figure">
<p><img src="https://realworlddatascience.net/viewpoints/interviews/posts/2024/01/15/images/robert-santos-sq.png" class="img-fluid figure-img" alt="Official photograph of US Census Bureau director Robert Santos, with US flag in background."></p>
<figcaption>Robert Santos, director, US Census Bureau</figcaption>
</figure>
</div>
</div>
<div class="g-col-12 g-col-lg-8 pullquote-grid pullquote">
<p><img src="https://realworlddatascience.net/images/pullquote-purple.png" class="img-fluid" width="50"></p>
<p>We absolutely have to transform and modernise our operation, and realise the value of taking [survey] information, blending it with existing data, administrative data, even third-party private sector data, into a huge data pool and linking it together, and that will create new data products that will serve the public in ways that we never imagined before.</p>
</div>
</div>
</div>
</section>
<section id="on-addressing-public-concerns-about-data-collection-and-data-privacy" class="level3">
<h3 class="anchored" data-anchor-id="on-addressing-public-concerns-about-data-collection-and-data-privacy">On addressing public concerns about data collection and data privacy</h3>
<p><strong>Michael Hawes:</strong> Even though the decennial census is mandatory under law, we rely on voluntary participation. We’re relying on people being willing to respond to their census. In the lead up to each census, we do an extensive survey of what are the attitudes or motivators that will encourage people to respond or to not respond. And one of the recurring themes in that is concerns about privacy, concerns about how their data can be used. So, in order to help encourage people who have those concerns – and this is a sizable percentage of the population – we do need to have strong messaging about how their data are protected, how they can only be used for statistical purposes, and so on. But that has to be in very easy-to-consume sound bites, because a lot of people don’t have a background in statistical disclosure control or even in the legal conceptions about what privacy is. So, that is a real challenge for us. How do we convey the fact that we are taking this very seriously, and that their data are protected, in a way that people can kind of internalise and respond to?</p>
</section>
<section id="on-making-sure-statistics-serve-the-public-good-and-the-role-of-the-census-bureau-in-supporting-data-literacy" class="level3">
<h3 class="anchored" data-anchor-id="on-making-sure-statistics-serve-the-public-good-and-the-role-of-the-census-bureau-in-supporting-data-literacy">On making sure statistics serve the public good, and the role of the Census Bureau in supporting data literacy</h3>
<p><strong>Sallie Ann Keller:</strong> In the US over the last decade, there’s been a really large movement around data for the public good, data science for the public good, and it’s really focused at trying to engage researchers and scholars – and we’re talking about high school students, community college students, undergraduates, graduate students – trying to engage them with civic engagement around data and data insights. That’s happening all over the country – really trying to democratise data and bring it in service of the public good. And I think that’s very exciting.</p>
<p><strong>Michael Hawes:</strong> We have a whole programme called Statistics in Schools which is about taking census data and making it valuable to teachers in the classroom, and allowing students at various levels – from elementary school through high school – to be able to engage with the data and use it to inform their own learning, and to learn about their own communities. That is especially profound in the years around the actual census, because that also serves as a catalyst for getting households to respond. If the kids are using the census data within the classroom, then they go home and say, “Hey, have you filled out your census form?”</p>
<p><strong>Robert Santos:</strong> It’s really important to start young, but then there’s also folks who want to use the data who are adults. So, we have something called the Census Academy, where you can go on to YouTube and get tutorials that show you visually somebody trying to use census data. And the second thing we do is, we really have a strong commitment for creating easier platforms for folks to access and utilise various types of data produced by the Census Bureau. We’re creating these data visualisation tools that bring together the demographic data that we collect, the economic data that we collect, and visualise it down to the census tract level so that local communities can pull that up. And then finally, in terms of the public good, there’s also work that we’re doing with the Federal Emergency Management Agency and the National Oceanic and Atmospheric Administration on our community resilience estimates to create the same type of data visualisations that can show where the potential worrisome geographic spots are.</p>
</section>
<section id="on-the-opportunities-for-bringing-together-census-bureau-data-and-large-language-models" class="level3">
<h3 class="anchored" data-anchor-id="on-the-opportunities-for-bringing-together-census-bureau-data-and-large-language-models">On the opportunities for bringing together Census Bureau data and large language models</h3>
<p><strong>Sallie Ann Keller:</strong> We’re not going to be in the business of building generative AI models. But what we want is the statistics that we put out, the data that we put out, to be picked up by these large language models – to be kind of an input into generative AI. So, we are focused on that in terms of really looking at the structure of how we’re disseminating statistics, and how we’re disseminating things like data tables. How harvestable are they for AI? What are the guardrails we should put around that? We’re looking at and considering issues on data integrity, because when questions are posed, we would like our official statistics to be answering those questions, not our statistics translated through three other parties. Data integrity is really a huge issue, because we don’t want false data and infiltration happening that gets branded as our statistics. I don’t know where we’ll take it all, but I think we’d also like to be incredibly creative here. So, let’s suppose you ask a question and some statistic comes back. Well, why not have that be an experience, so that not just a statistic comes back but maybe a question or two comes back, to try to assess the context that you’re really asking about, so that we can not only have our data coming to you, but we can have the right data coming to you?</p>
<p><strong>Michael Hawes:</strong> Even with some of our more traditional statistical data products, informing users of the limitations and the the uncertainty baked into a lot of those estimates has historically been a challenge – even for some more sophisticated users. The number of people who ignore margins of error on data tables, even in our data products, is not insubstantial. And so, when we get into an AI-driven data dissemination kind of framework, how can we use the flexibility of those platforms to not just provide the answers to the questions people are asking, but also to educate and inform about what the limitations of those answers are?</p>
<div class="article-btn">
<p><a href="../../../../../../viewpoints/interviews/index.html">Find more Interviews</a></p>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-6">
<dl>
<dt>Copyright and licence</dt>
<dd>
© 2023 Royal Statistical Society
</dd>
</dl>
<p><a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> <img style="height:22px!important;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"></a> This article is licensed under a Creative Commons Attribution 4.0 (CC BY 4.0) <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> International licence</a>. Photo of Robert Santos is excluded from this licence; it is a US Government work.</p>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>How to cite</dt>
<dd>
Tarran, Brian. 2023. “‘We absolutely have to transform and modernise our operation’ – US Census Bureau director Robert Santos.” Real World Data Science, January 15, 2024. <a href="https://realworlddatascience.net/viewpoints/interviews/posts/2024/01/15/census-bureau.html">URL</a>
</dd>
</dl>
</div>
</div>
</div>


</section>

 ]]></description>
  <category>Data</category>
  <category>Data privacy</category>
  <category>Data literacy</category>
  <category>Education</category>
  <category>Public engagement</category>
  <category>AI</category>
  <guid>https://realworlddatascience.net/viewpoints/interviews/posts/2024/01/15/census-bureau.html</guid>
  <pubDate>Mon, 15 Jan 2024 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/viewpoints/interviews/posts/2024/01/15/images/robert-santos.png" medium="image" type="image/png" height="105" width="144"/>
</item>
<item>
  <title>Creating a web publication with Quarto: the Real World Data Science origin story</title>
  <dc:creator>Brian Tarran</dc:creator>
  <link>https://realworlddatascience.net/viewpoints/editors-blog/posts/2024/01/03/posit-conf-video.html</link>
  <description><![CDATA[ 





<p>When I attended posit::conf(2023) in Chicago last year, I gave a talk about creating Real World Data Science using Quarto, the open source publishing system developed by Posit. That talk is now online, along with all the other conference talks and keynotes.</p>
<p>My talk, “From Journalist to Coder: Creating a Web Publication with Quarto,” is embedded below. You can also find a selection of talks on <a href="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/09/19/positconf-blog.html">our posit::conf highlights blog</a>. The <a href="https://www.youtube.com/playlist?list=PL9HYL-VRX0oRFZslRGHwHuwea7SvAATHp">full conference playlist is on YouTube</a>.</p>
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/ncDEqHxMWnE?si=A1GmLphRPlmspJCj" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<div class="article-btn">
<p><a href="../../../../../../viewpoints/editors-blog/index.html">Back to Editors’ blog</a></p>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-6">
<dl>
<dt>Copyright and licence</dt>
<dd>
© 2024 Royal Statistical Society
</dd>
</dl>
<p><a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> <img style="height:22px!important;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"></a> This article is licensed under a Creative Commons Attribution 4.0 (CC BY 4.0) <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> International licence</a>.</p>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>How to cite</dt>
<dd>
Tarran, Brian. 2024. “Creating a web publication with Quarto: the Real World Data Science origin story.” Real World Data Science, January 03, 2024. <a href="https://realworlddatascience.net/viewpoints/editors-blog/posts/2024/01/03/posit-conf-video.html">URL</a>
</dd>
</dl>
</div>
</div>
</div>



 ]]></description>
  <category>Coding</category>
  <category>Communication</category>
  <category>Events</category>
  <category>Communities</category>
  <category>Open source</category>
  <guid>https://realworlddatascience.net/viewpoints/editors-blog/posts/2024/01/03/posit-conf-video.html</guid>
  <pubDate>Wed, 03 Jan 2024 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/viewpoints/editors-blog/posts/2024/01/03/images/video-grab.png" medium="image" type="image/png" height="105" width="144"/>
</item>
<item>
  <title>‘I was pretty clear in my mind that we were into a no-going-back situation’</title>
  <dc:creator>Brian Tarran</dc:creator>
  <link>https://realworlddatascience.net/viewpoints/interviews/posts/2023/12/15/ian-diamond.html</link>
  <description><![CDATA[ 





<p>For many people, six months into a new job is about the time you start to feel fully on top of things. You’ve figured out how the organisation works and your place in it. You’ve met all of your colleagues and got to know your way around the office. The job makes sense, everything’s under control. But then, a pandemic hits! What do you do? What is going through your head?</p>
<p>That’s a question we put to Professor Sir Ian Diamond, UK national statistician, who was only six months into the job when Covid-19 upended everything. He said: “My overall sense at all times was one of, ‘What needs to be done? What role can we play in helping to do it? And how do we make sure that we are doing things at pace?’”</p>
<p>There was no “flapping,” he said, but there was a real risk of exhaustion. “I could see pretty quickly that this was going to be a marathon, not a sprint, and while we had a lot to do,” he explained, “the last thing on earth we needed was for people to start burning out.”</p>
<p>Almost four years have passed since that time, but the effects of the pandemic continue to be felt – not least within the Office for National Statistics (ONS), the organisation Sir Ian leads. The Covid experience helped shape his thinking about how the ONS would operate post-pandemic, as he explains in this interview.</p>
<p>When we spoke with Sir Ian, he was six months into a second term as national statistician. By the end of that term, in 2028, what kind of organisation will the ONS be? Read on to find out.</p>
<div class="keyline">
<hr>
</div>
<p><strong>What was your experience of the Covid pandemic, being only six months into the role of national statistician at the time?</strong><br>
It was all-consuming and required an enormous amount of focus. At the beginning of the pandemic, huge amounts of data were flying in every different direction. I felt we were in a data deluge, and we needed to move to [delivering] insight, and really working hard early on to change the agenda towards a situation where we were asking questions – really serious and sensible questions – and working out if we had the data, or how we answered those questions.</p>
<p><strong>On the whole, ONS and the Government Statistical Service were praised for the way they responded to Covid. Did the pandemic experience inform your thinking about how the statistical system should operate once we moved out of that crisis situation?</strong><br>
Yes, in a number of areas. One was that we should not be completely dependent on data collected traditionally. For example, as we went into the pandemic, our ways of calculating inflation were pretty much dependent on people with clipboards going into supermarkets and shops and writing down the prices of things. We already had a project which was starting to think long term of using scanner data. But actually, being able to pivot very quickly to using web scraping to get data was incredibly important. We were also able to use web scraping early on to understand the availability of various goods in what we might call “adaptive purchasing,” or some would call “stockpiling.” And so, identifying that there were new ways of doing things and new data sources, I was pretty clear in my mind that we were into a no-going-back situation.</p>
<p>The second thing we demonstrated was that we could set things up very agilely and very quickly. And one final thing that I thought we absolutely have to continue with all the time is improved communication. You may recall that there were press conferences every day [during the early part of the pandemic], and I think during the start of those press conferences, the graphs and the slides were not always as brilliant as I would want them to be. We embedded a team into the Government Communication Service to work on the slides, and I thought that team did a great job. Improving the communication of statistics was incredibly important, because one of the things to come out of this dreadful pandemic was that people across the country became more data literate, and more demanding of data, and more able to interpret data. That was a good thing which I wanted to make sure we continued.</p>
<p><strong>In terms of embedding the lessons or the learnings of the pandemic into the ONS going forward, how much of it is culture change? How much is about rethinking the systems and the processes?</strong><br>
Was it culture? Was it improved processes? Was it better methods? All of the above. As an organisation, our main role in life is to measure the economy and society, and if you take that as your starting point, and then you ask the question, “In your lifetime, has the economy ever stood still? Has society ever stood still?” In my lifetime, I would argue, no. Therefore, we have to be an organisation which is constantly changing in order to reflect what is going on in the economy and in society. We have to change how we do things, and to ask questions about whether there are better ways of doing things, and that, I think, has been a really important reflection for us over the period both during and since the pandemic. We’ve learned a lot about the use of, for example, reproducible analytic pipelines to really improve the quality of our data at large, to improve the quality of our processes, and to enable us to do things more efficiently and effectively. We’ve learned a lot about new data sources, and we’ve really built on the opportunities and the skills so that you can now link data to be able to address questions that I could only have dreamt of 20 years ago.</p>
<p>And so, I do think we have changed the culture, changed our techniques, and changed our data. But does that mean that we’ve metaphorically thrown away the baby with the bathwater? Absolutely not. What we have now are appropriate methodologies to answer appropriate questions. Do we still use qualitative data? A hundred percent, when it is necessary to do so. Do we still use surveys? Yes, we’ve got some of the best surveys in the world. But equally, we also use digital data, administrative data, and we use very modern techniques of analysing those data. And we use data science in its broadest sense as often as we can.</p>
<p>So, I do think it’s been a major change in what we do, and that will continue. But underlying it all is a total commitment to quality, a total commitment to making sure that we have the best data to answer the question that we are trying to answer, and that all the time we are using the best approach to answer the questions.</p>
<div class="pullquote-container">
<div class="grid">
<div class="g-col-12 g-col-lg-4">
<div class="quarto-figure quarto-figure-left">
<figure class="figure">
<p><img src="https://realworlddatascience.net/viewpoints/interviews/posts/2023/12/15/images/ian-diamond-sq.png" class="img-fluid figure-img" alt="Photo of national statistician Professor Sir Ian Diamond, standing, with microphone, during a talk."></p>
<figcaption>Professor Sir Ian Diamond, UK national statistician. Image supplied, used with permission.</figcaption>
</figure>
</div>
</div>
<div class="g-col-12 g-col-lg-8 pullquote-grid pullquote">
<p><img src="https://realworlddatascience.net/images/pullquote-purple.png" class="img-fluid" width="50"></p>
<p>We have changed the culture, our techniques, and our data. What we have now are appropriate methodologies to answer appropriate questions. Do we still use qualitative data? A hundred percent, when it is necessary to do so. Do we still use surveys? Yes, we’ve got some of the best surveys in the world. But equally, we also use digital data, administrative data, and we use very modern techniques of analysing those data.</p>
</div>
</div>
</div>
<p><strong>As well as changing the culture and the processes within the ONS itself, has some of your work also been about trying to bring the user community with you? When I first started reporting on official statistics 20 years ago, there was a sense that users of the data valued consistency in methodology, because that meant they could go back and look at the time series. But now, with this emphasis on innovation and looking at different ways of producing insight from different sources of data, has there been a tension, if you like, between these two cultures?</strong><br>
That whole question of “we’ve always done it this way” against “we can now do it better” is a super important one. And the length of time series is also important. When we change the ways of doing things, we need to take our user community with us, and we do. At the same time, we also need a very strong narrative (a) about why what we are doing gives us better data, and (b) about what the changes in the time series mean. So, just this year, with regard to prices and inflation, we’ve been able to bring in much better data than we had previously on rail ticket prices by using electronic data. It’s really super exciting. But we didn’t just bring them in and say, “Hey, we’ve got this new way of doing train prices and we’re planning to do the same again next year with used car prices using electronic data!” What we do is we dual run, and we work with our prices advisory committee to ensure that we understand what the implications of this change are, and we understand how to communicate them. But, you’ve got to be measuring the economy in the very, very best way that you can. We should not shy away from improving what we do.</p>
<p><strong>To what extent can the changes in thinking, the changes of approach, be credited to the experimentation and innovation work that is coming out of the ONS Data Science Campus?</strong><br>
The Data Science Campus has been absolutely brilliant. But at the same time, innovation does not only take place in the Data Science Campus. What we’ve built is a culture of innovation right across the organisation. Is that culture of innovation driven by the Data Science Campus? Not so much driven, but certainly helped, and certainly in partnership, and the fact that it is there encourages that culture of innovation.</p>
<p>I do think it is important to recognise, as I say to my colleagues many times, that we are not a blue-sky research institute, we are a national statistics institute, and our job is to produce economic and social statistics. Therefore, we need to be in the business of not just research but research and development – and thinking through how the research on new data that we do will enable improved economic measurement is, for us, incredibly exciting.</p>
<p>I’ll give you an example. We’ve [recently] signed a contract to get telephony data – a few years historically, and then regular data going forward. Now, this is entirely anonymised, but it will enable us to understand much more about, for example, commuting. It means that we will now need to do research on how to use those mobility data, and we’ll be really pushing that forward very quickly. But, at the same time, it’s not just about what can we do that’s interesting in this area; we need to have a very clear vision of what success looks like and the measurements, the economic measurements, that we are going to improve.</p>
<p><strong>How do you see that innovation mindset rolling out across government as a whole?</strong><br>
It’s worth saying two things. Firstly, my job is not only national statistician, I also have an extra couple of hats: one is head of the Government Analysis Function, and one is head of the Government Digital Service. I take those roles very seriously because I do think we need to propagate good practice and innovation right across government departments. It’s no use if it just sits in ONS.</p>
<p>We try really, really hard to have innovation meetings and innovation months, and I try to speak at as many as I’m invited to. And I think it is incredibly important that we really see ourselves – right across the Government Statistical Service, right across the Government Analysis Function – as seeking to propagate good practice.</p>
<p><strong>You mentioned there about the Government Statistical Service and the Government Analysis Function. Is there scope one day for a Data Science Service within government?</strong><br>
The answer is yes. Under both the leadership of Laura Gilbert, who is head of 10 Downing Street’s data science, called 10DS, and Osama Rahman, who heads the Data Science Campus, we recently held a town hall for data scientists right across government to discuss, fundamentally, the question of what data scientists want from the analysis function, but equally [what they want] from a community of data scientists. Part of that is a question as to whether there should be, in government, a data science profession. I stress we haven’t come to the conclusion for that yet, but I would have to say it was a very successful town hall – many, many people attended, we had a really good discussion, and Laura and Osama will be taking forward that discussion over the next couple of months.</p>
<p><strong>You gave a keynote address at the RSS Conference in September, and one of the things you mentioned that I was particularly excited about was “Stat Chat.” I understand this is in the very early stages, and I have a very rudimentary understanding that it might well be a large language model trained on the ONS website and the data resources available, as a way to query the website. Can you tell me a bit more about the project?</strong><br>
We’re in private beta, and so there’s a whole set of agendas there. But we started it as a much better way to enable people to interrogate a pretty complex website with an enormous amount of data on, and to not only get to the datasets but to get to the existing metadata that are attached to them. What we wanted to do was to use open-source models, where the underlying data and the research behind them are made publicly available, so there’s nothing secret about this at the moment, and it’s very early stage. But we see the potential, as we move forward, as being able to really make it much easier for people to interrogate the data that we own and the data that we have published. If we can actually use large language models to enable people to be able to ask questions and then to get an authoritative answer from publicly available data, that seems to me to be a good place to be.</p>
<p><strong>I imagine, though, that when you’re dealing with something like national statistics, you need to be very alive to the danger of <a href="https://realworlddatascience.net/viewpoints/editors-blog/posts/2022/11/23/LLM-content-warning.html#qa">the hallucination problem in large language models</a>; that if you’re querying something, it doesn’t throw up an invented statistic?</strong><br>
I couldn’t agree more. And that’s why we’re in private beta, working very hard to make sure that (a) it is working properly, (b) that it’s got the right security around it, and (c) that it is actually really useful.</p>
<p><strong>The hallucination issue in LLMs leads us onto the topic of trust in information, and obviously the ONS is very keen to ensure that there is trust in official statistics and in the data that is produced. This is a wider problem than anything the ONS can hope to address by itself, but what are the kinds of conversations you’re having internally about distrust in official sources of information?</strong><br>
This is something I say to my colleagues a lot: We should not expect people to trust us. We have to demonstrate to people that we are trustworthy. That’s incredibly important. A lot of it is about transparency. A lot of it is about absolute openness, showing your working, explaining where your data came from, and explaining your motivation for doing something. People say to me, “You might write a really strong methodological piece, but not many people read it.” Yes, but it’s there. And I’m a huge believer in research integrity, and in open data, and enabling data to be available for secondary analysis. And I think the more you are transparent, the more you work with people, the better.</p>
<p>A critical part, also, of demonstrating that you are trustworthy is engaging with the public. And that’s not telling the public; it’s engaging with the public. We put a lot of time into working with the public to say, “Well, what if we did this? What if we did that?” and getting their input. I don’t have any kind of switch to make people feel that we are trustworthy. It’s a continuous process of transparency and openness, where people feel that they have everything they need [to know] about what we do and about our data.</p>
<p>We also are absolutely passionate about explaining uncertainty. Don’t tell me the answer is 62% – the answer has some uncertainty about it, and we need to really think about how we display that uncertainty. And I have to say, I think some of the techniques now to display uncertainty are just so beautiful – unbelievably beautiful – and we need to do that, not in a gimmicky way, but in a way that really explains the uncertainty in any data that we present.</p>
<p><strong>Final question: by the end of your second term as national statistician, where do you think ONS will be as an organisation?</strong><br>
I hope it will be an innovative, agile organisation which is using evermore diverse types of information, but doing so in a transparent and open and rigorous way to improve economic and social statistics which can impact positively on the lives of our fellow citizens.</p>
<div class="article-btn">
<p><a href="../../../../../../viewpoints/interviews/index.html">Find more Interviews</a></p>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-6">
<dl>
<dt>Copyright and licence</dt>
<dd>
© 2023 Royal Statistical Society
</dd>
</dl>
<p><a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> <img style="height:22px!important;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"></a> This article is licensed under a Creative Commons Attribution 4.0 (CC BY 4.0) <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> International licence</a>. Photo of Professor Sir Ian Diamond is not included in this licence.</p>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>How to cite</dt>
<dd>
Tarran, Brian. 2023. “‘I was pretty clear in my mind that we were into a no-going-back situation.’” Real World Data Science, December 15, 2023. <a href="https://realworlddatascience.net/viewpoints/interviews/posts/2023/12/15/ian-diamond.html">URL</a>
</dd>
</dl>
</div>
</div>
</div>



 ]]></description>
  <category>Data</category>
  <category>People</category>
  <category>Innovation</category>
  <category>Data literacy</category>
  <category>Public engagement</category>
  <guid>https://realworlddatascience.net/viewpoints/interviews/posts/2023/12/15/ian-diamond.html</guid>
  <pubDate>Fri, 15 Dec 2023 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/viewpoints/interviews/posts/2023/12/15/images/ian-diamond.png" medium="image" type="image/png" height="105" width="144"/>
</item>
<item>
  <title>Creating Christmas cards with R</title>
  <dc:creator>Nicola Rennie</dc:creator>
  <link>https://realworlddatascience.net/ideas/tutorials/posts/2023/12/12/xmas-cards.html</link>
  <description><![CDATA[ 





<p>When you think about data visualisation in R <span class="citation" data-cites="R-base">(R Core Team 2022)</span>, you’d be forgiven for not jumping straight to thinking about creating Christmas cards. However, the package and functions we often use to create bar charts and line graphs can be repurposed to create festive images. This tutorial provides a step-by-step guide to creating a Christmas card featuring a snowman – entirely in R. Though this seems like just a fun exercise, the functions and techniques you learn in this tutorial can also transfer into more traditional data visualisations created using {ggplot2} <span class="citation" data-cites="ggplot2">(Wickham 2016)</span> in R.</p>
<p>The code in this tutorial relies on the following packages:</p>
<div class="sourceCode" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">library</span>(ggplot2)</span>
<span id="cb1-2"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">library</span>(ggforce)</span>
<span id="cb1-3"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">library</span>(sf)</span></code></pre></div>
<blockquote class="blockquote">
<p>You may also have seen this tutorial presented at the <a href="https://github.com/nrennie/oxford-RUG-christmas-cards">Oxford R User Group November 2023 Meetup</a>.</p>
</blockquote>
<section id="lets-build-a-snowman" class="level2">
<h2 class="anchored" data-anchor-id="lets-build-a-snowman">Let’s build a snowman!</h2>
<p>Before we jump in to writing R code, let’s take a step back and think about what you actually need to build a snowman. If you were given some crayons and a piece of paper, what would you draw?</p>
<p>You might draw two or three circles to make up the head and body. Perhaps some smaller dots for buttons and eyes, and a (rudimentary) hat constructed from some rectangles. Some brown lines create sticks for arms and, of course, a triangle to represent a carrot for a nose. For the background elements of our Christmas card, we also need the night sky (or day if you prefer), a light dusting of snow covering the ground, and a few snowflakes falling from the sky.</p>
<p>Now lines, rectangles, circles, and triangles are all just simple geometric objects. Crucially, they’re all things that we can create with {ggplot2} in R.</p>
</section>
<section id="build-a-snowman-with-r" class="level2">
<h2 class="anchored" data-anchor-id="build-a-snowman-with-r">Build a snowman with R</h2>
<p>Let’s start with the background. The easiest way to start with a blank canvas in {ggplot2} is to create an empty plot using <code>ggplot()</code> with no arguments. We can also remove all theme elements (such as the grey background and grid lines) with <code>theme_void()</code>. To change the background colour to a dark blue for the night sky, we can edit the <code>plot.background</code> element of the theme using <code>element_rect()</code> (since the background is essentially just a big rectangle).</p>
<p>In {ggplot2} <code>fill</code> is the inner colour of shapes whilst <code>colour</code> is the outline colour. You can specify colours in different ways in R: either via the <code>rgb()</code> function, using a character string for a hex colour such as <code>"#000000"</code>, or using a named colour. If you run <code>colors()</code>, you’ll see all the valid named colours you can use. Here, we’ve picked <code>"midnightblue"</code>.</p>
<p>Let’s save this initial plot as an object <code>s1</code> that we’ll keep adding layers to. Saving plots in different stages of styling as objects can help to keep your code more modular.</p>
<div class="sourceCode" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb2-1">s1 <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">ggplot</span>() <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span></span>
<span id="cb2-2">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">theme_void</span>() <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span></span>
<span id="cb2-3">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">theme</span>(</span>
<span id="cb2-4">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">plot.background =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">element_rect</span>(</span>
<span id="cb2-5">      <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">fill =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"midnightblue"</span></span>
<span id="cb2-6">      )</span>
<span id="cb2-7">  )</span>
<span id="cb2-8">s1</span></code></pre></div>
<p>Next we’ll add some snow on the ground. We’ll do this by drawing a white rectangle along the bottom of the plot. There are two different functions that we could use to add a rectangle: <code>geom_rect()</code> or <code>annotate()</code>. The difference between the two is that <code>geom_rect()</code> maps columns of a <code>data.frame</code> to different elements of a plot whereas <code>annotate()</code> can take values passed in as vectors. Most of the {ggplot2} graphs you’ll see will use <code>geom_*()</code> functions. However, if you’re only adding one or two elements to a plot then <code>annotate()</code> might be quicker.</p>
<p>Since we’re only adding one rectangle for the snow, it’s easier to use <code>annotate()</code> with the <code>"rect"</code> geometry. This requires four arguments: the minimum and maximum x and y coordinates of the rectangle – essentially specifying where the corners are. We can also change the colour of the rectangle and its outline using the <code>fill</code> and <code>colour</code> arguments. Here, I’ve used a very light grey instead of white.</p>
<p>If we don’t set the axis limits using <code>xlim()</code> and <code>ylim()</code>, the plot area will resize to fit the area of the snow rectangle. The night sky background will disappear. You can choose any axis limits you wish here – but the unit square will make it easier to find the right coordinates when deciding where to position other elements. Finally, we add <code>coord_fixed()</code> to fix the 1:1 aspect ratio and make sure our grid is actually square with <code>expand = FALSE</code> to remove the additional padding at the sides of the plot.</p>
<div class="sourceCode" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb3-1">s2 <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> s1 <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span></span>
<span id="cb3-2">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">annotate</span>(</span>
<span id="cb3-3">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">geom =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"rect"</span>,</span>
<span id="cb3-4">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">xmin =</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">xmax =</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>,</span>
<span id="cb3-5">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">ymin =</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">ymax =</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.2</span>,</span>
<span id="cb3-6">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">fill =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"grey98"</span>,</span>
<span id="cb3-7">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">colour =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"grey98"</span></span>
<span id="cb3-8">  ) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span></span>
<span id="cb3-9">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">xlim</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span></span>
<span id="cb3-10">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">ylim</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span></span>
<span id="cb3-11">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">coord_fixed</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">expand =</span> <span class="cn" style="color: #8f5902;
background-color: null;
font-style: inherit;">FALSE</span>)</span>
<span id="cb3-12">s2</span></code></pre></div>
<div>

</div>
<div class="quarto-layout-panel" data-layout-ncol="2">
<div class="quarto-layout-row">
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: center;">
<p><img src="https://realworlddatascience.net/ideas/tutorials/posts/2023/12/12/images/s1.png" class="img-fluid" alt="Dark blue square."></p>
</div>
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: center;">
<p><img src="https://realworlddatascience.net/ideas/tutorials/posts/2023/12/12/images/s2.png" class="img-fluid" alt="Dark blue square with off-white rectangle at the bottom."></p>
</div>
</div>
</div>
<p>To finish off the background, we’ll add some falling snowflakes. We first need to decide where on the plot the snowflakes will appear. We’ll be plotting lots of snowflakes, so manually typing out the coordinates of where they’ll be would be very inefficient. Instead, we can use functions to generate the locations randomly. For this we’ll use the uniform distribution. The uniform distribution has two parameters – the lower and upper bounds where any values between the bounds are equally likely. You can generate samples from a uniform distribution in R using the <code>runif()</code> function.</p>
<p>When generating random numbers in R (or any other programming language), it’s important to set a seed. This means that if you give your code to someone else, they’ll get the same random numbers as you. Some people choose to use the date as the random seed and since we’re making Christmas cards, we’ll use Christmas day as the random seed – in <code>yyyymmdd</code> format, of course!</p>
<p>We create a variable <code>n</code> specifying how many snowflakes we’ll create. Creating a variable rather than hard coding the variables makes it easier to vary how many snowflakes we want. Since our plot grid goes between 0 and 1 in both the x and y directions, we generate random numbers between 0 and 1 for both the x and y coordinates and store the values in a <code>data.frame</code> called <code>snowflakes</code>.</p>
<div class="sourceCode" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb4-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">set.seed</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">20231225</span>)</span>
<span id="cb4-2">n <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">100</span></span>
<span id="cb4-3">snowflakes <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">data.frame</span>(</span>
<span id="cb4-4">  <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">x =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">runif</span>(n, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>),</span>
<span id="cb4-5">  <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">y =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">runif</span>(n, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb4-6">)</span></code></pre></div>
<p>Now we can plot the <code>snowflakes</code> data using <code>geom_point()</code> – the same function you’d use for a scatter plot. Since we’re using a <code>geom_*()</code> function, we need to tell {ggplot2} which columns go on the <code>x</code> and <code>y</code> axes inside the <code>aes()</code> function. To plot the snowflakes, we’re going to make using of R’s different point characters. The default when plotting with <code>geom_point()</code> is a small black dot, but we can choose to use a small star (close enough to a snowflake!) by setting <code>pch = 8</code> and changing the <code>colour</code> to <code>"white"</code>.</p>
<div class="sourceCode" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb5-1">s3 <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> s2 <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span></span>
<span id="cb5-2">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">geom_point</span>(</span>
<span id="cb5-3">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">data =</span> snowflakes,</span>
<span id="cb5-4">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">mapping =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">aes</span>(</span>
<span id="cb5-5">      <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">x =</span> x,</span>
<span id="cb5-6">      <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">y =</span> y</span>
<span id="cb5-7">    ),</span>
<span id="cb5-8">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">colour =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"white"</span>,</span>
<span id="cb5-9">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">pch =</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">8</span></span>
<span id="cb5-10">  )</span>
<span id="cb5-11">s3</span></code></pre></div>
<p>Now comes the part where we start rolling up some snowballs! Or, in the case of an R snowman, we draw some circles. Unfortunately, there isn’t a built-in <code>geom_*()</code> function in {ggplot2} for plotting circles. We could use <code>geom_point()</code> here and increase the size of the points but this approach can look a little bit <em>fuzzy</em> when the points are very large. Instead, we’ll turn to a {ggplot2} extension package for some additional <code>geom_*</code> functions - {ggforce} <span class="citation" data-cites="ggforce">(Pedersen 2022)</span>.</p>
<p>The <code>geom_circle()</code> function requires at least three elements mapped to the aesthetics inside <code>aes()</code>: the coordinates of the centre of the circle given by <code>x0</code> and <code>y0</code>, and the radii of each of the circles, <code>r</code>. Instead of creating a separate data frame and passing it into <code>geom_circle()</code>, we can alternatively create the data frame inside the function. The <code>fill</code> and <code>colour</code> arguments work as they do in {ggplot2} and we can set both to <code>"white"</code>.</p>
<div class="sourceCode" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb6-1">s4 <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> s3 <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span></span>
<span id="cb6-2">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">geom_circle</span>(</span>
<span id="cb6-3">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">data =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">data.frame</span>(</span>
<span id="cb6-4">      <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">x0 =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">c</span>(<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.6</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.6</span>),</span>
<span id="cb6-5">      <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">y0 =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">c</span>(<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.3</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span>),</span>
<span id="cb6-6">      <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">r =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">c</span>(<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.15</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.1</span>)</span>
<span id="cb6-7">    ),</span>
<span id="cb6-8">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">mapping =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">aes</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">x0 =</span> x0, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">y0 =</span> y0, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">r =</span> r),</span>
<span id="cb6-9">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">fill =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"white"</span>,</span>
<span id="cb6-10">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">colour =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"white"</span></span>
<span id="cb6-11">  )</span>
<span id="cb6-12">s4</span></code></pre></div>
<div>

</div>
<div class="quarto-layout-panel" data-layout-ncol="2">
<div class="quarto-layout-row">
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: center;">
<p><img src="https://realworlddatascience.net/ideas/tutorials/posts/2023/12/12/images/s3.png" class="img-fluid" alt="Dark blue square with off-white rectangle at the bottom and small random white stars."></p>
</div>
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: center;">
<p><img src="https://realworlddatascience.net/ideas/tutorials/posts/2023/12/12/images/s4.png" class="img-fluid" alt="Dark blue square with off-white rectangle at the bottom and small random white stars, and two white circles slightly off centre."></p>
</div>
</div>
</div>
<p>We can use <code>geom_point()</code> again to add some more points to represent the buttons and the eyes. Here, we’ll manually specify the coordinates of the points. For the buttons we add them in a vertical line in the middle of the snowman’s body circle, and for the eyes we add them in a horizontal line in the middle of the head circle.</p>
<p>Since no two rocks are exactly the same size, we can add some random variation to the size of the points using <code>runif()</code> again. We generate five different sizes between 2 and 4.5. For reference, the default point size is 1.5. Adding <code>scale_size_identity()</code> means that the sizes of the points are actually equally to the sizes we generated from <code>runif()</code> and removes the legend that is automatically added when we add <code>size</code> inside <code>aes()</code>.</p>
<div class="sourceCode" id="cb7" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb7-1">s5 <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> s4 <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span></span>
<span id="cb7-2">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">geom_point</span>(</span>
<span id="cb7-3">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">data =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">data.frame</span>(</span>
<span id="cb7-4">      <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">x =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">c</span>(<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.6</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.6</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.6</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.57</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.62</span>),</span>
<span id="cb7-5">      <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">y =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">c</span>(<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.25</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.3</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.35</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.52</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.52</span>),</span>
<span id="cb7-6">      <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">size =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">runif</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">4.5</span>)</span>
<span id="cb7-7">    ),</span>
<span id="cb7-8">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">mapping =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">aes</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">x =</span> x, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">y =</span> y, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">size =</span> size)</span>
<span id="cb7-9">  ) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span></span>
<span id="cb7-10">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">scale_size_identity</span>()</span>
<span id="cb7-11">s5</span></code></pre></div>
<p>To add sticks for arms, we can make use of <code>geom_segment()</code> to draw some lines. We could also use <code>geom_path()</code> but that is designed to connect points across multiple cases, whereas <code>geom_segment()</code> draws a single line per row of data – and we don’t want to join the snowman’s arms together!</p>
<p>To use <code>geom_segment()</code> we need to create a data frame containing the x and y coordinates for the start and end of each line, and then pass this into the aesthetic mapping with <code>aes()</code>. We can control the colour and width of the lines using the <code>colour</code> and <code>linewidth</code> arguments. Setting the <code>lineend</code> argument to <code>"round"</code> means that the ends of the lines will be rounded rather than the default straight edge.</p>
<div class="sourceCode" id="cb8" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb8-1">s6 <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> s5 <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> </span>
<span id="cb8-2">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">geom_segment</span>(</span>
<span id="cb8-3">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">data =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">data.frame</span>(</span>
<span id="cb8-4">      <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">x =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">c</span>(<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.46</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.7</span>),</span>
<span id="cb8-5">      <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">xend =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">c</span>(<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.33</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.85</span>),</span>
<span id="cb8-6">      <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">y =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">c</span>(<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.3</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.3</span>),</span>
<span id="cb8-7">      <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">yend =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">c</span>(<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.4</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.4</span>)</span>
<span id="cb8-8">    ),</span>
<span id="cb8-9">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">mapping =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">aes</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">x =</span> x, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">y =</span> y, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">xend =</span> xend, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">yend =</span> yend),</span>
<span id="cb8-10">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">colour =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"chocolate4"</span>,</span>
<span id="cb8-11">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">lineend =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"round"</span>,</span>
<span id="cb8-12">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">linewidth =</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span></span>
<span id="cb8-13">  )</span>
<span id="cb8-14">s6</span></code></pre></div>
<div>

</div>
<div class="quarto-layout-panel" data-layout-ncol="2">
<div class="quarto-layout-row">
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: center;">
<p><img src="https://realworlddatascience.net/ideas/tutorials/posts/2023/12/12/images/s5.png" class="img-fluid" alt="Dark blue square with off-white rectangle at the bottom and small random white stars, and two white circles slightly off centre. Five black dots denote two eyes and three buttons on a snowman."></p>
</div>
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: center;">
<p><img src="https://realworlddatascience.net/ideas/tutorials/posts/2023/12/12/images/s6.png" class="img-fluid" alt="Dark blue square with off-white rectangle at the bottom and small random white stars, and two white circles slightly off centre. Five black dots denote two eyes and three buttons on a snowman. Two brown lines look like arms."></p>
</div>
</div>
</div>
<p>We’ll now add a (very simple) hat to our snowman, fashioned out of two rectangles. We can add the rectangles as we did before using the <code>annotate()</code> function and specifying the locations of the corners of the rectangles. We start with a shorter wider rectangle for the brim of the hat, and then a taller, narrower rectangle for the crown of the hat. Since we’ll colour them both <code>"brown"</code>, it doesn’t matter if they overlap a little bit.</p>
<p>This <em>might</em> be one of the situations we should have used <code>geom_rect()</code> instead of <code>annotate()</code> but it might take a lot of trial and error to position the hat exactly where we want it, and this seemed a little easier with <code>annotate()</code>.</p>
<div class="sourceCode" id="cb9" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb9-1">s7 <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> s6 <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span></span>
<span id="cb9-2">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">annotate</span>(</span>
<span id="cb9-3">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">geom =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"rect"</span>,</span>
<span id="cb9-4">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">xmin =</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.46</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">xmax =</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.74</span>,</span>
<span id="cb9-5">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">ymin =</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.55</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">ymax =</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.60</span>,</span>
<span id="cb9-6">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">fill =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"brown"</span></span>
<span id="cb9-7">  ) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span></span>
<span id="cb9-8">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">annotate</span>(</span>
<span id="cb9-9">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">geom =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"rect"</span>,</span>
<span id="cb9-10">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">xmin =</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.50</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">xmax =</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.70</span>,</span>
<span id="cb9-11">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">ymin =</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.56</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">ymax =</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.73</span>,</span>
<span id="cb9-12">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">fill =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"brown"</span></span>
<span id="cb9-13">  )</span>
<span id="cb9-14">s7</span></code></pre></div>
<p>Now we can move on to the final component of building a snowman – the carrot for his nose! We’re going to use a triangle for the nose. Unfortunately, there are no built-in triangle geoms in {ggplot2} so we’ll have to make our own. There are different ways to do this, but here we’re going to make use of the {sf} package <span class="citation" data-cites="sf">(Pebesma 2018)</span>. The {sf} package (short for <em>simple features</em>) is designed for working with spatial data. Although we’re not working with maps, we can still use {sf} to make shapes – including polygons.</p>
<p>We start by constructing a matrix with two columns – one for x coordinates and one for y. The x coordinates start in the middle of the head and go slightly to the right for the triangle point. The y coordinates take a little bit more trial and error to get right. Note that although triangles only have three corners, we have four rows of points. The last row must be the same as the first to make the polygon <em>closed</em>. The matrix is then converted into a spatial object using the <code>st_polygon()</code> function, and we can check how it looks using <code>plot()</code>.</p>
<div class="sourceCode" id="cb10" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb10-1">nose_pts <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">matrix</span>(</span>
<span id="cb10-2">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">c</span>(</span>
<span id="cb10-3">    <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.6</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span>,</span>
<span id="cb10-4">    <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.65</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.48</span>,</span>
<span id="cb10-5">    <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.6</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.46</span>,</span>
<span id="cb10-6">    <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.6</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span></span>
<span id="cb10-7">  ),</span>
<span id="cb10-8">  <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">ncol =</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>,</span>
<span id="cb10-9">  <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">byrow =</span> <span class="cn" style="color: #8f5902;
background-color: null;
font-style: inherit;">TRUE</span></span>
<span id="cb10-10">)</span>
<span id="cb10-11">nose <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">st_polygon</span>(<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">list</span>(nose_pts))</span>
<span id="cb10-12"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">plot</span>(nose)</span></code></pre></div>
<div>

</div>
<div class="quarto-layout-panel" data-layout-ncol="2">
<div class="quarto-layout-row">
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: center;">
<p><img src="https://realworlddatascience.net/ideas/tutorials/posts/2023/12/12/images/s7.png" class="img-fluid" alt="Dark blue square with off-white rectangle at the bottom and small random white stars, and two white circles slightly off centre. Five black dots denote two eyes and three buttons on a snowman. Two brown lines look like arms. Two red rectangles form a hat."></p>
</div>
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: center;">
<p><img src="https://realworlddatascience.net/ideas/tutorials/posts/2023/12/12/images/nose.png" class="img-fluid" alt="Outline of a triangle pointing to the right against a white background."></p>
</div>
</div>
</div>
<p>We can plot <code>sf</code> objects with {ggplot2} using <code>geom_sf()</code>. <code>geom_sf()</code> is a slightly special <code>geom</code> since we don’t need to specify an aesthetic mapping for the <code>x</code> and <code>y</code> axes – they are determined automatically from the <code>sf</code> object along with which type of geometry to draw. If your <code>sf</code> object has points, points will be drawn. If it has country shapes, polygons will be drawn. Like other <code>geom_*()</code> functions, we can change the <code>colour</code> and <code>fill</code> arguments to a different colour – in this case <code>"orange"</code> to represent a carrot!</p>
<p>You should see a <code>Coordinate system already present. Adding new coordinate system, which will replace the existing one.</code> message when you run the following code. The is because <code>geom_sf</code> forces it’s own coordinate system on the plot overriding our previous code specifying <code>coord_fixed()</code>. If you run it without the <code>coord_sf(expand = FALSE)</code>, the extra space around the plot will reappear. We can remove it again with <code>expand = FALSE</code>.</p>
<div class="sourceCode" id="cb11" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb11-1">s8 <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> s7 <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span></span>
<span id="cb11-2">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">geom_sf</span>(</span>
<span id="cb11-3">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">data =</span> nose,</span>
<span id="cb11-4">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">fill =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"orange"</span>,</span>
<span id="cb11-5">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">colour =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"orange"</span></span>
<span id="cb11-6">  ) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span></span>
<span id="cb11-7">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">coord_sf</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">expand =</span> <span class="cn" style="color: #8f5902;
background-color: null;
font-style: inherit;">FALSE</span>)</span>
<span id="cb11-8">s8</span></code></pre></div>
<blockquote class="blockquote">
<p>You <em>could</em> skip the <code>sf</code> part of this completely and pass the coordinates directly into <code>geom_polygon()</code> instead. However, I’ve often found it quicker and easier to tinker with polygon shapes using <code>sf</code>.</p>
</blockquote>
<p>A key part of any Christmas card is the message wishing recipients a Merry Christmas! We can add text to our plot using the <code>annotate()</code> function and the <code>"text"</code> geometry (you could instead use <code>geom_text()</code> if you prefer). When adding text, we require at least three arguments: the <code>x</code> and <code>y</code> coordinates of where the text should be added, and the <code>label</code> denoting what text should appear. We can supply additional arguments to <code>annotate()</code> to style the text, such as: <code>colour</code> (which changes the colour of the text); <code>family</code> (to define which font to use); <code>fontface</code> (which determines if the font is bold or italic, for example); and <code>size</code> (which changes the size of the text). The <code>"mono"</code> option for <code>family</code> tells {ggplot2} to use the default system monospace font.</p>
<div class="sourceCode" id="cb12" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb12-1">s9 <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> s8 <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span></span>
<span id="cb12-2">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">annotate</span>(</span>
<span id="cb12-3">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">geom =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"text"</span>,</span>
<span id="cb12-4">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">x =</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">y =</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.07</span>,</span>
<span id="cb12-5">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">label =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Merry Christmas"</span>,</span>
<span id="cb12-6">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">colour =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"red3"</span>,</span>
<span id="cb12-7">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">family =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"mono"</span>,</span>
<span id="cb12-8">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">fontface =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"bold"</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">size =</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">7</span></span>
<span id="cb12-9">  )</span>
<span id="cb12-10">s9</span></code></pre></div>
<div>

</div>
<div class="quarto-layout-panel" data-layout-ncol="2">
<div class="quarto-layout-row">
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: center;">
<p><img src="https://realworlddatascience.net/ideas/tutorials/posts/2023/12/12/images/s8.png" class="img-fluid" alt="Dark blue square with off-white rectangle at the bottom and small random white stars, and two white circles slightly off centre. Five black dots denote two eyes and three buttons on a snowman. Two brown lines look like arms. Two red rectangles form a hat. Orange triangle as a nose."></p>
</div>
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: center;">
<p><img src="https://realworlddatascience.net/ideas/tutorials/posts/2023/12/12/images/s9.png" class="img-fluid" alt="Dark blue square with off-white rectangle at the bottom and small random white stars, and two white circles slightly off centre. Five black dots denote two eyes and three buttons on a snowman. Two brown lines look like arms. Two red rectangles form a hat. Orange triangle as a nose, with text reading Merry Christmas at the bottom."></p>
</div>
</div>
</div>
</section>
<section id="sending-christmas-cards-in-r" class="level2">
<h2 class="anchored" data-anchor-id="sending-christmas-cards-in-r">Sending Christmas cards in R</h2>
<p>Now that we’ve finished creating our Christmas card, we need to think about how to send it. You could save it as an image file using <code>ggsave()</code>, print it out, and send it in the post. Or you could also use R to send it!</p>
<p>There are many different R packages for sending emails from R. If you create a database of email addresses and names, you could personalise the message on the Christmas card and then send it automatically as an email from R. If you want to automate the process of sending physical cards from R, you might be interested in the <a href="https://github.com/jnolis">{ggirl} package</a> from Jacqueline Nolis <span class="citation" data-cites="ggirl">(Nolis 2023)</span>. {ggirl} allows you to send postcards with a <code>ggplot</code> object printed on the front. {ggirl} is also an incredible example of <a href="https://jnolis.com/blog/introducing_ggirl/">an eCommerce platform built with R</a>! Note that {ggirl} can currently only send physical items to addresses in the United States.</p>
</section>
<section id="other-christmas-r-packages" class="level2">
<h2 class="anchored" data-anchor-id="other-christmas-r-packages">Other Christmas R packages</h2>
<p>If you’re curious about making Christmas cards with R but you don’t have the time to make them from scratch, you’ll likely find the <code>christmas</code> R package <span class="citation" data-cites="christmas">(Barrera-Gomez 2022)</span> helpful. This package from Jose Barrera-Gomez can generate lots of different Christmas cards, many of them animated and available in different languages (English, Catalan and Spanish).</p>
<p>Emil Hvitfeldt has also created a <a href="https://quarto.org/">Quarto</a> <a href="https://github.com/EmilHvitfeldt/quarto-snow">extension that gives the effect of falling snowflakes</a> on HTML outputs – including revealjs slides which is perfect for festive presentations!</p>
<p>Have you made your own Christmas cards with R? We’d love to see your designs!</p>
<div class="callout callout-style-simple callout-note" style="margin-top: 2.25rem;">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-body-container">
<p>Inspired by Nicola’s tutorial, Real World Data Science has indeed made its own Christmas card design. <a href="../../../../../../viewpoints/editors-blog/posts/2023/12/12/rwds-xmas-card.html">Check out our attempt over at the Editors’ Blog</a>!</p>
</div>
</div>
</div>
<div class="article-btn">
<p><a href="../../../../../../ideas/tutorials/index.html">Explore more Tutorials</a></p>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-12">
<dl>
<dt>About the author</dt>
<dd>
<strong>Nicola Rennie</strong> is a lecturer in health data science in the Centre for Health Informatics, Computing, and Statistics (CHICAS) within Lancaster Medical School at Lancaster University. She’s an R enthusiast, data visualisation aficionado, and generative artist, among other things. Her personal website is hosted at <a href="https://nrennie.github.io/">nrennie.rbind.io</a>, and she is a co-author of the <a href="https://royal-statistical-society.github.io/datavisguide/">Royal Statistical Society’s Best Practices for Data Visualisation</a>.
</dd>
</dl>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>Copyright and licence</dt>
<dd>
© 2023 Nicola Rennie
</dd>
</dl>
<p><a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> <img style="height:22px!important;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"></a> This article is licensed under a Creative Commons Attribution 4.0 (CC BY 4.0) <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> International licence</a>.</p>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>How to cite</dt>
<dd>
Rennie, Nicola. 2023. “Creating Christmas cards with R.” Real World Data Science, December 12, 2023. <a href="https://doi.org/10.5281/zenodo.10530635"><img src="https://zenodo.org/badge/DOI/10.5281/zenodo.10530635.svg" class="img-fluid" style="vertical-align:text-bottom;" alt="DOI"></a>
</dd>
</dl>
</div>
</div>
</div>



</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0">
<div id="ref-christmas" class="csl-entry">
Barrera-Gomez, Jose. 2022. <em>Christmas: Generation of Different Animated Christmas Cards</em>. <a href="https://CRAN.R-project.org/package=christmas">https://CRAN.R-project.org/package=christmas</a>.
</div>
<div id="ref-ggirl" class="csl-entry">
Nolis, Jacqueline. 2023. <em>Ggirl: Ggplot2 Art in Real Life</em>. <a href="https://github.com/jnolis/ggirl">https://github.com/jnolis/ggirl</a>.
</div>
<div id="ref-sf" class="csl-entry">
Pebesma, Edzer. 2018. <span>“<span class="nocase">Simple Features for R: Standardized Support for Spatial Vector Data</span>.”</span> <em><span>The R Journal</span></em> 10 (1): 439–46. <a href="https://doi.org/10.32614/RJ-2018-009">https://doi.org/10.32614/RJ-2018-009</a>.
</div>
<div id="ref-ggforce" class="csl-entry">
Pedersen, Thomas Lin. 2022. <em>Ggforce: Accelerating ’Ggplot2’</em>. <a href="https://CRAN.R-project.org/package=ggforce">https://CRAN.R-project.org/package=ggforce</a>.
</div>
<div id="ref-R-base" class="csl-entry">
R Core Team. 2022. <em>R: A Language and Environment for Statistical Computing</em>. Vienna, Austria: R Foundation for Statistical Computing. <a href="https://www.R-project.org/">https://www.R-project.org/</a>.
</div>
<div id="ref-ggplot2" class="csl-entry">
Wickham, Hadley. 2016. <em>Ggplot2: Elegant Graphics for Data Analysis</em>. Springer-Verlag New York. <a href="https://ggplot2.tidyverse.org">https://ggplot2.tidyverse.org</a>.
</div>
</div></section></div> ]]></description>
  <category>R</category>
  <category>Data visualisation</category>
  <guid>https://realworlddatascience.net/ideas/tutorials/posts/2023/12/12/xmas-cards.html</guid>
  <pubDate>Tue, 12 Dec 2023 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/ideas/tutorials/posts/2023/12/12/images/xmas-card.png" medium="image" type="image/png" height="105" width="144"/>
</item>
</channel>
</rss>
