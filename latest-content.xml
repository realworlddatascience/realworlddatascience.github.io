<?xml version="1.0" encoding="UTF-8"?>
<rss  xmlns:atom="http://www.w3.org/2005/Atom" 
      xmlns:media="http://search.yahoo.com/mrss/" 
      xmlns:content="http://purl.org/rss/1.0/modules/content/" 
      xmlns:dc="http://purl.org/dc/elements/1.1/" 
      version="2.0">
<channel>
<title>Real World Data Science</title>
<link>https://realworlddatascience.net/latest-content.html</link>
<atom:link href="https://realworlddatascience.net/latest-content.xml" rel="self" type="application/rss+xml"/>
<description></description>
<image>
<url>https://realworlddatascience.net/images/rwds-logo-150px.png</url>
<title>Real World Data Science</title>
<link>https://realworlddatascience.net/latest-content.html</link>
<height>83</height>
<width>144</width>
</image>
<generator>quarto-1.3.353</generator>
<lastBuildDate>Wed, 24 May 2023 00:00:00 GMT</lastBuildDate>
<item>
  <title>‘For me, data science is about bridging the gap between business requirements and the data that businesses have’</title>
  <dc:creator>Brian Tarran</dc:creator>
  <link>https://realworlddatascience.net/careers/career-profiles/posts/2023/05/24/jasmine-holdsworth.html</link>
  <description><![CDATA[ 




<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/Plga2ldbcTE" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<section id="transcript" class="level2">
<h2 class="anchored" data-anchor-id="transcript">Transcript</h2>
<div class="callout callout-style-simple callout-warning" style="margin-top: 0.75rem;">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-body-container">
<p>This transcript has been produced using <a href="https://otter.ai/">speech-to-text transcription software</a>. It has been only lightly edited to correct mistranscriptions and remove some repetitions.</p>
</div>
</div>
</div>
<section id="what-does-your-job-at-expedia-involve" class="level3">
<h3 class="anchored" data-anchor-id="what-does-your-job-at-expedia-involve">What does your job at Expedia involve?</h3>
<p>I would probably call myself more on the analyst side. So, while my day-to-day job doesn’t necessarily involve AI, ML and productionalising models, it’s more taking business goals or requirements and taking the data and essentially bridging the gap between the two. I am on the incrementality analytics team. So, what that means is I measure the short-term returns from our marketing efforts that we have. And I do that via geotesting. So, I’m essentially working in the geotesting part of the company if you like. And before that I worked in the customer data section. So, essentially looking at customer data and working with that.</p>
</section>
<section id="how-long-have-you-been-working-in-data-science" class="level3">
<h3 class="anchored" data-anchor-id="how-long-have-you-been-working-in-data-science">How long have you been working in data science?</h3>
<p>More in an analyst role, but probably about seven years now, I began in Stack Overflow just as a data analyst, and then worked at DAZN – which is like a Netflix for sports – as a data analyst, and then joined here as a senior analyst, and then moved into data science in the last couple of years. I would, I would credit Stack Overflow as the place where my career kind of was birthed, if you like. I started there as an account manager, so with hardly any technical background at all required, and then moved into a role that was essentially looking after, or reporting the metrics of advertising campaigns for companies that would advertise on Stack Overflow. So that required a little technical knowledge, not much – a few pivot tables and things like that. But then the longer I stayed there, the further my career developed, and they had, at the time – probably still do – some fantastically smart people that work there, as you can imagine. I was sponsored to do a General Assembly data analytics course, which was focused around Excel, dashboarding, and SQL and essentially fell in love with data analysis. It was the most technical subject matter that I had experienced to that point, and I found a real natural affinity to it, particularly SQL. And then [I] moved into more of a data analyst role within Stack Overflow, so – as you can probably imagine – an absolute sea of proprietary data that needed analysing, and started learning R, or rather being taught R within Stack Overflow, and loved it. I think I was there for three-and-a-half years, and then moved into a data analyst role at DAZN. At this point, I did a data science General Assembly bootcamp course, and fell in love with that. And then I decided that I really loved General Assembly as a concept; I actually started a second job teaching there, so the courses that I had previously taken I was now teaching, first as a teaching assistant, and then as a lead instructor, which was one of the most, yeah, one of the most amazing experiences I’ve had actually, I learned a lot from that. And then I got a job as a senior analyst within Expedia Group, which is where I am now, and then moved into a data science role, which is what I’m doing currently. So, I actually left school at 16, and had to go into a full-time employment. And the General Assembly education that I took a part in was my first of that type. So, when I realised that data science was absolutely something that I really wanted to dedicate the rest of my life to, I decided to take on a part-time data science bachelor’s degree, which I am now about a year away from finishing. Because I’m doing it part time it takes a bit longer. But yeah, so I will have my data science bachelor’s completed, hopefully, by 2024.</p>
</section>
<section id="who-or-what-inspired-you-to-work-in-data-science" class="level3">
<h3 class="anchored" data-anchor-id="who-or-what-inspired-you-to-work-in-data-science">Who or what inspired you to work in data science?</h3>
<p>There were two big inspirations into getting into data sciences. So, they were actually the data scientists that I worked with at Stack Overflow. They were the first two data scientists, I believe, that Stack Overflow had ever hired. I worked very closely with them as an analyst and one of them was, had previously worked – I don’t know if it was officially an astrophysicist – but had studied black holes, and I remember thinking that was just amazing. And the other was, was very famous within the field. And they spent a lot of time giving me one-on-one training on R and SQL and basic analysis, and I was so inspired by these two individuals that I, it was also a career path that I didn’t really know existed.</p>
<div class="pullquote-container">
<div class="grid">
<div class="g-col-12 g-col-lg-4">
<div class="quarto-figure quarto-figure-left">
<figure class="figure">
<p><img src="https://realworlddatascience.net/careers/career-profiles/posts/2023/05/24/images/jh-photo.png" class="img-fluid figure-img" alt="Portrait photo of Jasmine Holdsworth"></p>
<figcaption class="figure-caption">Jasmine Holdsworth</figcaption>
</figure>
</div>
</div>
<div class="g-col-12 g-col-lg-8 pullquote-grid pullquote">
<p><img src="https://realworlddatascience.net/images/pullquote-purple.png" class="img-fluid" width="50"></p>
<p>What was impressed upon me in that first year [in data science] was the importance of statistics and interpreting statistics in a way that’s honest.</p>
</div>
</div>
</div>
</section>
<section id="what-does-data-science-mean-to-you" class="level3">
<h3 class="anchored" data-anchor-id="what-does-data-science-mean-to-you">What does data science mean to you?</h3>
<p>For me, it is bridging the gap between the business requirements and the data that businesses have. So, you’ll have business goals, requirements that kind of come down the line and there’s a lot of data that’s being collected, and, essentially, you have to try and be the bridge between the two. So, not just doing very complicated analyses, with very sophisticated models – at least not in my role – it’s about being able to create analysis that’s interpretable, that you can present to non-technical stakeholders that they’re going to understand to a degree. So, I do know that in different roles in different companies, it will be slightly different. But yeah, for me, it’s about making data, yeah, interpretable, to the non-technical stakeholders to enable them to do their job better.</p>
</section>
<section id="what-is-your-most-important-skill-as-a-data-scientist" class="level3">
<h3 class="anchored" data-anchor-id="what-is-your-most-important-skill-as-a-data-scientist">What is your most important skill as a data scientist?</h3>
<p>I like to think that there is one responsibility around how statistics are interpreted. So, just making sure that when you’re giving someone a statistic, that they understand what it can be used for, what it can’t be used for, and that it doesn’t kind of get halfway around the company before, you know, without any danger of it being misinterpreted. And I do think that the other is just being a translator. So, as well as teaching with General Assembly, I teach people within my company, things like SQL, R, and some basic data analysis. And I feel like it’s taking what is quite a technical, complicated subject and almost translating it into, if you like, English, so that people can kind of get some sense of what something may mean, without necessarily having to have the degree to back it up.</p>
</section>
<section id="what-hurdles-did-you-face-in-becoming-a-data-scientist" class="level3">
<h3 class="anchored" data-anchor-id="what-hurdles-did-you-face-in-becoming-a-data-scientist">What hurdles did you face in becoming a data scientist?</h3>
<p>Towards the beginning of my career to say – 5, 6 years ago – it was quite hard to get interviews. It was never hard to get interviews with technical people within companies, because you can– a technical person can see whether or not you know what you’re talking about. But recruiters don’t, and if someone is a recruiter for a technical role, their proxy for whether or not you can do the role is what’s your level of education, which is completely understandable and that’s what education is for. But it did mean that sometimes I applied for roles that were well below my, my level, and if I did so through a recruiter, then I wouldn’t hear anything back. But if I spoke to a technical person within that company, then it would be fine.</p>
</section>
<section id="how-did-you-overcome-those-hurdles" class="level3">
<h3 class="anchored" data-anchor-id="how-did-you-overcome-those-hurdles">How did you overcome those hurdles?</h3>
<p>Actually, I guess the story of how I joined Expedia is quite relevant in that way. So, I presented some, just some fun analysis that I did at an R-Ladies meetup, and I was already talking to a recruiter within Expedia Group and I said to them, oh, well, I happen to be visiting your offices to present at this meetup, so maybe I can meet you there. And they actually sent the manager of the team that they wanted me to join. So, this manager attended the meetup, watched me present, and then they ended up hiring me, which is really great. But I do really think that that was a result of being able to see me on stage, talking about stuff that I had done, showing code that I had written, and it kind of bypassed a few steps. So yeah, I would definitely say meetups and connections are very helpful to overcome that.</p>
</section>
<section id="the-most-important-lesson-from-your-first-year-in-data-science" class="level3">
<h3 class="anchored" data-anchor-id="the-most-important-lesson-from-your-first-year-in-data-science">The most important lesson from your first year in data science?</h3>
<p>I think that what was impressed upon me in that first year – and what really drove me to do the bootcamp courses and then, ultimately, the degree – above everything, actually, was the importance of statistics and interpreting statistics in a way that’s honest. So, I feel like– I feel like with coding, that comes quite naturally to me, and writing SQL queries, R, that was all kind of fine. That didn’t require a lot. But I really, I had an amazing manager who taught me a lot about, essentially, if you’re going to go and speak to this company about the campaign that they’ve run on our website, then you need to impress that X doesn’t necessarily mean Y, it just gives evidence to, or alludes to, and essentially just making sure that how you’re communicating things is as accurate as possible.</p>
</section>
<section id="any-mistakes-or-regrets-in-your-career-so-far" class="level3">
<h3 class="anchored" data-anchor-id="any-mistakes-or-regrets-in-your-career-so-far">Any mistakes or regrets in your career so far?</h3>
<p>When I look back on my career, I think the things that have really stayed with me that I’ve really learned from, mistakes wise, are around small little mistakes around how you interpret data. Maybe it was a, like, years ago, summing the wrong cell in Excel but not checking two or three or four times before that goes out. I’m now quite– I over-check everything. I think that the most important part of our job, as well as being the translation, is being the correct translation. You need to be reliable. People need to know that if you put out analysis that they can trust you. So, I would say I regret every small, tiny little data error that I ever made, which I can’t even recall right now, but I know have kind of cumulated enough that it has made me a very fastidious checker, I suppose.</p>
</section>
<section id="how-do-you-see-your-role-in-data-science-evolving" class="level3">
<h3 class="anchored" data-anchor-id="how-do-you-see-your-role-in-data-science-evolving">How do you see your role in data science evolving?</h3>
<p>I definitely see myself being an individual contributor in a consumer-facing company, just because that is basically what I’ve been doing up to this point. I don’t really have any desire to get into people management. I very much love being stuck in a room with my laptop, solving problems. Above all else, it still makes me happy. However, I do also love knowledge sharing – I love teaching, whether it’s with General Assembly, or whether it’s within the company that I work now. And I would like to kind of balance those two goals moving forward. So, keeping my role within my company as like an individual contributor and actually being like the front face for the, for the analysis that’s happening rather than kind of managing it. But also making sure that I carve out time to upskill others, because data science as a field, I mean, as you all know, is growing so much and people are coming in from different backgrounds. And I’m lucky enough to be able to kind of speak to a few people like that and do some very casual mentorship. And it makes me happy to see, so I hope that as my career develops, I will see more people maybe with backgrounds a little bit more like mine, come through and bring some diversity to the sector.</p>
</section>
<section id="new-developments-or-ideas-you-are-most-excited-about" class="level3">
<h3 class="anchored" data-anchor-id="new-developments-or-ideas-you-are-most-excited-about">New developments or ideas you are most excited about?</h3>
<p>It would be remiss of me to not mention like ChatGPT or generative AI, etc. But honestly, I am more interested in – or vaguely interested, I should say – in wearable technology. So, I’ve read a few very, very interesting papers and articles that talk about the development of wearable technology, not just your kind of watches, but potentially clothing, etc., that can be used for people with specific health problems to really help pinpoint, like, inflection points in time when something might happen. For example, a heart attack is about to happen, or is imminent, or is happening. So I actually feel like at the moment, this is perhaps going slightly under the radar, compared with more, you know, sexy developments like chatbots and things. But I’m very interested to see in the next one to two decades how ubiquitous wearables will be, and how closely entwined that will become with healthcare. So that’s something that I’m keeping half an eye on.</p>
</section>
<section id="any-words-of-advice-for-budding-data-scientists" class="level3">
<h3 class="anchored" data-anchor-id="any-words-of-advice-for-budding-data-scientists">Any words of advice for budding data scientists?</h3>
<p>You will never stop learning at all because, frankly, the field is moving very, very quickly. So, even if you were to kind of consider yourself an absolute expert today, tomorrow that may not be the case. You will constantly be learning. And I have found that learning the same thing several times through different mediums and having things explained to you different ways is so valuable. Because you may think that you understand something from, say, your bootcamp, but then when you read about it as part of your degree – this is obviously personal to me – you read about it in a different way. And you think, Oh, I’ve never thought of it like that. And then you watch a YouTube video and someone visualises it and you think, okay, I understand this all a little bit deeper now. So, constantly revising what you do know and learning anything that’s new as it comes up, I think everyone at every stage of career can kind of, can do that.</p>
<div class="article-btn">
<p><a href="../../../../../../careers/career-profiles/index.html">Discover more Career profiles</a></p>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-6">
<dl>
<dt>Copyright and licence</dt>
<dd>
© 2023 Royal Statistical Society
</dd>
</dl>
<p><a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> <img style="height:22px!important;vertical-align:text-bottom;" src="https://realworlddatascience.net/careers/career-profiles/posts/2023/05/24/https:/mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://realworlddatascience.net/careers/career-profiles/posts/2023/05/24/https:/mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"></a> This interview is licensed under a Creative Commons Attribution 4.0 (CC BY 4.0) <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> International licence</a>.</p>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>How to cite</dt>
<dd>
Tarran, Brian. 2023. “‘For me, data science is about bridging the gap between business requirements and the data that businesses have.’” Real World Data Science, May 24, 2023. <a href="https://realworlddatascience.net/careers/career-profiles/posts/2023/05/24/jasmine-holdsworth.html">URL</a>
</dd>
</dl>
</div>
</div>
</div>


</section>
</section>

 ]]></description>
  <category>Data analysis</category>
  <category>SQL</category>
  <category>R</category>
  <category>Bootcamps</category>
  <category>Education</category>
  <guid>https://realworlddatascience.net/careers/career-profiles/posts/2023/05/24/jasmine-holdsworth.html</guid>
  <pubDate>Wed, 24 May 2023 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/careers/career-profiles/posts/2023/05/24/images/jh-photo.png" medium="image" type="image/png" height="105" width="144"/>
</item>
<item>
  <title>Large language models: Do we need to understand the maths, or simply recognise the limitations?</title>
  <dc:creator>Brian Tarran</dc:creator>
  <link>https://realworlddatascience.net/careers/posts/2023/05/18/chatgpt-data-science-pt2.html</link>
  <description><![CDATA[ 




<p><a href="https://realworlddatascience.net/careers/posts/2023/05/11/chatgpt-data-science-pt1.html">Part 1 of our conversation with the Royal Statistical Society’s Data Science and AI (DS&amp;AI) Section</a> ended on a discussion around the need to verify that large language models (LLMs), when embedded in workflows and operational processes, are working as intended. But there was also acknowledgement that this could be difficult to achieve, not least of all because, as Giles Pavey said, “nobody knows exactly how these things work – not even the people who build them.” And then, of course, there is the speed at which developments are taking place: Trevor Duguid Farrant made the point that an expert may not even have a chance to finish reviewing the latest version of an LLM before a new iteration is rolled out.</p>
<p>These issues – of verification, explainability and interpretability – are of particular interest to data scientists like Anjali Mazumder, whose work focuses on the impact AI technologies could have, and are having, on society and individuals.</p>
<p>In part 2 of our Q&amp;A about ChatGPT and other LLM-powered advances, and what all of this might mean for data science, Mazumder kicks off the conversation by setting out her perspective.</p>
<p>Our full list of interviewees, in order of appearance, are:</p>
<ul>
<li><p><strong>Anjali Mazumder</strong>, AI and Justice &amp; Human Rights Theme Lead at the Alan Turing Institute, and DS&amp;AI committee member.</p></li>
<li><p><strong>Detlef Nauck</strong>, head of AI and data science research at BT, and editorial board member, Real World Data Science.</p></li>
<li><p><strong>Martin Goodson</strong>, CEO and chief scientist at Evolution AI, and DS&amp;AI committee member.</p></li>
<li><p><strong>Louisa Nolan</strong>, head of public health data science, Public Health Wales, and DS&amp;AI secretary.</p></li>
<li><p><strong>Piers Stobbs</strong>, VP science at Deliveroo, and DS&amp;AI committee member.</p></li>
<li><p><strong>Trevor Duguid Farrant</strong>, senior principal statistician at Mondelez International, and DS&amp;AI committee member.</p></li>
<li><p><strong>Giles Pavey</strong>, global director for data science at Unilever, and DS&amp;AI vice-chair.</p></li>
<li><p><strong>Adam Davison</strong>, head of data science at the Advertising Standards Authority, and DS&amp;AI committee member.</p></li>
</ul>
<div class="keyline">
<hr>
</div>
<p><strong>Anjali Mazumder:</strong> I work in research, but I also sit in the crux of government, industry, and civil society, looking at how they’re using these technologies. For me, it’s about knowing what the opportunities are but also understanding the limitations, the risks and the harms, and how we balance those and put in place oversight mechanisms that act as safeguards to ensure that these technologies don’t cause harm. We’re taking a very socio-technical approach that requires an interdisciplinary team to understand these issues and what should be done. Part of this is about not only the outcomes and the impact but also the upstream side of it – recognising that these models have been built on the work of people who have done the labelling, and that this also has implications – to say nothing of the associated environmental issues or energy issues!</p>
<p><strong>Detlef Nauck:</strong> I think the regulators really have to look at this. It has come completely out of left field for them. All the regulators that we are monitoring, they regulate the space as it was three years ago – they are mainly concerned about predictive models and bias. But if you look at, say, what Microsoft wants to do – putting GPT into Office 365 and into Bing – that will completely change how people interact with and consume information. I think the large tech companies really have a responsibility here, when they make this public, to make sure that people understand what this technology actually is, and how it can be used and has to be used.</p>
<p>Also, they need to open up about how these things have been built. There are a lot of stories around <a href="https://time.com/6247678/openai-chatgpt-kenya-workers/">how OpenAI used cheap labour in order to do the labelling and reinforcement learning for ChatGPT</a>, and these things have to become public knowledge; they need to become part of some kind of Kitemark for these models: “Ethically built, properly checked, hallucinate only a little bit. Whatever you do, don’t take it for granted. Check it!” That’s the kind of disclaimer they need to put on these models.</p>
<div class="pullquote-container">
<div class="grid">
<div class="g-col-12 g-col-lg-12 pullquote-grid pullquote">
<p><img src="https://realworlddatascience.net/images/pullquote-purple.png" class="img-fluid" width="50"></p>
<p>If you look at what Microsoft wants to do – putting GPT into Office 365 and into Bing – that will completely change how people interact with and consume information. Large tech companies really have a responsibility here, when they make this public, to make sure that people understand what this technology actually is.</p>
</div>
</div>
</div>
<p><strong>Regulatory principles always seem to stress that AI systems should be understandable, and we should be able to explain how we get particular outputs. But a lot of our conversation has focused on how we don’t really know how these models work. So, is that, in itself, a problem, and is it something that the data science community can help with – to dig into how these things work and try and get that across – to help meet these principles of explainability and interpretability?</strong></p>
<p><strong>DN:</strong> That’s a very specialist job, I would say – specialist research into how these mathematical structures work. It’s not something I could do, and I’ve not seen any significant work there. One thing that we are interested in is whether we can do knowledge embedding, so that you can “teach” concepts that these models can then use to communicate, and that would lead to smaller systems where you have some understanding of what’s inside. But all of this kind of work, I think, is very much just beginning.</p>
<p><strong>Martin Goodson:</strong> Do we actually need this? There’s sort of a big assumption there that you need to understand how LLMs work in order to build in the kinds of things that we care about as a society. But we don’t understand how humans think. Of course, we can ask a human, “Why did you make that decision?” You can’t understand the cause of that decision – that’s a complex neuroscience question. But you can ask what the reason is for making a decision, and you can ask an LLM what its reasoning is as well. I think a lot of these questions about explainability are stuck in the past, when you’re trying to explain how a linear model works. It’s really not the same thing when you’ve got an LLM where you can just say, “Why did you make that decision?”</p>
<p><strong>Louisa Nolan:</strong> I was going to say something very similar. Most people don’t know how most things work…</p>
<p><strong>DN:</strong> My point was, these things are largely still like the Improbability Drive in the <em>Hitchhiker’s Guide to the Galaxy</em>. You press a button, and you don’t really know what comes out, and that’s the problem we need to get our heads around.</p>
<p><strong>LN:</strong> But people don’t know what percentages are, and yet we still use them for decision making. I don’t think people need to understand the maths behind LLMs, and I think it would be a hopeless job to expect everybody to do that. What we do need to understand is what LLMs can and can’t do. What’s the body of work that they are drawing from? What isn’t in there? What are the things that you need to check? So, for some things, it’ll be brilliant: if you’ve written something and you want it rewritten for a nine-year-old; if you want to summarise a paper; if you want to write code, as long as you already know how to code – these could be real labour-saving tasks. If you’re using ChatGPT to write a thesis about something that you haven’t looked at, that’s where the danger is. It’s this kind of simple understanding that people need to get in their heads – and the maths, except for the people who care about it, is beside the point, and probably detrimental, because it means that people won’t engage with it.</p>
<p><strong>DN:</strong> I agree, but I wasn’t talking about the general public. I meant, the people who build these things – they should know what they’re doing.</p>
<div class="pullquote-container">
<div class="grid">
<div class="g-col-12 g-col-lg-12 pullquote-grid pullquote">
<p><img src="https://realworlddatascience.net/images/pullquote-purple.png" class="img-fluid" width="50"></p>
<p>There’s a big assumption that you need to understand how LLMs work in order to build in the kinds of things that we care about as a society. But we don’t understand how humans think. You can ask a human what their reason is for making a decision, and you can ask an LLM what its reasoning is as well.</p>
</div>
</div>
</div>
<p><strong>We talked there about communication. There was a webinar recently by the <a href="https://rss.org.uk/membership/rss-groups-and-committees/groups/glasgow/">Royal Statistical Society’s Glasgow Local Group</a>, and the presenter, <a href="https://www.hannahrosekirk.com/">Hannah Rose Kirk</a>, showed how you can take tabular data and statistical results and ask ChatGPT to produce a nice paragraph or two that explains the numbers. Is this the sort of thing that any of you have experimented with? Have you had any successes at using ChatGPT to translate data into readable English that decision makers can act on?</strong></p>
<p><strong>Piers Stobbs:</strong> I have an interesting use case. We had a basic survey: 200-odd responses, multiple languages, and we just said, “Please summarise the results of this survey contained in this CSV file.” And it came up with five or six relevant bullet points. What was amazing was that we could then interrogate it. For example, “Please compare the results that were in English versus in French, and describe the differences.” Again, it did it, but then you have the issue of, was it all correct? Well, the bulk of it was. Now I am intrigued by whether you can ask it to do correlations and some actual statistical things on a dataset, and does it get that right? I don’t know. We’ve not really got to that. But, to go back to one of the earlier discussion points around productivity, that initial survey work could have easily taken a week of someone’s time if we didn’t run it through ChatGPT.</p>
<p><strong>Trevor Duguid Farrant:</strong> Piers, in this case you’re interested in checking and seeing if it’s right. If you’d asked a group of people to do that survey for you and get the results, you’d have just accepted whatever they gave you back. You wouldn’t have questioned it.</p>
<p><strong>PS:</strong> That’s true. And the results were plausible, certainly.</p>
<p><strong>AM:</strong> I think one of the challenges is that the results could seem like they’re plausible, right – whether that’s a statistical output or a text output. This was not a proper experiment, but I asked ChatGPT about colleagues and friends who are quite prominent researchers, asking, “Who is so-and-so?”, and it produced biographies that were quite plausibly them, but it wasn’t them. It might have listed the correct PhD, say, but the date was off by a year, or the date was correct but it was from the wrong institution. So, depending on what the issue is, these seemingly plausible results could have more serious implications.</p>
<p><strong>LN:</strong> So, just to join those two things together: for me, the question is not, “Do we understand how ChatGPT works?” As Martin says, we don’t understand how humans work, and surely we’re trying to develop something that enhances human thinking in some way. The more important question for me is, “How do we know that what is produced is useful?”</p>
<div class="pullquote-container">
<div class="grid">
<div class="g-col-12 g-col-lg-12 pullquote-grid pullquote">
<p><img src="https://realworlddatascience.net/images/pullquote-purple.png" class="img-fluid" width="50"></p>
<p>For me, the question is not, ‘Do we understand how ChatGPT works?’ We don’t understand how humans work, and surely we’re trying to develop something that enhances human thinking in some way. The more important question is, ‘How do we know that what is produced is useful?’</p>
</div>
</div>
</div>
<p><strong>Giles, <a href="https://realworlddatascience.net/careers/posts/2023/05/11/chatgpt-data-science-pt1.html">you mentioned previously that you’re doing some work at Unilever around how to minimise hallucination</a>. I don’t know how much you can say on what direction that’s going in, and how successful you expect that to be, but that’s obviously going to be a really important part of refining these models to be more widely usable.</strong></p>
<p><strong>Giles Pavey:</strong> I’m by no means an expert, but there’s quite a lot you can do with both the architecture of it and also the pre-prompts that you put in – more or less saying, “Quote what the source is, and if you’re not sure, then tell me you’re not sure.” I think what’s interesting is the question of whether we’ll have to rely on OpenAI or Microsoft to do that work, and it will be just another thing that we have to trust them for. Or, will it be something that people within an organisation can put in themselves?</p>
<p><strong>MG:</strong> I think it’s absolutely critical that open-source models are developed that can compete with these tech companies, otherwise there’s going to be a huge transfer of power to these companies.</p>
<p><strong>GP:</strong> Arguably, the single biggest issue is, who elected Sam Altman (no-one) and are we as society happy with him having so much power over our future?</p>
<p><strong>To close us out, I’d like to return to <a href="http://localhost:5404/careers/posts/2023/05/11/chatgpt-data-science-pt1.html">a question Trevor posed earlier</a>, which is: How might organisations like the Royal Statistical Society help companies to embrace LLMs and start using them, so that everyone can benefit from the technology?</strong></p>
<p><strong>Adam Davison:</strong> My instinct is that there’s some great parallel here with the stuff that the Data Science and AI Section have been doing in general, where we’ve said, “OK, there’s lots of good advice out there on how to do things in data science, but how do you make it practical? How do you make it real? How do you apply those ethical principles? How do you make sure you have people with the right technical understanding in charge of projects to get value?” If, five years ago, the hype around data science was leading organisations to hire 100 data scientists in the hope that something innovative would happen, well then, we don’t want those same organisations now thinking that they need to hire 100 prompt engineers and keep their fingers crossed for something special. Our focus has been on “<a href="https://realworlddatascience.net/viewpoints/newsletter/">industrial strength data science</a>”, so I think we can extend that to show what “industrial strength LLM usage” looks like in practice.</p>
<div class="callout callout-style-simple callout-note" style="margin-top: 2.25rem;">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-body-container">
<p>Want to hear more from the RSS Data Science and AI Section? Sign up for its newsletter at <a href="https://rssdsaisection.substack.com/">rssdsaisection.substack.com</a>.</p>
</div>
</div>
</div>
<div class="nav-btn-container">
<div class="grid">
<div class="g-col-12 g-col-sm-6">
<div class="nav-btn">
<p><a href="../../../../../careers/posts/2023/05/11/chatgpt-data-science-pt1.html">← Read part one</a></p>
</div>
</div>
<div class="g-col-12 g-col-sm-6">
<div class="nav-btn">
<p><a href="../../../../../careers/index.html">Back to Careers</a></p>
</div>
</div>
</div>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-12">
<dl>
<dt>Copyright and licence</dt>
<dd>
© 2023 Royal Statistical Society
</dd>
</dl>
<p><a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> <img src="https://realworlddatascience.net/careers/posts/2023/05/18/https:/mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1" style="height:22px!important;vertical-align:text-bottom;"><img src="https://realworlddatascience.net/careers/posts/2023/05/18/https:/mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1" style="height:22px!important;margin-left:3px;vertical-align:text-bottom;"></a> This interview is licensed under a Creative Commons Attribution 4.0 (CC BY 4.0) <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> International licence</a>. Images are not covered by this licence. Thumbnail image by <a href="https://unsplash.com/@deepmind?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Google DeepMind</a> on <a href="https://unsplash.com/photos/52afknBiUk4?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Unsplash</a>.</p>
</div>
<div class="g-col-12 g-col-md-12">
<dl>
<dt>How to cite</dt>
<dd>
Tarran, Brian. 2023. “Large language models: Do we need to understand the maths, or simply recognise the limitations?” Real World Data Science, May 18, 2023. <a href="https://realworlddatascience.net/careers/posts/2023/05/18/chatgpt-data-science-pt2.html">URL</a>
</dd>
</dl>
</div>
</div>
</div>



 ]]></description>
  <category>Large language models</category>
  <category>AI</category>
  <category>Communication</category>
  <category>Regulation</category>
  <guid>https://realworlddatascience.net/careers/posts/2023/05/18/chatgpt-data-science-pt2.html</guid>
  <pubDate>Thu, 18 May 2023 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/careers/posts/2023/05/18/images/google-deepmind-52afknBiUk4-unsplash.png" medium="image" type="image/png" height="105" width="144"/>
</item>
<item>
  <title>How is ChatGPT changing data science?</title>
  <dc:creator>Brian Tarran</dc:creator>
  <link>https://realworlddatascience.net/careers/posts/2023/05/11/chatgpt-data-science-pt1.html</link>
  <description><![CDATA[ 




<p>For many people, it starts with a question. Something simple, something they already know the answer to. A test, in other words, to see what these AI-powered chatbots are all about. But spend any amount of time with ChatGPT and other such tools and you’ll quickly start to wonder what else they might do, and how useful they might be in your day-to-day working life.</p>
<p>Data scientists certainly have been thinking along these lines, and to find out more about current use cases, proofs of concepts and potential applications, Real World Data Science got together with members of the <a href="https://rss.org.uk/membership/rss-groups-and-committees/sections/data-science-section/">Royal Statistical Society’s Data Science and AI Section</a> (DS&amp;AI) for a group discussion.</p>
<p>Our interviewees, in order of appearance, are:</p>
<ul>
<li><strong>Piers Stobbs</strong>, VP science at Deliveroo, and DS&amp;AI committee member.</li>
<li><strong>Detlef Nauck</strong>, head of AI and data science research at BT, and editorial board member, Real World Data Science.</li>
<li><strong>Adam Davison</strong>, head of data science at the Advertising Standards Authority, and DS&amp;AI committee member.</li>
<li><strong>Trevor Duguid Farrant</strong>, senior principal statistician at Mondelez International, and DS&amp;AI committee member.</li>
<li><strong>Giles Pavey</strong>, global director for data science at Unilever, and DS&amp;AI vice-chair.</li>
<li><strong>Martin Goodson</strong>, CEO and chief scientist at Evolution AI, and DS&amp;AI committee member.</li>
</ul>
<p>The first part of our discussion focuses on how large language models are becoming part of the data science toolkit, and what this new development means for data science teams and skillsets. Stay tuned for part two, which we’ll be publishing soon!</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://realworlddatascience.net/careers/posts/2023/05/11/images/chatgpt-homescreen.png" class="img-fluid figure-img" alt="Photo of ChatGPT homescreen, by Levart_Photographer on Unsplash." width="500"></p>
</figure>
</div>
<p><strong>As data scientists, how has ChatGPT – and other tools built on large language models (LLMs) – changed your working lives?</strong></p>
<p><strong>Piers Stobbs:</strong> Up to about a year ago, although I was really impressed with the developments in deep learning and the improvements in computer vision and natural language models, it felt in line with general improvements in machine learning. And then, probably about six months ago, with things like DALL·E and ChatGPT, it felt like something changed – properly ground-breaking capabilities. And I still can’t quite get my head around the fact that you can basically have a model that tries to predict the next token, and it comes up with outputs that really feel quite sensible and human-like – if prone to <a href="https://realworlddatascience.net/viewpoints/editors-blog/posts/2022/11/23/LLM-content-warning.html">hallucination</a>.</p>
<p>The way I think about it is, this feels like a brand-new capability that we’ve just not really had before. It’s almost like an interface with unstructured information. Historically, you sort of have to turn text into something, and then turn something back into text, if you want to have this interface with humans. Now, we’ve got this really quite elegant way of plugging the gaps, which feels full of opportunities.</p>
<p>I’m having great fun playing around with the code co-pilots – GitHub’s Copilot is amazing and, productivity wise, is helping me a lot. I am now a much faster coder because there’s all those Stack Exchange lookups that I don’t have to do anymore. Again, from a personal productivity perspective, I’m using [ChatGPT] for initial drafts of documents and other things. And then I use it almost for validating things. For instance, I had a random discussion the other night with ChatGPT about logistic algorithms. It’s not going to solve problems for you, but I asked it to give some pointers of things I could be thinking about – some of which I had, some of which I hadn’t. So, it’s almost like a brainstorming helper, somehow.</p>
<p>But probably the thing I’m most excited about is the knowledge sharing side of it – plugging it into, or on top of, private information, and surfacing all that knowledge that is locked away in documents and intranet pages.</p>
<div class="pullquote-container">
<div class="grid">
<div class="g-col-12 g-col-lg-4">
<div class="quarto-figure quarto-figure-left">
<figure class="figure">
<p><img src="https://realworlddatascience.net/careers/posts/2023/05/11/images/piers-stobbs.png" class="img-fluid figure-img" alt="Portrait photo of Piers Stobbs"></p>
<figcaption class="figure-caption">Piers Stobbs</figcaption>
</figure>
</div>
</div>
<div class="g-col-12 g-col-lg-8 pullquote-grid pullquote">
<p><img src="https://realworlddatascience.net/images/pullquote-purple.png" class="img-fluid" width="50"></p>
<p>This feels like a brand-new capability – an interface with unstructured information. Historically, you have to turn text into something, and then turn something back into text, if you want to have this interface with humans. Now, we’ve got this elegant way of plugging the gaps.</p>
</div>
</div>
</div>
<p><strong>Detlef Nauck:</strong> We’re looking into running proof of concepts to see whether LLMs do bring value. Software engineering is the most obvious one, and easiest to set up and run. And then we want to look at making use of internal documents – so, either summarization or creation of internal documents in appropriate language. The latter use cases are trickier to evaluate. We want to know whether the outputs produced are any good. With software engineering you can track GitHub statistics, for example. But if you give ChatGPT to somebody to write marketing material, or to get information out of a document, how do you know that the results are good? We need to get our head around metrics for evaluation.</p>
<p><strong>Adam Davison:</strong> I’ve been using it for basically anything where I don’t remember the API very well or it’s a bit confusing. <a href="https://pandas.pydata.org/">Pandas</a> is the key, right? We all use pandas, but you don’t really remember how to do some complicated thing with <code>apply()</code>, say, so you just ask GPT-4 to give you the answer, and it saves you that hassle. Also, I read some insightful tweet that said these chat systems are really good for things where generating the solution is hard, but verifying it is easy. And I think that’s true for some of these things. You know, you get a short piece of Python code, you can basically look at that and you can tell if it’s right.</p>
<p>In data science, you’re a bit of a jack-of-all-trades. You need to do little bits of everything, but you’re not a specialist in anything. And so, I think for software development, it’s been really helpful. For example, right now, I’m doing a bit of frontend development in a project to visualise something. I’m never going to be a professional frontend developer, but GPT-4 can help deal with the oddities of JavaScript much more easily than it would be for me to trawl through Stack Overflow posts.</p>
<p>But the thing that we’re using it for, practically, is natural language processing (NLP) and classification. We have this particular problem at the Advertising Standards Authority (ASA) where we are running lots of different models that are completely unconnected to each other because every project is a different topic. So, one week we’re looking at, “Do these gambling ads appeal to young people?” and then the week after it’s, “Are these cryptocurrency ads being clear about the risks involved?” It’s very disparate, we don’t have a lot of time to iterate on models, and we don’t have huge amounts of training data. Ten years ago, when you were doing sentiment classification, you were on Mechanical Turk getting 10,000 examples, and even then it didn’t work very well after these really complicated models. Now, you’ve got a couple of hundred examples and with the embeddings [from LLMs] you can get to a pretty decent classifier quite quickly. We’re also starting to experiment with using OpenAI’s fine-tuning tools, and the performance that we’ve seen from that is very impressive, to the extent that it’s making us rethink whether we bother doing anything else in some of our classifiers.</p>
<div class="pullquote-container">
<div class="grid">
<div class="g-col-12 g-col-lg-4">
<div class="quarto-figure quarto-figure-left">
<figure class="figure">
<p><img src="https://realworlddatascience.net/careers/posts/2023/05/11/images/adam-davison.png" class="img-fluid figure-img" alt="Portrait photo of Adam Davison"></p>
<figcaption class="figure-caption">Adam Davison</figcaption>
</figure>
</div>
</div>
<div class="g-col-12 g-col-lg-8 pullquote-grid pullquote">
<p><img src="https://realworlddatascience.net/images/pullquote-purple.png" class="img-fluid" width="50"></p>
<p>Five years ago, if you had a sophisticated problem involving text or images, you’d need a big research team with a big budget to tackle it. But increasingly we find, like many other people, that you can take models off the shelf and repurpose them for quite diverse tasks.</p>
</div>
</div>
</div>
<p><strong>Trevor Duguid Farrant:</strong> My organisation is not as far forward as the rest of you. I’ve introduced it to the leadership team, and the digital services team – what was IT – are looking to make a decision on whether we can use it or not. I think there’ll be so much pressure they’ll have to use it, but there’s still a feeling of discomfort with it, whereas I think it’s really good and have started using it. Everyone else on the call seems to have started using it. So, can organisations like the Royal Statistical Society help companies to embrace this and start using it, and then everyone can benefit from it?</p>
<p><strong>Giles Pavey:</strong> I wish I could be with Piers and Adam – actually using it – but my life has been taken over as the guy who goes and explains it to the business. Unilever is a massive business, and we are concerned about privacy, confidentiality and trustworthiness. We’ve now built an initial GPT instance on Azure and fed it with some of our own documents, and a lot of my time has been working with legal to convince ourselves that that’s okay. Now we are really trying to work out just how we manage the amazing demand for proofs of concepts and use cases – and what we’re just about to uncover, I think, is the unknown but potentially massive expense of running it.</p>
<p>In pure proofs of concepts, departments that have large knowledge banks are using it: research and development, and marketing, for example. And one of the big technical things that we’re working on – and, because of the size that we are, we’re doing a lot of work with OpenAI and Microsoft on this – is how to stop the models from hallucinating.</p>
<p><strong>Have your experiences with ChatGPT and other tools changed your thinking about the skillsets required of data scientists and data science teams?</strong></p>
<p><strong>AD:</strong> A little bit. As someone at a small organisation, I think it’s quite exciting because, five years ago, maybe you were in a world where if you had a sophisticated problem involving text or images, you’d need a big research team with a big budget to tackle it. But increasingly we find, like many other people, that you can take models off the shelf and repurpose them for quite diverse tasks. So, I think it’s becoming increasingly viable to have a small team of people who are implementers, who aren’t necessarily backed up by a big research organisation, doing increasingly sophisticated stuff.</p>
<p>I don’t think it does away with the sort of things that we always bang on about in the Data Science and AI Section, like the need for an understanding of statistics and how the underlying systems really work, because I think you still need to understand what you’re doing with LLMs, as with any other machine learning technique. But, if I had to guess, what we’re going to be seeing now is that for a lot of problems, you’re going to have more of a division – so, you’re either in one of a small number of very large labs doing research on very cutting-edge big models, or you can be an implementer who is taking things off the shelf and applying them. And maybe that space in between is going to get a little bit squeezed – that would be my guess, but obviously it’s very unpredictable.</p>
<div class="pullquote-container">
<div class="grid">
<div class="g-col-12 g-col-lg-4">
<div class="quarto-figure quarto-figure-left">
<figure class="figure">
<p><img src="https://realworlddatascience.net/careers/posts/2023/05/11/images/giles-pavey.png" class="img-fluid figure-img" alt="Portrait photo of Giles Pavey"></p>
<figcaption class="figure-caption">Giles Pavey</figcaption>
</figure>
</div>
</div>
<div class="g-col-12 g-col-lg-8 pullquote-grid pullquote">
<p><img src="https://realworlddatascience.net/images/pullquote-purple.png" class="img-fluid" width="50"></p>
<p>We’ve built an initial GPT instance on Azure. Now we are really trying to work out just how we manage the amazing demand for proofs of concepts and use cases – and what we’re just about to uncover, I think, is the unknown but potentially massive expense of running it.</p>
</div>
</div>
</div>
<p><strong>PS:</strong> That’s exactly my view. When I first started hiring data scientists, a long time ago, you basically had to write stuff from scratch, and you needed PhDs – people who really understood, at a deep level, how the maths all works. But I think there’s been a steady progression towards valuing software engineering skills, and I think, in some ways, this is another step along that path. If I think now about implementing a chatbot over your own knowledge base, it’s basically like plugging APIs together with some Python. Adam’s point is still hugely important, though, because I think we still need the background knowledge about what’s actually going on – OK, I’m creating embeddings here, and that’s allowing this search to work so I can surface the right docs – that whole process, which an average software engineer is maybe not going to know. But I think it’s definitely blurring the lines.</p>
<p><strong>Martin Goodson:</strong> It’s just as important now to understand how to evaluate performance. The difference is, it used to be that you were trying to figure out whether it’s 80% accurate, or 85%. Now, it’s like 99.9%. But you still need to figure it out. You still need to understand what the failure modes are, what caused it; how is it actually working, and is it doing what you need it to do for the product? Is it actually satisfying our needs as users or as customers of the products.</p>
<p><strong>DN:</strong> I think in the future, the skills we will need are people who can run and build these models. Giles made the point about how expensive it is to run these things. Right now, you have two options: subscribe to an API, and then you are limited in how you can modify these models; or build your own – take an open-source LLM and modify it. But then you need people who know how to build a high-performance computing environment and operate this efficiently. You need to know how to actually train the models, how to curate the data, how to set the model parameters. And I always think there’s too much alchemy still going on in this field, right? It’s not proper science. People build these things and then are surprised at what they can do; they didn’t know such things would be possible. A lot of these capabilities only emerge when you make the models really, really big and, essentially, you also have no control over them – you can’t stop them hallucinating. So, these are the kinds of issues we need to get under control if we want to get any value out of them.</p>
<p>Prompt engineering is another one – you really need to understand how these models work and how to prompt them. If you want to give them to, say, a marketer to generate copywriting, they may not have the right ideas of how to prompt the machine. So, I could see roles developing out of data science that understand how to influence these models and make them do what we want them to do.</p>
<p><strong>MG:</strong> The other angle to this is junior engineers. Now, the bar for being a useful junior engineer is that you’re better than GitHub Copilot. Why do you need a really junior person if you can just use a large language model to be the junior developer?</p>
<p><strong>DN:</strong> I’m not thinking about the data science person who needs to write some code for a project here, but if you have a large software team in an organisation that produces production code, they will become more efficient by using these tools. But still, with all this overhead of testing and putting it all together, there will be a lot of manual work that needs to be done. But the teams will get more efficient and junior people will get up to speed quicker. That’s probably another advantage.</p>
<div class="pullquote-container">
<div class="grid">
<div class="g-col-12 g-col-lg-4">
<div class="quarto-figure quarto-figure-left">
<figure class="figure">
<p><img src="https://realworlddatascience.net/careers/posts/2023/05/11/images/trevor-duguid-farrant.png" class="img-fluid figure-img" alt="Portrait photo of Trevor Duguid Farrant"></p>
<figcaption class="figure-caption">Trevor Duguid Farrant</figcaption>
</figure>
</div>
</div>
<div class="g-col-12 g-col-lg-8 pullquote-grid pullquote">
<p><img src="https://realworlddatascience.net/images/pullquote-purple.png" class="img-fluid" width="50"></p>
<p>Can the Royal Statistical Society help non-tech companies embrace large language models, extolling their virtues and dispelling the myths?</p>
</div>
</div>
</div>
<p><strong>PS:</strong> I think Detlef’s point about understanding is an interesting one. It definitely feels like there’s been this sort of continuum from, you know, “OK, it’s a linear regression, we know what’s going on” to complex models to ensemble models where, again, you’re combining these things you can individually understand. Even with big ImageNet architectures, billions of parameters, at least conceptually you can understand how these work and build out tools where you can understand the layers. To me, what’s different now is you’ve got this reinforcement learning layer on top, or diffusion layer, or some other additional approach – this combination of really complicated things. I honestly don’t know where to start with trying to understand why a specific output is generated, and I think that is a proper concern. That’s definitely an area of research, because I think we need to understand this.</p>
<p><strong>GP:</strong> I think there’s also a question in large companies of just who owns these things. Up until this point, everybody’s been happy that AI is the realm of data science. And, suddenly, generative AI looks like it might be the realm of the IT team – that it’s a service that you get off the shelf. It’s going to be interesting to see how that plays out. I really liked the point that Martin was making about being able to tell what the systems are actually doing, what they are supposed to do and how to check them, because if you don’t have a background in that area, you might just assume they work. Now, nobody knows exactly how these things work – not even the people who build them. But having a background in how you test things, for potential causes for things not working, is actually going to be incredibly powerful or useful.</p>
<p><strong>TDF:</strong> Will experts like us actually be able to check it because of the speed that new versions are coming out and the developments that are happening? Is it going to take us six months to check that GPT-3.5 works? Well, too late, a month later GPT-4’s out! I just think that pace is going to keep accelerating.</p>
<div class="callout callout-style-simple callout-note" style="margin-top: 2.25rem;">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-body-container">
<p>Want to hear more from the RSS Data Science and AI Section? Sign up for its newsletter at <a href="https://rssdsaisection.substack.com/">rssdsaisection.substack.com</a>.</p>
</div>
</div>
</div>
<div class="nav-btn-container">
<div class="grid">
<div class="g-col-12 g-col-sm-6">
<div class="nav-btn">
<p><a href="../../../../../careers/index.html">Back to Careers</a></p>
</div>
</div>
<div class="g-col-12 g-col-sm-6">
<div class="nav-btn">
<p><a href="../../../../../careers/posts/2023/05/18/chatgpt-data-science-pt2.html">Read part two →</a></p>
</div>
</div>
</div>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-12">
<dl>
<dt>Copyright and licence</dt>
<dd>
© 2023 Royal Statistical Society
</dd>
</dl>
<p><a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> <img src="https://realworlddatascience.net/careers/posts/2023/05/11/https:/mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1" style="height:22px!important;vertical-align:text-bottom;"><img src="https://realworlddatascience.net/careers/posts/2023/05/11/https:/mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1" style="height:22px!important;margin-left:3px;vertical-align:text-bottom;"></a> This interview is licensed under a Creative Commons Attribution 4.0 (CC BY 4.0) <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> International licence</a>. Photos are not covered by this licence. Portrait photos are supplied by interviewees and used with permission. ChatGPT homescreen photo by <a href="https://unsplash.com/@siva_photography?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Levart_Photographer</a> on <a href="https://unsplash.com/photos/drwpcjkvxuU?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Unsplash</a>.</p>
</div>
<div class="g-col-12 g-col-md-12">
<dl>
<dt>How to cite</dt>
<dd>
Tarran, Brian. 2023. “How is ChatGPT changing data science?” Real World Data Science, May 11, 2023. <a href="https://realworlddatascience.net/careers/posts/2023/05/11/chatgpt-data-science-pt1.html">URL</a>
</dd>
</dl>
</div>
</div>
</div>



 ]]></description>
  <category>Large language models</category>
  <category>AI</category>
  <category>Skills</category>
  <category>People</category>
  <guid>https://realworlddatascience.net/careers/posts/2023/05/11/chatgpt-data-science-pt1.html</guid>
  <pubDate>Thu, 11 May 2023 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/careers/posts/2023/05/11/images/chatgpt-homescreen.png" medium="image" type="image/png" height="105" width="144"/>
</item>
<item>
  <title>‘I’m way more into prevention than cure’: Stephanie Hare on why we need a culture of technology ethics</title>
  <dc:creator>Brian Tarran</dc:creator>
  <link>https://realworlddatascience.net/viewpoints/interviews/posts/04/28/stephanie-hare.html</link>
  <description><![CDATA[ 




<p>We’re about a year late coming to <a href="https://www.harebrain.co/">Stephanie Hare</a>’s book, <a href="https://londonpublishingpartnership.co.uk/technology-is-not-neutral/"><em>Technology is Not Neutral: A Short Guide to Technology Ethics</em></a>. But, as discussed in our interview below, time has only made the text more relevant. The book was written pre-ChatGPT, but Hare’s explorations of ethical questions in the context of facial recognition technology and Covid-19 exposure tracking apps feel both pointed and urgent at this moment, when researchers, regulators, and regular people are weighing the opportunities and potential harms of large language models and generative AI tools.</p>
<p>“We’re having some sort of moment with technology ethics – AI ethics being just a branch of that,” says Hare. Reflecting on her career, spanning 25 years, she says: “The stuff that we’re talking about today that dominates the headlines – that is dominating the discussion in the tech sector – was not discussed at all at the turn of the century, other than by maybe people in the science and technology studies domain or academics. But it wasn’t filtering into boardrooms. It wasn’t on the front pages of newspapers, and it wasn’t being covered in the national news. So, it’s amazing. A whole field has sprung up.”</p>
<p>However, as Hare makes clear in our interview, we still have a long way to go to build a culture of technology ethics throughout society. Check out the full conversation below or on YouTube.</p>
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/INKwSTNFSVY" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<section id="timestamps" class="level2">
<h2 class="anchored" data-anchor-id="timestamps">Timestamps</h2>
<ul>
<li>ChatGPT: just another “flavour of the month” in the tech industry? (<a href="https://youtu.be/INKwSTNFSVY?t=78">1:18</a>)</li>
<li>Has concern about large language models helped put technology ethics on the map? (<a href="https://youtu.be/INKwSTNFSVY?t=197">3:17</a>)</li>
<li>What will it take to build a culture of technology ethics – in society, in academia, in industry? (<a href="https://youtu.be/INKwSTNFSVY?t=556">9:16</a>)</li>
<li>Drawing lessons from history (<a href="https://youtu.be/INKwSTNFSVY?t=735">12:15</a>)</li>
<li>Why technology ethics is a “wicked problem” (<a href="https://youtu.be/INKwSTNFSVY?t=1497">24:57</a>)</li>
<li>Checklists and changing mindsets (<a href="https://youtu.be/INKwSTNFSVY?t=1789">29:49</a>)</li>
</ul>
</section>
<section id="quotes" class="level2">
<h2 class="anchored" data-anchor-id="quotes">Quotes</h2>
<p>“The European Union has the AI Act coming down the pike. It doesn’t cover stuff like ChatGPT specifically, but then I don’t know if you want good regulation to cover the technology itself, or how technology is used. I talked about this in my book: do you want to regulate forks – a tool – or do you want to regulate use cases for forks? We’ve regulated the use case, if you will, of murder, or of injury with a fork – or, frankly, any other tool. So it’s the use case we focus on. We don’t really regulate forks. [But] we do regulate some technologies, like biomedical technologies, human genetic stuff, anything nuclear. So we just need to think about where does AI fit with that?” (<a href="https://youtu.be/INKwSTNFSVY?t=342">5:42</a>)</p>
<p>“Move fast and break things was the mantra for this culture [in the technology industry] for a really long time, at least out of the US. And it made a lot of people a lot of money, and they got worshipped by the media. And, you know, they have a whole audience of ‘bros’ who are fans of them. And they’ve never really, any of them, been held to account for what they’ve built.” (<a href="https://youtu.be/INKwSTNFSVY?t=716">11:56</a>)</p>
<p>“Another generation or two, when we’re older, might look at some of what technology we’ve built or our behaviour on climate change, our track record – did we do what we could have done to slow global warming, to improve biodiversity? – and they might hold us to account, saying, ‘You could have stopped this and you didn’t, right? It’s not just what you did. It’s what you did not do.’ So we have to be super careful when we think about ethics, because ethics change, values change over time. And what seems okay today may not be okay in 10, 20, 30 years time. That is on my mind all the time. It’s not very relaxing.” (<a href="https://youtu.be/INKwSTNFSVY?t=1110">18:30</a>)</p>
<p>“[Laws and regulations] are important, they’re necessary, but they’re insufficient. You can act a lot faster if you can get people preventing stuff from being built in the first place, and that means you need to have a culture of people working in technology, both within the organisations – whether that’s research labs, government, companies, universities, whatever – and on the outside – journalists, academics, thinkers, etc., or just the public, an informed public – who can see something and sound the alarm and go, ‘Wait a minute, hang on. That’s not okay.’” (<a href="https://youtu.be/INKwSTNFSVY?t=1982">33:02</a>)</p>
</section>
<section id="transcript" class="level2">
<h2 class="anchored" data-anchor-id="transcript">Transcript</h2>
<div class="callout callout-style-simple callout-warning" style="margin-top: 0.75rem;">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-body-container">
<p>This transcript has been produced using <a href="https://otter.ai/">speech-to-text transcription software</a>. It has been only lightly edited to correct mistranscriptions and remove some repetitions.</p>
</div>
</div>
</div>
<p><strong>Brian Tarran</strong><br>
Hello, and welcome to another Real World Data Science interview. I’m Brian Tarran. And today I’m joined by Stephanie Hare, a researcher and broadcaster and author of the book Technology is Not Neutral: A Short Guide to Technology Ethics, which is the focus of our conversation today. Welcome, Stephanie.</p>
<p><strong>Stephanie Hare</strong><br>
Thank you so much for having me here.</p>
<p><strong>Brian Tarran</strong><br>
I feel I’m a bit late to the party with the book. The Financial Times picked it up as one of the best books of summer 2022. But I’ve only just got around to reading it.</p>
<p><strong>Stephanie Hare</strong><br>
I mean, I only just got around to reading War and Peace last year. So there’s no rush with these things.</p>
<p><strong>Brian Tarran</strong><br>
Okay. Well, I mean, I can definitely say it’s one of the best books I’ve read in spring 2023, if that helps, and the only other one I read was Lord of the Rings. So–</p>
<p><strong>Stephanie Hare</strong><br>
Wow. I mean that’s some pretty august company, you couldn’t thrill me more.</p>
<p><strong>Brian Tarran</strong><br>
Excellent, excellent. Well, I actually thought coming late to the book might actually have been of benefit to me as a reader because, you know, you’re talking about technology ethics quite broadly. But then you focus in on a couple of use cases, specifically around facial recognition, technology, Covid-19 exposure tracking apps and things like that. But, you know, obviously, since the book was published, the whole discussion around technology ethics has kind of been dominated maybe or taken on a new dimension following the launch and adoption of ChatGPT. I wonder, you know, when the technology was launched, people started using it, adoption rates, you know, went through, went through the roof, what was your kind of initial reaction to all that and what have you made of the kinds of conversations and criticisms that have followed?</p>
<p><strong>Stephanie Hare<br>
</strong>Well, I mean, like everybody I was curious and fascinated and wanted to play around with it a bit. I don’t think I’m of the school of thought that seems to be circulating that this will either you know, destroy mankind as we know it or take everybody’s jobs or potentially upend civilization. There’s been some quite extreme, some quite extreme views put across in the media in the past few months since this was widely released to the public. I don’t know, for some reason, I didn’t drink the Kool-Aid, when I started working in technology. So I always take these things with a grain of salt. And I guess my, my cautionary note to anybody listening to this is you know, at this time last year, all of my clients were wanting presentations and analysis about web3 and NFTs and cryptocurrency and before that, it was blockchain. There’s like always a sort of flavour of the month. AI, for people who’ve worked in this field, is known to have winters, summers, springs, autumns, you know, these seasons of when it’s like coming on and really exciting or not? I’m more excited by DeepMind’s use of artificial intelligence, I think they’re actually working on interesting problems, right, around like protein discovery, like real science, as opposed to like, oh, look, I can have a new sci fi avatar or do a deep fake, you know, people can do deep fakes already. We’re just doing them now in even more disturbing ways. So I guess, I guess it’s that. I’m intrigued by it. But I don’t I don’t feel the need to sort of freak out. Either way, positively or negatively, I have a much more sort of detached satellite-level view, I think probably just because I’m older, seeing these trends come and go. And it’s like, let’s just let’s just wait this out and see how it goes.</p>
<p><strong>Brian Tarran</strong><br>
From your perspective as someone who’s interested in and researching in the area of technology ethics, right, do you see a kind of almost a benefit that the conversation around this has put technology ethics, the conversation around that, on the map? Or do you worry that we’re kind of obsessing over this one technology and this one application? We’re not looking at the field more broadly?</p>
<p><strong>Stephanie Hare</strong><br>
Well, there’s a few things to say on this. So like, first of all, a couple of weeks ago, a bunch of people working in AI, about 1000-plus people – including some fictitious people, by the way – sign this this letter calling for a moratorium on AI research for six months, which was unenforceable, clearly not going to happen, was signed by Elon Musk, who then very quickly announced he was developing his own rival to OpenAI, the company that invented ChatGPT. So you take all of that with a grain of salt. But again, if you’re, if you’re an historian, or if you just have a long memory, you’ll remember that there have been several letters like this. There’s always somebody, you know, very big-wig people. It’s not that we want to dismiss it. But Stephen Hawking and Elon Musk were warning, you know, over around 10 years ago that AI was going to kill humanity if we didn’t put guardrails on it. Professor Stuart Russell talked about this in his Reith Lectures a couple of years ago, which are still online and you can listen to them. And you know, he’s not an alarmist. He’s a serious person and a serious thinker. So we want to listen to him. But I guess what I’m just saying is, you know, every time some sort of new technology or new use case for technology comes up, there’s a group of people who come out and freak out and they get lots of op-eds.&nbsp;It’s usually men, I must say. There’s a lot of women doing some really interesting scholarship in this area that don’t get the op-eds and quite the publicity. So there’s that. Then it is interesting because it makes people think about technology ethics, usually, again, from a place of either fear, right – Are they going to kill us? Are they going to take our jobs? Are they going to remove human agency? – or money – How are people going to make a huge amount of money? Who’s going to make the money? And by displacing whom, right? So, we have two levers: incredible doom or incredible opportunity. And that leaves the rest of us, I think, probably somewhere in the middle, scratching our heads and going like, is this going to actually change my life? And if so, how, and do I really care, given that I’ve got like, you know, a cost of living crisis, recovering from the Covid pandemic for the past few years? Like, if you’re not in this world, it can seem like a lot of shouting. There’s also the question of, do we need new laws? So we know that the European Union has the AI Act coming down the pike. That’s supposed to be passed this year, and there’ll be a two year implementation grace period. So that’s interesting. It doesn’t cover stuff really, like ChatGPT specifically, but then I don’t know if you want good regulation to cover the technology itself, or how technology is used. And I talked about this in my book, like, do you want to regulate forks – a tool – or do you want to regulate use cases for forks? So if I’m, if I stab you, or kill you with a fork, which is totally possible, that is something that we’ve regulated; we’ve regulated the use case, if you will, of murder, or of injury with a fork or frankly, any other tool. So it’s the use case we focus on. We don’t really regulate forks. We do regulate some technologies like bioethics technologies, or biomedical technologies, excuse me, sort of human genetic stuff, anything nuclear. Those technologies we do specifically regulate. So we just need to think about where does AI fit with that? And also, do we need new regulations for everything, or can we use existing ones? And that’s what’s becoming really interesting is that in the US, where I’m from, the main regulator, the FTC, seems to think that it can use a lot of existing laws already. So they’ve been like, if your AI is claiming to do stuff that it can’t, we’re gonna come after you under, like, kind of sort of false advertising, if you will, misrepresenting yourself. They might come after some of the big AI companies based on anti-competition law, right? So no new laws needed for that. And then with the music industry, they’ve been going after all the people who are like, oh, let’s like remix a Drake song, and saying, well, actually, you can’t do that, because you’re violating copyright law, take it down. Right. So again, I don’t want to be like too, too calm about it. Like, we do need to look at some of the use cases that are really problematic and hurting people. But we might actually have a lot more in our arsenal to combat this than we’re currently using. And I think what’s going to happen is, unfortunately, the pace of crafting legislation, and then regulators never fully enforce regulations– Look at the GDPR: no company’s ever been given the full fine. And here in the UK, the ICO is famous for letting companies off the hook, giving them less than half of the original fine. It’s ridiculous. So if you’re going to pin your hopes on regulation, I’m not sure that’s great. I’m weirdly more optimistic about landmark legal cases. So we’re seeing an Australian mayor who was totally defamed by ChatGPT, in Australia, he’s going to be taking or is taking OpenAI to court. And then we might see some of these copyright issues, that could be taken to court, right. And like, that’s where people I think will get more action and, frankly, more respect, because these companies are really happy to pay a lot of money to lobby our lawmakers, and water stuff down. And they always say, Oh, my God, it’s going to constrain innovation. And if they really get desperate, they’ll be like, China! If we don’t, if we’re not allowed to do everything we want, China will win! That is like a– that is just a game that takes everybody nowhere, whereas in the lawsuit angle, that’s interesting, because you’re demonstrating responsibility, you’re discussing liability, you’re having to demonstrate harm. And in the process of discovery, right, you might be able to actually get some of these companies to open up their datasets, how their algorithms work, like, I’m much more intrigued to see where that’s gonna go.</p>
<p><strong>Brian Tarran</strong><br>
Yeah, but I think I mean, having read your book, I would, I would have thought you might perceive all of this sort of stuff as kind of sticking plasters to put over the the injuries that might be caused by these technologies, right? Your argument seems to be that we have an issue whereby we don’t have a culture of technology ethics. So when we’re thinking about building these tools, or when we’re starting off down the path of creating something like this, we’re not already thinking about, you know, the use cases, the harms that might arise from that and things like that. What does it take to build a culture of technology ethics, do you think, in our society, in our academic institutions in our companies?</p>
<p><strong>Stephanie Hare</strong><br>
Honestly, I think, I think this whole accountability piece is going to be what it takes. Because you see, like Alphabet CEO Sundar Pichai gave an interview recently to CBS 60 Minutes in the US where he was like, yeah, there’s a risk that this technology could get out of control, like dot dot dot, this would be terrible for mankind. And you see him kind of be like, hope somebody does something about that. And it’s like, I know somebody that might do something about that, Mr Pichai – you! But clearly he feels, and you can see his point, he feels that right now, if it’s not illegal, then it’s permissible. And he has to win market share. If he doesn’t do it, he’s going to lose. And companies have this all the time. If they wait too long, they lose their first-mover advantage, and they get destroyed. We can go through like countless examples of that in business, particularly in technology. So I get it. But what he isn’t understanding is that if his company is the one that puts out the technology that leads to terrible harm – you know, physically killing people, harming them, destroying the national security infrastructure, something like that – right now, I don’t think he’s thinking about how that’s going to affect him. And that’s because we don’t really penalise executives very often. The worst that might happen is they might leave with a huge golden parachute, and go off and sort of retire in Hawaii with their millions, right? Like nothing really happens to them. So how do you have a culture of technology ethics, where the people who are creating technology and have the power to stop, right, to maybe like back off on stuff, they aren’t really thinking about how will I personally be held responsible if this goes south? So like, Sam Altman and OpenAI, same thing, he was like, he gave an interview where he’s like, I’m really scared about this technology I’m building. It’s like, okay, you could slow down or back off, you could make your datasets open, you could make your algorithms open. You’re called Open AI, that was supposed to be your whole mission, why you were created was to benefit humanity, like, what are you doing? So it’s weird. And I think it comes from the fact that, you know, move fast and break things was the mantra for this culture for a really long time, at least out of the US. And it made a lot of people a lot of money, and they got worshipped by the media. And you know, they have a whole audience of bros who are fans of them. And they’ve never really, any of them, been held to account for what they’ve built.</p>
<p><strong>Brian Tarran</strong><br>
So your interest in technology ethics clearly predates you know, that all the noise at the moment around large language models and generative AI and things like that. What was it that got you interested in this subject? Was it a particular application, something that caused some concern? Or– How did it come about?</p>
<p><strong>Stephanie Hare</strong><br>
This is gonna sound completely weird, but it didn’t come from my experience in tech, really, at all. I have had two paths in my adult life, one has been working in these technology companies with a brief but happy foray in political risk, which is now sort of part of the skill set for tech. But I trained as an historian, and I interviewed someone who was a French civil servant, who at the end of his life was put on trial for crimes against humanity for his actions as a young civil servant during the Second World War. So he collaborated, as so many French civil servants did. And in the course of that collaboration, over a period of many years, went from just, you know, just signing documents and kind of doing what he was told to do, to deporting people and sending them to Auschwitz. So I was very young when I interviewed him, and that marked me, as I would hope it would mark anybody. I talked with him on and off for about three years, until he died. And that was the subject of my PhD. And then I did a fellowship at St.&nbsp;Anthony’s College, Oxford, and spent years looking at it further. And that’s actually going to be my next book. I needed a long time to sit with that material and to read around it, but I had to get the interview while he was still alive. He was so old, he was 93 when I started talking to him, and so it was important to get that down for posterity’s sake first, and then circle back and do some analysis later when I was a bit older. When you talk to somebody who in his case was, you know, not antisemitic, not of the far right politically, was actually like centre-left, had lots of Jewish friends, etc. Was like top of his class, you know, came from a milieu and a background and a formation that I think many of us would read and be like, Okay, that seems pretty reasonable. You ask yourself, how on earth did that person in his, like, young period of his late 20s, early 30s end up being involved and actively participating in what ends up being mass murder. It’s probably the most extreme case study of ethics, or one of the most extreme case studies of ethics that I could have stumbled upon. And it stayed with me and to be honest, it shapes a lot of my work and how I think about human rights and civil liberties and the freedoms that we so often take for granted because I’ve studied, as an historian looking at France and Germany, how quickly those things can be taken away – very quickly, terrifyingly so, in fact. So that lens is always with me. And when I was then working in technology, and seeing some of the things that could be done with these tools and watching this lack of accountability, down to the point of gross negligence in some cases. And also, as a young technologist, not being given any training – we were given no training at all in ethics, in, like, discussing data protection – it was basically: this is the law, just obey the law, like, that’s the, that’s the box that you have to play in. Other than that, like, go for it. And when I look back on that now it’s like, Oh, my God, that’s the equivalent of putting your family in the car, and everybody goes off without wearing their seatbelts on and, you know, all this sort of safety design that we take for granted in cars now, it’s just mad when you think about it, or the way we used to fly. We’re in this phase, it’s really interesting, just over the course of my career – 25 years – where the stuff that we’re talking about today that dominates the headlines, right, that is dominating the discussion in the tech sector, was not discussed at all at the turn of the century, other than by maybe people in the science and technology studies domain or academics. But it wasn’t filtering into boardrooms. It wasn’t on the front pages of newspapers, and it wasn’t being covered in the national news, whereas like now that is all I’m doing. So it’s amazing. A whole field has sprung up.</p>
<p><strong>Brian Tarran</strong><br>
I think that that kind of origin story, if you like, explains some of your, perhaps, belief in the importance of exploring this accountability question when it comes to technology, ethics?</p>
<p><strong>Stephanie Hare</strong><br>
Yeah, because I watched it, and I think what was so fascinating– So as I say, I was in my early 20s. In fact, I was 20, when this man was put on trial, and I had just moved to France. It was the longest trial in French legal history – it was a big deal, you could not not watch it. So I was reading this and seeing it in the press every day, and I watched the French people discussing it around me, you know, really being divisive, this stuff does not go away. And his view was: I was just following orders, I was doing what I was told to do. Which you know, you hear that a lot from engineers or people who are like, this is the design spec I’ve been given, or this is what my boss has told me to do, or this is what our investors want, etc. Or people feel they don’t have the power to stand up because, you know what, they’ve got a mortgage, they’ve got kids, and employers know that, like, they know that and they use it as leverage against people to silence them. Or they’ve signed an NDA, because we get made to sign these NDAs when we work in tech, and then we get made to sign another NDA when we leave, right, so we can’t disparage our employer, and maybe we’re given some money so we don’t talk about the things we’ve seen. You know, it’s, it’s gross – it’s a gross little world, and like you have to be very, very solid and take good care of yourself to work in it, I reckon. To try and keep your ethical and moral compass. It’s hard. So I think because I saw that. And I saw that someone who – whether we believe him or not, this is what he claimed – in his 30s, he was just doing kind of what everybody around him was doing under a situation of crisis. He was let off the hook. I mean, he wasn’t just not persecuted in 1945, he was actually promoted. And then he became France’s top civil servant, and then he became an MP, and then he became budget minister. I mean, this guy’s career was not hurt in any way by what he did. On the contrary, right, he advanced. And yet, by the end of his life, French values had changed, so a new generation wanted to hold him to account. And I think about that a lot for all of us, right, who are sort of walking around in our 30s or 40s. Another generation or two, when we’re older, might look at some of what technology we’ve built or our behaviour on climate change, our track record – did we do what we could have done to slow global warming, to improve biodiversity? – and they might, they might hold us to account saying, you could have stopped this and you didn’t, right? It’s not just what you did. It’s what you did not do. Right. So we have to be super careful when we think about ethics, because ethics change, values change over time. And what seems okay today may not be okay in 10, 20, 30 years time, and we might be the 80- or 90-year-olds who are put on trial. That is on my mind all the time, right. It’s not very relaxing.</p>
<p><strong>Brian Tarran</strong><br>
No, and I guess it makes me think. Well, I mean, this is getting into the hypotheticals right. But is it– if we can’t necessarily predict or plan out how values might evolve over time, is it enough to be able to, to just say or to document that we asked the right questions at the time, rather than just doing things blindly. Is that where we need to kind of almost formalise our process of writing down, setting out, you know, we want to do this, we’ve considered these potential harms, we’ve considered these potential benefits, and we kind of document that so at least, you know, future generations can say well, “They thought about it. They might have not thought about it in the right way, but they tried”?</p>
<p><strong>Stephanie Hare</strong><br>
Absolutely, I think, you know, show your work and be like, these were our, you know, these were our sort of first principles of where we were starting from, this is the context in which we were making this decision. Because again, I don’t, I don’t necessarily fear the judgement of history in terms of if I get something wrong. People get stuff wrong all the time. That’s just being human. It’s, did I not care? You know, was I like, well, sorry, little little boys and girls who are babies now, like, I need to do my stuff, and like, I don’t care about you, right? That attitude is tough. Or I decided I just really, you know, I really needed to buy a flat. So I decided to work for some dodgy company, or dodgy, dodgy company that’s owned by a foreign government, but I knew it was going to be fine, and they’re offering me a tonne of money, and now I can go on nicer holidays. I’ve had these conversations with people about this literally this past week, like, these are live issues for people. There’s a cost of living crisis, ethics can feel like a luxury for some people rather than a necessity. And human beings are very bad, all of us, at thinking about, you know, future selves, right? Like we kind of, we optimise for how we’re feeling now, and we’ll deal with 20 years from now later if we even get there. So I think there’s that. There’s also– this really inspired the writing of the book, Technology is Not Neutral. I knew, I had this weird sense – I had just gone independent, so I had left working for these companies, I was not under any NDAs anymore, which right there gives you a clue; I could say what I wanted – but I also knew there was a chance that I was going to have to go back either into industry, or maybe work for a government, I don’t know what I’m going to need to do in the future or who I’m going to want to work with or what reasons I might even have for that. But I knew I had this window of being an independent researcher and broadcaster, that I could say whatever I wanted, and I had that thing of like, okay, if you’ve had a window of, say, five years, for example, what would you say if you were not afraid? If you were not scared? If you were like, you know, screw the money, screw the corporate pressure, screw the government, whatever, what do you want to talk to the public about? And my views were, I really wanted to talk to them about facial recognition, because I feel people just fundamentally do not understand how dangerous that technology is and how it can be used. I wanted to talk about the pandemic technologies, because we were, you know, I was writing it during the pandemic, and I thought, well, if a pandemic ever happens again, let’s have a nice little tidy case study for potentially future historians or future medical personnel, public health officials to pull out, because when the pandemic hit, we all had to go back and look at stuff from the Spanish flu. You know, there’s a lot of discussion of like, why has this come as such a surprise? Are we going to use these technologies again or not? Right. Like, you know, is it worth it? Is the return on investment worth it in all senses – ethically, as well as medically, all of those things? So I thought I would lay down a couple of markers that I hoped would stand the test of time. But the big thing I wanted to do, because I was always thinking I might have to go and sign another NDA and go work because I too must earn my living, was I wanted to write something so that anyone who cares about technology, is working in it, is investing in it, right – it’s not just people who code, it’s people who fund the people who code. Buying technology – procurement is massive, you’re a really powerful person if you’re in charge of procurement. But also just consumers, and citizens and parents, and teachers and kids. If I could write up everything that I had learned in my 25 years, and succinctly as possible, right – as short as possible, because people are tired, they’re busy – I could pass that baton on, so that if I ever have to stop going on television and radio, and I’m no longer allowed to write in newspapers and warn people about the stuff I’m seeing and the abuses of power, and showing them examples of history of how this can go so terribly wrong, maybe it will have, like, lit somebody else. And I’m delighted to report – I mean, we’ll see; time will tell, it’s only been out a year – the amount of people who have brought me in to train their staff, to talk to their board. I’ve talked to children. I’ve talked to university students, I’ve taught classes all over the world, because we can now do online teaching. I’ve taken a lot of it on television and radio and in the newspapers. People wanted this, and I’m not the only person working on it, of course – there’s been a whole flowering of people, scholars, etc., working in putting out amazing books and documentaries. It’s really, we’re having some sort of moment with technology ethics – AI ethics being just a branch of that. So that’s really encouraging. So I sort of feel like, you know, again, if I, if I’m gonna have to account for myself at the age of 93, I would like to be able to point to that and go, I tried. I tried. And I have no idea if it will succeed or not, but I stood up to the plate and I swung the bat and, you know, I aimed for the bleachers.</p>
<p><strong>Brian Tarran</strong><br>
One of the things I thought was really interesting about the book, it comes towards the end when you’re kind of talking about, you’re summing up, and you talk about how your thinking about almost like the the approach or solution to the technology ethics issue has changed over the course of the writing of the book. You had, like, a list of potential, like, proposals, proposed actions that you wanted to analyse, but then you realised that actually technology ethics is a “wicked problem”. I wonder if you could explain what that term means for people who might not be familiar with it and and why you think of it that way?</p>
<p><strong>Stephanie Hare</strong><br>
Yeah, I’m so grateful to have learned about the term “wicked problem”. My friend Jason Crabtree, who wrote an amazing book about electricity grids, like smart electricity grids, for Cambridge University Press, had asked me to read his manuscript maybe 10 years ago, and I read it, and one thing I took away that just absolutely blew my mind was this concept. So I shall gift it to you for those of you have not heard it. Because then suddenly, you’re like, God, it makes so much sense. There are certain problems, I would say, like, the climate crisis, and biodiversity loss would be a good example of this. There’s certain problems that have many causes, many causes, so there isn’t going to be one solution to fix them. So people constantly ask me, oh, is this the magic bullet? No, they’re like, there are certain problems that there is no magic bullet – the pandemic is probably another, actually. Then, if you do try to solve these wicked problems, the mere act of solving them can introduce a whole new set of problems to them. So like, it becomes even more of a head– You know, I’m trying not to swear, but a messing with your head moment. And it’s exhausting, you know, and it gives you your forehead wrinkles and makes you just sort of want to bang your forehead onto the nearest wall. And yet, you also can’t opt out and be like, well, it’s just too hard. It’s a wicked problem. There’s no solution, there’s nothing to be done, you know, throw up your hands, because you’re like, Yeah, but the problem is, is if we don’t do anything, like literally people are dying; literally, climates are becoming uninhabitable, we’re going to have massive climate migration, that’s going to cause all sorts of problems, water scarcity, we can have wars over this, like, we have to do something. So like, you have to still act on a wicked problem, all while knowing that it’s not going to be solved in a binary sense of like zero, one, black and white, I can point to it and measure it. And for people who like metrics, that’s a real pain, because they’re like, I want to know what good looks like and I want to know how we’ll know when we get there, you know, what’s the percentage, what’s the number? And you kind of have to be like, Well, with a wicked problem, you might never solve it, or you won’t solve it once. Because again, with something like climate change, or pandemics, these are things you’re probably gonna have to solve again, and again, and again, because it’s dynamic. And it’s constant, you know, we’re always going to be managing our relationship with the climate, with the environment. So, you know, we can pick a certain temperature, or a certain percentage of landmass that, you know, has trees or whatever, and like, come up with a little metric for our metric-oriented friends. But that’s still not very meaningful. So it’s more that when you think of a wicked problem, like facial recognition technologies, like, we need to be able to identify people in certain situations, and like, we want that, right. Like, we want to be able to catch criminals, and we want to be able to catch terrorists when they’ve managed to pull off a terrible act of, of harm to people. But at the same time, do you want to turn your society into a sort of permanent dragnet? Do we not care about privacy? If so, like, when do we care about privacy? And when are we okay with maybe sacrificing that for the greater good and who decides that? It’s really problematic if you live in London as I do, and your police force, which is using this technology, has admitted, they’ve admitted themselves to being misogynist, institutionally misogynist, homophobic, racist, right? And then we’re gonna give them a technology that doesn’t work very well on people with certain skin. It doesn’t identify people of a certain age as well. It’s got all sorts of problems. So you’re kind of like, hmm? Facial recognition is covered a bit under the EU AI Act. But even then there’s like so many loopholes. And the thing is, if you cite national security, it usually gets waved through because no one wants to be the person who said, I said we couldn’t use this technology, and then something bad happened. Right? So you err on the side of, like, the precautionary principle. The default is, let them use it. We must trust them. Except what do you do if your police force has given you quite ample evidence not to trust them? Or companies. You know, this is not to bash on the police, by the way – companies are some of the worst offenders in this area. So that’s what I mean about it being a wicked problem is, it’s out there. It’s installed. It’s all over the UK, it’s definitely all over the US as well. And we don’t really have a good framework for it.</p>
<p><strong>Brian Tarran</strong><br>
But then this is where we loop back around to the kind of culture, right, creating a culture of technology ethics? You know, we can’t just put a checklist in place once, do it, tick it off, yeah, we’ve done that for facial recognition technology, we’re good to go. Because there are always new potential use cases for it, new applications, new integrations with different systems that we always need to be thinking, every time, is this the right thing to do? Or–</p>
<p><strong>Stephanie Hare</strong><br>
I mean, I’m still a big fan of checklists. So it’s not that I’m anti-checklist. And I’m not saying that you said that, by the way, I’m more thinking aloud. Checklists can still be useful, right? Like, whenever I’m in a really bad mood, I’m like, Okay, hang on, have I slept? Do I just need a glass of water? Am I hungry? You know, what I think is angry may just be that I skipped lunch. You can kind of go through those things, and anybody who’s had to like troubleshoot why a baby or a small child is unhappy will also have a checklist and what’s on the thing – ah, they missed naptime, where’s their bear? That sort of thing. Companies need checklists, because you’re trying to get loads of people singing from the same hymn sheet, I get that. But what I wanted to get away from was this idea that, like, one person or one team gets this checklist and maybe does that once a year, once a quarter, pick your cadence – and everybody else gets a pass. Ethics doesn’t work that way, because again, ethics is kind of I think in the wicked problem scenario of, like, how do we decide what our values are and how to live them? And how do we know, where do we draw the line? And then how do you, how do you decide if you’ve gone over the line or not? And all of that, who decides who decides? Those are really complex questions that mean that really you can’t abdicate. This is, in a company’s case, it’s the CEO, it’s the board, all the way on down – it has to be baked in to every single employee, and also investors, mindset. And I was thinking about it in terms of cybersecurity, I once had a colleague who gave me an analogy that I think is helpful, so I’ll share it for what it’s worth: When you go on to, say, an oil rig, in the North Sea – a highly dangerous environment – you might be the most junior person there, and you’re there for your very first day of work. But if you spot something on that rig that is a health and safety risk, you have to speak up. You’re not going to go, like, Oh, my boss might say something, whatever, because, like, everybody’s life on that rig is depending on everyone having that culture of careful, that’s not okay. And that really put me in mind where it was like, Oh, wow, we’re going to have to like inculcate an entire new mindset. And we think about technology ethics a lot because of technology being the word, and we think it must mean like hardware or software, it’s always about coding, and it’s often guys in hoodies coding. But my preferred method of hacking is culture. Right. So like, again, if we tried to just solve everything through regulation and laws, that takes, you know – if you look at the average time it takes to pass a law and then for regulators to enforce it – ages, we’re talking years, like it’s too late. These technologies will have moved on. Ditto, calls for international treaties. Do it, by all means. Have a look at how long it takes most international treaties to get passed and then ratified – and then, P.S. What happens when people break them? Really, right. So like, they’re important, they’re necessary, but they’re insufficient. You can act a lot faster if you can get people preventing stuff from being built in the first place, and that means you need to have a culture of people working in technology, both within the organisations – whether that’s research labs, government, companies, universities, whatever – and on the outside – journalists, academics, thinkers, etc, just the public, an informed public – who can see something and do what I just described on the oil rig, like, sound the alarm and go, Wait a minute, hang on. That’s not okay. That is, that to me feels faster. And I’m way more into prevention than cure, for all sorts of reasons. So I think like, yes, to laws and regulations, yes, to treaties; this will be faster. And I think it will be more resilient.</p>
<p><strong>Brian Tarran</strong><br>
Yeah, I agree. And I have to say, wrapping up, that I think Technology is Not Neutral is a great place to start to inculcate that mind shift, that mindset change. So, Stephanie, thank you very much for joining us today.</p>
<p><strong>Stephanie Hare</strong><br>
Thank you for having me.</p>
<p><strong>Brian Tarran</strong><br>
You said you’re working on a new book. Have you got a timeline for that? Or a title?</p>
<p><strong>Stephanie Hare</strong><br>
No.&nbsp;I am the slowest thinker and writer, I’m like the opposite of move fast and break things, I’m like move slowly and like think it over maybe several times. So I’m just getting started out. I’ll sort of go five years. It’s gonna be, it’s a history book. Alright. So this is, this is different, I’m having to take my classes in French and German right now to get kind of match fit in those languages again, and then you know, I’ll be off and writing. But, yeah, I hope to have another book out, you know, in five years.</p>
<p><strong>Brian Tarran</strong><br>
Well, if the year it took me to read Technology is Not Neutral is any indication, in three, four or five years time it will still be relevant today. So–</p>
<p><strong>Stephanie Hare</strong><br>
That’s the thing with history, it always stands the test of time.</p>
<p><strong>Brian Tarran</strong><br>
Well, thank you, thank you again for joining us on Real World Data Science. It’s been a pleasure talking to you.</p>
<div class="article-btn">
<p><a href="../../../../../viewpoints/interviews/index.html">Find more Interviews</a></p>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-6">
<dl>
<dt>Copyright and licence</dt>
<dd>
<p>© 2023 Royal Statistical Society</p>
</dd>
</dl>
<p><a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> <img src="https://realworlddatascience.net/viewpoints/interviews/posts/04/28/https:/mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1" style="height:22px!important;vertical-align:text-bottom;"><img src="https://realworlddatascience.net/viewpoints/interviews/posts/04/28/https:/mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1" style="height:22px!important;margin-left:3px;vertical-align:text-bottom;"></a> This interview is licensed under a Creative Commons Attribution 4.0 (CC BY 4.0) <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> International licence</a>. Photo of Stephanie Hare is not covered by this licence. Photo is by Mitzi de Margary, supplied by Stephanie Hare and used with permission.</p>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>How to cite</dt>
<dd>
<p>Tarran, Brian. 2023. “‘I’m way more into prevention than cure’: Stephanie Hare on why we need a culture of technology ethics.” Real World Data Science, April 28, 2023. <a href="https://realworlddatascience.net/viewpoints/interviews/posts/04/28/stephanie-hare.html">URL</a></p>
</dd>
</dl>
</div>
</div>
</div>


</section>

 ]]></description>
  <category>Technology ethics</category>
  <category>AI ethics</category>
  <category>Culture</category>
  <category>Regulation</category>
  <guid>https://realworlddatascience.net/viewpoints/interviews/posts/04/28/stephanie-hare.html</guid>
  <pubDate>Fri, 28 Apr 2023 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/viewpoints/interviews/posts/04/28/images/stephanie-hare-bw.png" medium="image" type="image/png" height="105" width="144"/>
</item>
<item>
  <title>‘I always thought someone like me couldn’t work in data, let alone data science’</title>
  <dc:creator>Brian Tarran</dc:creator>
  <link>https://realworlddatascience.net/careers/career-profiles/posts/2023/04/24/sami-rahman.html</link>
  <description><![CDATA[ 




<p><strong>Hi, Sami. Thank you for sharing your career story with Real World Data Science. Please tell us a little about yourself and your role in data science.</strong><br>
Hello! I’m Sami Rahman, a passionate head of data engineering and data platform at Penguin Random House, the book publisher that has enriched lives through literature. I started my career in data science five years ago and I’ve evolved into a data generalist with expertise in machine learning, data infrastructure, and data strategy.</p>
<p><strong>What does your job involve?</strong><br>
My role is about harnessing the power of data to drive extraordinary outcomes. Leading a skilled team, we empower our company to leverage data and cutting-edge technologies for informed decisions and automation. I help shape our organisation’s capabilities in data science, analytics, machine learning, data management, and strategy.</p>
<p><strong>What does “data science” mean to you?</strong><br>
Data science, to me, is a captivating fusion of modern data technologies and computational statistics that tackles business challenges, crafts intelligent automation, and generates insightful revelations.</p>
<p><strong>What do you think is your most important skill as a data scientist?</strong><br>
Active listening is key. A data scientist must be surgical and precise in developing models, analysis, and tools that reinforce the company’s bottom line and operations. Data science exists to create value using data.</p>
<div class="pullquote-container">
<div class="grid">
<div class="g-col-12 g-col-lg-4">
<div class="quarto-figure quarto-figure-left">
<figure class="figure">
<p><img src="https://realworlddatascience.net/careers/career-profiles/posts/2023/04/24/images/sami-rahman.png" class="img-fluid figure-img" alt="Portrait photo of Sami Rahman"></p>
<figcaption class="figure-caption">Photo supplied by Sami Rahman, used with permission.</figcaption>
</figure>
</div>
</div>
<div class="g-col-12 g-col-lg-8 pullquote-grid pullquote">
<p><img src="https://realworlddatascience.net/images/pullquote-purple.png" class="img-fluid" width="50"></p>
<p>As I’ve transitioned into management, maintaining my coding prowess is an ongoing challenge. I stay sharp by doing data science and infrastructure development for fun, leveraging tools like ChatGPT and AirOps where I’m rusty.</p>
</div>
</div>
</div>
<p><strong>How did you get into data science?</strong><br>
I began with a psychology degree, which led to working as business psychologist where I discovered psychometric data analysis. After a master’s in countering organised crime and terrorism and a few short jobs in counter terrorism/intelligence, I decided that it wasn’t for me. I embraced my love for statistics and research, I dove into data science, learning Python through online platforms, and secured my first data scientist role at a WPP agency called Essence.</p>
<p><strong>What, or who, first inspired you to become a data scientist?</strong><br>
I always thought someone like me couldn’t work in data, let alone data science. <a href="https://www.wbs.ac.uk/about/person/suzy-moat/">Dr Suzy Moat’s</a> fascinating talk on machine learning’s application to human behaviour and psychology showed me that a psychologist could make a significant impact in this field, inspiring my aspiration to try to have a data science career.</p>
<p><strong>What were the hurdles or challenges that you needed to overcome on your route into the profession?</strong><br>
Breaking into data science without a typical background in maths/computer science/physics was daunting. Building a Kaggle portfolio and coding models for fun prepared me for interviews. Another challenge was learning to harmonise my “data brain” and “business brain” to solve problems efficiently. Understanding how data solutions impact business problems will always propel you forward. </p>
<p><strong>And what are the challenges that you face now, as a working data scientist?</strong><br>
As I’ve transitioned into management, maintaining my coding prowess is an ongoing challenge. I stay sharp by doing data science and infrastructure development for fun, leveraging tools like ChatGPT and AirOps where I’m rusty. I’m currently building my own cloud data platform and running a lot of image neural networks on it.</p>
<p><strong>What was your first job in data science, and how does it compare to your current role?</strong><br>
As an analytics executive at WPP agency Essence, I tackled data science, cloud engineering, and analytics problems for clients. They were a lot more singular and tactical in nature. Now, as head of data engineering and data platform at Penguin Random House, I focus on shaping data and technology strategy to align with the company’s broader vision.</p>
<p><strong>What was the most important thing you learned in your first year on the job?</strong><br>
To always consider the bigger picture: how your work integrates with the organisation/client’s objectives, delivers value, and aligns with the aspirations of other stakeholders. Actionable insights and value is the most important thing.</p>
<p><strong>What have been your career highlights so far?</strong><br>
Two shining moments include being the first of three of HSBC UK fraud data science leaders, where each of our departments tackled a different type of crime and protected our customers, and developing data strategies and capabilities for analytics, science, and business intelligence at Penguin Random House.</p>
<p><strong>Have there been any mistakes or regrets along the way?</strong><br>
I regret not delving deeper into natural language processing (NLP) or spatial data science, which are now more accessible and growing fields within data science. I reckon the NLP methodologies would’ve been extremely useful seeing as I’m at a publishing company now!</p>
<p><strong>How do you think your role will evolve over the rest of your career?</strong><br>
As data technologies become more accessible, I anticipate data roles will transform. I envision a future where data professionals focus on general AI, quantum machine learning, and multi-dimensional data analytics as traditional specialisms become democratised.</p>
<p><strong>If you were starting out in data science now, what three things would you put at the top of your reading/study list?</strong><br>
I’d recommend <em>Skin in the Game</em> by Nassim Nicholas Taleb, <em>Calling Bullshit: The Art of Scepticism in a Data-Driven World</em> by Jevin West and Carl Bergstrom,  and <em>Artificial Intelligence: How Machine Learning Will Shape the Next Decade</em> by Matthew Burgess.</p>
<p><strong>What personal or professional advice would you give for anyone wanting to be a data scientist now?</strong><br>
Success in data science hinges on understanding how it can transform organisations and engaging with business stakeholders. My advice: never stop listening to the business – the stakeholders are your biggest allies. I would also try to find your niche that sets you apart from everyone else. Mine when I first started in the field was my expertise on computational psychology and behavioural machine learning. </p>
<p><strong>What new ideas or developments in the field of data science are you personally most excited about or intrigued by?</strong><br>
Transfer learning excites me most, as numerous large technology companies now offer pre-trained models based on billions/trillions of parameters. This will revolutionise industries worldwide, as it will be easier to build more performant models even if a company has less data.</p>
<p><strong>What do you think will be the main challenges facing data science as a field in the next few years?</strong><br>
The challenge lies in staying relevant amidst the democratisation of data science. Through large language models, low-code, and transfer learning, advanced data science methods will become easier for non-specialists to do and use. Innovation and keeping up with modern data technologies will be crucial.</p>
<div class="article-btn">
<p><a href="../../../../../../careers/career-profiles/index.html">Discover more Career profiles</a></p>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-6">
<dl>
<dt>Copyright and licence</dt>
<dd>
© 2023 Royal Statistical Society
</dd>
</dl>
<p><a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> <img style="height:22px!important;vertical-align:text-bottom;" src="https://realworlddatascience.net/careers/career-profiles/posts/2023/04/24/https:/mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://realworlddatascience.net/careers/career-profiles/posts/2023/04/24/https:/mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"></a> This article is licensed under a Creative Commons Attribution 4.0 (CC BY 4.0) <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> International licence</a>. Photo of Sami Rahman is not covered by this licence.</p>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>How to cite</dt>
<dd>
Tarran, Brian. 2023. “‘I always thought someone like me couldn’t work in data, let alone data science.’” Real World Data Science, April 24, 2023. <a href="https://realworlddatascience.net/careers/career-profiles/posts/04/24/sami-rahman.html">URL</a>
</dd>
</dl>
</div>
</div>
</div>



 ]]></description>
  <category>Publishing</category>
  <category>Data engineering</category>
  <category>Data strategy</category>
  <category>Machine learning</category>
  <guid>https://realworlddatascience.net/careers/career-profiles/posts/2023/04/24/sami-rahman.html</guid>
  <pubDate>Mon, 24 Apr 2023 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/careers/career-profiles/posts/2023/04/24/images/sami-rahman-bw.png" medium="image" type="image/png" height="105" width="144"/>
</item>
<item>
  <title>The politics of performance measurement</title>
  <dc:creator>Noah Wright</dc:creator>
  <link>https://realworlddatascience.net/careers/posts/2023/04/18/politics-of-performance-measurement.html</link>
  <description><![CDATA[ 




<p>At the beginning of 2016, the Criminal Justice Division (CJD) of the Texas Governor’s Office received news all government agencies dread: budgets were to be cut. CJD oversaw a grant program that funded specialty courts throughout the state, however it was now being told that the program’s budget of $10.6m would be reduced 20% to $8.5m by 2018.</p>
<p>How should these cuts be distributed among grant holders? CJD had no meaningful performance data on which to base its decisions, and I would know: I was hired by the agency just a few months before to analyze grant performance. Still, decisions needed to be made. We had to come up with a plan of action, and the clock was ticking…</p>
<p>This is a story of making opportunity out of crisis, of the interaction between not just theory of change and technical implementation, but the “political” process of negotiating these changes with stakeholders in a manner that led to better decisions. Through careful outreach and continuous communication, we developed a data collection and performance assessment process that enabled us to allocate budget cuts in a manner widely accepted.</p>
<p>The story ends on a bittersweet note. But, along the way, there are lessons to be learned about how to find common ground, manage expectations, forge productive working partnerships, and sustain a data science project longer term.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://realworlddatascience.net/careers/posts/2023/04/18/images/crowd-of-voices.png" class="img-fluid figure-img" alt="A crowd of people talking, with speech bubbles representing the different voices, digital art. Image created by Real World Data Science using Microsoft Bing Image Creator" width="500"></p>
</figure>
</div>
<section id="step-1-consider-your-options" class="level2">
<h2 class="anchored" data-anchor-id="step-1-consider-your-options">Step 1: Consider your options</h2>
<p>Texas had over 150 specialty courts in 2016, providing a program of specialized services – usually drug treatment – to offenders as an alternative to incarceration. About half of the state’s specialty courts received CJD grant funds (and about half of grantees received 100% of their program budget from our grants). Funding cuts of the size we needed to make would not go over well with them. Any changes to the program would have to run a gauntlet of decision-makers including advisory boards, interest groups, and professional associations, most with contacts in the legislature.</p>
<p>Complicating this situation further, CJD didn’t even make the final funding decisions. We administered the grants, but the merit review process fell to the Specialty Courts Advisory Council, an appointed group of specialty courts staff and related experts who annually scored the grant applications we received. We needed to get them onboard.</p>
<p>The way our Executive Director saw it, we had three options to implement the cut in a way that could get us buy-in from stakeholders and the Advisory Council:</p>
<ol type="1">
<li><strong>Cut across the board.</strong> The Advisory Council would employ the same scoring method as the previous year but reduce each grant amount by 20%.</li>
</ol>
<p>This option would leave long-running grantees scrambling to make up for this shortfall by reducing services, laying off staff, or spending more of their limited local funds. Worse, it would punish all grantees equally – our most successful programs would be arbitrarily defunded.</p>
<ol start="2" type="1">
<li><strong>Fewer grants.</strong> Grants were scored based on the quality of their application and all grants that passed a certain threshold got funded. The Advisory Council would employ the same scoring method as the previous year but instead of funding the top $10.6m worth of grants, they would fund the top $8.5m worth.</li>
</ol>
<p>This seemed a less bad option than cutting across the board, but we would still run into the problem of arbitrarily defunding successful programs. Grants near the bottom of the Advisory Council’s cutoff that got funded the previous year would be denied renewal only because the goalposts had moved.</p>
<ol start="3" type="1">
<li><strong>Targeted funding.</strong> The Advisory Council would incorporate performance data and statewide strategic plan alignment into their scoring method and make cuts accordingly.</li>
</ol>
<p>At the time, the Advisory Council did not take performance into consideration when scoring grant applications. They agreed in theory that a grant requesting its tenth annual renewal should perhaps at some point be assessed on its outcomes, but they had never seen CJD commit to a rigorous performance assessment process before. We administered the grants, not them, so without our commitment to develop a performance assessment process, and their trust in that commitment, this would not be a viable option.</p>
<p>After due consideration, option 3 emerged as the favorite of our Executive Director. On the face of it, this seemed the most “objective” approach to take. We would let the data decide who gets funded and who doesn’t, rather than cutting arbitrarily. But that would be a fallacious argument. Data does not decide. It might inform our decisions, but it would be up to us to choose the structure of the performance measurement process: what aspects to focus on, what data to collect, what benchmarks to set – all of which would later help determine funding decisions. And in any funding decision, politics inevitably plays a role.</p>
<p>Politics is, in its broadest sense, the negotiated decision-making between groups with opposing interests. And in developing our performance measurement process we would encounter a variety of interests – from the Advisory Council down to the grantees themselves. Success would require us to acknowledge stakeholder perspectives and address or manage them appropriately. Planning decisions made in the early phases of a project as a result of political processes directly influence the type and scope of analysis a data scientist will eventually be able to perform, so it behooves the data scientist to participate in these processes!</p>
</section>
<section id="step-2-engage-stakeholders-and-define-performance" class="level2">
<h2 class="anchored" data-anchor-id="step-2-engage-stakeholders-and-define-performance">Step 2: Engage stakeholders and define performance</h2>
<p>Having settled on our preferred option, our Executive Director convened a strategy session with the Advisory Council to discuss how to proceed as part of a broader strategic plan. The session began by achieving consensus on high-level goals such as “fund strategically”, “focus on success”, “build capacity”, etc. The session also helped the Advisory Council and CJD alike to clarify our conception of how we ought to fit into the specialty courts field going forward. CJD would develop its performance assessment system to help the Advisory Council target funding, but that would come as part of a larger plan that included capacity building, training and technical assistance, helping courts obtain non-CJD sources of funding, and steering grantees toward established best practice.</p>
<p>We left the meeting with a very basic plan that looked good on paper. Our Executive Director set to work persuading our external stakeholders of the wisdom of this new strategic direction. Meanwhile, I had to build a performance assessment process that people could trust.</p>
<p>CJD had no formally designated standards to measure performance data against. However, drug courts have been around for decades and there existed a large body of research supporting the program model.<sup>1</sup> Offering supervised drug treatment instead of incarceration had been repeatedly shown to cost less money and lower recidivism rates. I performed a literature review and spoke with numerous subject matter experts to get started on defining program-specific performance metrics.</p>
<p>I was conscious that imposing metrics without any feedback or input from affected parties would all but guarantee bad-faith engagement, especially if these metrics are tied to funding. A problem inherent to any performance measurement is that once something gets measured as a performance outcome, it warps the very processes it is intended to measure. This phenomenon happens so frequently that the phrase “Campbell’s Law” was coined to describe it in 1979.<sup>2</sup> Think of standardized testing at schools: once the government ties test performance to school funding it creates powerful incentives for schools to improve test scores at any cost. Even in the absence of outright cheating, struggling schools feel massive pressure to adjust their curriculum, to the point where they teach test score optimization strategies more than math, language, history, and science.</p>
<p>I consistently heard from specialty court scholars and practitioners alike that arrest recidivism would be the ideal outcome measure. On paper, recidivism was a direct expression of long-term program success and could also be used as an outcome variable for classification modeling. And, in practice, a court could do little to affect recidivism by way of manipulation. Courts do not make arrests – police make arrests. Once a specialty court participant finished a program, the court itself no longer intervened in their lives. If a participant got arrested within 1-3 years of completion, the program had no say in the matter.</p>
<p>This, however, presented an implementation problem: one-year recidivism data would, by definition, take a year past the point of implementation to collect, i.e., not soon enough to inform our cuts. And while recidivism was the best measure of success, it could not be the only measure. Recidivism was, after all, a stochastic process not within the court’s control – a crime wave or other systemic factors could move recidivism up and make it look like a successful court had actually failed. We would have to use something else as well.</p>
<p>The National Association of Drug Court Professionals (NADCP) publishes a book of best practice standards, and our stakeholders identified a court’s adherence to these standards as another strong performance assessment standard. These criteria, unlike recidivism, were directly under the program’s control. Does your program have the recommended staff? Does your program drug test participants frequently enough to guarantee sobriety? Does your program meet with participants regularly enough? Do you offer a continuum of services instead of a “one-size-fits-all” approach?</p>
<p>In addition to being much easier to measure than recidivism, best practice adherence also resists Campbell’s Law by avoiding outcome measurement. In our school metaphor, this would be like measuring school performance based on student-to-teacher ratio, variety of course offerings, attendance rates, and teacher qualifications. Far from perfect, but measuring a variety of elements that predict success and taking them as a whole represents a vast improvement over a single, easily-gamed outcome measure.</p>
<p>But to operationalize these standards, we would have to have good data.</p>
</section>
<section id="step-3-update-processes-and-collect-data" class="level2">
<h2 class="anchored" data-anchor-id="step-3-update-processes-and-collect-data">Step 3: Update processes and collect data</h2>
<p>We inherited a longstanding process in which grantees had to fill out a form every six months asking them to report performance data. This is a screenshot of what that form looked like:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://realworlddatascience.net/careers/posts/2023/04/18/images/screenshot.png" class="img-fluid figure-img" alt="A screenshot of a data table containing example data collected from grantees in the Texas speciality courts funding program, prior to the development of a new performance measurement process."></p>
</figure>
</div>
<p>No additional definitions or instructions were provided, leaving grantees with many questions: Does the request for “annual data” mean as of fiscal year or calendar year? What counts as a person being “assessed for eligibility”? And so on. Grantees did not know the answers, and neither did we. And these were the more straightforward measures. The form went on for 10 pages, most of which asked grantees to report extensively on information they had already provided as part their application.</p>
<p>This disaster of an assessment process did have a silver lining. When we announced we were throwing out these forms entirely we faced almost no pushback from grantees.</p>
<p>We knew from the start that our new assessment process would need to collect individual-level participant data instead of aggregated measures. Even with clear definitions, 75 grants would mean 75 different aggregations at work. Asking the grantees to report their individual-level participant data in a consistent format and doing the aggregations ourselves meant a single aggregation at work.</p>
<p>But we needed to establish trust with grantees before making this request. Strictly speaking, we could mandate the reporting of this data. However, if that angered enough of our grantees, they or their contacts might take it up with our bosses at the Governor’s Office, and our bosses could cancel any plan we came up with if they thought it was not worth the fuss. So, from day one we communicated clearly to all grantees that we would maintain total transparency when it came to definitions and calculations. Before we used any calculated metric to assess performance we would send it to the grantees themselves to review for accuracy.</p>
<p>To avoid the vagueness and inscrutability that characterized the old reporting process, every piece of data we asked for in the new process had a clear written definition and specific reason for being asked. These reasons usually amounted to some combination of best practices, Advisory Council recommendations, and grantee suggestions.</p>
<p>Implementing the new process was far from easy, however. We faced numerous administrative and technical barriers. Texas courts at this time did not share a common case management system, so we couldn’t just get a data export from everybody. Meanwhile, the Governor’s Office banned all of its divisions from all usage of the cloud. This forced us to build a more labor-intensive reporting process, in which courts would obtain blank Excel templates with required data fields. Courts had either to fill out these templates by hand or export their case management data and reconfigure it to template specifications. Then, courts submitted their data for review and we sent back any bad formatting.</p>
<p>We collected preliminary data at the six-month mark and made another adjustment based on these results, which we would not count toward performance measurement. A majority of courts had some kind of data error in this first case. Specific definitions of data fields had to be written and rewritten using grantee feedback over the course of the year, leading to significant changes between the six-month reports and the year-end reports.</p>
<p>Importantly, we had developed reporting requirements iteratively with participation from grantees and the Advisory Council from the start. By mid-2017 we had so successfully achieved buy-in that only one grantee court’s judge refused to give us data (the court’s grant manager later sent it to us).</p>
</section>
<section id="step-4-analyze-and-report-findings" class="level2">
<h2 class="anchored" data-anchor-id="step-4-analyze-and-report-findings">Step 4: Analyze and report findings</h2>
<p>In the course of this process, we established the benchmarks in Table 1 based on best practices and justification for funding. Because this was our initial rollout, we set the specific values low to function more as minimum standards than targets.</p>
<div class="figure-caption">
<p><strong>Table 1:</strong> Specialty court best practices translated into quantitative measures.</p>
</div>
<table class="table">
<colgroup>
<col style="width: 34%">
<col style="width: 19%">
<col style="width: 46%">
</colgroup>
<thead>
<tr class="header">
<th>Benchmark</th>
<th style="text-align: center;">Best practice</th>
<th>Rationale</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1. Number of participants</td>
<td style="text-align: center;">10+</td>
<td>CJD decision: programs should be of sufficient size to justify a grant</td>
</tr>
<tr class="even">
<td>2. Number of graduates</td>
<td style="text-align: center;">5+</td>
<td>CJD decision: programs should be of sufficient size to justify a grant</td>
</tr>
<tr class="odd">
<td>3. Graduation rate</td>
<td style="text-align: center;">20%-90%</td>
<td>CJD decision: 0% and 100% success rates are both red flags</td>
</tr>
<tr class="even">
<td>4. Average amount of time graduates spent in program (in months)</td>
<td style="text-align: center;">12-24</td>
<td>NADCP best practice recommended program lengths of 1-2 years</td>
</tr>
<tr class="odd">
<td>5. Percent of graduates employed, seeking education, or supported through family, partner, SSI, etc.</td>
<td style="text-align: center;">100%</td>
<td>NADCP best practice recommended against releasing participants without financial support, which all but guarantees relapse or rearrest.</td>
</tr>
<tr class="even">
<td>6. Percent of participants with “low-risk” assessment score</td>
<td style="text-align: center;">0%</td>
<td>NADCP best practice recommended moderate- or high-risk participants. Research had shown that low-risk participants get little benefit.</td>
</tr>
<tr class="odd">
<td>7. Average sessions per participant per month</td>
<td style="text-align: center;">1+</td>
<td>NADCP best practice recommended sessions be held at least monthly.</td>
</tr>
</tbody>
</table>
<p>Grantee performance data for each benchmark would be generated from the individual level data that courts sent us. Crucially, we sent our aggregations back to grantees for confirmation prior to using them in any kind of evaluation, alongside the program-wide average and the best practice values for comparison (example in the table below). If something didn’t look right, they had the chance to let us know before we took their numbers as final.</p>
<div class="figure-caption">
<p><strong>Table 2:</strong> Specialty court best practices compared with program-wide averages and grantee reported values.</p>
</div>
<table class="table">
<colgroup>
<col style="width: 47%">
<col style="width: 17%">
<col style="width: 17%">
<col style="width: 17%">
</colgroup>
<tbody>
<tr class="odd">
<td><strong>Benchmark</strong></td>
<td style="text-align: center;"><strong>Best practice</strong></td>
<td style="text-align: center;"><strong>Program-wide average</strong></td>
<td style="text-align: center;"><strong>Grantee reported values</strong></td>
</tr>
<tr class="even">
<td>1. Number of participants</td>
<td style="text-align: center;">10+</td>
<td style="text-align: center;">89</td>
<td style="text-align: center;">96</td>
</tr>
<tr class="odd">
<td>2. Number of graduates</td>
<td style="text-align: center;">5+</td>
<td style="text-align: center;">25</td>
<td style="text-align: center;">27</td>
</tr>
<tr class="even">
<td>3. Graduation rate</td>
<td style="text-align: center;">20%-90%</td>
<td style="text-align: center;">71%</td>
<td style="text-align: center;">56%</td>
</tr>
<tr class="odd">
<td>4. Average amount of time graduates spent in program (in months)</td>
<td style="text-align: center;">12-24</td>
<td style="text-align: center;">17</td>
<td style="text-align: center;">14</td>
</tr>
<tr class="even">
<td>5. Percent of graduates employed, seeking education, or supported through family, partner, SSI, etc.</td>
<td style="text-align: center;">100%</td>
<td style="text-align: center;">95%</td>
<td style="text-align: center;">100%</td>
</tr>
<tr class="odd">
<td>6. Percent of participants with “low-risk” assessment score</td>
<td style="text-align: center;">0%</td>
<td style="text-align: center;">18%</td>
<td style="text-align: center;">2%</td>
</tr>
<tr class="even">
<td>7. Average sessions per participant per month</td>
<td style="text-align: center;">1+</td>
<td style="text-align: center;">2</td>
<td style="text-align: center;">3.7</td>
</tr>
</tbody>
</table>
<p>In the end, we found seven grants that we could unequivocally recommend be cut. Two of the seven had effectively never gotten off the ground, and served almost no participants the entire year. The other five served mostly low-risk participants, the type of people that research had shown do not benefit from specialty court programs. Some of these grantees were inevitably disappointed at the decision, but we had so actively worked within the field to develop and justify our processes that they understood why the decision had been made.</p>
</section>
<section id="factors-for-success" class="level2">
<h2 class="anchored" data-anchor-id="factors-for-success">Factors for success</h2>
<p>In the span of one year, CJD went from collecting a large volume of useless data to a specific, targeted collection of data informed by best practices. The new collection process had high grantee compliance and stakeholder buy-in.</p>
<p>The following factors proved essential to getting to a place where we had useful, reliable data upon which to base future data science efforts:</p>
<ol type="1">
<li><dl>
<dt>Discontent with status quo</dt>
<dd>
<p>The Advisory Council wanted CJD to play a more active support role in the field. Meanwhile, everyone disliked the existing performance assessment process. As a result, most of the challenges we faced along the way related to implementation rather than defending the status quo on its merits.</p>
</dd>
</dl></li>
<li><dl>
<dt>A catalyst for change</dt>
<dd>
<p>Despite existing discontent, it took a funding shortfall to kickstart the process of change. It would have been unlikely for us to be able to create this system <em>a priori</em>.</p>
</dd>
</dl></li>
<li><dl>
<dt>Continuous, high-quality communication</dt>
<dd>
<p>We could impose rules and requirements all day long, but without good faith engagement from the grantees we could never collect the quality of data we needed. Note that “continuous communication” does not mean “tell them everything you do at every point”. People become overwhelmed by torrents of information.</p>
</dd>
</dl></li>
<li><dl>
<dt>Humility and flexibility</dt>
<dd>
<p>Had we begun this process assuming we had all of the answers, we would have been dead in the water. Continuous outreach and willingness to take criticism and suggestions shaped the process as it progressed, ultimately producing a better end-product than we could have devised on our own.</p>
</dd>
</dl></li>
<li><dl>
<dt>An established program model</dt>
<dd>
<p>Drug courts have been around for decades, with a vast body of supporting research and a community of practitioners and scholars we could speak to. That meant we could focus on implementation and execution instead of determining if the model worked or not.</p>
</dd>
</dl></li>
<li><dl>
<dt>Strong leadership support</dt>
<dd>
<p>From the very beginning, we could not have accomplished what we did without the full support and advocacy of our Executive Director.</p>
</dd>
</dl></li>
</ol>
</section>
<section id="coda-why-knowledge-transfer-is-vital" class="level2">
<h2 class="anchored" data-anchor-id="coda-why-knowledge-transfer-is-vital">Coda: Why knowledge transfer is vital</h2>
<p>I wish I could write a follow-up article about how we started using classification modeling to identify the most successful programs and to promote better approaches and practices; about how we iterated the process through multiple funding cycles, tuning and perfecting it to better meet stakeholder needs. But I cannot.</p>
<p>The performance assessment system we built had some major weaknesses from the outset. It was labor intensive, not required by law, produced no immediate benefit to the agency itself, and was so new it had yet to be entrenched in agency practice. In other words, no institutional incentives worked in its favor. Only the continual push of our Executive Director and myself kept this new performance assessment system going, and once we left the agency, it foundered.</p>
<p>Still, the experience taught me much. I learned first and foremost that programs do not sustain themselves. Most of our attention had been focused on building up the best process we could. Only a minimal effort had been spent on institutionalizing and sustaining it. We had written documentation but no fundamental changes in policy or rule. We had undertaken groundbreaking efforts and built relationships, but had not planned for any meaningful knowledge transfer to other staff. While we had intended to eventually do these things, fate took us away before we could get them in place.</p>
<p>For any kind of change to last, sustainability must be built in from the start. In the moment, these actions can seem low-priority. Policy and rule changes can be arduous and time-consuming. Knowledge transfer from one stably employed staff to another feels redundant and wasteful. But without embedding sustainability, no success will outlast the individual people pushing for it.</p>
<div class="article-btn">
<p><a href="../../../../../careers/index.html">Back to Careers</a></p>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-12">
<dl>
<dt>About the author</dt>
<dd>
<strong>Noah Wright</strong> is a data scientist with the Texas Juvenile Justice Department. He is interested in the applications of data science to public policy in the context of real-world constraints, and the ethics thereof (ethics being highly relevant in his line of work). He can be reached on <a href="https://www.linkedin.com/in/noahdwright/">LinkedIn</a>.
</dd>
</dl>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>Copyright and licence</dt>
<dd>
© 2023 Noah Wright
</dd>
</dl>
<p><a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> <img style="height:22px!important;vertical-align:text-bottom;" src="https://realworlddatascience.net/careers/posts/2023/04/18/https:/mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://realworlddatascience.net/careers/posts/2023/04/18/https:/mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"></a> This article is licensed under a Creative Commons Attribution 4.0 (CC BY 4.0) <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> International licence</a>.</p>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>How to cite</dt>
<dd>
Wright, Noah. 2023. “The politics of performance measurement.” Real World Data Science, April 18, 2023. <a href="https://realworlddatascience.net/careers/posts/2023/04/18/politics-of-performance-measurement.html">URL</a>
</dd>
</dl>
</div>
</div>
</div>


</section>


<div id="quarto-appendix" class="default"><section id="footnotes" class="footnotes footnotes-end-of-document"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p>Some newer types of courts (Commercial Sexual Exploitation, Mental Health, Veterans) had a much more limited body of research and had to be accommodated separately. For the sake of keeping this narrative coherent I’m focusing on drug courts, which were the majority of our programs.↩︎</p></li>
<li id="fn2"><p>Rodamar, Jeffery. 2018. “There ought to be a law! Campbell versus Goodhart.” <em>Significance</em> 15 (6): 9. <a href="https://doi.org/10.1111/j.1740-9713.2018.01205.x" class="uri">https://doi.org/10.1111/j.1740-9713.2018.01205.x</a>↩︎</p></li>
</ol>
</section></div> ]]></description>
  <category>Problem definition</category>
  <category>Stakeholder communication</category>
  <category>Relationship management</category>
  <guid>https://realworlddatascience.net/careers/posts/2023/04/18/politics-of-performance-measurement.html</guid>
  <pubDate>Tue, 18 Apr 2023 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/careers/posts/2023/04/18/images/crowd-of-voices.png" medium="image" type="image/png" height="105" width="144"/>
</item>
<item>
  <title>A demonstration of the law of the flowering plants</title>
  <dc:creator>Jonathan Auerbach</dc:creator>
  <link>https://realworlddatascience.net/ideas/tutorials/posts/2023/04/13/flowers.html</link>
  <description><![CDATA[ 




<p>This tutorial will demonstrate a popular method for predicting the day a flower will bloom. There are many reasons why you might want to predict a bloom date. You might be a scientist studying ecosystems stressed by climate change. Or you might be planning a trip to Amsterdam and would like to time your stay to when the tulips are in bloom. Or maybe you are participating in the annual <a href="https://competition.statistics.gmu.edu/">Cherry Blossom Prediction Competition</a> and want some ideas to help you get started.</p>
<p>In any case, you might be surprised to learn that the day a flower blooms is one of the earliest phenomena studied with systematic data collection and analysis. The mathematical rule developed in the eighteenth century to make these predictions – now called the “law of the flowering plants” – shaped the direction of statistics as a field and is still used by scientists with relatively few changes.</p>
<p>We present the law of the flowering plants as it was stated by Adolphe Quetelet, an influential nineteenth century statistician. Upon completing this tutorial, you will be able to:</p>
<ol type="1">
<li>State the law of the flowering plants and explain how Quetelet derived it.</li>
<li>Reproduce Quetelet’s findings with weather data from the Global Historical Climatology Network.</li>
<li>Replicate Quetelet’s findings with more recent data from the USA National Phenology Network.</li>
<li>Predict the day the lilac will bloom in Brussels in 2023 with weather forecasts from AccuWeather.</li>
<li>Describe how the USA National Phenology Network uses the bloom dates of lilacs to monitor the start of spring.</li>
</ol>
<p>At the end of the tutorial, we challenge you to design an algorithm that beats our predictions. The tutorial uses the <code>R</code> programming language. In particular, the code relies on the following packages:</p>
<div class="sourceCode" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb1-1"><span class="in" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">```{r}</span></span>
<span id="cb1-2"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">library</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"knitr"</span>)</span>
<span id="cb1-3"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">library</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"kableExtra"</span>)</span>
<span id="cb1-4"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">library</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"tidyverse"</span>)</span>
<span id="cb1-5"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">library</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"plotly"</span>)</span>
<span id="cb1-6"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">library</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"rnoaa"</span>)</span>
<span id="cb1-7"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">library</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"rnpn"</span>)</span>
<span id="cb1-8"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">library</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"rvest"</span>)</span>
<span id="cb1-9"><span class="in" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">```</span></span></code></pre></div>
<section id="the-law-of-the-flowering-plants" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="the-law-of-the-flowering-plants">The law of the flowering plants</h2>
<p>We begin by reviewing the law of the flowering plants as it was stated by Adolphe Quetelet. You may already know Quetelet as the inventor of the body mass index. Less known is that Quetelet recorded the bloom dates of hundreds of different plants between 1833 and 1852 at the Brussels Observatory, which he founded and directed. Quetelet reported that a plant flowers when exposed to a specific quantity of heat, measured in degrees of Celsius squared (°C²). For example, he calculated that a lilac blooms when the sum of the daily temperatures squared exceeds 4264°C² following the last frost.</p>
<p>He communicated this law in his <em>Letters addressed to HRH the grand duke of Saxe-Coburg and Gotha</em> <span class="citation" data-cites="quetelet1846lettres quetelet_1849">(Number 33, 1846; translated 1849)</span> and in his reporting <em>On the climate of Belgium</em> <span class="citation" data-cites="observatoire1834annales quetelet_1857">(Chapter 4, Part 4, 1848; data updated in Part 7, 1857)</span>. A picture of Quetelet and the title page of <em>On the climate of Belgium</em> are displayed in Figure 1.</p>
<div class="no-row-height column-margin column-container"><div id="ref-quetelet1846lettres" class="csl-entry">
Quetelet, Adolphe. 1846. <em>Lettres à s.a.r. Le Duc Régnant de Saxe-Coburg Et Gotha: Sur La Théorie Des Probabilités, Appliquée Aux Sciences Morales Et Politiques</em>. Bruxelles: M. Hayez. <a href="https://catalog.hathitrust.org/Record/001387625">https://catalog.hathitrust.org/Record/001387625</a>.
</div><div id="ref-quetelet_1849" class="csl-entry">
———. 1849. <em>Letters Addressed to h.r.h. The Grand Duke of Saxe Coburg and Gotha on the Theory of Probabilities as Applied to the Moral and Political Sciences</em>. London: C. &amp; E. Layton. <a href="https://catalog.hathitrust.org/Record/008956987">https://catalog.hathitrust.org/Record/008956987</a>.
</div><div id="ref-observatoire1834annales" class="csl-entry">
Observatoire royal de Bruxelles. 1848. <em>Annales de l’observatoire Royal de Bruxelles</em>. Bruxelles: M. Hayez. <a href="https://catalog.hathitrust.org/Record/000553895">https://catalog.hathitrust.org/Record/000553895</a>.
</div><div id="ref-quetelet_1857" class="csl-entry">
———. 1857. <em>Sur Le Climat de La Belgique : De l’état Du Ciel En Général</em>. Bruxelles: M. Hayez. <a href="https://catalog.hathitrust.org/Record/000553895">https://catalog.hathitrust.org/Record/000553895</a>.
</div></div><div class="quarto-layout-panel">
<div class="quarto-layout-row quarto-layout-valign-top">
<div class="quarto-figure quarto-figure-center" style="flex-basis: 50.0%;justify-content: center;">
<figure class="figure">
<p><a href="images/quetelet_1875400.jpg" class="lightbox" title="Portrait of Adolphe Quetelet." data-description="Source:

<a
href=&quot;https://en.wikipedia.org/wiki/Adolphe_Quetelet#/media/File:Adolphe_Qu%C3%A9telet_by_Joseph-Arnold_Demannez.jpg&quot;>Wikimedia
Commons</a>" data-gallery="Quetelet"><img src="https://realworlddatascience.net/ideas/tutorials/posts/2023/04/13/images/quetelet_1875400.jpg" class="img-fluid figure-img" alt="Portrait of Adolphe Quetelet."></a></p>
</figure>
</div>
<div class="quarto-figure quarto-figure-center" style="flex-basis: 50.0%;justify-content: center;">
<figure class="figure">
<p><a href="images/sur_le_climat400.jpeg" class="lightbox" title="Title page of Adolphe Quetelet's 'On the climate of Belgium'." data-description="Source:

<a href=&quot;https://gallica.bnf.fr/ark:/12148/bpt6k95028d&quot;>Gallica</a>" data-gallery="Quetelet"><img src="https://realworlddatascience.net/ideas/tutorials/posts/2023/04/13/images/sur_le_climat400.jpeg" class="img-fluid figure-img" alt="Title page of Adolphe Quetelet's 'On the climate of Belgium'."></a></p>
</figure>
</div>
</div>
</div>
<div class="figure-caption">
<p><strong>Figure 1:</strong> Quetelet reported on the law of the flowering plants in <em>On the climate of Belgium</em> (1857). Sources: <a href="https://en.wikipedia.org/wiki/Adolphe_Quetelet#/media/File:Adolphe_Qu%C3%A9telet_by_Joseph-Arnold_Demannez.jpg">Wikimedia Commons</a>, <a href="https://gallica.bnf.fr/ark:/12148/bpt6k95028d">Gallica</a>.</p>
</div>
<p>Quetelet was not the first to study bloom dates. Anthophiles have recorded the dates that flowers bloom for centuries. Written records of cherry trees go back as far as 812 AD in Japan and peach and plum trees as far as 1308 AD in China. Systematic record keeping began a century before Quetelet with Robert Marsham’s <em>Indications of Spring</em> <span class="citation" data-cites="marsham_1789">(1789)</span>.</p>
<div class="no-row-height column-margin column-container"><div id="ref-marsham_1789" class="csl-entry">
Marsham, Robert. 1789. <span>“XIII. Indications of Spring, Observed by Robert Marsham, Esquire, f. R. S. Of Stratton in Norfolk. Latitude 52° 45’.”</span> <em>Philosophical Transactions of the Royal Society of London</em> 79: 154–56. <a href="https://doi.org/10.1098/rstl.1789.0014">https://doi.org/10.1098/rstl.1789.0014</a>.
</div><div id="ref-deréaumur_1735" class="csl-entry">
De Réaumur, René. 1735. <span>“Observations Du Thermometre, Faites a Paris Pendant l’annees 1735, Comparees a Celles Qui Ont Ete Faites Sous La Ligne, a l’isle de France, a Alger Et En Quelques-Unes de Nos Isles de l’amerique.”</span> <em>Mémoire de l’Académie Royale Des Sciences</em>, 545–76. <a href="https://www.academie-sciences.fr/pdf/dossiers/Reaumur/Reaumur_pdf/p545_576_vol3532m.pdf">https://www.academie-sciences.fr/pdf/dossiers/Reaumur/Reaumur_pdf/p545_576_vol3532m.pdf</a>.
</div></div><p>Quetelet was also not the first to study the relationship between temperature and bloom dates. René Réaumur <span class="citation" data-cites="deréaumur_1735">(1735)</span>, an early adopter of the thermometer, noted the relationship before Marsham published his <em>Indications</em>. But Quetelet was the first to systematically study the relationship across a wide variety of plants and derive the amount of heat needed to bloom. An example of Quetelet’s careful record keeping can be seen in Figure 2, one of many tables he reported in his publications.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="images/quetelet_bloom.png" class="lightbox" title="A table of bloom dates at Brussels Observatory observed by Quetelet between 1839 and 1852." data-description="Source:

<a href=&quot;https://gallica.bnf.fr/ark:/12148/bpt6k95028d&quot;>Gallica</a>" data-gallery="quarto-lightbox-gallery-3"><img src="https://realworlddatascience.net/ideas/tutorials/posts/2023/04/13/images/quetelet_bloom.png" class="img-fluid figure-img" alt="A table of bloom dates at Brussels Observatory observed by Quetelet between 1839 and 1852." width="600"></a></p>
</figure>
</div>
<div class="figure-caption">
<p><strong>Figure 2:</strong> Bloom dates at Brussels Observatory observed by Quetelet between 1839 and 1852. Source: <a href="https://gallica.bnf.fr/ark:/12148/bpt6k95028d">Gallica</a>.</p>
</div>
</section>
<section id="reproducing-quetelets-law-of-the-flowering-plants" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="reproducing-quetelets-law-of-the-flowering-plants">Reproducing Quetelet’s law of the flowering plants</h2>
<p>To reproduce Quetelet’s law, we combine the data in Figure 2 with additional observations from his <em>Letters</em>. We focus on Quetelet’s primary example, the bloom date of the common lilac, <em>Syringa vulgaris</em>, row 18 of Figure 2. We do this because Quetelet carefully describes his methodology for measuring the bloom date of lilacs. For example, Quetelet considers a lilac to have bloomed when “the first corolla opens and shows the stamina.” That event is closest to what the USA Phenology Network describes as “open flowers”, depicted in the center image of Figure 3 below. This detail will become relevant when we attempt to replicate Quetelet’s law in a later section. Note that although we focus on lilacs in this tutorial, the <code>R</code> code is easily edited to predict the day that other plants will bloom.</p>
<div class="quarto-layout-panel">
<div class="quarto-layout-row quarto-layout-valign-top">
<div class="quarto-figure quarto-figure-center" style="flex-basis: 33.3%;justify-content: center;">
<figure class="figure">
<p><a href="images/buds250.jpg" class="lightbox" title="Photo of lilac flower buds." data-description="Source:

<a href=&quot;https://www.usanpn.org/nn/TrackaLilac&quot;>USA National Phenology
Network</a>" data-gallery="flowers"><img src="https://realworlddatascience.net/ideas/tutorials/posts/2023/04/13/images/buds250.jpg" class="img-fluid figure-img" alt="Photo of lilac flower buds."></a></p>
</figure>
</div>
<div class="quarto-figure quarto-figure-center" style="flex-basis: 33.3%;justify-content: center;">
<figure class="figure">
<p><a href="images/open_flowers250.jpg" class="lightbox" title="Photo of open lilac flowers." data-description="Source:

<a href=&quot;https://www.usanpn.org/nn/TrackaLilac&quot;>USA National Phenology
Network</a>" data-gallery="flowers"><img src="https://realworlddatascience.net/ideas/tutorials/posts/2023/04/13/images/open_flowers250.jpg" class="img-fluid figure-img" alt="Photo of open lilac flowers."></a></p>
</figure>
</div>
<div class="quarto-figure quarto-figure-center" style="flex-basis: 33.3%;justify-content: center;">
<figure class="figure">
<p><a href="images/full_flowers250.jpg" class="lightbox" title="Photo of full lilac flowers." data-description="Source:

<a href=&quot;https://www.usanpn.org/nn/TrackaLilac&quot;>USA National Phenology
Network</a>" data-gallery="flowers"><img src="https://realworlddatascience.net/ideas/tutorials/posts/2023/04/13/images/full_flowers250.jpg" class="img-fluid figure-img" alt="Photo of full lilac flowers."></a></p>
</figure>
</div>
</div>
</div>
<div class="figure-caption">
<p><strong>Figure 3:</strong> The bloom date occurs when the first corolla opens and shows the stamina (center image). Source: <a href="https://www.usanpn.org/nn/TrackaLilac">USA National Phenology Network</a>.</p>
</div>
<p>In the <code>R</code> code below, the five-column tibble <code>lilac</code> contains the date each year that Quetelet observed the lilacs bloom at Brussels Observatory. The first three columns are the month, day, and year the lilacs bloomed between 1839 and 1852. These columns are combined to form the fourth column, the full date the lilacs bloomed. The last column converts the date to the day of the year the lilacs bloomed, abbreviated “doy.” That is, “doy” is the number of days it took for the lilacs bloom following January 1. Both “date” and “doy” representations of Quetelet’s observations will be useful throughout this tutorial.</p>
<div class="sourceCode" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb2-1"><span class="in" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">```{r}</span></span>
<span id="cb2-2">lilac <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span>                   </span>
<span id="cb2-3">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">tibble</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">month =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">c</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"May"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"April"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"April"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"April"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"April"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"April"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"May"</span>, </span>
<span id="cb2-4">                   <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"April"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"May"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"April"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"May"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"April"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"May"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"May"</span>),</span>
<span id="cb2-5">         <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">day   =</span>  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">c</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">28</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">24</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">28</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">20</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">25</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">13</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">12</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">9</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">21</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">30</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">12</span>),</span>
<span id="cb2-6">         <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">year  =</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1839</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1852</span>,</span>
<span id="cb2-7">         <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">date  =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">as.Date</span>(<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">paste</span>(month, day, year), <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">format =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"%B %d %Y"</span>),</span>
<span id="cb2-8">         <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">doy   =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">parse_number</span>(<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">format</span>(date, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"%j"</span>))) </span>
<span id="cb2-9"></span>
<span id="cb2-10">lilac <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span> </span>
<span id="cb2-11">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">kable</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">align =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"c"</span>,</span>
<span id="cb2-12">        <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">caption =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Table 1: Bloom dates of lilacs observed by Quetelet between 1839 and 1852."</span>) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span></span>
<span id="cb2-13">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">kable_styling</span>() <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span></span>
<span id="cb2-14">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">scroll_box</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">width =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"100%"</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">height =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"400px"</span>)</span>
<span id="cb2-15"><span class="in" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">```</span></span></code></pre></div>
<div id="tab-table1">
<div style="border: 1px solid #ddd; padding: 0px; overflow-y: scroll; height:400px; overflow-x: scroll; width:100%; margin-bottom: 1.5em;">

<table class="table" style="margin-left: auto; margin-right: auto;">
<caption>
<b>Table 1:</b> Bloom dates of lilacs observed by Quetelet between 1839 and 1852.
</caption>
<thead>
<tr>
<th style="text-align:center;position: sticky; top:0; background-color: #FFFFFF;">
month
</th>
<th style="text-align:center;position: sticky; top:0; background-color: #FFFFFF;">
day
</th>
<th style="text-align:center;position: sticky; top:0; background-color: #FFFFFF;">
year
</th>
<th style="text-align:center;position: sticky; top:0; background-color: #FFFFFF;">
date
</th>
<th style="text-align:center;position: sticky; top:0; background-color: #FFFFFF;">
doy
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center;">
May
</td>
<td style="text-align:center;">
10
</td>
<td style="text-align:center;">
1839
</td>
<td style="text-align:center;">
1839-05-10
</td>
<td style="text-align:center;">
130
</td>
</tr>
<tr>
<td style="text-align:center;">
April
</td>
<td style="text-align:center;">
28
</td>
<td style="text-align:center;">
1840
</td>
<td style="text-align:center;">
1840-04-28
</td>
<td style="text-align:center;">
119
</td>
</tr>
<tr>
<td style="text-align:center;">
April
</td>
<td style="text-align:center;">
24
</td>
<td style="text-align:center;">
1841
</td>
<td style="text-align:center;">
1841-04-24
</td>
<td style="text-align:center;">
114
</td>
</tr>
<tr>
<td style="text-align:center;">
April
</td>
<td style="text-align:center;">
28
</td>
<td style="text-align:center;">
1842
</td>
<td style="text-align:center;">
1842-04-28
</td>
<td style="text-align:center;">
118
</td>
</tr>
<tr>
<td style="text-align:center;">
April
</td>
<td style="text-align:center;">
20
</td>
<td style="text-align:center;">
1843
</td>
<td style="text-align:center;">
1843-04-20
</td>
<td style="text-align:center;">
110
</td>
</tr>
<tr>
<td style="text-align:center;">
April
</td>
<td style="text-align:center;">
25
</td>
<td style="text-align:center;">
1844
</td>
<td style="text-align:center;">
1844-04-25
</td>
<td style="text-align:center;">
116
</td>
</tr>
<tr>
<td style="text-align:center;">
May
</td>
<td style="text-align:center;">
13
</td>
<td style="text-align:center;">
1845
</td>
<td style="text-align:center;">
1845-05-13
</td>
<td style="text-align:center;">
133
</td>
</tr>
<tr>
<td style="text-align:center;">
April
</td>
<td style="text-align:center;">
12
</td>
<td style="text-align:center;">
1846
</td>
<td style="text-align:center;">
1846-04-12
</td>
<td style="text-align:center;">
102
</td>
</tr>
<tr>
<td style="text-align:center;">
May
</td>
<td style="text-align:center;">
9
</td>
<td style="text-align:center;">
1847
</td>
<td style="text-align:center;">
1847-05-09
</td>
<td style="text-align:center;">
129
</td>
</tr>
<tr>
<td style="text-align:center;">
April
</td>
<td style="text-align:center;">
21
</td>
<td style="text-align:center;">
1848
</td>
<td style="text-align:center;">
1848-04-21
</td>
<td style="text-align:center;">
112
</td>
</tr>
<tr>
<td style="text-align:center;">
May
</td>
<td style="text-align:center;">
2
</td>
<td style="text-align:center;">
1849
</td>
<td style="text-align:center;">
1849-05-02
</td>
<td style="text-align:center;">
122
</td>
</tr>
<tr>
<td style="text-align:center;">
April
</td>
<td style="text-align:center;">
30
</td>
<td style="text-align:center;">
1850
</td>
<td style="text-align:center;">
1850-04-30
</td>
<td style="text-align:center;">
120
</td>
</tr>
<tr>
<td style="text-align:center;">
May
</td>
<td style="text-align:center;">
1
</td>
<td style="text-align:center;">
1851
</td>
<td style="text-align:center;">
1851-05-01
</td>
<td style="text-align:center;">
121
</td>
</tr>
<tr>
<td style="text-align:center;">
May
</td>
<td style="text-align:center;">
12
</td>
<td style="text-align:center;">
1852
</td>
<td style="text-align:center;">
1852-05-12
</td>
<td style="text-align:center;">
133
</td>
</tr>
</tbody>

</table>
</div>
</div>
<p>To reproduce Quetelet’s law of the flowering plants, we will combine these bloom dates with daily temperature. The daily maximum and minimum temperatures at Brussels Observatory between 1839 and 1852 are available from the Global Historical Climatology Network. The data can be downloaded using the <code>ghcnd_search</code> function contained within the <code>R</code> package <code>rnoaa</code> <span class="citation" data-cites="chamberlain_2021">(2021)</span>. The station id for Brussels Observatory is “BE000006447”.</p>
<div class="no-row-height column-margin column-container"><div id="ref-chamberlain_2021" class="csl-entry">
Chamberlain, Scott. 2021. <span>“’NOAA’ Weather Data from r [r Package Rnoaa Version 1.3.8].”</span> <em>The Comprehensive R Archive Network</em>. Comprehensive R Archive Network (CRAN). <a href="https://CRAN.R-project.org/package=rnoaa">https://CRAN.R-project.org/package=rnoaa</a>.
</div></div><p>The <code>ghcnd_search</code> function returns the maximum and minimum temperature as separate tibbles in a list. In the <code>R</code> code below, we join the tibbles using the <code>reduce</code> function. Note that the temperature is reported in tenths of a degree (i.e.&nbsp;0.1°C) so we divide by 10 before calculating the temperature midrange, our estimate of the daily temperature.</p>
<p>The result is a five-column tibble <code>temp</code>, which contains the year of the temperature record (“year”), the date of the temperature record (“date”), the maximum temperature (“tmax”), the minimum temperature (“tmin”), and the midrange temperature (“temp”). The first 10 rows of the table are below. When you produce the full table yourself, you may notice that a small portion of temperature records are missing. We found that imputing these missing values does not significantly change the results. Therefore, we ignore these days when conducting our analysis.</p>
<div class="sourceCode" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb3-1"><span class="in" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">```{r}</span></span>
<span id="cb3-2">temp <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> </span>
<span id="cb3-3">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">ghcnd_search</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">stationid =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"BE000006447"</span>,</span>
<span id="cb3-4">               <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">var =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">c</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"tmax"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"tmin"</span>),</span>
<span id="cb3-5">               <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">date_min =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"1839-01-01"</span>,</span>
<span id="cb3-6">               <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">date_max =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"1852-12-31"</span>) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span></span>
<span id="cb3-7">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">reduce</span>(left_join) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span></span>
<span id="cb3-8">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">transmute</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">year =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">parse_number</span>(<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">format</span>(date, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"%Y"</span>)), </span>
<span id="cb3-9">            date, </span>
<span id="cb3-10">            <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">tmax =</span> tmax <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>, </span>
<span id="cb3-11">            <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">tmin =</span> tmin <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>, </span>
<span id="cb3-12">            <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">temp =</span> (tmax <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> tmin) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>)</span>
<span id="cb3-13">  </span>
<span id="cb3-14">temp <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span> </span>
<span id="cb3-15">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">kable</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">align =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"c"</span>, </span>
<span id="cb3-16">        <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">col.names =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">c</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"year"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"date"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"maximum temperature (°C)"</span>, </span>
<span id="cb3-17">                      <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"minimum temperature (°C)"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"midrange temperature (°C)"</span>),</span>
<span id="cb3-18">        <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">caption =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Table 2: Temperature observed at Brussels Observatory between 1839 and 1852."</span>) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span></span>
<span id="cb3-19">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">kable_styling</span>() <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span></span>
<span id="cb3-20">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">scroll_box</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">width =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"100%"</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">height =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"400px"</span>)</span>
<span id="cb3-21"><span class="in" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">```</span></span></code></pre></div>
<div id="tab-table2">
<div style="border: 1px solid #ddd; padding: 0px; overflow-y: scroll; height:400px; overflow-x: scroll; width:100%; margin-bottom: 1.5em;">

<table class="table" style="margin-left: auto; margin-right: auto;">
<caption>
<b>Table 2:</b> Temperature observed at Brussels Observatory between 1839 and 1852.
</caption>
<thead>
<tr>
<th style="text-align:center;position: sticky; top:0; background-color: #FFFFFF;">
year
</th>
<th style="text-align:center;position: sticky; top:0; background-color: #FFFFFF;">
date
</th>
<th style="text-align:center;position: sticky; top:0; background-color: #FFFFFF;">
maximum temperature (°C)
</th>
<th style="text-align:center;position: sticky; top:0; background-color: #FFFFFF;">
minimum temperature (°C)
</th>
<th style="text-align:center;position: sticky; top:0; background-color: #FFFFFF;">
midrange temperature (°C)
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center;">
1839
</td>
<td style="text-align:center;">
1839-01-01
</td>
<td style="text-align:center;">
5.7
</td>
<td style="text-align:center;">
-0.2
</td>
<td style="text-align:center;">
2.75
</td>
</tr>
<tr>
<td style="text-align:center;">
1839
</td>
<td style="text-align:center;">
1839-01-02
</td>
<td style="text-align:center;">
6.3
</td>
<td style="text-align:center;">
0.8
</td>
<td style="text-align:center;">
3.55
</td>
</tr>
<tr>
<td style="text-align:center;">
1839
</td>
<td style="text-align:center;">
1839-01-03
</td>
<td style="text-align:center;">
7.2
</td>
<td style="text-align:center;">
1.8
</td>
<td style="text-align:center;">
4.50
</td>
</tr>
<tr>
<td style="text-align:center;">
1839
</td>
<td style="text-align:center;">
1839-01-04
</td>
<td style="text-align:center;">
8.0
</td>
<td style="text-align:center;">
1.8
</td>
<td style="text-align:center;">
4.90
</td>
</tr>
<tr>
<td style="text-align:center;">
1839
</td>
<td style="text-align:center;">
1839-01-05
</td>
<td style="text-align:center;">
5.3
</td>
<td style="text-align:center;">
0.8
</td>
<td style="text-align:center;">
3.05
</td>
</tr>
<tr>
<td style="text-align:center;">
1839
</td>
<td style="text-align:center;">
1839-01-06
</td>
<td style="text-align:center;">
10.0
</td>
<td style="text-align:center;">
1.3
</td>
<td style="text-align:center;">
5.65
</td>
</tr>
<tr>
<td style="text-align:center;">
1839
</td>
<td style="text-align:center;">
1839-01-07
</td>
<td style="text-align:center;">
8.9
</td>
<td style="text-align:center;">
1.4
</td>
<td style="text-align:center;">
5.15
</td>
</tr>
<tr>
<td style="text-align:center;">
1839
</td>
<td style="text-align:center;">
1839-01-08
</td>
<td style="text-align:center;">
3.0
</td>
<td style="text-align:center;">
0.1
</td>
<td style="text-align:center;">
1.55
</td>
</tr>
<tr>
<td style="text-align:center;">
1839
</td>
<td style="text-align:center;">
1839-01-09
</td>
<td style="text-align:center;">
0.8
</td>
<td style="text-align:center;">
-0.1
</td>
<td style="text-align:center;">
0.35
</td>
</tr>
<tr>
<td style="text-align:center;">
1839
</td>
<td style="text-align:center;">
1839-01-10
</td>
<td style="text-align:center;">
2.8
</td>
<td style="text-align:center;">
-2.8
</td>
<td style="text-align:center;">
0.00
</td>
</tr>
<tr>
<td style="text-align:center;">
…
</td>
<td style="text-align:center;">
…
</td>
<td style="text-align:center;">
…
</td>
<td style="text-align:center;">
…
</td>
<td style="text-align:center;">
…
</td>
</tr>
</tbody>

</table>
</div>
</div>
<p>Reproducing Quetelet’s law is now a simple matter of calculating the sum of the squared daily temperature from the day of last frost until the bloom day. We could use the day of last frost reported in Quetelet’s <em>Letters</em>. However, since we will replicate Quetelet’s analysis with recent data in a later section, we use our own definition of the day of last frost. We define the day of last frost to be the day following the last day the maximum temperature is below 0. The <code>R</code> code below creates the function <code>doy_last_frost</code> to extract the day of last frost from the maximum temperature. To demonstrate this function, we then compare the bloom date with the last frost date in 1839, the first year Quetelet observed.</p>
<div class="sourceCode" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb4-1"><span class="in" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">```{r}</span></span>
<span id="cb4-2">doy_last_frost <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">function</span>(tmax, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">doy_max =</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">100</span>) {</span>
<span id="cb4-3">  dof <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">which</span>(tmax[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span>doy_max] <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&lt;=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>)</span>
<span id="cb4-4">  <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span>(<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">length</span>(dof) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>) <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span> <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">else</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">max</span>(dof) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span></span>
<span id="cb4-5">  }</span>
<span id="cb4-6"></span>
<span id="cb4-7">bloom_day <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> </span>
<span id="cb4-8">  lilac <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span> </span>
<span id="cb4-9">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">filter</span>(year <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1839</span>) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span></span>
<span id="cb4-10">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">pull</span>(doy) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> </span>
<span id="cb4-11">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">as.Date</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"1839-01-01"</span>)</span>
<span id="cb4-12">  </span>
<span id="cb4-13">frost_day <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> </span>
<span id="cb4-14">  temp <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span> </span>
<span id="cb4-15">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">filter</span>(year <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1839</span>) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span> </span>
<span id="cb4-16">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">pull</span>(tmax) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span> </span>
<span id="cb4-17">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">doy_last_frost</span>() <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">as.Date</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"1839-01-01"</span>) </span>
<span id="cb4-18"></span>
<span id="cb4-19"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">tibble</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">`</span><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">last frost date</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">`</span> <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">=</span> frost_day, </span>
<span id="cb4-20">       <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">`</span><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">bloom date</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">`</span> <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">=</span> bloom_day) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span></span>
<span id="cb4-21">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">kable</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">align =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"c"</span>,</span>
<span id="cb4-22">        <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">caption =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Table 3: Last frost date and lilac bloom date at Brussels Observatory in 1839."</span>) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span></span>
<span id="cb4-23">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">kable_styling</span>()</span>
<span id="cb4-24"><span class="in" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">```</span></span></code></pre></div>
<div id="tab-table3">

<table class="table" style="margin-left: auto; margin-right: auto; margin-bottom: 1.5em;">
<caption>
<b>Table 3:</b> Last frost date and lilac bloom date at Brussels Observatory in 1839.
</caption>
<thead>
<tr>
<th style="text-align:center;">
last frost date
</th>
<th style="text-align:center;">
bloom date
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center;">
1839-03-08
</td>
<td style="text-align:center;">
1839-05-11
</td>
</tr>
</tbody>

</table>
</div>
<p>If Quetelet’s law of the flowering plants is correct, Table 3 has the following interpretation. On March 8, 1839 the lilacs at Brussels Observatory began “collecting” temperature. The lilacs continued to “collect” temperature until May 11, at which point they exceeded their 4264°C² quota and bloomed. We visualize this theory in Figure 4 with the <code>R</code> packages <code>ggplot2</code>, a member of the set of packages that constitute the “tidyverse” <span class="citation" data-cites="Wickham2019">(2019)</span>, and <code>plotly</code>.</p>
<div class="no-row-height column-margin column-container"><div id="ref-Wickham2019" class="csl-entry">
Wickham, Hadley, Mara Averick, Jennifer Bryan, Winston Chang, Lucy D’Agostino McGowan, Romain François, Garrett Grolemund, et al. 2019. <span>“Welcome to the Tidyverse.”</span> <em>Journal of Open Source Software</em> 4 (43): 1686. <a href="https://doi.org/10.21105/joss.01686">https://doi.org/10.21105/joss.01686</a>.
</div></div><div class="sourceCode" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb5-1"><span class="in" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">```{r}</span></span>
<span id="cb5-2">(temp <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span> </span>
<span id="cb5-3">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">filter</span>(date <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&lt;</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">as.Date</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"1839-06-01"</span>)) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span> </span>
<span id="cb5-4">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">ggplot</span>() <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> </span>
<span id="cb5-5">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">aes</span>(date, temp) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> </span>
<span id="cb5-6">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">geom_line</span>() <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> </span>
<span id="cb5-7">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">labs</span>(</span>
<span id="cb5-8">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">x =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">""</span>,</span>
<span id="cb5-9">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">y =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"midrange temperature (°C)"</span>,</span>
<span id="cb5-10">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">title =</span> </span>
<span id="cb5-11">      <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Figure 4: According to Quetelet's law, the lilacs bloom when exposed to 4264°C² following the last frost."</span>) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span></span>
<span id="cb5-12">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">geom_vline</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">xintercept =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">as.numeric</span>(<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">c</span>(bloom_day, frost_day)), </span>
<span id="cb5-13">             <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">linetype =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"dotted"</span>)) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span></span>
<span id="cb5-14">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">ggplotly</span>() <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span> </span>
<span id="cb5-15">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">add_annotations</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">x =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">as.numeric</span>(<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">c</span>(frost_day, bloom_day)),</span>
<span id="cb5-16">                  <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">y =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">c</span>(<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>, <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>),</span>
<span id="cb5-17">                  <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">text =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">c</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"last</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">\n</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">frost"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"first</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">\n</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">bloom"</span>),</span>
<span id="cb5-18">                  <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">font =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">list</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">size =</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">14</span>),</span>
<span id="cb5-19">                  <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">ay =</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>,</span>
<span id="cb5-20">                  <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">xshift =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">c</span>(<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>, <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">12</span>)) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span></span>
<span id="cb5-21">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">config</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">displaylogo =</span> <span class="cn" style="color: #8f5902;
background-color: null;
font-style: inherit;">FALSE</span>)</span>
<span id="cb5-22"><span class="in" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">```</span></span></code></pre></div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="images/fig4.png" class="lightbox" title="A line graph of midrange temperature by day, for January to June 1839, with day of last frost (March 8) and day of first bloom (May 11) marked by vertical dashed lines." data-description="Author

provided,

<a href=&quot;https://creativecommons.org/licenses/by/4.0/&quot;>CC BY 4.0</a>" data-gallery="quarto-lightbox-gallery-7"><img src="https://realworlddatascience.net/ideas/tutorials/posts/2023/04/13/images/fig4.png" class="img-fluid figure-img" alt="A line graph of midrange temperature by day, for January to June 1839, with day of last frost (March 8) and day of first bloom (May 11) marked by vertical dashed lines."></a></p>
</figure>
</div>
<div class="figure-caption">
<p><strong>Figure 4:</strong> According to Quetelet’s law, the lilacs bloom when exposed to 4264°C² following the last frost. Author provided, <a href="https://creativecommons.org/licenses/by/4.0/">CC BY 4.0</a>.</p>
</div>
<p>We now have all the ingredients necessary to reproduce Quetelet’s findings. Our reproduction is greatly simplified by using the <code>nest</code> function from the <code>tidyr</code> package, another member of the “tidyverse”. For an overview of <code>nest</code>, see the <a href="https://r4ds.had.co.nz/many-models.html?q=nest#nested-data">“Nested data” section</a> of <span class="citation" data-cites="grolemund2017r">Grolemund and Wickham (2017)</span>. We will group the data by year, nest, calculate the cumulative squared temperature from the frost date to the bloom date within each year, and then unnest. We ignore temperatures below 0°C. That is, temperatures below 0°C are set to 0°C. We do this because it is clear from Quetelet’s derivation of the law that only positive temperatures should be squared. See the next section for details.</p>
<div class="no-row-height column-margin column-container"><div id="ref-grolemund2017r" class="csl-entry">
Grolemund, Garrett, and Hadley Wickham. 2017. <em>R for Data Science</em>. Sebastopol, CA: O’Reilly Media.
</div></div><div class="sourceCode" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb6-1"><span class="in" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">```{r}</span></span>
<span id="cb6-2">quetelet <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> </span>
<span id="cb6-3">  temp <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span> </span>
<span id="cb6-4">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">group_by</span>(year) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span> </span>
<span id="cb6-5">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">nest</span>() <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span> </span>
<span id="cb6-6">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">left_join</span>(lilac) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span> </span>
<span id="cb6-7">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">mutate</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">law =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">map</span>(data, <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">~</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">sum</span>(<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">pmax</span>(.<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">$</span>temp, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">na.rm =</span> <span class="cn" style="color: #8f5902;
background-color: null;
font-style: inherit;">TRUE</span>)[(<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">doy_last_frost</span>(.<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">$</span>tmax) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span>doy]<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">^</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>))) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span> </span>
<span id="cb6-8">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">unnest</span>(law) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span> </span>
<span id="cb6-9">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">ungroup</span>()</span>
<span id="cb6-10"></span>
<span id="cb6-11">quetelet <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span> </span>
<span id="cb6-12">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">summarize</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">Quetelet =</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4264</span>, </span>
<span id="cb6-13">            <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">est =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">mean</span>(law), </span>
<span id="cb6-14">            <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">se =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">sd</span>(law)<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">sqrt</span>(<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">n</span>()),</span>
<span id="cb6-15">            <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">ci  =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">str_c</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"["</span>, <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">round</span>(est <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span> <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> se), <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">", "</span>, <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">round</span>(est <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span> <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> se), <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"]"</span>)) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span></span>
<span id="cb6-16">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">kable</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">dig =</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, </span>
<span id="cb6-17">        <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">align =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"c"</span>, </span>
<span id="cb6-18">        <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">col.names =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">c</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Quetelet's law (°C²)"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"estimate (°C²)"</span>, </span>
<span id="cb6-19">                      <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"standard error (°C²)"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"95% confidence interval (°C²)"</span>),</span>
<span id="cb6-20">        <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">caption =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Table 4: Reproduction of Quetelet's analysis."</span>) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span></span>
<span id="cb6-21">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">kable_styling</span>()</span>
<span id="cb6-22"><span class="in" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">```</span></span></code></pre></div>
<div id="tab-table4">

<table class="table" style="margin-left: auto; margin-right: auto; margin-bottom: 1.5em;">
<caption>
<b>Table 4:</b> Reproduction of Quetelet’s analysis.
</caption>
<thead>
<tr>
<th style="text-align:center;">
Quetelet’s law (°C²)
</th>
<th style="text-align:center;">
estimate (°C²)
</th>
<th style="text-align:center;">
standard error (°C²)
</th>
<th style="text-align:center;">
95% confidence interval (°C²)
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center;">
4264
</td>
<td style="text-align:center;">
4261
</td>
<td style="text-align:center;">
197
</td>
<td style="text-align:center;">
[3867, 4656]
</td>
</tr>
</tbody>

</table>
</div>
<p>The results show that Quetelet’s findings are indeed reproducible. Quetelet estimated that lilacs bloom once exposed to 4264°C² following the last frost. Our reanalysis suggests a similar amount. However, 4264°C² is the overall average across all years – the estimated amount needed to bloom varies year to year. As a result, the average has a 95% confidence interval of approximately 3870°C² to 4660°C². Quetelet was well aware of this variation. He argued it was due to unobserved factors that influence growing conditions and change each year, and he dedicated significant space in his <em>Letters</em> to discuss them.</p>
<p>These unobserved factors limit the accuracy of predictions made using the law. To assess the predictive accuracy of the law, we temporarily ignore the bloom dates Quetelet observed. Instead, we apply the 4264°C² quota to the temperature records at Brussels Observatory to predict the bloom date. We then compare our predictions with the bloom date Quetelet observed. The <code>R</code> code below creates the function <code>doy_prediction</code> to estimate the day the lilac will bloom from temperature records. Table 5 summarizes the accuracy of Quetelet’s law by the mean absolute error and root mean squared error.</p>
<div class="sourceCode" id="cb7" style="background: #f1f3f5;"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb7-1"><span class="in" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">```{r}</span></span>
<span id="cb7-2">doy_prediction <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">function</span>(temp, tmax)</span>
<span id="cb7-3">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">doy_last_frost</span>(tmax) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">which.max</span>(<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">cumsum</span>(<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">pmax</span>(temp[(<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">doy_last_frost</span>(tmax) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">365</span>], <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">na.rm =</span> <span class="cn" style="color: #8f5902;
background-color: null;
font-style: inherit;">TRUE</span>)<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">^</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&gt;</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4264</span>)</span>
<span id="cb7-4"></span>
<span id="cb7-5">quetelet <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span> </span>
<span id="cb7-6">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">mutate</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">pred =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">map</span>(data, <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">~</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">doy_prediction</span>(.<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">$</span>temp, .<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">$</span>tmax))) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span> </span>
<span id="cb7-7">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">unnest</span>(pred) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span> </span>
<span id="cb7-8">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">ungroup</span>() <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span></span>
<span id="cb7-9">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">summarize</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">mae  =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">mean</span>(<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">abs</span>(doy <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> pred)),</span>
<span id="cb7-10">            <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">rmse =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">sqrt</span>(<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">mean</span>((doy <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> pred)<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">^</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>))) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span></span>
<span id="cb7-11">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">kable</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">dig =</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>,</span>
<span id="cb7-12">        <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">align =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"c"</span>,</span>
<span id="cb7-13">        <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">col.names =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">c</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"mean absolute error (days)"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"root mean squared error (days)"</span>),</span>
<span id="cb7-14">        <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">caption =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Table 5: Predictions using Quetelet's law are accurate within a week on average."</span>) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span></span>
<span id="cb7-15">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">kable_styling</span>()</span>
<span id="cb7-16"><span class="in" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">```</span></span></code></pre></div>
<div id="tab-table5">

<table class="table" style="margin-left: auto; margin-right: auto; margin-bottom: 1.5em;">
<caption>
<b>Table 5:</b> Predictions using Quetelet’s law are accurate within a week on average.
</caption>
<thead>
<tr>
<th style="text-align:center;">
mean absolute error (days)
</th>
<th style="text-align:center;">
root mean squared error (days)
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center;">
5
</td>
<td style="text-align:center;">
6
</td>
</tr>
</tbody>

</table>
</div>
<p>Table 5 indicates that predictions made using the law are accurate to within a week on average. For comparison purposes, we also predict the day the lilacs will bloom using the average bloom date between 1839 and 1852. That is, on average the lilac bloomed on April 30 (April 29 on leap years), and we check the accuracy of simply predicting this average date each year. Table 6 indicates the average bloom date yields predictions that are less accurate by an average of two days.</p>
<div class="sourceCode" id="cb8" style="background: #f1f3f5;"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb8-1"><span class="in" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">```{r}</span></span>
<span id="cb8-2">quetelet <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span></span>
<span id="cb8-3">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">summarize</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">pred =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">mean</span>(doy),</span>
<span id="cb8-4">            <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">mae  =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">mean</span>(<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">abs</span>(doy <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> pred)),</span>
<span id="cb8-5">            <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">rmse =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">sqrt</span>(<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">mean</span>((doy <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> pred)<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">^</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>))) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span></span>
<span id="cb8-6">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">select</span>(mae, rmse) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span></span>
<span id="cb8-7">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">kable</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">dig =</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>,</span>
<span id="cb8-8">        <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">align =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"c"</span>,</span>
<span id="cb8-9">        <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">col.names =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">c</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"mean absolute error (days)"</span>,</span>
<span id="cb8-10">                      <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"root mean squared error (days)"</span>),</span>
<span id="cb8-11">        <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">caption =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Table 6: Predictions using the average bloom date are off by a week or more on average."</span>) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span></span>
<span id="cb8-12">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">kable_styling</span>()</span>
<span id="cb8-13"><span class="in" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">```</span></span></code></pre></div>
<div id="tab-table6">

<table class="table" style="margin-left: auto; margin-right: auto; margin-bottom: 1.5em;">
<caption>
<b>Table 6:</b> Predictions using the average bloom date are off by a week or more on average.
</caption>
<thead>
<tr>
<th style="text-align:center;">
mean absolute error (days)
</th>
<th style="text-align:center;">
root mean squared error (days)
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center;">
7
</td>
<td style="text-align:center;">
9
</td>
</tr>
</tbody>

</table>
</div>
</section>
<section id="quetelets-derivation-of-the-law-of-the-flowering-plants" class="level2">
<h2 class="anchored" data-anchor-id="quetelets-derivation-of-the-law-of-the-flowering-plants">Quetelet’s derivation of the law of the flowering plants</h2>
<p>Quetelet believed that, as in physics, universal laws govern social and biological phenomenon. Quetelet was not only inspired by physics to describe social and biological patterns using mathematical formulas. He often took his formulas directly from physics. In fact, you may have already recognized similarities between his law and Newton’s second law of motion.</p>
<p>Quetelet reasoned that temperature exerts a “force” on plants in the same way that gravity exerts a force on a falling object. Newton’s second law states that acceleration is proportional to force. It follows that an object initially at rest and subject to a constant force will travel a distance proportional to time squared. Quetelet simply substituted temperature for time.</p>
<p>We briefly elaborate. Let <img src="https://latex.codecogs.com/png.latex?d(t)"> denote the distance an object travels after time <img src="https://latex.codecogs.com/png.latex?t">. Let <img src="https://latex.codecogs.com/png.latex?v(t)%20=%20d'(t)"> denote its speed and <img src="https://latex.codecogs.com/png.latex?a(t)%20=%20v'(t)"> its acceleration. If acceleration is constant, i.e.&nbsp;<img src="https://latex.codecogs.com/png.latex?a(t)%20=%20c">,</p>
<div style="text-align:center;">
<p><img src="https://latex.codecogs.com/png.latex?v(t)%20=%20%5Cint_0%5Et%20a(s)%20%5C,%20ds%20=%20%5Cint_0%5Et%20c%20%5C,%20ds%20=%20c%20t"></p>
</div>
<p>and</p>
<div style="text-align:center;">
<p><img src="https://latex.codecogs.com/png.latex?d(t)%20=%20%5Cint_0%5Et%20v(s)%20%5C,%20ds%20=%20%5Cint_0%5Et%20c%20s%20%5C,%20ds%20=%20%5Ctfrac%7Bc%7D%7B2%7D%20t%5E2"></p>
</div>
<p>Quetelet imagined plants experience time in temperature and bloom after “traveling” distance <img src="https://latex.codecogs.com/png.latex?d_*">. If a plant is exposed to temperature <img src="https://latex.codecogs.com/png.latex?t_i"> on day <img src="https://latex.codecogs.com/png.latex?i%20=%201,%202,%20%5Cldots">, then the bloom date, <img src="https://latex.codecogs.com/png.latex?n_*">, is the first day <img src="https://latex.codecogs.com/png.latex?%5Csum_%7Bi=1%7D%5E%7Bn_*%7D%20%5Ctfrac%7Bc%7D%7B2%7D%20t_i%5E2%20%5Cgeq%20d_*">. Multiplying both sides of the inequality by <img src="https://latex.codecogs.com/png.latex?%5Ctfrac%7B2%7D%7Bc%7D">, yields Quetelet’s law: the bloom is the first day, <img src="https://latex.codecogs.com/png.latex?n_*">, that <img src="https://latex.codecogs.com/png.latex?%5Csum_%7Bi=1%7D%5E%7Bn_*%7D%20t_i%5E2%20%5Cgeq%20%5Ctfrac%7B2%7D%7Bc%7D%20d_*">.</p>
<p>The derivation of laws like the law of the flowering plants was popular in the nineteenth century. But any similarities between the “force” of temperature and the force of gravity are likely coincidental. We are not aware of any biological mechanisms that justify Quetelet’s application of Newton’s law.</p>
<p>Today, the law of the flowering plants is considered a heuristic, or rule of thumb, that approximates complicated biological mechanisms. Like Quetelet, scientists model plants as experiencing time in temperature instead of calendar time. These temperature units are typically called “growing degree days”. Scientists often find that plants may only be sensitive to temperatures in specific ranges or “modified growing degree days”. Although modern statistical methods can greatly improve the accuracy of predictions, laws like Quetelet’s remain popular because they are simple to communicate and easy to replicate, as we demonstrate in the next section.</p>
</section>
<section id="replicating-quetelets-law-of-the-flowering-plants" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="replicating-quetelets-law-of-the-flowering-plants">Replicating Quetelet’s law of the flowering plants</h2>
<p>In the previous section, we explained how Quetelet derived the law of the flowering plants. Quetelet believed the law of the flowering plants was universal, describing the bloom date of all flowers around the world and in any year. Whether the law can in fact be considered universal requires replicating Quetelet’s results with new data collected at a different location in a different year.</p>
<p>In this section, we replicate the law of the flowering plants using lilac bloom dates observed by scientists between 1956 and 2009 at 53 locations throughout the Pacific Northwest <span class="citation" data-cites="rosemartin_denny_weltzin_lee_marsh_wilson_mehdipoor_zurita-milla_schwartz_2015">(2015)</span>. The data can be downloaded from the USA National Phenology Network using the <code>rnpn</code> package <span class="citation" data-cites="the_comprehensive_r_archive_network_2022">(2022)</span>. For space considerations, the <code>R</code> code that downloads and cleans the data is provided in the Appendix. Running this code yields the tibble <code>usa_npn</code>. Each row of the tibble corresponds with a bloom date observed at a given site in a given year. There are 31 columns, only seven of which we use in our replication. The remaining columns are documented in the <code>rnpn</code> package, and we will not review them here.</p>
<div class="no-row-height column-margin column-container"><div id="ref-rosemartin_denny_weltzin_lee_marsh_wilson_mehdipoor_zurita-milla_schwartz_2015" class="csl-entry">
Rosemartin, Alyssa H., Ellen G. Denny, Jake F. Weltzin, R. Lee Marsh, Bruce E. Wilson, Hamed Mehdipoor, Raul Zurita-Milla, and Mark D. Schwartz. 2015. <span>“Lilac and Honeysuckle Phenology Data 1956-2014.”</span> <em>Scientific Data</em> 2 (1). <a href="https://doi.org/10.1038/sdata.2015.38">https://doi.org/10.1038/sdata.2015.38</a>.
</div><div id="ref-the_comprehensive_r_archive_network_2022" class="csl-entry">
Rosemartin, Alyssa, Chamberlain Scott, Lee Marsh, and Kevin Wong. 2022. <span>“Interface to the National ’Phenology’ Network ’API’ [r Package Rnpn Version 1.2.5].”</span> <em>The Comprehensive R Archive Network</em>. Comprehensive R Archive Network (CRAN). <a href="https://cran.r-project.org/package=rnpn">https://cran.r-project.org/package=rnpn</a>.
</div></div><p>Table 7 displays six of the seven columns (and only the first 10 rows of the full table). These columns are defined in the same way as the columns of Table 1, except for “site_id”, which denotes the site at which the observation was made. Table 1 does not have a “site_id” column because all observations were made at the same site, Brussels Observatory.</p>
<div class="sourceCode" id="cb9" style="background: #f1f3f5;"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb9-1"><span class="in" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">```{r}</span></span>
<span id="cb9-2"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">load</span>(<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">url</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"https://github.com/jauerbach/miscellaneous/blob/main/usa_npn.RData?raw=true"</span>))</span>
<span id="cb9-3"></span>
<span id="cb9-4">usa_npn <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span></span>
<span id="cb9-5">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">transmute</span>(site_id, </span>
<span id="cb9-6">            <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">month =</span> first_yes_month, </span>
<span id="cb9-7">            <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">day   =</span> first_yes_day, </span>
<span id="cb9-8">            <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">year  =</span> first_yes_year, </span>
<span id="cb9-9">            <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">date  =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">as.Date</span>(<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">paste</span>(month, day, year), <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">format =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"%m %d %Y"</span>),</span>
<span id="cb9-10">            doy) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span></span>
<span id="cb9-11">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">kable</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">align =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"c"</span>,</span>
<span id="cb9-12">        <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">caption =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Table 7: Bloom dates of lilacs observed in pacific northwest between 1956 and 2009."</span>) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span></span>
<span id="cb9-13">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">kable_styling</span>() <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span></span>
<span id="cb9-14">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">scroll_box</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">width =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"100%"</span>, </span>
<span id="cb9-15">             <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">height =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"400px"</span>)</span>
<span id="cb9-16"><span class="in" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">```</span></span></code></pre></div>
<div id="tab-table7">
<div style="border: 1px solid #ddd; padding: 0px; overflow-y: scroll; height:400px; overflow-x: scroll; width:100%; margin-bottom: 1.5em; ">

<table class="table" style="margin-left: auto; margin-right: auto;">
<caption>
<b>Table 7:</b> Bloom dates of lilacs observed in pacific northwest between 1956 and 2009.
</caption>
<thead>
<tr>
<th style="text-align:center;position: sticky; top:0; background-color: #FFFFFF;">
site_id
</th>
<th style="text-align:center;position: sticky; top:0; background-color: #FFFFFF;">
month
</th>
<th style="text-align:center;position: sticky; top:0; background-color: #FFFFFF;">
day
</th>
<th style="text-align:center;position: sticky; top:0; background-color: #FFFFFF;">
year
</th>
<th style="text-align:center;position: sticky; top:0; background-color: #FFFFFF;">
date
</th>
<th style="text-align:center;position: sticky; top:0; background-color: #FFFFFF;">
doy
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center;">
150
</td>
<td style="text-align:center;">
5
</td>
<td style="text-align:center;">
25
</td>
<td style="text-align:center;">
1956
</td>
<td style="text-align:center;">
1956-05-25
</td>
<td style="text-align:center;">
146
</td>
</tr>
<tr>
<td style="text-align:center;">
150
</td>
<td style="text-align:center;">
5
</td>
<td style="text-align:center;">
22
</td>
<td style="text-align:center;">
1957
</td>
<td style="text-align:center;">
1957-05-22
</td>
<td style="text-align:center;">
142
</td>
</tr>
<tr>
<td style="text-align:center;">
150
</td>
<td style="text-align:center;">
5
</td>
<td style="text-align:center;">
12
</td>
<td style="text-align:center;">
1958
</td>
<td style="text-align:center;">
1958-05-12
</td>
<td style="text-align:center;">
132
</td>
</tr>
<tr>
<td style="text-align:center;">
150
</td>
<td style="text-align:center;">
6
</td>
<td style="text-align:center;">
3
</td>
<td style="text-align:center;">
1959
</td>
<td style="text-align:center;">
1959-06-03
</td>
<td style="text-align:center;">
154
</td>
</tr>
<tr>
<td style="text-align:center;">
150
</td>
<td style="text-align:center;">
5
</td>
<td style="text-align:center;">
27
</td>
<td style="text-align:center;">
1960
</td>
<td style="text-align:center;">
1960-05-27
</td>
<td style="text-align:center;">
148
</td>
</tr>
<tr>
<td style="text-align:center;">
150
</td>
<td style="text-align:center;">
5
</td>
<td style="text-align:center;">
27
</td>
<td style="text-align:center;">
1961
</td>
<td style="text-align:center;">
1961-05-27
</td>
<td style="text-align:center;">
147
</td>
</tr>
<tr>
<td style="text-align:center;">
150
</td>
<td style="text-align:center;">
5
</td>
<td style="text-align:center;">
26
</td>
<td style="text-align:center;">
1962
</td>
<td style="text-align:center;">
1962-05-26
</td>
<td style="text-align:center;">
146
</td>
</tr>
<tr>
<td style="text-align:center;">
150
</td>
<td style="text-align:center;">
5
</td>
<td style="text-align:center;">
24
</td>
<td style="text-align:center;">
1963
</td>
<td style="text-align:center;">
1963-05-24
</td>
<td style="text-align:center;">
144
</td>
</tr>
<tr>
<td style="text-align:center;">
150
</td>
<td style="text-align:center;">
5
</td>
<td style="text-align:center;">
28
</td>
<td style="text-align:center;">
1964
</td>
<td style="text-align:center;">
1964-05-28
</td>
<td style="text-align:center;">
149
</td>
</tr>
<tr>
<td style="text-align:center;">
150
</td>
<td style="text-align:center;">
5
</td>
<td style="text-align:center;">
26
</td>
<td style="text-align:center;">
1966
</td>
<td style="text-align:center;">
1966-05-26
</td>
<td style="text-align:center;">
146
</td>
</tr>
<tr>
<td style="text-align:center;">
…
</td>
<td style="text-align:center;">
…
</td>
<td style="text-align:center;">
…
</td>
<td style="text-align:center;">
…
</td>
<td style="text-align:center;">
…
</td>
<td style="text-align:center;">
…
</td>
</tr>
</tbody>

</table>
</div>
</div>
<p>The seventh column we review is “temp”. Each row of “temp” is a tibble of temperature records taken at the nearest station in the Global Historical Climatology Network. The first tibble (again, only the first 10 rows) is displayed in Table 8 below. The columns are defined in the same way as the columns of Table 2, except for “id”, which denotes the location at which the temperature record was made. Table 2 does not have an “id” column because all observations were made at the same site, Brussels Observatory.</p>
<div class="sourceCode" id="cb10" style="background: #f1f3f5;"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb10-1"><span class="in" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">```{r}</span></span>
<span id="cb10-2">usa_npn <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span></span>
<span id="cb10-3">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">pull</span>(temp) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span></span>
<span id="cb10-4">  .[[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>]] <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span></span>
<span id="cb10-5">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">mutate</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">year =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">parse_number</span>(<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">format</span>(date, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"%Y"</span>))) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span></span>
<span id="cb10-6">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">select</span>(id, year, date, tmax, tmin, temp) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span></span>
<span id="cb10-7">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">kable</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">align =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"c"</span>,</span>
<span id="cb10-8">        <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">col.names =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">c</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"id"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"year"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"date"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"maximum temperature (°C)"</span>, </span>
<span id="cb10-9">                      <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"minimum temperature (°C)"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"midrange temperature (°C)"</span>),</span>
<span id="cb10-10">        <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">caption =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Table 8: Temperature observed at an example pacific northwest site in 1956."</span>) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span></span>
<span id="cb10-11">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">kable_styling</span>() <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span></span>
<span id="cb10-12">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">scroll_box</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">width =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"100%"</span>, </span>
<span id="cb10-13">             <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">height =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"400px"</span>)</span>
<span id="cb10-14"><span class="in" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">```</span></span></code></pre></div>
<div id="tab-table8">
<div style="border: 1px solid #ddd; padding: 0px; overflow-y: scroll; height:400px; overflow-x: scroll; width:100%; margin-bottom: 1.5em;">

<table class="table" style="margin-left: auto; margin-right: auto;">
<caption>
<b>Table 8:</b> Temperature observed at an example pacific northwest site in 1956.
</caption>
<thead>
<tr>
<th style="text-align:center;position: sticky; top:0; background-color: #FFFFFF;">
id
</th>
<th style="text-align:center;position: sticky; top:0; background-color: #FFFFFF;">
year
</th>
<th style="text-align:center;position: sticky; top:0; background-color: #FFFFFF;">
date
</th>
<th style="text-align:center;position: sticky; top:0; background-color: #FFFFFF;">
maximum temperature (°C)
</th>
<th style="text-align:center;position: sticky; top:0; background-color: #FFFFFF;">
minimum temperature (°C)
</th>
<th style="text-align:center;position: sticky; top:0; background-color: #FFFFFF;">
midrange temperature (°C)
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center;">
USC00245761
</td>
<td style="text-align:center;">
1956
</td>
<td style="text-align:center;">
1956-01-01
</td>
<td style="text-align:center;">
5.6
</td>
<td style="text-align:center;">
-5.6
</td>
<td style="text-align:center;">
0.00
</td>
</tr>
<tr>
<td style="text-align:center;">
USC00245761
</td>
<td style="text-align:center;">
1956
</td>
<td style="text-align:center;">
1956-01-02
</td>
<td style="text-align:center;">
1.7
</td>
<td style="text-align:center;">
-7.2
</td>
<td style="text-align:center;">
-2.75
</td>
</tr>
<tr>
<td style="text-align:center;">
USC00245761
</td>
<td style="text-align:center;">
1956
</td>
<td style="text-align:center;">
1956-01-03
</td>
<td style="text-align:center;">
3.3
</td>
<td style="text-align:center;">
-11.7
</td>
<td style="text-align:center;">
-4.20
</td>
</tr>
<tr>
<td style="text-align:center;">
USC00245761
</td>
<td style="text-align:center;">
1956
</td>
<td style="text-align:center;">
1956-01-04
</td>
<td style="text-align:center;">
4.4
</td>
<td style="text-align:center;">
-10.0
</td>
<td style="text-align:center;">
-2.80
</td>
</tr>
<tr>
<td style="text-align:center;">
USC00245761
</td>
<td style="text-align:center;">
1956
</td>
<td style="text-align:center;">
1956-01-05
</td>
<td style="text-align:center;">
7.8
</td>
<td style="text-align:center;">
0.0
</td>
<td style="text-align:center;">
3.90
</td>
</tr>
<tr>
<td style="text-align:center;">
USC00245761
</td>
<td style="text-align:center;">
1956
</td>
<td style="text-align:center;">
1956-01-06
</td>
<td style="text-align:center;">
4.4
</td>
<td style="text-align:center;">
-11.1
</td>
<td style="text-align:center;">
-3.35
</td>
</tr>
<tr>
<td style="text-align:center;">
USC00245761
</td>
<td style="text-align:center;">
1956
</td>
<td style="text-align:center;">
1956-01-07
</td>
<td style="text-align:center;">
2.8
</td>
<td style="text-align:center;">
-6.1
</td>
<td style="text-align:center;">
-1.65
</td>
</tr>
<tr>
<td style="text-align:center;">
USC00245761
</td>
<td style="text-align:center;">
1956
</td>
<td style="text-align:center;">
1956-01-08
</td>
<td style="text-align:center;">
4.4
</td>
<td style="text-align:center;">
-4.4
</td>
<td style="text-align:center;">
0.00
</td>
</tr>
<tr>
<td style="text-align:center;">
USC00245761
</td>
<td style="text-align:center;">
1956
</td>
<td style="text-align:center;">
1956-01-09
</td>
<td style="text-align:center;">
1.7
</td>
<td style="text-align:center;">
-9.4
</td>
<td style="text-align:center;">
-3.85
</td>
</tr>
<tr>
<td style="text-align:center;">
USC00245761
</td>
<td style="text-align:center;">
1956
</td>
<td style="text-align:center;">
1956-01-10
</td>
<td style="text-align:center;">
2.8
</td>
<td style="text-align:center;">
-6.1
</td>
<td style="text-align:center;">
-1.65
</td>
</tr>
<tr>
<td style="text-align:center;">
…
</td>
<td style="text-align:center;">
…
</td>
<td style="text-align:center;">
…
</td>
<td style="text-align:center;">
…
</td>
<td style="text-align:center;">
…
</td>
<td style="text-align:center;">
…
</td>
</tr>
</tbody>

</table>
</div>
</div>
<p>We are now prepared to replicate Quetelet’s findings. We will use <code>R</code> code nearly identical to the code we used to reproduce Quetelet’s findings earlier. The main difference is due to the fact that temperature records are dependent across sites within a year. To account for this dependence, we compute the cumulative temperature squared from the last frost to the bloom date for each site and year. We then take the average across all sites within a year. Finally, we calculate the standard error and confidence interval using only the variation of the averages across years. Table 9 displays the results.</p>
<div class="sourceCode" id="cb11" style="background: #f1f3f5;"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb11-1"><span class="in" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">```{r}</span></span>
<span id="cb11-2">usa_npn <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span>             </span>
<span id="cb11-3">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">group_by</span>(<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">rownames</span>(usa_npn)) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span></span>
<span id="cb11-4">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">mutate</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">law =</span> </span>
<span id="cb11-5">           <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">map</span>(temp, <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">~</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">sum</span>(<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">pmax</span>(.<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">$</span>temp, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">na.rm =</span> <span class="cn" style="color: #8f5902;
background-color: null;
font-style: inherit;">TRUE</span>)[(<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">doy_last_frost</span>(.<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">$</span>tmax, doy) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span>(doy <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)]<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">^</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>))) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span></span>
<span id="cb11-6">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">unnest</span>(law) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span> </span>
<span id="cb11-7">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">group_by</span>(year) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span>    </span>
<span id="cb11-8">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">summarize</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">law =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">mean</span>(law)) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span></span>
<span id="cb11-9">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">summarize</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">Quetelet =</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4264</span>, </span>
<span id="cb11-10">            <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">est =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">mean</span>(law), </span>
<span id="cb11-11">            <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">se =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">sd</span>(law) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">sqrt</span>(<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">n</span>()),</span>
<span id="cb11-12">            <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">ci  =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">str_c</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"["</span>, <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">round</span>(est <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span> <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> se), <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">", "</span>, <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">round</span>(est <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span> <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> se), <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"]"</span>)) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span></span>
<span id="cb11-13">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">kable</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">dig =</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, </span>
<span id="cb11-14">        <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">align =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"c"</span>,</span>
<span id="cb11-15">        <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">col.names =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">c</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Quetelet's law (°C²)"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"estimate (°C²)"</span>,</span>
<span id="cb11-16">                      <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"standard error (°C²)"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"95% confidence interval (°C²)"</span>),</span>
<span id="cb11-17">        <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">caption =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Table 9: Replication of Quetelet's analysis."</span>) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span></span>
<span id="cb11-18">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">kable_styling</span>()</span>
<span id="cb11-19"><span class="in" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">```</span></span></code></pre></div>
<div id="tab-table9">

<table class="table" style="margin-left: auto; margin-right: auto; margin-bottom: 1.5em;">
<caption>
<b>Table 9:</b> Replication of Quetelet’s analysis.
</caption>
<thead>
<tr>
<th style="text-align:center;">
Quetelet’s law (°C²)
</th>
<th style="text-align:center;">
estimate (°C²)
</th>
<th style="text-align:center;">
standard error (°C²)
</th>
<th style="text-align:center;">
95% confidence interval (°C²)
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center;">
4264
</td>
<td style="text-align:center;">
4329
</td>
<td style="text-align:center;">
116
</td>
<td style="text-align:center;">
[4098, 4560]
</td>
</tr>
</tbody>

</table>
</div>
<p>Table 9 indicates that Quetelet’s findings are replicable in the sense that the confidence interval calculated using Quetelet’s data (Table 4) overlaps with the confidence interval calculated using the USA lilac data (Table 9). The standard error in Table 9 is smaller than Table 4 because the replication uses 54 years of data compared to Quetelet’s 14. Note that in the <code>R</code> code above, we subtract 1 from “doy” to correct for differences in how the bloom date is reported. This correction is not particularly important; the confidence intervals still overlap when this correction is removed.</p>
<p>We now investigate the accuracy of Quetelet’s law when applied to the USA lilac data. As before, we make use of the <code>doy_prediction</code> function.</p>
<div class="sourceCode" id="cb12" style="background: #f1f3f5;"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb12-1"><span class="in" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">```{r}</span></span>
<span id="cb12-2">usa_npn <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> </span>
<span id="cb12-3">  usa_npn <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span> </span>
<span id="cb12-4">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">mutate</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">pred =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">map</span>(temp, <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">~</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">doy_prediction</span>(.<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">$</span>temp, .<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">$</span>tmax))) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span> </span>
<span id="cb12-5">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">unnest</span>(pred) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span> </span>
<span id="cb12-6">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">ungroup</span>()</span>
<span id="cb12-7"></span>
<span id="cb12-8">usa_npn <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span> </span>
<span id="cb12-9">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">summarize</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">mae  =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">mean</span>(<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">abs</span>(doy <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span> <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> pred)),</span>
<span id="cb12-10">            <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">rmse =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">sqrt</span>(<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">mean</span>((doy <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span> <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> pred)<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">^</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>))) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span></span>
<span id="cb12-11">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">kable</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">dig =</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>,</span>
<span id="cb12-12">        <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">align =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"c"</span>, </span>
<span id="cb12-13">        <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">col.names =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">c</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"mean absolute error (days)"</span>,</span>
<span id="cb12-14">                      <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"root mean squared error (days)"</span>),</span>
<span id="cb12-15">        <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">caption =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Table 10: Predictions using Quetelet's law are accurate within about two weeks on average."</span>) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span></span>
<span id="cb12-16">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">kable_styling</span>()</span>
<span id="cb12-17"><span class="in" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">```</span></span></code></pre></div>
<div id="tab-table10">

<table class="table" style="margin-left: auto; margin-right: auto; margin-bottom: 1.5em;">
<caption>
<b>Table 10:</b> Predictions using Quetelet’s law are accurate within about two weeks on average.
</caption>
<thead>
<tr>
<th style="text-align:center;">
mean absolute error (days)
</th>
<th style="text-align:center;">
root mean squared error (days)
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center;">
10
</td>
<td style="text-align:center;">
15
</td>
</tr>
</tbody>

</table>
</div>
<p>Table 10 indicates that the predictions are accurate to within two weeks on average. Recall that the predictions using Quetelet’s own data were accurate to within one week on average (Table 5). We speculate that the decrease in accuracy is due in part to the fact that both Quetelet’s lilacs and the temperature were observed at the same site, Brussels Observatory. In some cases, the USA lilacs were a few miles from where the temperature was recorded.</p>
<p>Although the accuracy of the predictions made using Quetelet’s law is lower when applied to the USA lilac data, Figure 5 indicates that the law produces the correct bloom date on average. The figure plots the predictions made by the law against the actual bloom dates scientists observed. Note that instead of representing prediction-observation pairs as points in a scatter plot, the data are represented using blue contours. We use contours because there are more than 1,500 observations – too many to study using a scatter plot.</p>
<div class="sourceCode" id="cb13" style="background: #f1f3f5;"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb13-1"><span class="in" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">```{r}</span></span>
<span id="cb13-2">(usa_npn <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span> </span>
<span id="cb13-3">   <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">mutate</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">doy =</span> first_yes_doy) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span></span>
<span id="cb13-4">   <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">unnest</span>(pred) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span> </span>
<span id="cb13-5">   <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">ungroup</span>() <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span></span>
<span id="cb13-6">   <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">mutate</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">predicted =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">as.Date</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"2020-01-01"</span>) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> pred,</span>
<span id="cb13-7">          <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">observed =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">as.Date</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"2020-01-01"</span>) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> doy) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span></span>
<span id="cb13-8">   <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">ggplot</span>() <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> </span>
<span id="cb13-9">    <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">aes</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">x =</span> observed, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">y =</span> predicted) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span></span>
<span id="cb13-10">    <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">geom_density2d</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">contour_var =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"ndensity"</span>) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span></span>
<span id="cb13-11">    <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">geom_abline</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">intercept =</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">slope =</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">linetype =</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span></span>
<span id="cb13-12">    <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">labs</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">x =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"date observed"</span>, </span>
<span id="cb13-13">         <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">y =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"date predicted"</span>,</span>
<span id="cb13-14">         <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">title =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Figure 5: Predictions using Quetelet's law are accurate within about two weeks on average."</span>) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span></span>
<span id="cb13-15">    <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">theme</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">legend.position =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"none"</span>)) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span></span>
<span id="cb13-16">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">ggplotly</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">tooltip =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">""</span>) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span></span>
<span id="cb13-17">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">config</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">displaylogo =</span> <span class="cn" style="color: #8f5902;
background-color: null;
font-style: inherit;">FALSE</span>)</span>
<span id="cb13-18"><span class="in" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">```</span></span></code></pre></div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="images/fig5.png" class="lightbox" title="This figure plots the predictions made by Quetelet's law against the actual bloom dates scientists observed from US lilac data. Data are represented using blue contours, and a dotted line of equality is drawn through the graph. The dotted line intersects the blue contours at their peak, suggesting that the law derived from Quetelet’s data accurately predicts the typical bloom date of the USA data." data-description="Author

provided,

<a href=&quot;https://creativecommons.org/licenses/by/4.0/&quot;>CC BY 4.0</a>" data-gallery="quarto-lightbox-gallery-8"><img src="https://realworlddatascience.net/ideas/tutorials/posts/2023/04/13/images/fig5.png" class="img-fluid figure-img" alt="This figure plots the predictions made by Quetelet's law against the actual bloom dates scientists observed from US lilac data. Data are represented using blue contours, and a dotted line of equality is drawn through the graph. The dotted line intersects the blue contours at their peak, suggesting that the law derived from Quetelet’s data accurately predicts the typical bloom date of the USA data."></a></p>
</figure>
</div>
<div class="figure-caption">
<p><strong>Figure 5:</strong> Predictions using Quetelet’s law are accurate within about two weeks on average. Author provided, <a href="https://creativecommons.org/licenses/by/4.0/">CC BY 4.0</a>.</p>
</div>
<p>The contours are easy to interpret. The blue lines are much like a mountain range observed from above. The inner circles are peaks of high elevation in which many prediction-observation pairs co-occur. The outer circles are areas of low elevation in which few prediction-observation pairs co-occur.</p>
<p>The dotted line is the “y = x” line, having zero intercept and unit slope. Prediction-observation pairs that lie on the line indicate perfect predictions. The fact that the dotted line intersects the blue contours at their peak suggests the law derived from Quetelet’s data accurately predicts the typical bloom date of the USA data. This accuracy is impressive given the fact that the USA lilacs were observed more than a century later and on a different continent. The blue curves deviate from the line by about two weeks in the vertical direction, which is consistent with Table 10.</p>
<p>An average accuracy of two weeks might not sound impressive. But it is far more accurate than using the average bloom date Quetelet observed, April 30 (April 29 on leap years). The average bloom date yields predictions that are off by an additional eleven days on average.</p>
<div class="sourceCode" id="cb14" style="background: #f1f3f5;"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb14-1"><span class="in" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">```{r}</span></span>
<span id="cb14-2">usa_npn <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span></span>
<span id="cb14-3">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">mutate</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">doy =</span> first_yes_doy) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span></span>
<span id="cb14-4">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">ungroup</span>() <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span></span>
<span id="cb14-5">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">summarize</span>(</span>
<span id="cb14-6">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">pred =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">mean</span>(quetelet<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">$</span>doy), </span>
<span id="cb14-7">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">mae  =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">mean</span>(<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">abs</span>(doy <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> pred)),</span>
<span id="cb14-8">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">rmse =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">sqrt</span>(<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">mean</span>((doy <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> pred)<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">^</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>))) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span></span>
<span id="cb14-9">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">select</span>(mae, rmse) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span></span>
<span id="cb14-10">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">kable</span>(</span>
<span id="cb14-11">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">dig =</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>,</span>
<span id="cb14-12">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">align =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"c"</span>,</span>
<span id="cb14-13">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">col.names =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">c</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"mean absolute error (days)"</span>,</span>
<span id="cb14-14">                  <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"root mean squared error (days)"</span>),</span>
<span id="cb14-15">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">caption =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Table 11: Predictions using the average bloom date are off by three weeks or more on average."</span>) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span></span>
<span id="cb14-16">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">kable_styling</span>()</span>
<span id="cb14-17"><span class="in" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">```</span></span></code></pre></div>
<div id="tab-table11">

<table class="table" style="margin-left: auto; margin-right: auto; margin-bottom: 1.5em;">
<caption>
<b>Table 11:</b> Predictions using the average bloom date are off by three weeks or more on average.
</caption>
<thead>
<tr>
<th style="text-align:center;">
mean absolute error (days)
</th>
<th style="text-align:center;">
root mean squared error (days)
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center;">
21
</td>
<td style="text-align:center;">
24
</td>
</tr>
</tbody>

</table>
</div>
</section>
<section id="predicting-the-day-the-lilac-will-bloom-in-brussels-in-2023" class="level2">
<h2 class="anchored" data-anchor-id="predicting-the-day-the-lilac-will-bloom-in-brussels-in-2023">Predicting the day the lilac will bloom in Brussels in 2023</h2>
<p>Any weather forecast can become a flower forecast by applying the law of the flowering plants. In this section, we use the AccuWeather forecast to predict the day a hypothetical lilac will bloom in Brussels in 2023. AccuWeather forecasts daily maximum and minimum temperatures three months into the future. We do not evaluate the quality of these forecasts. The purpose of this section is to simply convert them into flower forecasts.</p>
<p>We use the AccuWeather forecast as it appeared on the webpage <a href="https://www.accuweather.com/en/be/brussels/27581/january-weather/27581?year=2023">AccuWeather.com</a> on February 19, 2023. AccuWeather reports the forecast for each month on a separate webpage. For reproducibility, we saved each page on the <a href="https://web.archive.org/web/20230219151906/https://www.accuweather.com/en/be/brussels/27581/january-weather/27581?year=2023&amp;unit=c">Internet Archive</a>. The following <code>R</code> code creates the function <code>get_weather_table</code> to retrieve each page we saved, extract the forecast contained within that page, and arrange the data as a tibble. The <code>get_weather_table</code> function combines several functions from the <code>rvest</code> package, which is yet another member of the “tidyverse”. In particular, the forecast on each page is contained within the div “monthly-calendar” and can be extracted with the <code>html_nodes</code> and <code>html_text2</code> functions.</p>
<p>Applying the <code>get_weather_table</code> function to the url for each page yields a five column tibble <code>temp_br</code>, with columns defined in the same way as the tibble <code>temp</code>, discussed in previous sections. The first 10 rows are below; the data are also available on the author’s <a href="https://raw.githubusercontent.com/jauerbach/miscellaneous/main/temp_br.csv">GitHub</a>.</p>
<div class="sourceCode" id="cb15" style="background: #f1f3f5;"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb15-1"><span class="in" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">```{r}</span></span>
<span id="cb15-2"> get_weather_table <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">function</span>(url)</span>
<span id="cb15-3">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">read_html</span>(url) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span> </span>
<span id="cb15-4">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">html_nodes</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"div.monthly-calendar"</span>) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span> </span>
<span id="cb15-5">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">html_text2</span>() <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span></span>
<span id="cb15-6">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">str_remove_all</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"°|Hist. Avg. "</span>) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span></span>
<span id="cb15-7">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">str_split</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">" "</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">simplify =</span> <span class="cn" style="color: #8f5902;
background-color: null;
font-style: inherit;">TRUE</span>) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span></span>
<span id="cb15-8">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">parse_number</span>() <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span></span>
<span id="cb15-9">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">matrix</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">ncol =</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>, </span>
<span id="cb15-10">         <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">byrow =</span> <span class="cn" style="color: #8f5902;
background-color: null;
font-style: inherit;">TRUE</span>,</span>
<span id="cb15-11">         <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">dimnames =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">list</span>(<span class="cn" style="color: #8f5902;
background-color: null;
font-style: inherit;">NULL</span>, <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">c</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"day"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"tmax"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"tmin"</span>))) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span></span>
<span id="cb15-12">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">as_tibble</span>() <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span></span>
<span id="cb15-13">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">filter</span>(</span>
<span id="cb15-14">    <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">row_number</span>() <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%in%</span></span>
<span id="cb15-15">      (<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">which</span>(<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">diff</span>(day) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&lt;</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span> (<span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">function</span>(x) <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span>(<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">length</span>(x) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>) <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">seq</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, x[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>], <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>) <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">else</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">seq</span>(x[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>] <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, x[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>], <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>))))</span>
<span id="cb15-16"></span>
<span id="cb15-17">temp_br <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span></span>
<span id="cb15-18">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">tibble</span>(</span>
<span id="cb15-19">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">base_url =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"https://web.archive.org/web/20230219151906/https://www.accuweather.com/en/be/brussels/27581/"</span>,</span>
<span id="cb15-20">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">month =</span> month.name[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>],</span>
<span id="cb15-21">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">year =</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2023</span>,</span>
<span id="cb15-22">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">url =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">str_c</span>(base_url, <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">tolower</span>(month), <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"-weather/27581?year="</span>, year, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"&amp;unit=c"</span>)) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span></span>
<span id="cb15-23">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">mutate</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">temp =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">map</span>(url, get_weather_table)) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span></span>
<span id="cb15-24">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">pull</span>(temp) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span></span>
<span id="cb15-25">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">reduce</span>(bind_rows) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span></span>
<span id="cb15-26">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">transmute</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">date =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">seq</span>(<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">as.Date</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"2023-01-01"</span>), <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">as.Date</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"2023-05-31"</span>), <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>),</span>
<span id="cb15-27">            <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">year =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">parse_number</span>(<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">format</span>(date, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"%Y"</span>)),</span>
<span id="cb15-28">            tmax,</span>
<span id="cb15-29">            tmin,</span>
<span id="cb15-30">            <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">temp =</span> (tmax <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> tmin) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>)</span>
<span id="cb15-31"></span>
<span id="cb15-32">temp_br <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span></span>
<span id="cb15-33">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">relocate</span>(year) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span></span>
<span id="cb15-34">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">kable</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">dig =</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>,</span>
<span id="cb15-35">        <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">align =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"c"</span>, </span>
<span id="cb15-36">        <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">col.names =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">c</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"year"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"date"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"maximum temperature (°C)"</span>,</span>
<span id="cb15-37">                      <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"minimum temperature (°C)"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"midrange temperature (°C)"</span>),</span>
<span id="cb15-38">        <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">caption =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Table 12: Temperature forecast for Brussels, retrieved on February 19, 2023."</span>) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span></span>
<span id="cb15-39">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">kable_styling</span>() <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span></span>
<span id="cb15-40">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">scroll_box</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">width =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"100%"</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">height =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"400px"</span>)</span>
<span id="cb15-41"><span class="in" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">```</span></span></code></pre></div>
<div id="tab-table12">
<div style="border: 1px solid #ddd; padding: 0px; overflow-y: scroll; height:400px; overflow-x: scroll; width:100%; margin-bottom: 1.5em;">

<table class="table" style="margin-left: auto; margin-right: auto;">
<caption>
<b>Table 12:</b> Temperature forecast for Brussels, retrieved on February 19, 2023.
</caption>
<thead>
<tr>
<th style="text-align:center;position: sticky; top:0; background-color: #FFFFFF;">
year
</th>
<th style="text-align:center;position: sticky; top:0; background-color: #FFFFFF;">
date
</th>
<th style="text-align:center;position: sticky; top:0; background-color: #FFFFFF;">
maximum temperature (°C)
</th>
<th style="text-align:center;position: sticky; top:0; background-color: #FFFFFF;">
minimum temperature (°C)
</th>
<th style="text-align:center;position: sticky; top:0; background-color: #FFFFFF;">
midrange temperature (°C)
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center;">
2023
</td>
<td style="text-align:center;">
2023-01-01
</td>
<td style="text-align:center;">
15
</td>
<td style="text-align:center;">
11
</td>
<td style="text-align:center;">
13.0
</td>
</tr>
<tr>
<td style="text-align:center;">
2023
</td>
<td style="text-align:center;">
2023-01-02
</td>
<td style="text-align:center;">
14
</td>
<td style="text-align:center;">
5
</td>
<td style="text-align:center;">
9.5
</td>
</tr>
<tr>
<td style="text-align:center;">
2023
</td>
<td style="text-align:center;">
2023-01-03
</td>
<td style="text-align:center;">
9
</td>
<td style="text-align:center;">
3
</td>
<td style="text-align:center;">
6.0
</td>
</tr>
<tr>
<td style="text-align:center;">
2023
</td>
<td style="text-align:center;">
2023-01-04
</td>
<td style="text-align:center;">
13
</td>
<td style="text-align:center;">
8
</td>
<td style="text-align:center;">
10.5
</td>
</tr>
<tr>
<td style="text-align:center;">
2023
</td>
<td style="text-align:center;">
2023-01-05
</td>
<td style="text-align:center;">
12
</td>
<td style="text-align:center;">
10
</td>
<td style="text-align:center;">
11.0
</td>
</tr>
<tr>
<td style="text-align:center;">
2023
</td>
<td style="text-align:center;">
2023-01-06
</td>
<td style="text-align:center;">
12
</td>
<td style="text-align:center;">
10
</td>
<td style="text-align:center;">
11.0
</td>
</tr>
<tr>
<td style="text-align:center;">
2023
</td>
<td style="text-align:center;">
2023-01-07
</td>
<td style="text-align:center;">
11
</td>
<td style="text-align:center;">
9
</td>
<td style="text-align:center;">
10.0
</td>
</tr>
<tr>
<td style="text-align:center;">
2023
</td>
<td style="text-align:center;">
2023-01-08
</td>
<td style="text-align:center;">
10
</td>
<td style="text-align:center;">
6
</td>
<td style="text-align:center;">
8.0
</td>
</tr>
<tr>
<td style="text-align:center;">
2023
</td>
<td style="text-align:center;">
2023-01-09
</td>
<td style="text-align:center;">
8
</td>
<td style="text-align:center;">
5
</td>
<td style="text-align:center;">
6.5
</td>
</tr>
<tr>
<td style="text-align:center;">
2023
</td>
<td style="text-align:center;">
2023-01-10
</td>
<td style="text-align:center;">
12
</td>
<td style="text-align:center;">
4
</td>
<td style="text-align:center;">
8.0
</td>
</tr>
<tr>
<td style="text-align:center;">
…
</td>
<td style="text-align:center;">
…
</td>
<td style="text-align:center;">
…
</td>
<td style="text-align:center;">
…
</td>
<td style="text-align:center;">
…
</td>
</tr>
</tbody>

</table>
</div>
</div>
<p>We now predict the day the lilacs will bloom. The <code>R</code> code below uses the <code>doy_prediction</code> and <code>doy_last_frost</code> functions created in earlier sections and displays the prediction in Table 13. At the time of our writing, the predicted date is <strong>April 19</strong>. The forecast is easily updated by providing the url to the updated AccuWeather webpage. (You might use the url <a href="https://web.archive.org/save">https://web.archive.org/save</a> to save a webpage to the Internet Archive to ensure your work is reproducible.)</p>
<div class="sourceCode" id="cb16" style="background: #f1f3f5;"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb16-1"><span class="in" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">```{r}</span></span>
<span id="cb16-2">bloom_day_br <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span></span>
<span id="cb16-3">  temp_br <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span></span>
<span id="cb16-4">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">summarize</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">date =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">doy_prediction</span>(temp, tmax) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">as.Date</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"2023-01-01"</span>)) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span></span>
<span id="cb16-5">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">pull</span>(date)</span>
<span id="cb16-6"></span>
<span id="cb16-7">frost_day_br <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> </span>
<span id="cb16-8">  temp_br <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span> </span>
<span id="cb16-9">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">pull</span>(tmax) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span> </span>
<span id="cb16-10">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">doy_last_frost</span>() <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">as.Date</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"2023-01-01"</span>) </span>
<span id="cb16-11"></span>
<span id="cb16-12"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">tibble</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">`</span><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">last frost date</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">`</span> <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">=</span> frost_day_br, </span>
<span id="cb16-13">       <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">`</span><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">bloom date</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">`</span> <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">=</span> bloom_day_br) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span></span>
<span id="cb16-14">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">kable</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">align =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"c"</span>,</span>
<span id="cb16-15">        <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">caption =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Table 13: Last frost date and lilac bloom date in Brussels in 2023."</span>) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span></span>
<span id="cb16-16">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">kable_styling</span>()</span>
<span id="cb16-17"><span class="in" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">```</span></span></code></pre></div>
<div id="tab-table13">

<table class="table" style="margin-left: auto; margin-right: auto; margin-bottom: 1.5em">
<caption>
<b>Table 13:</b> Last frost date and lilac bloom date in Brussels in 2023.
</caption>
<thead>
<tr>
<th style="text-align:center;">
last frost date
</th>
<th style="text-align:center;">
bloom date
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center;">
2023-01-27
</td>
<td style="text-align:center;">
2023-04-19
</td>
</tr>
</tbody>

</table>
</div>
<p>We visualize the predictions in Figure 6, which has the same interpretation as Figure 4. If the temperature forecast and Quetelet’s law are correct, on January 27, 2023 the lilacs in Brussels began “collecting” temperature. The lilacs will continue to “collect” temperature until April 19, at which point they will exceed their 4264°C² quota and bloom.</p>
<div class="sourceCode" id="cb17" style="background: #f1f3f5;"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb17-1"><span class="in" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">```{r}</span></span>
<span id="cb17-2">(temp_br <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span> </span>
<span id="cb17-3">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">ggplot</span>() <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> </span>
<span id="cb17-4">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">aes</span>(date, temp) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> </span>
<span id="cb17-5">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">geom_line</span>() <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> </span>
<span id="cb17-6">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">labs</span>(</span>
<span id="cb17-7">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">x =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">""</span>,</span>
<span id="cb17-8">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">y =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"midrange temperature (°C)"</span>,</span>
<span id="cb17-9">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">title =</span></span>
<span id="cb17-10">      <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Figure 6: According to Quetelet's law, the lilacs will bloom once exposed to 4264°C² following the last frost."</span>) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span></span>
<span id="cb17-11">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">geom_vline</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">xintercept =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">as.numeric</span>(<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">c</span>(frost_day_br, bloom_day_br)), </span>
<span id="cb17-12">             <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">linetype =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"dotted"</span>)) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span></span>
<span id="cb17-13">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">ggplotly</span>() <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span> </span>
<span id="cb17-14">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">add_annotations</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">x =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">as.numeric</span>(<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">c</span>(frost_day_br, bloom_day_br)),</span>
<span id="cb17-15">                  <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">y =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">c</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">14</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">14</span>),</span>
<span id="cb17-16">                  <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">text =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">c</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"last</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">\n</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">frost"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"first</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">\n</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">bloom"</span>),</span>
<span id="cb17-17">                  <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">font =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">list</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">size =</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">14</span>),</span>
<span id="cb17-18">                  <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">ay =</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>,</span>
<span id="cb17-19">                  <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">xshift =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">c</span>(<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">14</span>, <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">16</span>)) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span></span>
<span id="cb17-20">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">config</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">displaylogo =</span> <span class="cn" style="color: #8f5902;
background-color: null;
font-style: inherit;">FALSE</span>)</span>
<span id="cb17-21"><span class="in" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">```</span></span></code></pre></div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="images/fig6.png" class="lightbox" title="A line graph of midrange temperature by day in Brussels for January 1 to February 18 (observed) and February 19 to May 20 (forecast), 2023, with day of last frost (January 27) and predicted day of first bloom (April 19) marked by vertical dashed lines." data-description="Author

provided,

<a href=&quot;https://creativecommons.org/licenses/by/4.0/&quot;>CC BY 4.0</a>" data-gallery="quarto-lightbox-gallery-9"><img src="https://realworlddatascience.net/ideas/tutorials/posts/2023/04/13/images/fig6.png" class="img-fluid figure-img" alt="A line graph of midrange temperature by day in Brussels for January 1 to February 18 (observed) and February 19 to May 20 (forecast), 2023, with day of last frost (January 27) and predicted day of first bloom (April 19) marked by vertical dashed lines."></a></p>
</figure>
</div>
<div class="figure-caption">
<p><strong>Figure 6:</strong> According to Quetelet’s law, the lilacs will bloom once exposed to 4264°C² following the last frost. Author provided, <a href="https://creativecommons.org/licenses/by/4.0/">CC BY 4.0</a>.</p>
</div>
</section>
<section id="quetelets-legacy-advocate-mentor-and-perhaps-data-scientist" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="quetelets-legacy-advocate-mentor-and-perhaps-data-scientist">Quetelet’s legacy: advocate, mentor, and perhaps data scientist</h2>
<p>In this tutorial, we stated the law of the flowering plants and explained how Quetelet derived it. We also reproduced and replicated Quetelet’s findings before using his law to predict the day the lilac will bloom in Brussels. We now conclude with a reflection on Quetelet’s legacy.</p>
<p>The law of the flowering plants surely stands the test of time. It continues to be used by scientists – with relatively few changes – to plan harvests, manage pests, and study ecosystems stressed by climate change. We speculate the law’s longevity is due to the fact that it balances simplicity with relatively accurate predictions.</p>
<p>Although Quetelet did not discover the law, he did much to advance it. Quetelet founded an international network for “observations of the periodical phenomena” (in addition to numerous statistical societies and publications, including the precursor to the Royal Statistical Society). Quetelet’s network of 80 stations collected observations throughout Europe from 1841 until 1872. In particular, Quetelet collaborated with Charles Morren – who later coined the term phenology, the name of the field that now studies biological life-cycle events like the timing of flower blooms <span class="citation" data-cites="demarée_rutishauser_2011">(Demarée and Rutishauser 2011)</span>.</p>
<div class="no-row-height column-margin column-container"><div id="ref-demarée_rutishauser_2011" class="csl-entry">
Demarée, Gaston R., and This Rutishauser. 2011. <span>“From <span>‘Periodical Observations’</span> to <span>‘Anthochronology’</span> and <span>‘Phenology’</span> – the Scientific Debate Between Adolphe Quetelet and Charles Morren on the Origin of the Word <span>‘Phenology’</span>.”</span> <em>International Journal of Biometeorology</em> 55 (6): 753–61. <a href="https://doi.org/10.1007/s00484-011-0442-5">https://doi.org/10.1007/s00484-011-0442-5</a>.
</div></div><p>In recent years, the observations collected through phenology networks have become an important resource for understanding the impacts of climate change. For example, the USA National Phenology Network calculates the Spring Bloom Index, which measures the “first day of spring” using the days lilacs are observed to bloom at locations across the United States. The index is then compared to previous years. Figure 7 shows one comparison, called the Return Interval. The Return Interval is much like a p-value, calculating how frequently more extreme spring indices were observed in previous decades. Bloom dates that are uncommonly early (green) or late (purple) may indicate environments stressed by changing climate. Scientists exploit the relationship between temperature and bloom date to extrapolate the index to areas with few observations.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="images/six-bloom-return-interval-2020.png" class="lightbox" title="A map of the United States showing the Spring Bloom Index Return Interval 2020, which measures whether spring is typical when compared to recent decades." data-description="Source:

<a
href=&quot;https://www.usanpn.org/files/npn/maps/six-bloom-return-interval-2020.png&quot;>USA
National Phenology Network</a>" data-gallery="quarto-lightbox-gallery-10"><img src="https://realworlddatascience.net/ideas/tutorials/posts/2023/04/13/images/six-bloom-return-interval-2020.png" class="img-fluid figure-img" alt="A map of the United States showing the Spring Bloom Index Return Interval 2020, which measures whether spring is typical when compared to recent decades."></a></p>
</figure>
</div>
<div class="figure-caption">
<p><strong>Figure 7:</strong> The Spring Bloom Index Return Interval measures whether spring is typical when compared to recent decades. Source: <a href="https://www.usanpn.org/files/npn/maps/six-bloom-return-interval-2020.png">USA National Phenology Network</a>.</p>
</div>
<p>Quetelet’s emphasis on discovering the universal laws he believed govern social and biological phenomenon has not endured. But data scientists continue to appropriate laws from one area of science to study another. For example, data scientists use neural networks and genetic algorithms to study a wide variety of phenomenon unrelated to neuroscience or genetics. Perhaps Quetelet’s appropriation of Newton’s law, in addition to his careful use of data, make him among the first data scientists?</p>
</section>
<section id="your-turn-do-you-have-what-it-takes-to-beat-quetelets-law" class="level2">
<h2 class="anchored" data-anchor-id="your-turn-do-you-have-what-it-takes-to-beat-quetelets-law">Your turn: Do you have what it takes to beat Quetelet’s law?</h2>
<p>Quetelet reported that a plant flowers when the sum of the daily temperatures squared exceeds a specific quantity. His prediction rule was state of the art in 1833. But surely you, a twenty-first century data scientist, can do better. Here are some ideas to get you started.</p>
<ol type="1">
<li><p>Quetelet squared the temperature before calculating the sum. Would another function of temperature produce a more accurate prediction?</p>
<ol type="i">
<li><p>Remove the square so that a plant flowers once the sum of the daily temperatures exceeds a (different) specific quantity. Does this version of the law produce more accurate predictions? What if you use the daily temperatures cubed? (Beginner)</p></li>
<li><p>Suppose a lilac only registers temperatures between 0°C and 10°C. That is, a lilac experiences temperature below the lower limit, 0°C, as 0°C, and above the upper limit, 10°C, as 10°C. Does the accuracy of the predictions improve if you use the temperature the lilac experienced instead of the ambient temperature measured by a weather station? Write a program that finds the lower and upper limits that produce the most accurate predictions. (Intermediate)</p></li>
<li><p>Quetelet used mean absolute error to evaluate the accuracy of his predictions. But his estimate of the specific quantity of heat needed to bloom, 4264°C², does not actually minimize mean absolute error. Write a program that finds the specific quantity that minimizes mean absolute error. Redo part i. and ii. using this function. (Advanced)</p></li>
</ol></li>
<li><p>Quetelet calculated the sum of the daily temperature squared between the day of last frost and the bloom date. Would another time interval produce more accurate predictions?</p>
<ol type="i">
<li><p>We estimated the day of last frost using the last day the maximum temperature was below 0°C. Try estimating the day of last frost by the last day the midrange temperature was below 0°C? Which estimate yields the most accurate predictions? What if you ignore the day of last frost and simply calculate the sum of the daily temperatures squared between February 1 and the bloom date? When you change the time interval, be sure to calculate the new specific quantity of heat needed to bloom. (Beginner)</p></li>
<li><p>Write a program that finds the time interval which yields the best predictions. (Intermediate)</p></li>
<li><p>Write a program that calculates the prediction rule for many different time intervals. Use cross-validation to combine these prediction rules into a single prediction rule. (Advanced)</p></li>
</ol></li>
<li><p>Quetelet’s law only considers the temperature. Would additional information provide more accurate predictions?</p>
<ol type="i">
<li><p>Is the specific quantity of heat needed to bloom different in years with abnormally cold winters? Would the predictions be more accurate if you use one quantity of heat for years with cold winters and a different quantity of heat for years with warm winters? (Beginner)</p></li>
<li><p>Is the estimated quantity of heat needed to bloom similar for locations close in space and time? Write a program that leverages spatial and temporal correlation to improve the accuracy of the predictions. (Intermediate)</p></li>
<li><p>Some biologists report that a plant must be exposed to a fixed amount of cold temperature in the winter – in addition to a fixed amount of warm temperature in the spring – before it can bloom. Augment the law of the flowering plants to require the accumulation of a specific quantity of cold temperature before the accumulation of a specific quantity of warm temperature. Write a program that uses this new law to predict the day the lilac blooms. (Advanced)</p></li>
</ol></li>
</ol>
<p>Feeling good about your prediction algorithm? Show it off at the annual <a href="https://competition.statistics.gmu.edu/">Cherry Blossom Prediction Competition</a>!</p>
</section>
<section id="appendix-preparing-usa-npn-data" class="level2">
<h2 class="anchored" data-anchor-id="appendix-preparing-usa-npn-data">Appendix: Preparing USA NPN Data</h2>
<div class="sourceCode" id="cb18" style="background: #f1f3f5;"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb18-1"><span class="in" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">```{r}</span></span>
<span id="cb18-2"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 1. download lilac data using `rnpn`</span></span>
<span id="cb18-3">usa_npn <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> </span>
<span id="cb18-4">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">npn_download_individual_phenometrics</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">request_source =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Jonathan Auerbach"</span>,</span>
<span id="cb18-5">                                       <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">year =</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1900</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2050</span>,</span>
<span id="cb18-6">                                       <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">species_ids =</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">36</span>,                       </span>
<span id="cb18-7">                                       <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">phenophase_ids =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">c</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">77</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">412</span>))            </span>
<span id="cb18-8"></span>
<span id="cb18-9"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 2. limit analysis to sites that report more than 25 times</span></span>
<span id="cb18-10">site_ids <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> </span>
<span id="cb18-11">  usa_npn <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span> </span>
<span id="cb18-12">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">group_by</span>(site_id) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span> </span>
<span id="cb18-13">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">summarize</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">n =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">n</span>()) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">filter</span>(n <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&gt;</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">25</span>) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">pull</span>(site_id)</span>
<span id="cb18-14"></span>
<span id="cb18-15">usa_npn <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> </span>
<span id="cb18-16">  usa_npn <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span> </span>
<span id="cb18-17">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">filter</span>(site_id <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%in%</span> site_ids)</span>
<span id="cb18-18"></span>
<span id="cb18-19"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 3. find nearest weather stations for each site</span></span>
<span id="cb18-20">locations <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> </span>
<span id="cb18-21">  usa_npn <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span> </span>
<span id="cb18-22">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">group_by</span>(site_id) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span> </span>
<span id="cb18-23">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">summarize</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">latitude =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">first</span>(latitude), </span>
<span id="cb18-24">            <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">longitude =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">first</span>(longitude))</span>
<span id="cb18-25"></span>
<span id="cb18-26">stations <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> </span>
<span id="cb18-27">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">ghcnd_stations</span>() <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span></span>
<span id="cb18-28">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">filter</span>(first_year <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&lt;=</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">min</span>(usa_npn<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">$</span>first_yes_year),</span>
<span id="cb18-29">         last_year  <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&gt;=</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">max</span>(usa_npn<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">$</span>first_yes_year),</span>
<span id="cb18-30">         state <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">!=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">""</span>) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span></span>
<span id="cb18-31">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">group_by</span>(id, latitude, longitude, state) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span></span>
<span id="cb18-32">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">summarize</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">temp_flag =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">sum</span>(element <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%in%</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">c</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"TMIN"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"TMAX"</span>))) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span>            </span>
<span id="cb18-33">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">filter</span>(temp_flag <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span> </span>
<span id="cb18-34">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">ungroup</span>()</span>
<span id="cb18-35"></span>
<span id="cb18-36">dist <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">function</span>(x, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">y =</span> stations <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">select</span>(latitude, longitude)) </span>
<span id="cb18-37">  stations<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">$</span>id[<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">which.min</span>(<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">sqrt</span>((x[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>] <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> y[,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>])<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">^</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span> <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> (x[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>] <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> y[,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>])<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">^</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>)[,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>])]</span>
<span id="cb18-38"></span>
<span id="cb18-39">locations<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">$</span>station_id <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">apply</span>(locations, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">function</span>(x) <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">dist</span>(<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">c</span>(x[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"latitude"</span>], x[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"longitude"</span>])))</span>
<span id="cb18-40"></span>
<span id="cb18-41"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 4. get weather data from nearest station using `rnoaa`</span></span>
<span id="cb18-42">get_station_data <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">function</span>(station_id) </span>
<span id="cb18-43">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">ghcnd_search</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">stationid =</span> station_id,</span>
<span id="cb18-44">               <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">var =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">c</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"tmin"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"tmax"</span>),</span>
<span id="cb18-45">               <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">date_min =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"1956-01-01"</span>,</span>
<span id="cb18-46">               <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">date_max =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"2011-12-31"</span>) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span></span>
<span id="cb18-47">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">reduce</span>(left_join, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">by =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">c</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"id"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"date"</span>)) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span></span>
<span id="cb18-48">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">transmute</span>(id, </span>
<span id="cb18-49">            date, </span>
<span id="cb18-50">            <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">tmax =</span> tmax <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>,</span>
<span id="cb18-51">            <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">tmin =</span> tmin <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>)</span>
<span id="cb18-52"></span>
<span id="cb18-53">usa_npn <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> </span>
<span id="cb18-54">  locations <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span></span>
<span id="cb18-55">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">mutate</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">temp =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">map</span>(station_id, get_station_data)) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span></span>
<span id="cb18-56">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">right_join</span>(usa_npn, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">by =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">c</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"site_id"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"latitude"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"longitude"</span>)) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span> </span>
<span id="cb18-57">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">group_by</span>(<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">rownames</span>(usa_npn)) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span> </span>
<span id="cb18-58">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">mutate</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">temp =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">map</span>(temp, <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">~</span> .x <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span> </span>
<span id="cb18-59">                      <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">filter</span>(<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">format</span>(date, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"%Y"</span>) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> first_yes_year) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span></span>
<span id="cb18-60">                      <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">mutate</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">temp =</span> (tmin <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> tmax) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>)),</span>
<span id="cb18-61">         <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">num_obs =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">map</span>(temp,<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">~</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">sum</span>(<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">format</span>(.x<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">$</span>date,<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"%j"</span>) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&lt;=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">150</span>)),</span>
<span id="cb18-62">         <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">doy =</span> first_yes_doy, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">year =</span> first_yes_year) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span> </span>
<span id="cb18-63">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">unnest</span>(num_obs) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span>  </span>
<span id="cb18-64">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">filter</span>(num_obs <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">150</span>) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span></span>
<span id="cb18-65">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">ungroup</span>()</span>
<span id="cb18-66"><span class="in" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">```</span></span></code></pre></div>
<div class="article-btn">
<p><a href="../../../../../../ideas/tutorials/index.html">Explore more Tutorials</a></p>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-12">
<dl>
<dt>About the author</dt>
<dd>
<strong>Jonathan Auerbach</strong> is an assistant professor in the Department of Statistics at George Mason University. His research covers a wide range of topics at the intersection of statistics and public policy. His interests include the analysis of longitudinal data, particularly for data science and causal inference, as well as urban analytics, open data, and the collection, evaluation, and communication of official statistics. He co-organizes the annual <a href="https://competition.statistics.gmu.edu/">Cherry Blossom Prediction Competition</a> with David Kepplinger and Elizabeth Wolkovich.
</dd>
</dl>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>Copyright and licence</dt>
<dd>
© 2023 Jonathan Auerbach
</dd>
</dl>
<p><a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> <img style="height:22px!important;vertical-align:text-bottom;" src="https://realworlddatascience.net/ideas/tutorials/posts/2023/04/13/https:/mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://realworlddatascience.net/ideas/tutorials/posts/2023/04/13/https:/mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"></a> Text and code are licensed under a Creative Commons Attribution 4.0 (CC BY 4.0) <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> International licence</a>. Images are not covered by this licence, except where otherwise noted.</p>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>How to cite</dt>
<dd>
Auerbach, Jonathan. 2023. “A demonstration of the law of the flowering plants.” Real World Data Science, April 13, 2023. <a href="https://realworlddatascience.net/ideas/tutorials/posts/2023/04/13/flowers.html">URL</a>
</dd>
</dl>
</div>
</div>
</div>



</section>

 ]]></description>
  <category>Prediction</category>
  <category>History of data science</category>
  <category>Statistics</category>
  <guid>https://realworlddatascience.net/ideas/tutorials/posts/2023/04/13/flowers.html</guid>
  <pubDate>Thu, 13 Apr 2023 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/ideas/tutorials/posts/2023/04/13/images/quetelet-flowers.png" medium="image" type="image/png" height="105" width="144"/>
</item>
<item>
  <title>Data science as ‘a rainbow’, and other definitions</title>
  <dc:creator>Brian Tarran</dc:creator>
  <link>https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/03/29/defining-DS.html</link>
  <description><![CDATA[ 




<p>What does “data science” mean to you? That’s a question we’ve been asking a lot in recent weeks as part of our <a href="https://realworlddatascience.net/careers/career-profiles/">career profiles</a> series of interviews – the first of which, featuring <a href="https://realworlddatascience.net/careers/career-profiles/posts/03/28/tamanna-haque.html">Jaguar Land Rover’s Tamanna Haque</a>, was published yesterday.</p>
<p>It’s also a question that was asked recently of Sylvia Richardson, emeritus director of the Medical Research Council Biostatistics Unit at the University of Cambridge and immediate past president of the Royal Statistical Society (RSS).</p>
<p>Richardson was interviewed by Francesca Dominici, interim co-editor-in-chief of the Harvard Data Science Review. In response to the question “What’s data science for you?”, Richardson said:</p>
<blockquote class="blockquote">
<p>It’s hard to be original, but I was racking my brain for a good metaphor, and came up with the metaphor of a rainbow of interconnected disciplines, sharing the common aim of making the best use of data-rich environments we live in to solve problems in society. So, like in a rainbow, data scientists have to work together to draw out information from data. And the colors must match, [though] they are different. Similarly, there are different but intersecting data science tasks, taking different shapes and forms. As data scientists, we recognize and enjoy diversity, we’re not doing all the same tasks. Nevertheless, there is a backbone, a shape to the rainbow. And for us, this backbone is probability theory, study design, and quantifying uncertainty using statistical thinking. We also know that rainbows change all the time. They don’t last, but they keep reappearing. Data science is also evolving constantly because new questions and new types of data keep arising. In a similar way to the rainbow which is strongly influenced by the atmosphere, one key aspect of data science is that we have a strong link to practice. So, we work together to solve problems from different perspectives, we evolve, we try to be relevant to science and society, and make the best use of the data. [<a href="https://hdsr.mitpress.mit.edu/pub/v27yux58/release/2?from=2089&amp;to=3374">Source</a>]</p>
</blockquote>
<p>Richardson’s view on the meaning and importance of data science has special resonance to me, as editor of Real World Data Science. While president of RSS, Richardson set up the <a href="https://rss.org.uk/policy-campaigns/policy-groups/data-science-task-force/">Data Science Task Force</a> out of which this website emerged. As she explains to Dominici:</p>
<blockquote class="blockquote">
<p>… while I was president, I felt a sense of urgency to encourage the RSS to revisit its engagement with data science, and I created a data science task force right at the beginning of my presidency. It didn’t get going earlier because there was COVID to keep us busy! Nevertheless, the Data Science Task Force got underway in 2021 and came up with two major recommendations. One was to give more resources to the practitioners’ community, which led the RSS to create a Real World Data Science online platform. A second direction was to brainstorm on what is still needed for the discipline to thrive. [<a href="https://hdsr.mitpress.mit.edu/pub/v27yux58/release/2?from=17202&amp;to=17799">Source</a>]</p>
</blockquote>
<p>You can read (or listen) to Richardson and Dominici’s conversation in full on the <a href="https://hdsr.mitpress.mit.edu/pub/v27yux58/release/2">Harvard Data Science Review website</a>.</p>
<p>And we’ll have more <a href="https://realworlddatascience.net/careers/career-profiles/">career profiles</a> – and more personal definitions of data science – to share soon. In the meantime, why not tell us what “data science” means to you?</p>
<div class="article-btn">
<p><a href="../../../../../../viewpoints/editors-blog/index.html">Back to Editors’ blog</a></p>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-6">
<dl>
<dt>Copyright and licence</dt>
<dd>
© 2023 Royal Statistical Society
</dd>
</dl>
<p><a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> <img style="height:22px!important;vertical-align:text-bottom;" src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/03/29/https:/mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/03/29/https:/mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"></a> This work is licensed under a Creative Commons Attribution 4.0 (CC BY 4.0) <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> International licence</a>, except where otherwise noted.</p>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>How to cite</dt>
<dd>
Tarran, Brian. 2023. “Data science as ‘a rainbow’, and other definitions.” Real World Data Science, March 29, 2023. <a href="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/03/29/defining-DS.html">URL</a>
</dd>
</dl>
</div>
</div>
</div>



 ]]></description>
  <category>Updates</category>
  <category>Themes</category>
  <category>People</category>
  <guid>https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/03/29/defining-DS.html</guid>
  <pubDate>Wed, 29 Mar 2023 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/03/29/images/rainbow.png" medium="image" type="image/png" height="105" width="144"/>
</item>
<item>
  <title>‘Data science challenges you to keep learning – there’ll always be new advances in the field’</title>
  <dc:creator>Brian Tarran</dc:creator>
  <link>https://realworlddatascience.net/careers/career-profiles/posts/2023/03/28/tamanna-haque.html</link>
  <description><![CDATA[ 




<p><strong>Hi, Tamanna. Thank you for sharing your career story with Real World Data Science. Please tell us a little about yourself and your role in data science.</strong><br>
I’m Tamanna Haque. I’ve been working at Jaguar Land Rover for nearly four years, recently promoted to lead data scientist working within product engineering. It’s coming up to eight years that I’ve been working in the field, and my areas of interest are the use of machine learning to provide the best products and experiences for my customers and stakeholders.</p>
<p><strong>What does your job involve?</strong><br>
My role involves using the connected car and AI to make our products and customer experiences better, whilst leading within our wide data science team too. The data science team in Manchester, UK, originated with myself and one of my teammates – it’s since grown to nearly 40 (cross-sites and countries) and developed into a high-performing, advanced data science team.</p>
<p>What makes us stand out is the nature of our work – we mostly use vehicle data (of participating customers), which is different to a lot of other commercial businesses or teams who’ll focus more on transactional or web data. The data we use lends itself to some pretty interesting projects, and a general futuristic feel here.</p>
<p>I’m particularly interested and active in enabling a more electric and modern luxury future from the use of vehicle data.</p>
<p><strong>What does “data science” mean to you?</strong><br>
The realisation of value! Whether that is added revenue, saved costs or improved growth, I’m led by what data science can do for the business and its customers. The use of data science can open up many exciting, value-adding opportunities.</p>
<div class="pullquote-container">
<div class="grid">
<div class="g-col-12 g-col-lg-4">
<div class="quarto-figure quarto-figure-left">
<figure class="figure">
<p><img src="https://realworlddatascience.net/careers/career-profiles/posts/2023/03/28/images/tamanna-haque.png" class="img-fluid figure-img" alt="Black and white portrait photo of Tamanna Haque"></p>
<figcaption class="figure-caption">Photo supplied by Tamanna Haque, courtesy of Jaguar Land Rover. Used with permission.</figcaption>
</figure>
</div>
</div>
<div class="g-col-12 g-col-lg-8 pullquote-grid pullquote">
<p><img src="https://realworlddatascience.net/images/pullquote-purple.png" class="img-fluid" width="50"></p>
<p>There are more routes to getting into data science nowadays, but it’s important to not lose sight of fundamentals such as statistics and mathematics. A lot of people can code-up models but it’s fair to say that only a portion of them appreciate how to do this responsibly.</p>
</div>
</div>
</div>
<p><strong>What do you think is your most important skill as a data scientist?</strong><br>
I’ve always presented myself as a technically astute data scientist, even when entering leadership. But my niche is my ever-growing commercial awareness and passion about our products, customers and business. These aren’t new qualities, but they now align with my professional interests, as well as personal (I’ve been a fan of the Jaguar brand since childhood)!</p>
<p><strong>How did you get into data science?</strong><br>
I did a maths degree at the University of Manchester, where I specialised in statistics. I didn’t do any post-graduate education and this was fine for me.</p>
<p>After graduating, I joined a digital fashion retailer (with a financial services proposition) as an analyst initially. I learned a lot about real-life data and analytics itself, whilst developing a rounded understanding about the business and how to deal with stakeholders cross-functionally. I must have served a few hundred at least(!) and left most of the ‘fancy’ stuff I learned at university aside, whilst getting to grips with so many aspects of commercial analytics. A great way for me to set solid foundations for what followed, and I personally feel this gives me a lens that others who dive straight into data science don’t have.</p>
<p>I was soon attracted to data science because it tapped into what I learned at university and challenges you to keep learning; there’ll always be things to learn, and new advances in the field.</p>
<p><strong>What, or who, first inspired you to become a data scientist?</strong><br>
I have a twin sister, we’ve always been together throughout education. Even before we graduated together, she secured her first role as an analyst. This opened my eyes to data, and data science followed for us both!</p>
<p><strong>What were the hurdles or challenges that you needed to overcome on your route into the profession?</strong><br>
I had a few people tell me I couldn’t do data science, possibly because I didn’t fit the typical data scientist stereotype in several ways. I think attitudes in the field have changed over time though and on a personal level, it’s motivated me to give it everything, and I can’t regret that.</p>
<p><strong>And what are the challenges that you face now, as a working data scientist?</strong><br>
I need to manage my diary well to ensure effectiveness and work-life balance. I’m overseeing people, other projects, doing public speaking and trying to remain hands on. I sometimes block out chunks of time in my diary – I need some meeting-free time to produce quality technical work. I try to finish on time and enjoy a very busy social life with my family and friends. A flexible attitude to how we work helps to keep me happy and energised whilst I’m delivering from various angles.</p>
<p><strong>Thinking back to your earlier roles in data science, how do they compare to your current role?</strong><br>
My current role is very different to my previous roles. I’m continually learning and adapting how I can be a good leader, providing support to a breadth of colleagues (in and outside the team) whilst delivering myself. I’m actively involved in setting and refining our team’s strategy and I’m enjoying leading projects which either deliver high financial impact or help set the path in terms of new tech and/or machine learning capability. There is much more responsibility but it’s easy to stay energised when working on cars and for a business I’ve long admired.</p>
<p><strong>What was the most important thing you learned in your first year on the job?</strong><br>
I should have had more confidence in myself, but this grew – as I adjusted to the new environment I became much more assertive. My domain knowledge and data science expertise combined help to build my self-confidence, credibility and reputation.</p>
<p><strong>What have been your career highlights so far?</strong><br>
I’m most proud of my recent promotion from senior to lead data scientist. Also it was exciting for my family and I when I gained an offer to join Jaguar Land Rover.</p>
<p><strong>Have there been any mistakes or regrets along the way?</strong><br>
No, what’s meant to be will be!</p>
<p><strong>How do you think your role will evolve over the rest of your career?</strong><br>
My progression has been relatively rapid, and I hope I’ve got many, many years ahead of me in my career. It’s hard to say how my role will evolve, I have a blend of responsibilities in my role which combined provide great fulfilment for me at the moment.</p>
<p><strong>If you were starting out in data science now, what would you put at the top of your reading/study list?</strong><br>
A good understanding of analytics and the domain you’re in are my recommended prerequisites to doing data science.</p>
<p>Analytics is an important part of the data science lifecycle, being able to get the data yourself and communicate results with influence, for example, are just a few aspects of analytics which underpin successful data science projects.</p>
<p>Also, without awareness of the business and industry you’re working in, you can become very dependent on others. Data science itself can be quite challenging, so it’s great to have a solid foundation before starting out.</p>
<p><strong>What personal or professional advice would you give for anyone wanting to be a data scientist now?</strong><br>
With the level of continuous learning required to just simply keep up, it can be more of a lifestyle and not a job, so this is something to consider!</p>
<p><strong>What do you think will be the main challenges facing data science as a field in the next few years?</strong><br>
I still expect to see a skills gap in the field. There are more routes to getting into data science nowadays, but it’s important to not lose sight of fundamentals such as statistics and mathematics. A lot of people can code-up models but it’s fair to say that only a portion of them appreciate how to do this responsibly, understanding samples versus populations, statistical testing, which type of regularisation to use in a neural network, et cetera.</p>
<p>I also think there’s a challenge of questionable data science products reaching high levels of popularity and usage amongst the public… Some recent developments in this space have been extremely intelligent but raise ethical concerns. Just because something can be done with AI doesn’t mean it should, and my preferences are towards AI being ethical and (ideally) explainable.</p>
<div class="article-btn">
<p><a href="../../../../../../careers/career-profiles/index.html">Discover more Career profiles</a></p>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-6">
<dl>
<dt>Copyright and licence</dt>
<dd>
© 2023 Royal Statistical Society
</dd>
</dl>
<p><a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> <img style="height:22px!important;vertical-align:text-bottom;" src="https://realworlddatascience.net/careers/career-profiles/posts/2023/03/28/https:/mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://realworlddatascience.net/careers/career-profiles/posts/2023/03/28/https:/mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"></a> This work is licensed under a Creative Commons Attribution 4.0 (CC BY 4.0) <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> International licence</a>, except where otherwise noted.</p>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>How to cite</dt>
<dd>
Tarran, Brian. 2023. “‘Data science challenges you to keep learning – there’ll always be new advances in the field.’” Real World Data Science, March 28, 2023. <a href="https://realworlddatascience.net/careers/career-profiles/posts/03/28/tamanna-haque.html">URL</a>
</dd>
</dl>
</div>
</div>
</div>



 ]]></description>
  <category>Automotive</category>
  <category>Analytics</category>
  <category>Leadership</category>
  <category>Machine learning</category>
  <guid>https://realworlddatascience.net/careers/career-profiles/posts/2023/03/28/tamanna-haque.html</guid>
  <pubDate>Tue, 28 Mar 2023 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/careers/career-profiles/posts/2023/03/28/images/tamanna-haque-crop.png" medium="image" type="image/png" height="105" width="144"/>
</item>
<item>
  <title>OpenAI’s text classifier won’t calm fears about AI-written homework</title>
  <dc:creator>Brian Tarran</dc:creator>
  <link>https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/03/15/AI-screening.html</link>
  <description><![CDATA[ 




<p>When ChatGPT launched in December 2022, it wasn’t long before users highlighted <a href="https://news.sky.com/story/the-ultimate-homework-cheat-how-teachers-are-facing-up-to-chatgpt-12780601">the tool’s potential as a homework aid</a>. Pop an essay question into ChatGPT’s prompt box or feed your creative writing task to the AI instead, <em>et voila</em> – your work is done!</p>
<p>In reality, of course, things aren’t quite so simple. ChatGPT, like other large language models, has an unfortunate <a href="https://realworlddatascience.net/news-and-views/editors-blog/posts/2023/01/27/talking-chatgpt.html">habit of making stuff up</a> – fine for creative writing, perhaps; not so good for a history essay. Outputs need to be checked and verified if you want to guarantee a good mark on your assignments. But while ChatGPT can’t – and shouldn’t – be trusted completely, many have found that it can help lighten the homework load.</p>
<p>With <a href="https://www.theguardian.com/technology/2023/feb/02/chatgpt-100-million-users-open-ai-fastest-growing-app">ChatGPT’s user count crossing the 100 million mark</a> last month, it’s understandable that worries about an explosion of AI-written text have proliferated in many professions, including education. <a href="https://www.washingtonpost.com/education/2023/01/05/nyc-schools-ban-chatgpt/">Some education systems</a> have decided to <a href="https://www.smh.com.au/national/nsw/can-you-tell-between-a-year-6-student-and-ai-teachers-say-they-can-20230120-p5ce5s.html">ban the use of ChatGPT</a>. Other educators have adopted a more relaxed approach. Writing in <em>Scientific American</em>, <a href="https://www.scientificamerican.com/article/how-chatgpt-can-improve-education-not-threaten-it/">law professor John Villasenor argued</a>:</p>
<blockquote class="blockquote">
<p>“The time when a person had to be a good writer to produce good writing ended in late 2022, and we need to adapt. Rather than banning students from using labor-saving and time-saving AI writing tools, we should teach students to use them ethically and productively… They need to learn to compose well-organized, coherent essays involving a mix of AI-generated text and traditional writing.”</p>
</blockquote>
<p>Villasenor makes a valid point. But experience tells us that not every student is going to use these tools ethically. Some will pursue the path of least resistance and will attempt to present ChatGPT’s outputs as their own. So, the question becomes: Is it possible to tell the difference between human-generated text and AI-generated text?</p>
<section id="spot-the-difference" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="spot-the-difference">Spot the difference</h2>
<p>One answer to that question comes from OpenAI, makers of ChatGPT. On January 31, they launched a classifier “to distinguish between text written by a human and text written by AIs from a variety of providers”.</p>
<p>OpenAI <a href="https://openai.com/blog/new-ai-classifier-for-indicating-ai-written-text">introduces the classifier</a> by saying that reliably detecting <em>all</em> AI-written text is “impossible”. But it goes on to say:</p>
<blockquote class="blockquote">
<p>“… we believe good classifiers can inform mitigations for false claims that AI-generated text was written by a human: for example, running automated misinformation campaigns, using AI tools for academic dishonesty, and positioning an AI chatbot as a human.”</p>
</blockquote>
<p>OpenAI stresses that the current version of the classifier “should not be used as a primary decision-making tool”, and users should take that statement to heart – especially if they are planning to vet student homework with it. In evaluations, OpenAI reports that its classifier correctly identifies AI-written text as “likely AI-written” only 26% of the time, while human written text is incorrectly labelled as AI-written 9% of the time.</p>
<p>These two reported numbers are important. They are, respectively, the classifier’s <strong>true positive rate</strong> and the <strong>false positive rate</strong>. The former is the conditional probability of a positive result given that a piece of text <em>is</em> AI generated; the latter is the conditional probability of a positive result given that a piece of text <em>is not</em> AI generated. However, neither piece of information directly addresses the question that will be of most interest to teachers: “If a piece of homework is flagged as ‘likely AI-written’ by the OpenAI classifier, what is the probability that it actually <em>is</em> AI-written?”</p>
<p>To answer this question, we need to flip the conditional probabilities – from “the probability of positive test given text is AI generated” to “the probability text is AI generated given positive test”. Bayes’ theorem provides a formula for doing just that, as described in <a href="https://www.significancemagazine.com/science/547-a-visual-guide-to-screening-test-results">this 2017 article by Tim Brock, published by Significance magazine</a>.</p>
<p>As Brock’s article demonstrates, versions of this problem are familiar to medical statisticians, who often find themselves having to explain screening test outcomes – specifically, the probability that a person has disease X given that they have tested positive for said disease. This probability depends on the <strong>prevalence</strong> of a disease and the <strong>sensitivity</strong> and <strong>specificity</strong> of the test, and Brock defines these terms as follows:</p>
<ul>
<li><dl>
<dt>Prevalence</dt>
<dd>
The proportion of the population being tested that are affected by a given condition.
</dd>
</dl></li>
<li><dl>
<dt>Sensitivity</dt>
<dd>
The proportion of patients with the condition being screened for that are correctly identified as having the condition.
</dd>
</dl></li>
<li><dl>
<dt>Specificity</dt>
<dd>
The proportion of patients without the condition being screened for that are correctly identified as not having the condition.
</dd>
</dl></li>
</ul>
<p>Sensitivity and specificity are also referred to as, respectively, the true positive rate (mentioned earlier) and the true negative rate.</p>
<p>We know from OpenAI’s own evaluations that out of 100 pieces of AI-written text, only around 26 would be correctly classified as “likely AI-written”, so the classifier’s sensitivity is 26%. And out of 100 pieces of human-written text, around 9 would be incorrectly classified as AI written, meaning 91 would be correctly classified as not AI written, so specificity is 91%. But the big piece of information we don’t have is prevalence: What proportion of homework assignments are written by AI?</p>
<p>This prevalence figure is likely to vary based on where students live, what age they are, their level of interest in AI tools and technologies, and many other factors. <a href="https://stanforddaily.com/2023/01/22/scores-of-stanford-students-used-chatgpt-on-final-exams-survey-suggests/">A poll of Stanford University students by The Stanford Daily</a>, for example, found that 17% of respondents used ChatGPT for final assignments or exams in the fall quarter – though it reports that “only about 5% reported having submitted written material directly from ChatGPT with little to no edits”.</p>
<p>So, let’s assume for the moment that 5% of homework assignments are AI-generated. If you were screening 1,000 pieces of homework with the OpenAI classifier, you’d see something close to the following results:</p>
<table class="table">
<colgroup>
<col style="width: 12%">
<col style="width: 21%">
<col style="width: 22%">
<col style="width: 21%">
<col style="width: 22%">
</colgroup>
<thead>
<tr class="header">
<th></th>
<th style="text-align: right;">True positives</th>
<th style="text-align: right;">False positives</th>
<th style="text-align: right;">True negatives</th>
<th style="text-align: right;">False negatives</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Results</td>
<td style="text-align: right;">13</td>
<td style="text-align: right;">86</td>
<td style="text-align: right;">864</td>
<td style="text-align: right;">37</td>
</tr>
</tbody>
</table>
<p>The figures below show the results graphically as proportions of (a) all tests and (b) all positive tests. (All plots are produced using Python and the <code>matplotlib</code> package; code and functions are available from <a href="https://github.com/fatso-jetson/screening-tests">this GitHub repository</a>.)</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/03/15/images/fig1a.png" class="img-fluid figure-img" alt="Horizontal stacked bar chart showing test results as a percentage of all tests, assuming 5% prevalence of AI-written homework"></p>
</figure>
</div>

<div class="no-row-height column-margin column-container"><div class="">
<p><strong>Figure 1a:</strong> Classifier test results as a percentage of all tests, assuming 5% prevalence of AI-written homework.</p>
</div></div><div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/03/15/images/fig1b.png" class="img-fluid figure-img" alt="Horizontal stacked bar chart showing test results as a percentage of all positive tests, assuming 5% prevalence of AI-written homework"></p>
</figure>
</div>

<div class="no-row-height column-margin column-container"><div class="">
<p><strong>Figure 1b:</strong> Classifier test results as a percentage of all positive tests, assuming 5% prevalence of AI-written homework.</p>
</div></div><p>From Figure 1b, we see that if the classifier delivers a “likely AI-written” result, the chance that the text is AI-written is only about 13%. This is the classifier’s <a href="https://uk.cochrane.org/news/sensitivity-and-specificity-explained-cochrane-uk-trainees-blog">positive predictive value</a> at the assumed 5% prevalence.</p>
<p>If we reproduce our figures using a prevalence rate of 17%, also from the Stanford survey, the chance that a positive result is a true positive is now about 37%.</p>
<table class="table">
<colgroup>
<col style="width: 12%">
<col style="width: 21%">
<col style="width: 22%">
<col style="width: 21%">
<col style="width: 22%">
</colgroup>
<thead>
<tr class="header">
<th></th>
<th style="text-align: right;">True positives</th>
<th style="text-align: right;">False positives</th>
<th style="text-align: right;">True negatives</th>
<th style="text-align: right;">False negatives</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Results</td>
<td style="text-align: right;">44</td>
<td style="text-align: right;">75</td>
<td style="text-align: right;">755</td>
<td style="text-align: right;">126</td>
</tr>
</tbody>
</table>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/03/15/images/fig2a.png" class="img-fluid figure-img" alt="Horizontal stacked bar chart showing test results as a percentage of all tests, assuming 17% prevalence of AI-written homework"></p>
</figure>
</div>

<div class="no-row-height column-margin column-container"><div class="">
<p><strong>Figure 2a:</strong> Classifier test results as a percentage of all tests, assuming 17% prevalence of AI-written homework.</p>
</div></div><div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/03/15/images/fig2b.png" class="img-fluid figure-img" alt="Horizontal stacked bar chart showing test results as a percentage of all positive tests,  assuming 17% prevalence of AI-written homework"></p>
</figure>
</div>

<div class="no-row-height column-margin column-container"><div class="">
<p><strong>Figure 2b:</strong> Classifier test results as a percentage of all positive tests, assuming 17% prevalence of AI-written homework.</p>
</div></div><p>Yet another survey, <a href="https://www.prweb.com/releases/intelligent_com_survey_finds_30_percent_of_college_students_use_artificial_intelligence_chatbot_chatgpt_for_written_homework/prweb19141759.htm">this one from Intelligent.com</a>, claims that 30% of college students have used ChatGPT for written homework. Plugging this number into our calculations, the chance that a positive test result is a true positive is now slightly better than 50/50.</p>
<table class="table">
<colgroup>
<col style="width: 12%">
<col style="width: 21%">
<col style="width: 22%">
<col style="width: 21%">
<col style="width: 22%">
</colgroup>
<thead>
<tr class="header">
<th></th>
<th style="text-align: right;">True positives</th>
<th style="text-align: right;">False positives</th>
<th style="text-align: right;">True negatives</th>
<th style="text-align: right;">False negatives</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Results</td>
<td style="text-align: right;">78</td>
<td style="text-align: right;">63</td>
<td style="text-align: right;">637</td>
<td style="text-align: right;">222</td>
</tr>
</tbody>
</table>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/03/15/images/fig3a.png" class="img-fluid figure-img" alt="Horizontal stacked bar chart showing test results as a percentage of all tests, assuming 30% prevalence of AI-written homework"></p>
</figure>
</div>

<div class="no-row-height column-margin column-container"><div class="">
<p><strong>Figure 3a:</strong> Classifier test results as a percentage of all tests, assuming 30% prevalence of AI-written homework.</p>
</div></div><div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/03/15/images/fig3b.png" class="img-fluid figure-img" alt="Horizontal stacked bar chart showing test results as a percentage of all positive tests,  assuming 30% prevalence of AI-written homework"></p>
</figure>
</div>

<div class="no-row-height column-margin column-container"><div class="">
<p><strong>Figure 3b:</strong> Classifier test results as a percentage of all positive tests, assuming 30% prevalence of AI-written homework.</p>
</div></div></section>
<section id="determining-guilt" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="determining-guilt">Determining ‘guilt’</h2>
<p>If a test has a positive predictive value of just over 50% (at an assumed prevalence rate of 30%), does that provide a reasonable basis on which to accuse someone of getting ChatGPT to do their homework? That depends on who you ask. If we look to the legal system for guidance, in civil cases like personal injury claims or contract disputes judges typically make decisions on the so-called “balance of probabilities”. This is generally assumed to mean if we are more than 50% sure of someone’s “guilt” in this context, that might be sufficient to find against them. However, in criminal law, a higher standard applies: “beyond reasonable doubt”. Legal scholars have long wrestled with how to quantify this in probabilistic terms, and surveys of judges put “beyond reasonable doubt” somewhere in the range of being 80% to 99% certain of guilt – see, for example <span class="citation" data-cites="mccauliff1982burdens">McCauliff (1982)</span> and <span class="citation" data-cites="solan1999refocusing">Solan (1999)</span>.</p>
<div class="no-row-height column-margin column-container"><div id="ref-mccauliff1982burdens" class="csl-entry">
McCauliff, Catherine MA. 1982. <span>“Burdens of Proof: Degrees of Belief, Quanta of Evidence, or Constitutional Guarantees.”</span> <em>Vand. L. Rev.</em> 35: 1293.
</div><div id="ref-solan1999refocusing" class="csl-entry">
Solan, Lawrence M. 1999. <span>“Refocusing the Burden of Proof in Criminal Cases: Some Doubt about Resaonable Doubt.”</span> <em>Tex. L. Rev.</em> 78: 105.
</div></div><p>It is at this standard of evidence that OpenAI’s classifier shows its limitations. For example, if we flip Bayes’ theorem around, we find that to achieve a positive predictive value of at least 80%, the prevalence rate needs to be at least 58%. For a positive predictive value of 90%, prevalence needs to be 76%. (Verify these figures for yourself: Python code and functions are available from this <a href="https://github.com/fatso-jetson/screening-tests">GitHub repository</a>).</p>
<p>Thus far in our calculations, we’ve set prevalence according to estimates of the percentage of students who use ChatGPT for their homework. But, according to statistician and science writer Robert Matthews, individual students could justifiably complain about having their guilt decided on this basis. “It’s like deciding someone is guilty of a crime just because they happen to live in an area notorious for criminal gangs,” he says. Instead, the guilt of individual students should be decided using an estimate of the chances that <em>they</em> would use ChatGPT for <em>that particular</em> homework assignment.</p>
<p>Looked at in this way, Matthews says, “You already have to be pretty convinced of a person’s ‘guilt’ even before applying the classifier if you want to put the evidence ‘beyond reasonable doubt’. Bayes’ theorem highlights the need to be really clear about what you mean by the ‘accuracy’ of a test, and about what question you want the test to answer.”</p>
<p>So, here’s a question that teachers will be asking if they are worried about ChatGPT-generated homework: “Has the piece of text I’m marking been written by AI?” If those same teachers use the OpenAI classifier to try to answer that question, they will no doubt expect that something classified as “likely AI-written” is more likely to be AI-written than not. However, as it stands now – and as our examples above have shown – users can’t be confident that’s the case. In education terms, this particular ‘test’ is a long way from scoring top marks.</p>
<div class="article-btn">
<p><a href="../../../../../../viewpoints/editors-blog/index.html">Back to Editors’ blog</a></p>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-6">
<dl>
<dt>Copyright and licence</dt>
<dd>
© 2023 Royal Statistical Society
</dd>
</dl>
<p><a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> <img style="height:22px!important;vertical-align:text-bottom;" src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/03/15/https:/mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/03/15/https:/mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"></a> This work is licensed under a Creative Commons Attribution 4.0 (CC BY 4.0) <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> International licence</a>, except where otherwise noted.</p>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>How to cite</dt>
<dd>
Tarran, Brian. 2023. “OpenAI’s text classifier won’t calm fears about AI-written homework.” Real World Data Science, March 15, 2023. <a href="https://realworlddatascience.net/news-and-views/editors-blog/posts/2023/03/15/AI-screening.html">URL</a>
</dd>
</dl>
</div>
</div>
</div>



</section>

 ]]></description>
  <category>AI</category>
  <category>Large language models</category>
  <category>Classifiers</category>
  <category>Screening tests</category>
  <guid>https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/03/15/AI-screening.html</guid>
  <pubDate>Wed, 15 Mar 2023 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/03/15/images/teacher-marking-homework.png" medium="image" type="image/png" height="105" width="144"/>
</item>
<item>
  <title>US legislators get their data science act together</title>
  <dc:creator>Brian Tarran</dc:creator>
  <link>https://realworlddatascience.net/viewpoints/interviews/posts/03/06/data-science-act.html</link>
  <description><![CDATA[ 




<p>On February 14, 2023, a bipartisan group of US legislators introduced the <a href="https://stevens.house.gov/media/press-releases/rep-stevens-leads-bipartisan-legislation-increase-access-data-science-and">Data Science and Literacy Act</a> with the goal of boosting access to data science education and building “America’s 21st century STEM workforce”. We sat down with guests Zarek Drozda, Anna Bargagliotti, Christine Franklin and Steve Pierson to discuss the news and to hear why data science education is “the new apple pie”.</p>
<ul>
<li>Zarek Drozda is director of the <a href="https://www.datascience4everyone.org/about">Data Science 4 Everyone</a> coalition.</li>
<li><a href="https://cse.lmu.edu/faculty/?expert=anna.bargagliotti">Anna Bargagliotti</a> is graduate program director and professor of mathematics at the Seaver College of Science and Engineering, Loyola Marymount University.</li>
<li>Christine Franklin is the American Statistical Association’s <a href="https://www.amstat.org/education/asa-k-12-statistical-ambassador">K-12 statistical ambassador</a>.</li>
<li>Steve Pierson is the <a href="https://twitter.com/asa_scipol?lang=en">ASA’s director of science policy</a>.</li>
</ul>
<p>Check out our full conversation below or on YouTube.</p>
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/OaRFFgKb1S0" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<section id="timestamps" class="level2">
<h2 class="anchored" data-anchor-id="timestamps">Timestamps</h2>
<ul>
<li>The state of data science education in the United States (<a href="https://youtu.be/OaRFFgKb1S0?t=211">3:31</a>)</li>
<li>What will be the main impacts of the Data Science and Literacy Act? (<a href="https://youtu.be/OaRFFgKb1S0?t=554">9:14</a>)</li>
<li>Professional development support for teachers and teacher-educators (<a href="https://youtu.be/OaRFFgKb1S0?t=786">13:06</a>)</li>
<li>How much money is needed to deliver data science education? (<a href="https://youtu.be/OaRFFgKb1S0?t=1133">18:53</a>)</li>
<li>Developing a data science curriculum (<a href="https://youtu.be/OaRFFgKb1S0?t=1629">27:09</a>)</li>
<li>Building confidence in data, statistics, and technology (<a href="https://youtu.be/OaRFFgKb1S0?t=1914">31:54</a>)</li>
<li>Learning from, and making connections with, international colleagues (<a href="https://youtu.be/OaRFFgKb1S0?t=2223">37:03</a>)</li>
</ul>
</section>
<section id="quotes" class="level2">
<h2 class="anchored" data-anchor-id="quotes">Quotes</h2>
<p>“Most of our teachers in US schools, math teachers, have not had any formal training in statistics. Or if they have, it’s been maybe one course. They’re very uncomfortable with trying to implement these standards [for data science and statistics education]. And it’s just going to require a tremendous amount of professional development. Sounds easy in theory to deliver professional development, but very difficult in practice.” (<a href="https://youtu.be/OaRFFgKb1S0?t=618">10:18</a>)</p>
<p>“We know that in aggregate, between federal, state, private and local funding, we’re going to have to create the necessary resources to make sure that our K-12 public education system can prepare students for a world that’s changing super fast, and the K-12 system moves super slow in how it adapts to new content. And so really it’s both about what can we do to upskill data science, data literacy skills [and] it’s also about how do we help the system adapt faster as new technology comes out and leverage the importance of data in that.” (<a href="https://youtu.be/OaRFFgKb1S0?t=1176">19:36</a>)</p>
<p>“I think we’ve spoken to some 50 or 60 offices, both on the Senate side and the House side. And this [has been] received really well. We don’t get any pushback on that there is a need for greater data literacy. Here stateside, I’ve been saying it’s kind of like advocating for apple pie. People get it and they resonate.” (<a href="https://youtu.be/OaRFFgKb1S0?t=1280">21:20</a>)</p>
<p>“As we introduce this bill, I think we should be messaging [that] there’s a economic competition aspect to this; that it’ll be really important for the US to make investments in this area to, frankly, catch up to where I think other international peers are.” (<a href="https://youtu.be/OaRFFgKb1S0?t=2434">40:34</a>)</p>
<p>“Data tell our stories, and they reflect what’s happening in our world today – much like art around us in some ways. And a way to think about data science education is to think about what we need our data understanding to be at each point in time in our educational career, or in our lives. And it’s not static, it’s an evolving thing. So you have to move with the data that are being collected.” (<a href="https://youtu.be/OaRFFgKb1S0?t=2574">42:54</a>)</p>
</section>
<section id="transcript" class="level2">
<h2 class="anchored" data-anchor-id="transcript">Transcript</h2>
<div class="callout callout-style-simple callout-warning" style="margin-top: 0.75rem;">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-body-container">
<p>This transcript has been produced using <a href="https://otter.ai/">speech-to-text transcription software</a>. It has been only lightly edited to correct mistranscriptions and remove repetitions.</p>
</div>
</div>
</div>
<p><strong>Brian Tarran</strong><br>
Hello, and welcome to the Real World Data Science news q&amp;a. I’m Brian Tarran. And I’m joined today by a panel of guests to discuss some promising developments in the United States around data science education. On the show today we have Zarek Drozda, director of the Data Science 4 Everyone coalition, Anna Bargagliotti, Graduate Programme Director and Professor of Mathematics at the Seaver College of Science and Engineering, Loyola Marymount University, Christine Franklin, the American Statistical Association’s K-12 statistical ambassador, and Steve Pearson, who is the ASA’s Director of Science Policy. Welcome all. Thank you for joining us. Steve, I’d like to come to you first, because it was one of your ASA science policy tweets that that first drew my attention to this story. And that specifically was the tweet about the introduction of a new Data Science and Literacy Act in the US House of Representatives. Can you give our viewers an overview of the act and its significance to the data science education landscape, please.</p>
<p><strong>Steve Pierson</strong><br>
Happy to Brian and I also want to credit my colleague, Ed Wu, an ASA science policy fellow who worked a lot on this and championed it. So I see kind of two overarching points here for the bill. One is just to help out those budding efforts around the United States to bring more data science education to students, right, the demand in the jobs is out there. Students should know about these jobs, we want to connect them to the 21st century jobs. So this is a Department of Education programme that helps out those schools, communities that need the help that want the help. We’re not trying to require anything of schools, which already have enough curriculum requirements. So this is a voluntary programme, that I mean, I think it’s developing curriculum, it’s providing professional development. But I think there’s another aspect of this, Brian, which is just kind of the attention that this can bring to these jobs, to the schools to the members of Congress that, you know, data intensive jobs are a great job opportunity in the 21st century, right? You can look at so many places to know that, right? The Bureau of Labor Statistics has both statistician and data scientist as the top 10 jobs in terms of projected growth for the next decade. There’s Glassdoor, there’s many others, so we know that. We want to make sure that today’s students know about those opportunities and are connected to them. But we also want to just kind of diversify the STEM workforce. So there’s components of that in the bill as well. And so we want, we think that, you know, a bill introduced into the US Congress will help bring attention to that, including the members of Congress and others.</p>
<p><strong>Brian Tarran</strong><br>
Excellent. I’ll take a step back briefly to look at the data science education landscape as it is today and Zarek, you helped facilitate a National Academies workshop last September, and one of the aims was indeed to survey that landscape for data science education for the K-12 grades – and for international audiences, correct me if I’m wrong, that’s students aged about five up to 17. Is that correct?</p>
<p><strong>Zarek Drozda</strong><br>
Right, for five to 18 range.</p>
<p><strong>Brian Tarran</strong><br>
So yeah, so how would you summarise that kind of state of data science education in the US right now?</p>
<p><strong>Zarek Drozda</strong><br>
Yeah, well, first focus on the workshop that was facilitated by the National Academies. And that was not the first but definitely the largest to date, in terms of a national convening of the United States for data science and data literacy education. We had 100 plus researchers, programme developers, and higher ed faculty in the room. There were 500 online, it was a big, you know, kind of early stage milestone for billing data science education in the United States. And we had a number of topics ranging from you know, what does this look like a practice? What is the professional development for, for K-12 teachers look like? What are examples both standalone data science courses, and also integration into different existing K-12 subject areas. And it was really a showcase of you know, a lot of the curriculum work that’s been developed over the past 10, 15 years for building your full length data science high school courses, or for building lesson plans or for building, you know, education, classroom specific software for data analysis that students can really get their their head around. And so I think it was a milestone to then this legislation then built off right that Steve was mentioning. I’m glad that you know news of both the National Academies workshop and then the legislation and kind of the growing momentum here in the US generally has made it across the pond. I think, partially our social media game was strong enough, which is exciting to hear. But I think it’s just a testament to you know, the energy for this space is really growing, right? Because it’s, it’s career connected. I think it’s so relevant to so many other emerging technologies, whether it’s artificial intelligence or ChatGPT or cyber. And I think, students, what came through really clearly in the workshop is that students really find this content relevant because of the technology applications. And it seems so, you know, of the moment.</p>
<p><strong>Brian Tarran</strong><br>
Yep. Well, certainly, you talked about jumping across the pond. So two weeks ago now, but it might have been three, I attended a meeting, a discussion around what they refer to as the digital skills gap in the UK. And I left that meeting feeling very much like what they were talking about, defining as digital skills were data science skills. And so when I saw that there was this Data Science and Literacy Act, I thought, well, you know, here’s, here’s something that hopefully, other other places like the UK can learn from. So Anna, you participated didn’t you in the workshop? So do you mind sort of giving us an overview of the data science landscape as it is, as it is now?</p>
<p><strong>Anna Bargagliotti</strong><br>
Absolutely, um, so I think, in the United States, at the moment, I think we’re at a spot where the different states are sort of moving. And in the United States, each state has their own department of education. So they, we are not, they’re not federal standards, they are state standards. And each in a lot of states, those standards are being revised and to include data science standards, and those discussions are moving pretty quickly, with some states already approving, other states implementing this coming fall, for example. And other states that are still in the process of sort of starting that. But it’s, but it’s exciting. The other thing that’s really been happening is trying to understand what the curriculum should what curriculum should look like in K-12, in particular. And the GAISE report, like you mentioned before, has a, lays out a, you know, a nice sort of example of what that should look like at the elementary, middle school and high school levels, and can be used sort of as an anchor point for states looking at what they should be doing. I would say at the university level, at the what we call the 12-16 level in the US, we are pretty good. There are many data science programmes and majors and minors across the United States. And they are quite strong, there’s more and more that pop up. And overall, those majors and minors look pretty similar from university to university, and those students are coming out with very, you know, a good skill set, and they are all finding jobs. As Steve mentioned, the job growth is there. And students are feeling quite prepared when they go to into the job growth. So I think where the university level is, could have been well articulated and well defined at the moment, the K-12 level is still sort of in flux of trying to figure out what should be there. And part of that has to do also with teacher preparation, it’s trying to understand what teachers should have and know in order to teach whatever these data science ideas are that are important for the K-12 level. The GAISE report makes some very, I think, concrete recommendations about what that should be, particularly being anchored in the statistical investigative process or problem solving process and understanding how you can use questioning in that and that being really a skill set that we are trying to promote in K-12 education, that then they use also at the university level if they continue on that way. And then just understanding that there’s different large conceptions of data now. Data are not just numbers, data could be sounds, could be text and whatnot. And these ideas are sort of these data science ideas that we are trying to promote in K-12, as well as at the university level. So I think overall, the landscape is quite good. I mean, we’re moving in these great directions. And I think slowly, we’re getting to some consensus about what that looks like. And we’re seeing that in the states moving forward with different standards.</p>
<p><strong>Brian Tarran</strong><br>
Excellent. And so you mentioned the GAISE report there and that’s the Guidelines for Assessment and Instruction in Statistics Education, and of course that’s something you co-authored with, with Chris Franklin, Chris. Yeah, of course. Yeah. I’d like to bring you into the conversation. Now, Chris. You know, you and I have spoken a number of times over the years about GAISE about statistics, education and statistical literacy and, and the challenges of delivering high quality education in data and statistics at all levels of the curriculum. I wanted to get your impression of what you think the big contributions are that this act will hopefully make towards improvement of the data science education landscape.</p>
<p><strong>Christine Franklin</strong><br>
Well, I was very excited to see this act. And I think one of the big impacts that I see is how it can help our state departments of education actually try to implement standards that we’re seeing put in place right now, in terms of statistics and data science. Teachers, right now, most of our teachers in the US schools, math teachers have not had any formal training in statistics. Or if they have, it’s been maybe one course, they’re very uncomfortable with trying to implement these standards. And it’s just going to require a tremendous amount of professional development. Sounds easy in theory to deliver professional development, but very difficult in practice. And a big part of the difficulty of delivering professional development is funding to, to pay for this. Unfortunately, what I’ve seen is state departments of education will often implement these very nice standards in their curriculum, but then they’ve run out of money, or they don’t have sources of funding to where they can then think about the professional development of the teachers. So it’s not only the professional development of the teachers, but also the curriculum that’s going to support the standards that are put in place. Now, fortunately, ASA, for example, has just a wealth of open source resources that teachers can use. But then how did the teachers know where to get it? How do they know how to implement it in the classroom. So state departments are charged with trying to develop a framework of materials for their teachers. This takes money, this takes expertise. So not only that, but I think this bill can help with funding to allow state departments to do that. But professional development typically has been like week long workshops, day workshops, maybe they go online and do workshops, but really, for professional development to be successful. Teachers need day to day support, which requires funding once again, to provide the resource within schools and school systems to provide more of the day to day support that these teachers need. And I think lastly, one thing that we don’t think a lot about, but I’m hoping this bill will help, is the assessment that goes along with the curriculum that we’re implementing for statistics and data science. Once again, that takes funding that takes manpower support. And I’m really hoping that this bill can be a source that that our state DoE’s can turn to make their standards more successful with implementation.</p>
<p><strong>Brian Tarran</strong><br>
Yeah, Chris, when you were speaking there about providing professional development support for the teachers, it reminded me of when I was a primary school governor here in the UK a few months back, a few years back, sorry. And we would always talk about math education, trying to improve math education, and that I think, the teacher confidence to deliver the math curriculum is always the issue that we run up against. So having support, having resources, having people that can go in and help, that changes the dynamic, I think, for teachers and certainly equips them to, to deliver on, you know, on that vision of, of data science education and statistical literacy for all, which is something that we spoke about before, right?</p>
<p><strong>Christine Franklin</strong><br>
That’s exactly right.</p>
<p><strong>Brian Tarran</strong><br>
That’s, that’s your vision for where we get to as a society?</p>
<p><strong>Christine Franklin</strong><br>
Well, I think one thing, one other thing we need to remember, it’s not just the teachers that need our support. It’s also the teacher educators that are preparing our school level teachers. And we, we need to keep that at the top of the list of priorities because most of our teacher educators recognise that our school level teachers need this support, but they are in a similar situation to where they don’t know exactly what they need to do. And so we’ve got kind of two big spots here that we need to work on for professional development, and it’s gonna take a lot of time and effort.</p>
<p><strong>Brian Tarran</strong><br>
Yeah, well, we’ll come back to that later, if you don’t mind. Zarek, did you want to come in? It looked like you was about to chime in.</p>
<p><strong>Zarek Drozda</strong><br>
Yeah, I was just, I wanted to agree with Chris and second it and expand it because I think it’s professional development for teacher educators and every layer above that, right. It’s every layer above the teachers: teacher educators, it’s the district staff who are implementing and creating these programmes, it’s the state staff we’re creating the standards, it’s state policy makers, it’s federal policymakers – like, you could think about professional development for all those stakeholders. And we know we need to build, you know, better education, right, for every one of those groups that are above the individual educator in a classroom, knowing that the national infrastructure is just supporting the teacher in the individual classroom to do this best at the end of the day. So yeah, we think about that in terms of a, there’s a whole system that needs to move here.</p>
<p><strong>Brian Tarran</strong><br>
I think that’s an important point to note, I think, because I go back to that digital skills workshop I was at and one of the questions that came up from from the chair was, you know, what one thing can I take back to the Secretary of State to say we need to add this to the curriculum, but it’s not one thing is it? It’s, it’s it’s a whole system, as you say, Zarek. I did want to ask you a bit about the organisation that you’re a part of, you have a coalition called Data Science 4 Everyone. To what extent was you involved in the kind of shaping of this, of this bill? And, you know, you obviously, you’ve obviously welcomed it, and you’re excited about the potential, and how much work do you see as being left to do to, to kind of get it over the line and get it into application?</p>
<p><strong>Zarek Drozda</strong><br>
Sure, well, just a very quick background on DS4E. We’re a national initiative and a coalition as you said, based at the University of Chicago here in the States. We’ve been putting together a community of education researchers and K-12, system leaders to advance policy and advance awareness and advance the case making right for why data science and data literacy and statistical acumen is so important in this day and age. And we’re really working across the K-12 system, which is very decentralised in the US, to try to forward those goals. Yeah, as I think about next steps and what’s needed, again, just re-double what Chris said, we need more funding. We did some, to give you an example. So when computer science was being built out as a new school subject in the States, they spent somewhere in the range of three to $4 billion over 15 years to build an entirely new school subject. We’re not necessarily doing that here, right? We’re not necessarily building out a whole new school subject, I think we’re really, at least our group has been much more focused on how can we integrate and upskill teachers in K-12 math, or K-12 science or K-12 social studies, right, and integrate these concepts into the existing K-12 ecosystem, working with the different subject societies. But, you know, this bill is a first really great milestone, but we know now we’re going to have to call on state legislators to pass appropriations at the state level to fund teacher support locally, we’re going to have to, you know, call on schools and districts, right, to help give teachers time to be able to implement these classroom experiences. And we’re going to need more research. Right. So this bill calls for grant programmes to state and local partners to create. But I think we also need more funding for NSF and IES, the two kind of education research bodies in the US at the national level, to fund things like student assessments, or to fund accommodations for students with disabilities to be able access to technology for data science software. There’s a lot more R&amp;D work that also has to happen to bring down the adoption costs over time for doing this type of work and making sure that every student regardless of their background, can benefit from the skill areas, and you know, upskilling in this space. And I think the last thing I would say is that we know we also need to work on teacher confidence, right? I think it’s both teacher confidence with statistics, right, and probabilistic thinking. And it’s also the the confidence of the technology, which is brand new, right? Most classrooms in the US have not been using spreadsheets, even though most workplaces do, let alone, you know, R, Python, SQL, any of the more kind of modern computational tools that are used in modern day statistics. And so we have a lot of work on that front to do as well.</p>
<p><strong>Brian Tarran</strong><br>
Okay. And so, if I’ve understood it correctly, there’s about $50 million over five years that is being asked for in this bill. But that’s, from what you’re saying, am I correct in thinking that’s just a kind of a small part of what’s needed to completely deliver on your goals?</p>
<p><strong>Zarek Drozda</strong><br>
It is a first step. An important one, but a first step.</p>
<p><strong>Brian Tarran</strong><br>
So, longer term, is it– Do you head towards the billions territory, like in the computer science space? Or is it a little less demanding of finances and resources and that, do you think? I know it’s hard to say, to pin these things down, but–</p>
<p><strong>Zarek Drozda</strong><br>
At least from my angle, I’d love the group to jump in here, it’s probably a little bit less demanding. But we know that in aggregate between federal, state, private and local funding, we’re going to have to create the necessary resources to make sure that our K-12 public education system can prepare students for a world that’s changing super fast, and the K-12 system moves super slow, right, in how it adapts to new content. And so really it’s both about, you know, what can we do to upskill data science, data literacy skills. It’s also about how do we help the system just adapt faster as new technology comes out and, you know, leverage the importance of data in that.</p>
<p><strong>Steve Pierson</strong><br>
And Brian, I can jump in a little bit on the price tag, which, when we were shopping around this bill, we didn’t actually include like a cost per year for this, because we know that that can be a very sensitive topic, and we were, we really wanted to have bipartisan introduction. So, and we were fortunate to get it right. But it was the offices who have agreed to kind of consider us that came up with the $10 million. And I’m, you know, I know for a fact that, you know, a few of the offices, at least one of the offices did want significantly more, but this was how we were gonna get bipartisan introduction.</p>
<p><strong>Brian Tarran</strong><br>
Yeah. Okay. And on that point, that bipartisan nature of the bill’s introduction, does that give you as a group hope that it will eventually make it through Congress and become a law, and that there’ll be these resources made available?</p>
<p><strong>Steve Pierson</strong><br>
Yeah, absolutely. And I’ll also just say, Brian, that I think we’ve spoken to some 50 or 60 offices, both on the Senate side and the House side. And this is, it’s received really well, we don’t get any pushback on that, you know, yes, there is a need for greater data literacy. Here stateside, I’ve been saying it’s kind of like advocating for apple pie. Right. This is, people get it and they resonate. And to that point, we only brought this to Representative Stevens, I think it was maybe late October. But they really wanted to move on this, they wanted to wait for the new Congress for bandwidth issues. But, significantly, we’re told that the representative wanted this to be her first bill introduced of the new Congress, and she had many to choose from. So I think that’s really positive. The other thing is, I’ve heard from email, we haven’t had a chance to debrief with the staff yet, because they’re swamped with all kinds of things, but they’re getting a lot of positive feedback from people about this bill. So it really seems to be kind of tapping a nerve. A recognition.</p>
<p><strong>Zarek Drozda</strong><br>
I was just going to add to Steve that when we went– So in advance of that legislation being introduced, we had 15 of the largest math and science and technology education associations supporting the legislation, which was a huge win. It showed, I think, that this data science, data literacy, education is really a collaborative multi-subject effort in the States, which does not happen often, it’s usually very siloed. And I think the other thing I’d say is, in the first 24 hours since the bill was introduced, we had 150-160 additional education leaders and organisations sign on to the letter of support that we were helping circulate between Data Science 4 Everyone and the American Statistical Association. And just to re-emphasise that we saw a lot of energy around this, and bipartisan, right. We’re building support on both sides of the aisle, because it’s, you know, this is apple pie, it’s so evident that every student’s going to need this for the next decade.</p>
<p><strong>Brian Tarran</strong> I like this. So data was once the new oil, but now data science education is the new apple pie. I think this is this is great. Anna, you know, assuming that the Data Science and Literacy Act goes through, funds are made available, this work starts in earnest, what sort of timescales are we looking at, do you think, before we start to see the real world impact, you know, in terms of teacher training, student outcomes, and then eventually, obviously, building this workforce, that is so needed, that is equipped with data literacy and data science skills?</p>
<p><strong>Anna Bargagliotti</strong><br>
Yeah, I think I kind of want to say two things to this point. I think post K-12, the college level, we are seeing those outcomes, and they are great. And I think we are really, that is, it feels very good. It feels like we’ve targeted the right things. It feels that students report back that they’re excelling in their jobs and doing great things. So I think that part is sort of, is taken care of. I think at the K-12 level, what’s harder is we’re less nimble. Like Zarek mentioned, K-12 is just a beast to move. It’s very difficult. And we’re in a situation where the target of data science changes every day, truly every day, for two real reasons. One is because the conceptualization of data changes every day. We can imagine today we think of data as text, but in probably a month, there’s some other type of data that we haven’t thought of that will emerge. And so now all of a sudden, you’ve got, you’re trying to teach pillars or concepts in K-12 that are actually a moving target. And then the other big thing that changes pretty much every day is our capabilities for wrangling, visualising access to data, all that stuff is changing. And so at the university level, you’re much more nimble because you’re in these courseworks, and your students are very advanced, and you can kind of move within those, those spaces, and you can change a course at a time. At the K-12 level we’re much more prescribed and harder to move. So I think in terms of timeframe, I think if we focus on the sort of large concepts and the baseline skill sets that we want to graduate students from K-12, I think we can move much quicker than getting into sort of the nitty gritty of a student needs to be able to programme per se, or something like that, like I think more that statistical investigative process, and those questioning, those types of ideas are really the crux of what K-12 looks like that then allows the university level to be more nimble. So for me, the timeframe is I think we have to, we have to think about it differently as we’re never going to arrive. It’s not going to be like, Oh, in five years, this is completed. It’s a, are we reacting in the right way? Or are we sort of ahead of the game. And I think we can get ahead of the game if we go to the concepts and that idea instead of thinking of topics that we’re teaching. And I hope that with this, I have great hope for this bill. I think it’s like everybody said that this is just such a great first drop in the bucket with the apple pie that I think hopefully in the next few years, the states are going to have been moved and then everybody will be doing some type of data science at the state level. And then it’s like Chris mentioned, before moving the professional development, which is a big challenge.</p>
<p><strong>Brian Tarran</strong><br>
When you were speaking, just there, Anna, and you were you were talking about the difference between you what you’re achieving at the college level versus the younger level, it made me think that, you know, this isn’t just about providing a next generation of data science workers, right, it’s about equipping everyone with the skills to be able to exist in a data science world. And this goes to the point that I think Chris and I have spoke about before, right, about being able to be, when you’re confronted with data, being able to ask the right questions about that data. And so I think obviously, that’s, to me, that’s where I think maybe the Guidelines for Assessment and Instruction in Statistics Education seems a promising first step in the development of a data science, data literacy, statistics curricula, do you see that that needing to be – obviously these things are always needing to be revised, right – but do you see that, Chris, as a kind of foundation on which the states can start to build and to move towards this vision that’s laid down in the act?</p>
<p><strong>Christine Franklin</strong><br>
Well, most definitely. And we’ve been real fortunate in the US here that our states right now that are trying to implement more statistics and data science standards, are going to the GAISE II document to use as a guiding document. And ASA has been very fortunate also to where these states, many of them have reached out to us to actually help advise them as they go through the process. I wanted to come in on a follow up with something Anna said in terms of the timeline. As she was speaking, I thought about how when we were sending out our document for review with the GAISE II, the updates, and we sent it out to probably about 20 to 25 different reviewers, we received more feedback than we knew what to do with. But many of the reviewers, very well respected people in the field, came back to us and said, we were being way too ambitious with the GAISE II document that, in fact, so many states here in the US we’re still back trying to implement the recommendations we made in the 2005 GAISE document. And our response was, we can’t be writing for today. What our goal is, is to try to write a document to where 5, 10 years from now, this is where we hope that our K through 12 system will be. And I’ve noticed this in working with other national documents, that I think the tendency oftentimes is to try to write a document for where we are now. And I think that we always need to, in terms of a timeline, think about 10 years down the road when we wrote the document. And it’s hard to be visionary. But as Anna was saying, things are changing so quickly. I mean, the GAISE II document, I think the writers are all saying, oh, we should have included this, we should have included that. Because since its publication in 2020, we’re already seeing needed changes. So I think we’re always going to be catching up to some degree. But as Anna said, I think the goal of these documents needs to be conceptual understanding, it needs to be that role of questioning. I like to say, I just want people to be healthy sceptics to where when they see statistical information, they see data, they immediately start asking questions. They may not know the answers, or know what the answers aresupposed to be, but at least they’re questioning.</p>
<p><strong>Anna Bargagliotti</strong><br>
And I’ll just add one really quick thing, Brian, if that’s okay. Chris and I are about to embark on another ASA initiative, which is the revision of the SET report, which is the Statistics Education for Teachers report that the last publication was, oh my gosh, Chris, I can’t remember even the date–</p>
<p><strong>Christine Franklin</strong><br>
2015.</p>
<p><strong>Anna Bargagliotti</strong><br>
2015. And the the idea of the new report that we will be starting to write this year, along with some wonderful colleagues, is going to be to talk about the teacher preparation aspect of that in light of everything that’s happened with statistics and data science in particular, what should that look like? And how, how could that be? So I just wanted to add that.</p>
<p><strong>Brian Tarran</strong><br>
Excellent. I also wanted to ask, again, maybe this is a question for Zarek. If we’re talking about data science for everyone, what about people like me, who have already already finished their education? I mean, I know you can always learn; every day is an opportunity to learn new things. But, you know, from your coalition’s perspectives, Zarek, what do you want to see happen so that, you know, that we’re not leaving behind big chunks of the population, you know, the older chunks of the population who haven’t had the benefit of going through this education system as it is now, let alone what it might be in five years time, right?</p>
<p><strong>Zarek Drozda</strong><br>
Yeah, Brian, it’s a great question. And I, I just came off a year of serving as a fellow in the US Department of Education. And I had a lot of conversations with the programme officer who is responsible for research, education research and adult education, about that subject. Right. And I think one of the themes that I learned from that work and from that, from those conversations was this idea around fear of technology, as it accelerates. It’s really hard for people to deal with, you know, ChatGPT, DALL-E, AI, neural networks, you know, the list goes like on and on, and it changes every month, as as we’ve discussed here. And I think a big goal from our side is both to build confidence when people are dealing with a deluge of data and a increasing amount of information, right, which we talked about, and it’s also the confidence in the technology tools that are constantly changing. So I think as we think about, you know, a student K-12, we want to get them on a tool, so they can be confident and switch to the next one when it comes out. Because we know that technology integration is just is really critical. And the same thing is true for the adult learners, right, or for the for the folks that are older, there is a wealth of online digital learning, online courses, asynchronous experiences, to learn any coding languages, any programming language, any just software – doesn’t even have to be computation or coding intensive, right, it can just be spreadsheets or, or Tableau or some of the not-too-syntax heavy tools, and there’s so much digital and elearning opportunities for that. If we can build formal exposure into the classroom pathway, and build student confidence to then jump on to those later on. That is really critical. Because if you don’t get an exposure, it’s so hard to take the first step to jump in to the digital training or to you know, go to your employer and say, I want this, you know, this professional development programme, because it’s hard to know where to start. And we also worked on a data literacy training programme for Department of Ed employees while I was there and helping design that experience. You know, for professional or mid career, folks, I think the most important thing was you build confidence and create bitesize first steps to try to like tone down the fear, so people can approach the new world with confidence rather than just responding to it.</p>
<p><strong>Brian Tarran</strong><br>
So I just want to wrap up now, last question for you all, really, maybe if we start with Steve. From a policy perspective, Steve, you know, are there other initiatives on the horizon and things in the pipeline that, you know, people should be watching for in terms of trying to improve data science education across the board in the US, and maybe specifically for the ASA are their areas you’re going to be focusing your efforts and support on.</p>
<p><strong>Steve Pierson</strong><br>
We certainly do want to expand this effort. And we’re trying– In a way, this bill is serving as a way for us to gather that information, because people then know that we’re doing this and they might well hopefully suggest items to, to us. We’ve gotten some I know that, you know, Zarek has a file, I have my own file of what we might want to, how we might want to extend it just with this bill. But yes, we certainly do want to do that. And so for listeners out there that have ideas, please please send them to us. I won’t offer specifics at this point. And I’d love to hear what my colleagues have to say, as well.</p>
<p><strong>Brian Tarran</strong><br>
Does anybody want to jump in on that? Zarek, what’s on your list?</p>
<p><strong>Zarek Drozda</strong><br>
Very short term is just building a Senate version of the legislation, I think, right? We’re going to be working with with the ASA on that, to find champions in that chamber. But then I think I would go back to my call for you know, state legislators need to be thinking about this as well, right, because we know that every state is going to look a little different. We’re in a context right now where locally driven education solutions are going to be really important. And so we’re going to have to build different slightly different flavours of this all around the country. And we’re going to need a lot of work from, I think, state and local champions to fund and help support and build these experiences that are so critical for students across the country.</p>
<p><strong>Brian Tarran</strong><br>
And are there, you know, on the point you mentioned earlier, Zarek, about this news,crossing the pond and reaching me over here in the UK, do you look elsewhere, you know, outside the US and the UK for other good examples of where education systems are starting to integrate data science into the teaching at, you know, the earlier parts of the school curriculum and the school levels.</p>
<p><strong>Anna Bargagliotti</strong><br>
I think Chris can probably jump in even more than me on this one. But definitely in New Zealand. Our colleagues in New Zealand are fantastic. And they’ve been doing K-12 data science and statistics very well for many, many years. And Chris has some very close collaborators. So I’ll hand it over to her to on that. But I thought I’d mention it.</p>
<p><strong>Christine Franklin</strong><br>
Yes, I I think that that’s when you know, when Steve says how can we reach out, I think even beyond policy, a collaboration with international colleagues that have advanced their work in K through 12. I mean, I had the good fortune of having a Fulbright to New Zealand back in 2015. And just the inspiration, the wealth of knowledge that I obtained from there, to bring back to the US with our work here was phenomenal. Plus, we built up collaborations that we are continuing today. We have collaborations with people in the UK, for example, in other countries. I think the other thing I wanted to say besides reaching out internationally is that we as statisticians in the US need to be doing more to help K through 12. And I think about my, you know, my colleagues at the university in the statistics department which I was part of, my colleagues, some of them actually worked with me to reach out to the math educators so that they could try to help with what needed to be done with the preparation of teachers. So I think statisticians need to become more involved, both practising statisticians and academic statisticians, with helping educators at K through 12. And that includes trying to become involved with state departments of education as well, because that’s really where things filter down to the local level in our school districts. So I would like to see somehow a structure put in place to make that happen more. And I’m hoping things such as this bill will bring that awareness to practising statisticians, that this is really important, and you need to become more aware of what’s happening at K through 12, and become involved.</p>
<p><strong>Zarek Drozda</strong><br>
To just add to what Chris is saying, I think it is so important for investment in the K-12. space. And, Brian, I’ll give you a sneak preview of a report that we were collating on international examples of data science and statistics education in K-12, and really serious investments that we’ve seen, I think, and Chris already mentioned, some really great ones that have been long running champions at this internationally. Our recent scan: Israel, their ministry of education is doing a tonne of work for data science, data literacy education. I’ve had so many conversations with them over Zoom. China added a standard semester for big data statistics coding and modelling. And it’s now also in their college entrance exam. There’s examples in Germany, New Zealand, South Korea, Scotland, we’ve we’re continuing to build the list. Frankly, in the UK, right, with core maths, you’re seeing more integration of data and computational thinking into the curricula pathways there. I think in many ways the US is behind, and as we introduce this bill, I think we should be messaging, there’s a economic competition aspect to this, right; that it’ll be really important for the US to make investments in this area to, frankly, catch up to where I think other international peers are.</p>
<p><strong>Brian Tarran</strong><br>
Steve, you wanted to come in on that?</p>
<p><strong>Steve Pierson</strong><br>
I mean, you mentioned like someone coming in mid career, right. And I think that that is really important. But we’ve also kind of been talking about the other ways you can access this, right, in any part of your career, but you can also access data jobs, rural and urban. So we’ve been kind of selling that dimension. But also, you know, just access in terms of diversifying the STEM workforce, we think that’s really important. But it’s also about degree level, right? We did a search for one member of Congress that had a major, I think it was a pharmaceutical in their district. And if you put in data, right, and thousands of jobs pop up for that company. And it’s not just the PhDs, right, it’s more entry level, the people who are what Zarek mentioned in terms of just accreditation, that you can enter a lot of points. But I also want to just make a– point out one part of the bill, which really singles out two-year colleges, which can help the mid career people, the early career people or others, and they face a lot of the same challenges as K through 12. Right, making sure that the instructors are upskilled, that they have a curriculum, but they also need the time to coordinate with their other disciplines that are involved here. They need time to go to that local workforce, what do you need in terms of data science? And for those students that want to go on to a four-year degree, they need to make sure that there’s a smooth pathway for those students. So there are provisions in the bill also for for two year colleges. And those would be my closing comments, Brian.</p>
<p><strong>Brian Tarran</strong><br>
Okay. Anybody else for some closing words? Or should we wrap up on reminding everyone that data science education is the new apple pie?</p>
<p><strong>Anna Bargagliotti</strong><br>
I can close this with something more philosophical, maybe. To me, I think a nice way to think about it or sort of a romantic way to think about it is it’s just data tell our stories, and they reflect what’s happening in our world today, much like art around us in some ways. And a way to think about just data science education is just to think about what we need, what we need our data understanding to be at each point in time in our educational career, or in our lives. And it’s not static, it’s an evolving thing. So you have to move sort of with the data that are being collected.</p>
<p><strong>Brian Tarran</strong><br>
Very good point. Thank you very much, Anna, Steve, Zarek, and Chris, for joining us to talk about the Data Science and Literacy Act. I’m sure there’ll be much more to to follow and update on as this act or bill winds its way through through Congress. So we’ll look forward to hearing more about that in due course. So thank you for joining us today. Thank you to those of you who are watching for joining us. Stay tuned at realworlddatascience.net for more news Q&amp;As.</p>
<div class="article-btn">
<p><a href="../../../../../viewpoints/interviews/index.html">Find more Interviews</a></p>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-6">
<dl>
<dt>Copyright and licence</dt>
<dd>
© 2023 Royal Statistical Society
</dd>
</dl>
<p><a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> <img style="height:22px!important;vertical-align:text-bottom;" src="https://realworlddatascience.net/viewpoints/interviews/posts/03/06/https:/mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://realworlddatascience.net/viewpoints/interviews/posts/03/06/https:/mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"></a> This work is licensed under a Creative Commons Attribution 4.0 (CC BY 4.0) <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> International licence</a>, except where otherwise noted.</p>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>How to cite</dt>
<dd>
Tarran, Brian. 2023. “US legislators get their data science act together.” Real World Data Science, March 6, 2023. <a href="https://realworlddatascience.net/news-and-views/editors-blog/posts/2023/03/06/data-science-act.html">URL</a>
</dd>
</dl>
</div>
</div>
</div>


</section>

 ]]></description>
  <category>Data science education</category>
  <category>Data literacy</category>
  <category>Policy</category>
  <guid>https://realworlddatascience.net/viewpoints/interviews/posts/03/06/data-science-act.html</guid>
  <pubDate>Mon, 06 Mar 2023 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/viewpoints/interviews/posts/03/06/images/andy-feliciotti-isg8AL7-6uk-unsplash.png" medium="image" type="image/png" height="93" width="144"/>
</item>
<item>
  <title>Using ‘basket complementarity’ to make product recommendations</title>
  <dc:creator>Moinak Bhaduri</dc:creator>
  <link>https://realworlddatascience.net/ideas/datasciencebites/posts/2023/03/02/basket-complementarity.html</link>
  <description><![CDATA[ 




<p>Anyone who has ever worked in a retail store will be familiar with the concept of cross-selling. A customer wants a can of paint? Try to sell them some paintbrushes. That new cellphone they’ve just decided to buy? They’ll probably need a case to protect it. Online retailers (and digital services of all sorts) have taken this idea and run with it, to great success. Sophisticated algorithms sort through data on a customer’s past transactions, and those of similar-looking customers, to identify and recommend other products a customer might be interested in.</p>
<p>A large amount of cross-selling, whether attempted in store by a sales assistant or online by an algorithm, relies on the concept of <em>complementarity</em>: that certain products are often bought and/or used together. Relationships between products might be obvious – paint and paintbrushes, for example – or they may be obscure and only revealed through the analysis of large datasets. In a 2021 paper that highlights complementarity’s relevance to association analysis, Puka and Jedrusik put forward “<a href="https://www.mdpi.com/0718-1876/16/4/39">a new measure of complementarity in market basket data</a>”, which sheds light on how product recommendations can be derived.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-1-contents" aria-controls="callout-1" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
About the paper
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-1" class="callout-1-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<p><strong>Title:</strong> A new measure of complementarity in market basket data</p>
<p><strong>Author(s) and year:</strong> Radosław Puka and Stanislaw Jedrusik (2021)</p>
<p><strong>Status:</strong> Published in the <em>Journal of Theoretical and Applied Electronic Commerce Research</em>, open access: <a href="https://www.mdpi.com/0718-1876/16/4/39">HTML</a>, <a href="https://www.mdpi.com/0718-1876/16/4/39/pdf?version=1609984879">PDF</a>.</p>
</div>
</div>
</div>
<p>Inspired by complementarity-based ideas prevalent in microeconomics, Puka and Jedrusik begin by collecting some established ideas from traditional market basket analysis, the key one being “confidence”. In this case, we’re talking about the confidence that item A leads (in a way) to item B (which we can express in notation as <em>conf</em>({A} → {B})). Take a look at Table 1 (below), which presents a numbered list of 18 shopping trips, with details of what was purchased on each trip. Notice how two of the trips (1 and 3) resulted in sales of both milk (B) and cornflakes (A), while five trips (1, 3, 7, 17, and 18) had cornflakes. Under the assumption that someone already has cornflakes in their trolley, the probability that they will buy milk is 2/5 = 0.4. So, <em>conf</em>({cornflakes} → {milk}) = 0.4. The closer this number gets to one, the more automatic the cornflakes–milk connection becomes. This number can therefore be used to recommend an item that is related in some way to another already bought.</p>
<div class="column-body-outset">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="images/tab1-fig1.png"><img src="https://realworlddatascience.net/ideas/datasciencebites/posts/2023/03/02/images/tab1-fig1.png" class="img-fluid figure-img"></a></p>
</figure>
</div>
</div>
<div class="figure-caption">
<div class="grid">
<div class="g-col-12 g-col-md-4">
<p><strong>Table 1:</strong> A list (with each row representing a trip to a grocery store) that can be seen in one of two ways: (a) a record of what 18 different people bought, or (b) a history of one person’s purchases over 18 trips. The list is similar to the one examined by Puka and Jedrusik, except for the last three rows. These trips, under interpretation (b) may help us develop an understanding of a single shopper’s preferences.</p>
</div>
<div class="g-col-12 g-col-md-8">
<p><strong>Figure 1:</strong> Basket complementarity under varying tolerance. The horizontal axis reports the probability that someone will buy item B under the assumption that A is already in their shopping trolley (i.e., <em>conf</em>({A} → {B})). The vertical axis reports the opposite: the chance that someone will go for A given that B is already in the cart (i.e., <em>conf</em>({B} → {A})). For any pair of items, these two probabilities can be found and, when plotted in 2D, a pair of items generates a single point. The more similar the two probabilities are for each pair, the closer the point comes to the line of equality (the red dashed line that runs diagonally through the origin), and the more complementary the items become. It’s rare that a dot will land exactly on the line of equality, so the green and orange lines parallel to the red line mark how far off a dot is from this ideal setting, using different levels of tolerance. From this we may say, for example, that cornflakes and milk are more complementary to each other than bread rolls and butter, as the first pairing lies closer to the line of equality.</p>
</div>
</div>
</div>
<section id="asymmetry-and-tolerance" class="level2">
<h2 class="anchored" data-anchor-id="asymmetry-and-tolerance">Asymmetry and tolerance</h2>
<p>Milk and cornflakes are reasonably complementary, and we can see from Figure 1 above that, regardless of whether you start by picking up milk or cornflakes, the probabilities of a shopper buying the other item are broadly similar: <em>conf</em>({cornflakes} → {milk}) = 0.4, while <em>conf</em>({milk} → {cornflakes}) = 0.33. There is a small amount of asymmetry in the probabilities in this particular example, but asymmetry can be more extreme for other pairs of items. This leads to the idea of one- and two-sided complementarity. Two items sharing a smallish asymmetry – like milk and cornflakes – will be connected through two-sided complementarity, while large asymmetries indicate one-sided complementarity. Such imbalances will be quite common when, for instance, items of hugely different prices are involved. When someone buys a house, for example, they may want to buy a bookcase, but buying a bookcase doesn’t mean someone wants to buy a house: this would be an instance of one-sided complementarity.</p>
<p>Puka and Jedrusik capitalize on this observation. They define two items to be “basket complementary” if the two probabilities – the normal and its opposite – remain close and reasonably high. The items need to share a bond that is blind to the direction: seeing you bought one, no matter which, means you are (almost equally) likely to buy the other.</p>
<p>It is rare that the two probabilities should be exactly the same, of course, and the authors allow some deviation. Along the red diagonal line of perfect equality (Figure 1) we may lay tolerance bands marking degrees of product inseparability. This, if need be, may lead to the notion of being complementary at such-and-such a tolerance level – 0%, 1%, 5%, etc. – generating a score of sorts. In cases where a dot representing the two-way dependencies between two items falls within a narrow band – corresponding to a smaller tolerance – the more inseparable the items are, and the more sensible a cross-selling recommendation may become.</p>
</section>
<section id="in-conclusion" class="level2">
<h2 class="anchored" data-anchor-id="in-conclusion">In conclusion</h2>
<p>A large part of the world we inhabit, particularly the economy, is powered by recommendations: from strangers, friends and algorithms. That applies not only to the things we buy but also to the things we watch or read. (Perhaps you arrived at this article because of a tweet that Twitter thought you might like, or maybe it was suggested to you by Google News because of your past reading habits.) Whatever the intent of these recommendations, the key challenge is in knowing which two things are functionally or thematically intertwined. Which item or product is, by default, synonymous with which? Puka and Jedrusik deliver an answer: two items that are basket complementary to each other, preferably at a slim tolerance, are inextricably linked. One may be safely offered – perhaps always – whenever the other is already in the shopping basket.</p>
<p>The relative simplicity and interpretability of basket complementary may provide small-scale retailers, starved of analytical wherewithal, a sane and safe strategy for developing their product offer. It might also serve as a benchmark to keep other, more sophisticated recommendation algorithms in check. (In weather forecasting, for example, it is often seen that <a href="https://www.sciencedirect.com/science/article/pii/S0022169415000414">naive benchmarks</a> – such as using today’s temperature to predict tomorrow’s – frequently outperform more advanced models.)</p>
<p>Basket complementarity could also be used to help individuals understand their own shopping habits and the links between the things they buy. I’ve built <a href="https://moinak.shinyapps.io/MarketBasketDashboard/">an interactive dashboard</a> where you can enter your own receipt lists and filter associations based on various confidence thresholds. The <a href="https://github.com/moinakbhaduri/MarketBasketAnalysis">underlying code</a> is also available.</p>
 <iframe src="https://moinak.shinyapps.io/MarketBasketDashboard/" style="border: none; width: 100%; height: 500px" frameborder="0"></iframe>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-6">
<dl>
<dt>About the author</dt>
<dd>
<strong>Moinak Bhaduri</strong> is assistant professor in the Department of Mathematical Sciences, Bentley University. He studies spatio-temporal Poisson processes and others like the self-exciting Hawkes or log-Gaussian Cox processes that are natural generalizations. His primary interest includes developing change-detection algorithms in systems modeled by these stochastic processes, especially through trend permutations.
</dd>
</dl>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>About DataScienceBites</dt>
<dd>
<a href="../../../../../../ideas/datasciencebites/index.html"><strong>DataScienceBites</strong></a> is written by graduate students and early career researchers in data science (and related subjects) at universities throughout the world, as well as industry researchers. We publish digestible, engaging summaries of interesting new pre-print and peer-reviewed publications in the data science space, with the goal of making scientific papers more accessible. Find out how to <a href="../../../../../../contributor-docs/datasciencebites.html">become a contributor</a>.
</dd>
</dl>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>Copyright and licence</dt>
<dd>
© 2023 Moinak Bhaduri
</dd>
</dl>
<p><a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> <img style="height:22px!important;vertical-align:text-bottom;" src="https://realworlddatascience.net/ideas/datasciencebites/posts/2023/03/02/https:/mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://realworlddatascience.net/ideas/datasciencebites/posts/2023/03/02/https:/mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"></a> This work is licensed under a Creative Commons Attribution 4.0 (CC BY 4.0) <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> International licence</a>, except where otherwise noted.</p>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>How to cite</dt>
<dd>
Bhaduri, Moinak. 2023. “Using ‘basket complementarity’ to make product recommendations.” Real World Data Science, March 2, 2023. <a href="https://realworlddatascience.net/news-and-views/datasciencebites/posts/2023/03/02/basket-complementarity.html">URL</a>
</dd>
</dl>
</div>
</div>
</div>


</section>

 ]]></description>
  <category>Market basket analysis</category>
  <category>Recommendation systems</category>
  <category>Complementarity</category>
  <guid>https://realworlddatascience.net/ideas/datasciencebites/posts/2023/03/02/basket-complementarity.html</guid>
  <pubDate>Thu, 02 Mar 2023 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/ideas/datasciencebites/posts/2023/03/02/images/marjan-blan-marjanblan-3nURJV_L7-8-unsplash.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>Data science can help close the ‘digital skills’ gap, or so it seems</title>
  <dc:creator>Brian Tarran</dc:creator>
  <link>https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/02/14/digital-skills.html</link>
  <description><![CDATA[ 




<p>Digital skills. We all need them. Employers say they want them, but there aren’t enough to go around. Supply can’t meet demand, so we’re left with a gap – a digital skills gap. But what are <em>digital skills</em> exactly?</p>
<p>This is a question that was asked repeatedly, in various different constructions, by <a href="https://members.parliament.uk/member/4092/career">Stephen Metcalfe MP</a>, chairing a meeting of the <a href="https://www.scienceinparliament.org.uk/information/about/">Parliamentary and Scientific Committee</a> on Tuesday, February 7. I went along to the meeting as an observer, hoping to hear an answer to that very question.</p>
<p>What I got was several different answers – no single solid definition, but a reasonable sense that boosting data science skills would go a long way towards closing the digital skills gap.</p>
<section id="survey-says" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="survey-says">Survey says…</h2>
<p>The committee meeting was sponsored by the Institution of Engineering and Technology (IET), and the main focus of discussion was the results of IET’s <a href="https://www.theiet.org/impact-society/factfiles/innovation-and-skills-factfiles/iet-skills-survey/skills-for-a-digital-future-survey/">skills for a digital future survey</a>, based on a YouGov poll of 1,235 respondents drawn from engineering employers (defined as “employers who employ at least one engineering and technology employee in the UK”).</p>

<div class="no-row-height column-margin column-container"><div class="">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/02/14/images/billetto-editorial-YvLd3xbo0ac-unsplash.jpg" class="img-fluid figure-img" alt="Woman painting while wearing virtual reality headset. Photo by Billetto Editorial on Unsplash." width="500"></p>
<figcaption class="figure-caption">Digital skills, including AI skills, are not only required of engineers, says the IET’s Graham Herries. Generative AI tools like Stable Diffusion threaten to shake-up the creative industries. (Photo by <a href="https://unsplash.com/@billetto?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Billetto Editorial</a> on <a href="https://unsplash.com/photos/YvLd3xbo0ac?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Unsplash</a>)</figcaption>
</figure>
</div>
</div></div><p>Kicking off the discussion was Graham Herries, an engineering director and chair of the IET’s Innovation and Skills Panel, who drew attention to the harms that the digital skills gap is reportedly having. Of those respondents who identified skills gaps in their own organisations, 49% pointed to a reduction in productivity, while 35% said skills shortages were restricting company growth.</p>
<p>As the hot topic of the day, <a href="../../../../../../news-and-views/editors-blog/posts/2023/01/27/talking-chatgpt.html">ChatGPT inevitably came up during the discussion</a>. Herries sees it as a disruptive force, and 36% of all respondents believe artificial intelligence (AI) skills will be important for their engineers to have within five years (24% say they are important <em>now</em>). But AI skills are important for non-engineers too, argued Herries, as he pointed to stirrings in the creative industries caused by generative art tools such as <a href="https://stability.ai/blog/stable-diffusion-public-release">Stable Diffusion</a>.</p>
<p>Herries therefore puts AI skills under the broad umbrella of “digital skills”. But, to him, it’s not enough to simply be able to use AI technology; rather, users should know enough to be able to ask the right questions about the provenance of the data used to train the AI, its quality and biases, etc. This was a point developed further by Yvonne Baker, an engineer and the CEO of STEM Learning. Baker talked about digital skills as being both the ability to use digital technology and also to understand its limitations. Yet another perspective was offered by Rab Scott, director of industrial digitalisation at the University of Sheffield’s Advanced Manufacturing Research Centre. Scott defined digital skills in the context of <a href="https://rss.onlinelibrary.wiley.com/doi/10.1111/1740-9713.01523">quality control systems in industry 4.0</a>: it’s about knowing how and where to place a sensor to collect data about the manufacturing process, to feed that data into a data collection system, analyse the data for insights, and use those insights to inform decision-making.</p>
</section>
<section id="closing-the-gap" class="level2">
<h2 class="anchored" data-anchor-id="closing-the-gap">Closing the gap</h2>
<p>Further definitions of “digital skills” are to be found in the <a href="https://www.theiet.org/impact-society/factfiles/innovation-and-skills-factfiles/iet-skills-survey/skills-for-a-digital-future-survey/">IET’s published report</a>. Survey respondents were encouraged to describe the term in their own words, so we see things like:</p>
<ul>
<li><p>“the ability to understand, process and analyse data.”</p></li>
<li><p>“Coding, programming, software design, use of social media for marketing and communicating with stakeholders, data visualisation, work that relies solely on the use [of] online systems.”</p></li>
</ul>
<p>When respondents were asked what skills were lacking in both the external labour market and their internal workforce, around a fifth cited “more complex numerical/statistical skills and understanding”. And when looking to the future and to the skills anticipated to be important areas for growth in the next five years, 39% of respondents picked “data analytics” while 31% said “artificial intelligence and machine learning”.</p>
<p>So, perhaps you now understand why I left the meeting with the feeling that more data science skills, more data science training, could help address the shortfall in “digital skills”.</p>
<p>But how exactly can we equip more people with the right skills? At one point during the discussion, Metcalfe told the meeting that he was still looking for a key takeaway, something he could take to the Secretary of State and say, ‘This is what we need to embed in the curriculum’. What was offered instead was a range of possible solutions.</p>
<p>The IET survey found broad backing for government support for reskilling: 40% of respondents favoured grants or loans for training (and retraining) programmes, 39% would like more funding for apprenticeships, while 33% think there should be better carers advice and guidance in schools and colleges.</p>
<p>Baker also made the case for digital skills to be taught in schools as part of every subject, not just in computer science lessons, and that teachers would need to be supported to deliver this.</p>
<p>But how would <em>you</em> close the “digital skills” gap, if given the chance?</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Have you got news for us?
</div>
</div>
<div class="callout-body-container callout-body">
<p>Is there a recent data science story you’d like our team to discuss? Do you have your own thoughts to share on a hot topic, or a burning question to put to the community? If so, either comment below or <a href="../../../../../../contact.html">contact us</a>.</p>
</div>
</div>
<div class="article-btn">
<p><a href="../../../../../../viewpoints/editors-blog/index.html">Back to Editors’ blog</a></p>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-6">
<dl>
<dt>Copyright and licence</dt>
<dd>
© 2023 Royal Statistical Society
</dd>
</dl>
<p><a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> <img style="height:22px!important;vertical-align:text-bottom;" src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/02/14/https:/mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/02/14/https:/mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"></a> This work is licensed under a Creative Commons Attribution 4.0 (CC BY 4.0) <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> International licence</a>, except where otherwise noted.</p>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>How to cite</dt>
<dd>
Tarran, Brian. 2023. “Data science can help close the ‘digital skills’ gap, or so it seems.” Real World Data Science, February 14, 2023. <a href="https://realworlddatascience.net/news-and-views/editors-blog/posts/2023/02/14/digital-skills.html">URL</a>
</dd>
</dl>
</div>
</div>
</div>


</section>

 ]]></description>
  <category>Skills</category>
  <category>Training</category>
  <category>AI</category>
  <category>Machine learning</category>
  <category>Data analytics</category>
  <guid>https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/02/14/digital-skills.html</guid>
  <pubDate>Tue, 14 Feb 2023 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/02/14/images/billetto-editorial-YvLd3xbo0ac-unsplash.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>Why open science is ‘just good science in a digital era’</title>
  <dc:creator>Brian Tarran</dc:creator>
  <link>https://realworlddatascience.net/viewpoints/interviews/posts/02/03/heidi-seibold.html</link>
  <description><![CDATA[ 




<p>Years are often dedicated to different causes and aims by different organisations. The United Nations, for example, has designated 2023 the <a href="https://www.undocs.org/en/A/RES/77/32">International Year of Dialogue as a Guarantee of Peace</a>, while for the European Commission it is the <a href="https://ec.europa.eu/commission/presscorner/detail/en/ip_22_6086">European Year of Skills</a>. But over at the White House Office of Science and Technology Policy, 2023 has been declared the <a href="https://www.whitehouse.gov/ostp/news-updates/2023/01/11/fact-sheet-biden-harris-administration-announces-new-actions-to-advance-open-and-equitable-research/">Year of Open Science</a>.</p>
<p>To discuss what this means for science generally and data science in particular, Real World Data Science invited <a href="https://heidiseibold.com/">Heidi Seibold</a> for an interview. Seibold is a statistician and data scientist, and also an open science trainer and consultant, and we talked about how she became involved in open science, what it means to her, the benefits of it, and how academic and industry researchers can move towards it.</p>
<p>Check out our full conversation below or on <a href="https://youtu.be/GD2g7cJ_yE4">YouTube</a>.</p>
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/GD2g7cJ_yE4" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<section id="timestamps" class="level2">
<h2 class="anchored" data-anchor-id="timestamps">Timestamps</h2>
<ul>
<li>How did Heidi become interested in open science? (<a href="https://youtu.be/GD2g7cJ_yE4?t=106">1:46</a>)</li>
<li>What does open data science mean to Heidi? (<a href="https://youtu.be/GD2g7cJ_yE4?t=470">7:50</a>)</li>
<li>Working with PhD students on open science (<a href="https://youtu.be/GD2g7cJ_yE4?t=720">12:00</a>)</li>
<li>How do open data science principles fit into an industry environment? (<a href="https://youtu.be/GD2g7cJ_yE4?t=850">14:10</a>)</li>
<li>Knowledge transfer and public science (<a href="https://youtu.be/GD2g7cJ_yE4?t=1049">17:29</a>)</li>
<li>Year of Open Science initiatives and lasting impacts (<a href="https://youtu.be/GD2g7cJ_yE4?t=1268">21:08</a>)</li>
</ul>
</section>
<section id="quotes" class="level2">
<h2 class="anchored" data-anchor-id="quotes">Quotes</h2>
<p>“Reproducibility [is] just like this minimum standard in research quality, where we say, ‘When we have the same data and the same analysis, we also want to see the same results’, and being able to check that from others is really, really important.” (<a href="https://youtu.be/GD2g7cJ_yE4?t=165">2:45</a>)</p>
<p>“On the back of my wall here in my office I have written, ‘Open science is just good science in a digital era’… Before, we only had the printing press, and we had to print journals in order to distribute the knowledge that we have.” (<a href="https://youtu.be/GD2g7cJ_yE4?t=323">5:23</a>)</p>
<p>“For me, open data science entails the part of the scientific process that focuses on everything that happens on the computer: the data processing and the data analysis, and then getting from the data analysis – getting the results and the knowledge, really – in sort of a pipeline where you go from one step to the next. And so the image that I have in my head, when I think about open data science, is of a pipeline.” (<a href="https://youtu.be/GD2g7cJ_yE4?t=616">10:16</a>)</p>
<p>“Nobody’s perfect from the beginning. And open science and reproducible research is really hard, and it requires a lot of technical knowledge. And I always feel like people are so scared, because on one hand, they don’t know how to do it yet, and the goal is so far away. And so I always like [to say], you don’t have to be perfect right away; going one step into the right direction is super important.” (<a href="https://youtu.be/GD2g7cJ_yE4?t=754">12:34</a>)</p>
<p>“If we think of companies, for example, like Microsoft – they put a lot of money right now into open source: they bought GitHub, they publish open source software, they put money into open source software projects like R, for example. So, somehow, this must be a good way of making profits.” (<a href="https://youtu.be/GD2g7cJ_yE4?t=909">15:09</a>)</p>
<p>“[Open science for the public has value because] we don’t know what ideas people will have. There’s so many skilled people out there that probably will do amazing things… We have this with the software Stable Diffusion right now. That’s an AI that generates images from text, and it runs on my computer here. And I don’t need AI skills to be able to do that. And people are building such incredible images out of this, and it’s really fun to see.” (<a href="https://youtu.be/GD2g7cJ_yE4?t=1130">18:50</a>)</p>
</section>
<section id="transcript" class="level2">
<h2 class="anchored" data-anchor-id="transcript">Transcript</h2>
<div class="callout callout-style-simple callout-warning" style="margin-top: 0.75rem;">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-body-container">
<p>This transcript has been produced using <a href="https://otter.ai/">speech-to-text transcription software</a>. It has been only lightly edited to correct mistranscriptions and remove repetitions.</p>
</div>
</div>
</div>
<p><strong>Brian Tarran</strong><br>
Hello, and welcome to another Real World Data Science interview. I’m Brian Tarran. And today I’m joined by Heidi Seibold, a statistician and data scientist. I invited Heidi along to speak about open science, what it means, the benefits of it, and how to move towards it. So welcome, Heidi, how are you?</p>
<p><strong>Heidi Seibold</strong><br>
Hello, thanks for having me. I’m good.</p>
<p><strong>Brian Tarran</strong><br>
Excellent. Excellent. Well, Heidi, I contacted you because, you know, I know you have a real deep interest in open science. And the conversation I think was really motivated by the White House Office of Science and Technology Policy declaring 2023 to be the year of open science. So first off, I wanted to get your reaction to that announcement.</p>
<p><strong>Heidi Seibold</strong><br>
Yeah, I think in general, that’s a really cool thing for open science to happen. Right? We, there’s this movement that’s been going on for a while, and people have been doing these grassroots communities and growing open science from the bottom up. And now we see more and more also top down decisions, which I think is a very good sign for, yeah, quality of science, really.</p>
<p><strong>Brian Tarran</strong><br>
Yeah, definitely. So I mean, we’ll get into some of the details of the initiatives a little later, maybe, but I thought that maybe we could kick off by asking you what you thought of the official definition of open science that the US government has come up with, and, and for the benefit of people watching that’s, in quotes, the principle and practice of making research products and processes available to all while respecting diverse cultures, maintaining security and privacy and fostering collaborations, reproducibility and equity. So as definitions go, does that, you know, does that hit the mark, for you, do you think?</p>
<p><strong>Heidi Seibold</strong><br>
Yeah, I think given that this is a federal definition, right, from the US. And they have to like, yeah, take so many opinions into account, I think it’s a great definition. I also asked like on social media, what people thought about it, and I think the response generally was pretty good. What I liked especially is that they focus on collaboration, reproducibility, and equity, which aligns very much with how I personally see open science. So collaboration means like, I always think of the term like building on the shoulders of giants, right. So this is what we want to do in research, we want to build on the work of others. They might be like famous people, but they might also be our colleagues next door. And it’s so important to take that into focus. And also reproducibility, just like this minimum standard in research quality, where we say, when we have the same data and the same analysis, we also want to see the same results, and being able to check that from others is really, really important. And so I think, this focus, I personally like it a lot.</p>
<p><strong>Brian Tarran</strong><br>
Excellent. Excellent. So can you tell me a little bit about your background and how you became interested, and I think committed to open science would be a great way of describing it, right?</p>
<p><strong>Heidi Seibold</strong><br>
Yeah, so I’m a trained statistician, I studied statistics. And then how did I get into this whole open science thing was, for me, really through reproducible research. So my first research project was during my master’s programme, and we wrote a paper and it was a very computationally complex project, and we had lots of files and folders, and, you know, scripts and stuff like this. And then, at some point, it just all got so messy. And I felt like, oh, no, I’m the worst scientist in the world. And then I told my colleague who I was working with on this project. And he was like, No, this is normal. And I was like, No, this can’t be normal. I want to be on top of things when I do research. And I want to be sure that, like, the code that I’m using for this is the correct code that I actually wanted to use, right. So that must be like a minimum standard that we have. And so through that, I learned about reproducible research and good coding practices. And then I also thought more and more about like, well, if I do all this, I should also publish it so that others can actually check that I’m good doing good work here. Right. And so through that I got more and more into open science and really always felt like that’s the right thing to do, especially if you’re funded through public money.</p>
<p><strong>Brian Tarran</strong><br>
Yeah, yeah. Can I ask you what you think is kind of driving the shift to open science because the way you’ve described open science to me just there, you know, that sounds like to me like, just good scientific practice, and the fact that it’s not something that’s been done before, I wonder whether is it a cultural change, a philosophical change, a technological development, that’s kind of spurring this shift?</p>
<p><strong>Heidi Seibold</strong><br>
Yeah. So that’s a really, really good and deep question. So on the back of my wall here in my office, I have written open science is just good science in a digital era. And I think that describes the answer to your question pretty well. So there was a technological change, right? Before, we only had the printing press. And we had to print journals in order to distribute the knowledge that we have. And of course, that costs money. So journals cost money historically. But now, journal costs are really super low, because nobody needs them printed anyhow. And you only ever want to read like one or two articles out of one issue. So it doesn’t really make sense anymore, right. And also publishing data and code. It’s just like, the cost is so so low, that now in this digital age of the internet, really, we have such a low burden of, of doing the right thing. But on the other hand, we need to make this social shift, because we’ve been always, like, researchers have always done it a certain way. And there are especially certain fields that are really into, like, they feel like this is my data. This is my code. This is my research. Why should I share it? But I feel like the young generation of researchers are like, well, because it’s the right thing to do. And the reason why we’re in research is because we want to have scientific progress and scientific progress comes when we can build upon each other’s work.</p>
<p><strong>Brian Tarran</strong><br>
Of course, and you mentioned, obviously, journal publications, but I wonder to what extent is it that the scale of science has almost kind of outgrown the ability to kind of condense it all down into a, even if it’s a 20 or 30 page, academic paper, right? Because it’s not just about, you know, setting out the research question describing the methods, you know, presenting a table of the data, all that stuff can’t be published now, or it can be, but it can’t be fit within the framework of an academic paper, it has to be on a GitHub repository or in a Jupyter notebook or something like that. So kind of open science encourages us to, to think about distributing that knowledge in different ways.</p>
<p><strong>Heidi Seibold</strong><br>
I think that’s completely true. So, research now is so much more complex than it used to be right. There used to be single researchers who did like, yeah, such breakthroughs within one paper. And now, we already have so much knowledge, and the questions are so much more detailed and complicated. And also the data is so much more and the things that we can do is so much more complex. And so I feel like one paper doesn’t– isn’t enough to describe the research that we’re doing. And we did this one project with, with a group of students, actually, where we took 11 papers that were related to the topic that we were teaching about. And we took these 11 papers and data was available for the papers. And so we thought, well, we try to reproduce the results that they have there. And we found that it is really hard if we don’t have the code, because the method section in papers is really super short, right? It’s a super short section, if it’s not like a statistics paper. And it’s impossible to describe all the intricate steps that you took from the data to the complex model and analysis that you did. It’s just not enough space within the paper. And the code is the perfect description of what you did, right? So why not publish it with it, and especially in cases where data privacy is not an issue, then, and you already publish the data, then it just makes so much sense to also publish the code, because the code is not like there’s no privacy issues to that – usually at least.</p>
<p><strong>Brian Tarran</strong><br>
So is there a kind of you know– when we say open data science, you know, what does that look like? And do you have a kind of example or simplified example of what that would look like, right? And how it’s more than just, you know, the finished paper, the product of the science scientific process?</p>
<p><strong>Heidi Seibold</strong><br>
Yeah, so for me, open data science entails the process of– the part of the scientific process that focuses on everything that happens on the computer. So the data processing and the data analysis, and then getting from the data analysis, getting the results and the knowledge really, in sort of, yeah, in sort of a pipeline where you go from one step to the next. And so what the image that I have, in my head, when I think about open data science, I really think of a of a pipeline where you stick the different parts of the pipeline together, in a consecutive order. But of course, research projects are really complicated. And the pipeline just looks really messy, in some ways, but if you still manage to organise it in a way that the different bits all fit together, then you can make it so that in the end, you can imagine something that goes from the start to the finish. And you really understand every step of this pipeline every step of the way, from the raw data to the paper.</p>
<p><strong>Brian Tarran</strong><br>
Yeah. So the idea would be that people provide almost like a framework for you to recreate that yourself if you want to either check the results or yeah, replicate, just replicate the process generally. Right? So is your– so your job now is, I guess, as an open science trainer and consultant, so are you the person that goes into organisations and kind of shows them how to build that pipeline? Or how to, you know, map it out and to present that to people?</p>
<p><strong>Heidi Seibold</strong><br>
Yeah, so what I do a lot is do workshops and trainings with PhD students. So graduate programmes will ask me to come in for a day, or, also, we do longer trainings, which are often more useful, because people can in between take the steps that I recommend. And then we just, like, work together on ideas and steps that they can actually take. And I think what’s always important there is to know that nobody’s perfect from the beginning. And open science and reproducible research is really hard. And it requires a lot of technical knowledge. And I always feel like people are so scared, because on one hand, they don’t know how to do it yet. And the goal is so far away. And so I always like, you don’t have to be perfect right away, going one step into the right direction is super important. And that also helps with like the social change, because then the question is, well, I do want to do this, but my supervisor doesn’t know the technology, what do I do? And then we always try to find like one step that they can take, rather than trying to be perfect right away.</p>
<p><strong>Brian Tarran</strong><br>
And it’s, I guess, it’s encouraging to see people like you being brought in to work with people on graduate programmes. So you’re, we’re trying to almost train the next generation of scientists to be thinking, open science first, rather than, you know, falling into bad habits or old habits that, you know, we are trying to do away with.</p>
<p><strong>Heidi Seibold</strong><br>
Yeah, and really, the young researchers, my feeling so far has been that the only pushback I get for my work is from established researchers who feel like well, this is the way I did it, and so it has to be the right way. But the younger generation for them, it’s super obvious that this is the way we should go in order to achieve scientific progress and good scientific practice.</p>
<p><strong>Brian Tarran</strong><br>
Yeah, yeah. A lot of data science now is obviously now done within industry. I wondered how open data science or open science principles fit in an environment you know, where competitive advantages is linked to keeping things in house and confidential and not wanting to share too much. Do you see a conflict there or can the two work together?</p>
<p><strong>Heidi Seibold</strong><br>
So I think there’s– first of all, I think, if we, if we get it done in academia, I’d be already super happy, right? If we get it done in the space where we have public funded projects that then are available for the public, I’d be already like super stoked. But in industry, it’s really interesting because a lot of the work that is done in industry is already done pretty well. So we if we think of, for example, companies, for example, like Microsoft, right, they put a lot of money right now into open source, they bought GitHub, they publish open source software, they put money into open source software projects like R, for example, right. So somehow, this must be a good way of making profits as well. And we see lots of companies investing in open source. So why not think about other research products, like data, and so on, also in the same line as we do of open source, because software is just a similar product. And I don’t think that there’s, I mean, there is some software, or some products, where it makes sense to have a patent or a trade secret or something. But sometimes it’s just more profitable, to have something where people can look into it and trust it. And I’d also helps like finding the next coders, and the next researchers to work on these projects, because, well, we like looking into what we’re going to do next. Right. And also, if we look, for example, into pharma industry, there, we see that a lot of the work they’re doing is already pretty good. For example, if we look at clinical trial transparency, pharma is doing better than academia there. And also, they’re pretty good on reproducible research, because they have to stick to certain rules. And when we look on the other side, so industry also benefits from open science, right? Because if we do open science, in academia, and publicly funded projects, then this will help companies make more money, because they have access to more knowledge and maybe interesting ideas as well, that they don’t have right now. So I think this is a win-win situation for companies as well. And I feel like if academia gives more to the industry, then eventually there will be like a mindset change. And industry will also give more back as well.</p>
<p><strong>Brian Tarran</strong><br>
Yeah, I see– I can see that and I guess it’s, you know, knowledge transfer is a big objective of a lot of academic institutions, right, we want our outputs to be of use to wider society, and that includes business and industry, right. So if people can pick those things up, you know, download it off of the web without having to, you know, make one-to-one links with the researchers who’ve done that project, it just it smooths that transition, and that that knowledge transfer becomes a lot more straightforward. You did, you mentioned about, you know, open science is about public science, essentially putting these, when it’s publicly funded research, this data and this work goes into the public space. You know, I’m guessing that, to a large extent, a lot of, you know, regular members of the public aren’t going to be interacting with open science. They’re not going to be downloading the datasets, they’re not going to be rebuilding the pipelines and rerunning the analysis. But do you still see that there’s a value there for the public in that information being there should they need it? And where are the kind of areas of value that you think the public will exploit?</p>
<p><strong>Heidi Seibold</strong><br>
Yeah, I think that’s an interesting question. And I think the biggest answer to that is that we don’t, we don’t know what ideas people will have, right? There’s so many skilled people out there, that probably will do amazing things. And we see that over and over again, when we put stuff out there, that people just get the super cool ideas. So we have this with the software Stable Diffusion right now, right? So that’s an AI that generates images from text, and it runs on my computer here. And I don’t need AI skills to be able to do that. And people are building such incredible images out of this. And it’s really fun to see. So I think, yeah, we just don’t know what’s going to happen. And on the other hand, I think, well, I am a researcher, but I’m also the public, right? And so if I have a question about something that concerns my private life or my friends’ private life, then I can also– I do have the skills to go into this and look at some research for example, I don’t know, how to best raise children or whatever. Um, that’s– so I have a friend, she’s an epidemiologist, and she always goes and looks at research on like, how to feed her child best and what to do. There’s, there’s all kinds of questions you have as a mother. And she, as a researcher can just go into the research and figure out, like, what is the best path for me to take. And I think the more we do open science, the more we can also do, like science communication, that adds on to that as well. Right? So if we have her now, she could now help other mothers make the same good decisions as well. And she would be sort of a science communicator for research that isn’t even hers. Um, so that is pretty cool, I think.</p>
<p><strong>Brian Tarran</strong><br>
I think so, and it’s speaks to me of breaking down silos that, and I guess, blurring the lines between our roles, our professional roles and our personal lives, right. It’s about bringing science into that kind of public sphere, so I can see why the benefits would accrue from doing so. Just to wrap up, let’s go back to that year of open science, that was announced by the White House, are there any other specific initiatives in that big long list that constituted the announcement that you’re excited about?</p>
<p><strong>Heidi Seibold</strong><br>
Yeah, there is. I think, especially what I really liked was that, yeah, federally funded research, um, needs to be accessible, including the data when possible. So again, there’s open when possible, closed when necessary. But I think this is a very good first step, to say, okay, it depends on the funding, if it’s publicly funded, then it should also be publicly available. And I think that’s a really good sign. And then also, these, the statement had like, mentioned all these open science initiatives in different fields, which I really liked. So for example, from NASA, they have this transform to open science programme, and they’re already super active. And it’s really cool to see what comes out of that. For medicine, they have requirements for data management plans, which I think is a very solid step towards open science in medicine, because they are we have the issue of data privacy. And we really have to think from the get-go of a project about what should we do in terms of best practices of data management and having a requirement on that is, I think, a really, really solid step. And also, I’m thinking about open science in the field of like federal government even, because open data and federal government is a huge topic, right. And it, that’s definitely something that a lot of people will be interested in as well.</p>
<p><strong>Brian Tarran</strong><br>
Last question for you, then Heidi, you know, what would you want the lasting impact of an initiative like this to be? And you know, would you like to see this sort of thing replicated in other countries around the world? If indeed, you know, other countries may already be doing this and have already done this?</p>
<p><strong>Heidi Seibold</strong><br>
I think in general, it’s a very, very good sign that we’re seeing right now. We’ve seen lots of movement, for example, in the Netherlands – Netherlands is really big on open science – and seeing such a big country [the US] that also plays such an important role in the world, doing– taking this step, is a great sign for the entire, like all of research, really. And yeah, I think it’s also nice to see that we’re going from like, Oh, this is a niche topic that only experts are interested in, and people that are like advocates and nerds focus on, to something that really governments are thinking about.</p>
<p><strong>Brian Tarran</strong><br>
So, open science is going mainstream, I think is the message. And let’s hope that it continues to do so. So Heidi, thank you very much for your time today. Where can people find you online, if f they want to find out more about you and your work and your thoughts on open science?</p>
<p><strong>Heidi Seibold</strong><br>
Yeah, thank you so much for having me. It was wonderful. And I always like talking about open science, so people can find me on my website, heidiseibold.com. And I’m also on Mastodon, Twitter, LinkedIn, YouTube, wherever your search for Heidi Seibold, you’ll find me.</p>
<p><strong>Brian Tarran</strong><br>
Excellent. Excellent. Well, thank you again. And thank you to those of you who are tuning in today. Make sure to check realworlddatascience.net for more interviews. Take care.</p>
<div class="article-btn">
<p><a href="../../../../../viewpoints/interviews/index.html">Find more Interviews</a></p>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-6">
<dl>
<dt>Copyright and licence</dt>
<dd>
© 2023 Royal Statistical Society
</dd>
</dl>
<p><a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> <img style="height:22px!important;vertical-align:text-bottom;" src="https://realworlddatascience.net/viewpoints/interviews/posts/02/03/https:/mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://realworlddatascience.net/viewpoints/interviews/posts/02/03/https:/mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"></a> This work is licensed under a Creative Commons Attribution 4.0 (CC BY 4.0) <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> International licence</a>, except where otherwise noted.</p>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>How to cite</dt>
<dd>
Tarran, Brian. 2023. “Why open science is ‘just good science in a digital era’.” Real World Data Science, February 3, 2023. <a href="https://realworlddatascience.net/news-and-views/interviews/posts/02/03/heidi-seibold.html">URL</a>
</dd>
</dl>
</div>
</div>
</div>


</section>

 ]]></description>
  <category>Open science</category>
  <category>Reproducible research</category>
  <guid>https://realworlddatascience.net/viewpoints/interviews/posts/02/03/heidi-seibold.html</guid>
  <pubDate>Fri, 03 Feb 2023 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/viewpoints/interviews/posts/02/03/images/heidi-seibold.png" medium="image" type="image/png" height="105" width="144"/>
</item>
<item>
  <title>ChatGPT can hold a conversation, but lacks knowledge representation and original sources for verification</title>
  <dc:creator>Brian Tarran</dc:creator>
  <link>https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/01/27/talking-chatgpt.html</link>
  <description><![CDATA[ 




<p>ChatGPT is, right now, the world’s most popular - and controversial - chatbot. Users have been both wowed by its capabilities<sup>1</sup> and concerned by the confident-sounding nonsense it can produce.</p>
<p>But perhaps what impresses most is the way it is able to sustain a conversation. <a href="../../../../../../news-and-views/editors-blog/posts/2022-11-23-LLMs-content-warning/LLM-content-warning.html">When I interviewed our editorial board member Detlef Nauck about large language models (LLMs)</a>, back in November, he said:</p>
<blockquote class="blockquote">
<p>… if you use these systems for dialogues, then you have to script the dialogue. They don’t sustain a dialogue by themselves. You create a dialogue tree, and what they do is they parse the text that comes from the user and then generate a response to it. And the response is then guided by the dialogue tree. But this is quite brittle; it can break. If you run out of dialogue tree, you need to pass the conversation over to a person. Systems like Siri and Alexa are like that, right? They break very quickly. So, you want these systems to be able to sustain conversations based on the correct context.</p>
</blockquote>
<p>Fast-forward a couple of months and, as discussed in our follow-up interview below, OpenAI, the makers of ChatGPT, have succeeded in building a question answering system that can sustain a dialogue. As Nauck says: “I have not yet seen an example where [ChatGPT] lost track of the conversation… It seems to have quite a long memory, and doing quite well in this.”</p>
<p>There are still major challenges to overcome, says Nauck - not least the fact that ChatGPT has no way to verify the accuracy or correctness of its outputs. But, if it <em>can</em> be linked to original sources, new types of search engines could follow.</p>
<p>Check out the full conversation below or on <a href="https://www.youtube.com/watch?v=AWxfSmcgPbo">YouTube</a>.</p>
<p>Detlef Nauck is a member of the <a href="../../../../../../news-and-views/editors-blog/posts/2022-10-18-meet-the-team/meet-the-team.html">Real World Data Science editorial board</a> and head of AI and data science research for BT’s Applied Research Division.</p>
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/AWxfSmcgPbo" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<section id="timestamps" class="level2">
<h2 class="anchored" data-anchor-id="timestamps">Timestamps</h2>
<ul>
<li>How ChatGPT was built and trained (<a href="https://youtu.be/AWxfSmcgPbo?t=41">0:41</a>)</li>
<li>ChatGPT’s major advance (<a href="https://youtu.be/AWxfSmcgPbo?t=185">3:05</a>)</li>
<li>The big problems with large language models (<a href="https://youtu.be/AWxfSmcgPbo?t=276">4:36</a>)</li>
<li>Search engines and chatbots (<a href="https://youtu.be/AWxfSmcgPbo?t=575">9:35</a>)</li>
<li>Questions for OpenAI and other model builders (<a href="https://youtu.be/AWxfSmcgPbo?t=689">11:29</a>)</li>
</ul>
</section>
<section id="quotes" class="level2">
<h2 class="anchored" data-anchor-id="quotes">Quotes</h2>
<p>“[OpenAI] have achieved quite remarkable capabilities in terms of sustaining conversations, and producing very realistic sounding responses… But sometimes [ChatGPT] makes silly mistakes. Sometimes the mistakes are not that obvious. It can hallucinate content… And it still doesn’t know what it’s talking about. It has no knowledge representation, doesn’t have a word model. And it’s just a statistical language model.” (<a href="https://youtu.be/AWxfSmcgPbo?t=124">2:04</a>)</p>
<p>“These models, they produce an answer, which is based on the kind of texts that they have been trained on. And that can be quite effective. But it cannot yet link back to an original source. So what’s still missing is the step where it says, ‘Okay, this my answer to your question, and here’s some evidence.’ As soon as they have done this, then these kinds of systems will probably replace the search engines that we’re used to.” (<a href="https://youtu.be/AWxfSmcgPbo?t=247">4:07</a>)</p>
<p>“[These large language models are] still too big and too expensive to run… For [use in a] contact centre or similar, what you need is a much smaller model that is restricted in terms of what it can say. It should have knowledge representation, so it gives correct answers. And it doesn’t need to speak 48 languages and be able to produce programming code. It only needs to be able to talk about a singular domain, where the information, the knowledge about the domain, has been carefully curated and prepared. And that’s what we’re not seeing yet. Can we build something like this, much smaller, much more restricted, and provably correct, so we can actually use the output?” (<a href="https://youtu.be/AWxfSmcgPbo?t=469">7:49</a>)</p>
<p>“We are seeing communities who don’t necessarily have the technical background to judge the capabilities of these models, but see the opportunities for their own domain and might be acting too fast in adopting them. So the producer of these models has a certain responsibility to make sure that this doesn’t happen.” (<a href="https://youtu.be/AWxfSmcgPbo?t=746">12:26</a>)</p>
</section>
<section id="further-reading" class="level2">
<h2 class="anchored" data-anchor-id="further-reading">Further reading</h2>
<ul>
<li><a href="https://philadelphiaphysicist.wordpress.com/2023/01/13/chatgpt-the-robot-the-myth-the-legend/">ChatGPT: The Robot, the Myth, the Legend</a> - Philadelphia Physicist blog, January 13, 2023</li>
<li><a href="https://twitter.com/sama/status/1599671496636780546?s=20&amp;t=TbscFaGtn5JFu_dfZDczVg">Cost to run ChatGPT</a> - tweet by OpenAI CEO Sam Altman, December 5, 2022</li>
<li><a href="https://www.cnbc.com/2022/12/13/google-execs-warn-of-reputational-risk-with-chatgbt-like-tool.html">Google execs warn company’s reputation could suffer if it moves too fast on AI-chat technology</a> - CNBC, December 13, 2022</li>
<li><a href="https://www.theguardian.com/technology/2023/jan/05/microsoft-chatgpt-bing-search-engine">Microsoft reportedly to add ChatGPT to Bing search engine</a> - <em>The Guardian</em>, January 5, 2023</li>
<li><a href="https://www.theverge.com/2023/1/17/23558516/ai-art-copyright-stable-diffusion-getty-images-lawsuit">Getty Images is suing the creators of AI art tool Stable Diffusion for scraping its content</a> - The Verge, January 17, 2023</li>
</ul>
</section>
<section id="transcript" class="level2">
<h2 class="anchored" data-anchor-id="transcript">Transcript</h2>
<div class="callout callout-style-simple callout-warning">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-body-container">
<p>This transcript has been produced using <a href="https://otter.ai/">speech-to-text transcription software</a>. It has been only lightly edited to correct mistranscriptions and remove repetitions.</p>
</div>
</div>
</div>
<p><strong>Brian Tarran</strong><br>
We’re following up today Detlef on the, I guess, one of the biggest stories in artificial intelligence and data science at the moment, ChatGPT, the chat bot that’s driven by a large language model and is proving endless amounts of– providing endless amounts of either entertainment or concern, depending on what you ask it, and what outputs you get. So, but you’ve been looking at it in some detail, right, ChatGPT. And that’s why I thought we would follow up and have a conversation to see, get your view on it, get your take on it. What’s going on?</p>
<p><strong>Detlef Nauck</strong><br>
Yeah. So, what they have done is, OpenAI have used their large language model GPT-3 and they have trained an instance to basically answer questions and have conversations, where the model remembers what has been said in the conversation. And they have done this by using curated data of question and answers, where they basically have posed a question and said, This is what the answer should be. They trained the system on doing this, then, in the next step, they began use questions, potentially different ones, the system came up with a variety of answers, and then again, human curators would mark which is the best answer. And they would use this data to train what’s called a reward model - so, a separate deep network that learns what kind of answer for a particular question is a good one - and then they would use this reward model to do additional reinforcement learning on the ChatGPT that they had built so far, basically using dialogues and the reward model would then either reward or penalise the response that comes out of the system. And by doing that they have achieved quite remarkable capabilities in terms of sustaining conversations, and producing kind of very realistic sounding kind of responses. Sounds all very convincing. The model presents its responses quite confidently. But sometimes it makes silly mistakes. Sometimes the mistakes are not that obvious. It can hallucinate content. So let’s say you ask it to write you scientific text about whatever topic and put some references in and these references are typically completely fabricated and not real. And it still doesn’t know what it’s talking about. It has no knowledge representation, doesn’t have a word model. And it’s just a statistical language model. So it’s what we would call a sequence to sequence model. It uses an input sequence, which are words, and then guesses what’s the next most likely word in the sequence. And then it continues building these sequences.</p>
<p><strong>Brian Tarran</strong><br>
Yeah. But, do you think the big advance as you see it is the way it’s able to remember or store some knowledge, if you like, of the conversation, because that was something that came out of our first conversation that we had, where you were saying that, you know, if you’re looking at these as a potential chatbots for customer service lines, or whatever it might be, actually, the trees, the conversation trees break down after a while, and they don’t, you know, these models get lost, but actually, they’re able to maintain it a little longer, are they, or– ?</p>
<p><strong>Detlef Nauck</strong><br>
Yeah, I have not yet seen an example where they lost track of the conversation they seem to have, it seems to have quite a long memory, and doing quite well in this. So the main capability here is they have built a question answering system. And that’s kind of the ultimate goal for search engines. So if you put something into Google, essentially, you have a question, show me something that answered this, answers this particular question. Of course, what you want this kind of an original source. And these models, they produce an answer, which is based on the kind of texts that they have been trained on. And that can be quite effective. But it cannot yet link back to an original source. So what’s still missing is the step where it says, Okay, this my answer to your question, and here’s some evidence. Then if, as soon as they have done this, then these kinds of systems will probably replace the search engines that we’re used to.</p>
<p><strong>Brian Tarran</strong><br>
Yeah. The other thing that struck me with them was that the, if you’re asking somebody a question - a human, you know, for instance - you expect a response that and you would hope you will be able to trust that response, especially if it’s someone in an expert position or someone you’re calling, you know, on behalf of a company or something. The fact that - and I asked this question of ChatGPT itself - and the response was, again, you should consult external sources to verify the information that’s been provided by the chatbot. So it’s like, I guess that leaves a question as to what the utility of it is, if you if you’re always having to go elsewhere to verify that information.</p>
<p><strong>Detlef Nauck</strong><br>
Yeah, I mean, that’s the main problem with these models, because they don’t have a knowledge representation. They don’t have a word model, they can’t fall back on facts that are represented as being true and present those. They come up with an answer. But I mean, there has been a lot of kind of pre-prompting going in to ChatGPT. So when you start writing something, the session has already been prompted with a lot of text, telling the model how to behave, what not to say, to avoid certain topics. There are additional moderation APIs running that make sure that you can’t create certain type of responses, which are based on classical text filtering, and topic filtering. So they try to kind of restrict what the model can do to make sure it’s not offensive or inappropriate. But that is limited. So through crafting your requests, intelligently, you can convince it to ignore all of these things and go past it in some instances. So the, it’s not yet perfect, and certainly it’s not authoritative. So you can’t trust the information if you’re not an expert yourself. So at the moment, I’d say these kind of models are really useful for experts who can judge the correctness of the answer. And then what you get this kind of maybe a helpful kind of text representation of something that you would have to write yourself otherwise.</p>
<p><strong>Brian Tarran</strong><br>
Yeah, and certainly conversations I’ve had with people, those who kind of work, maybe in creative industries, are finding them quite intriguing, in terms of things like, you know, maybe trying to come up with some clever tweets or something for a particular purpose, or something I want to try out is getting ChatGPT to write headlines for me, because it’s always my least favourite part of the editing job. So that sort of works. But you know, for you, in your position in the industry, has ChatGPT changed your mind at all about, you know, the way you’re perceiving these models and how they might be used? Or is it is it just kind of a next step along in the process of what you’d expect to see before these can become tools that we use?</p>
<p><strong>Detlef Nauck</strong><br>
Yeah, it’s the next step in the evolution of these models. They’re still too big and too expensive to run, right. So now, it is not quite clear how much it costs OpenAI to run the service that they’re currently running. So you see estimates around millions of dollars per day that they have to spend on running the compute infrastructure to serve all of these questions. And this is not quite clear, the only official piece of information that I’ve seen is in a tweet, where the CEO said, a single question costs in the order of single digit cents, but we have no idea how many questions they serve per day, and therefore how much money they are spending. If you want to run a contact centre, or something like this, it all depends on how much compute need to stand up to be able to respond to hundreds or thousands of questions in parallel. And then obviously, if you can’t trust that the answer is correct, it is of no use. So for making use in the service industry for contact centre or similar, what you need is a much smaller model that is restricted in terms of what it can say, it should have knowledge representation, so it gives correct answers. And it doesn’t need to speak 48 languages and be able to produce programming code, it only needs to be able to talk about a singular domain, where it kind of the information, the knowledge about the domain has been carefully curated and prepared. And that’s what we’re not seeing yet. Can we build something like this, much smaller, much more restricted, and kind of provably correct, so we can actually use the output?</p>
<p><strong>Brian Tarran</strong><br>
Yeah. Can we go back just to the point you mentioned earlier about, you know, the, the potential of like linking these sorts of chatbots up with search engines, you know, like Google? There’s been some conversations and reporting around, you know, what breakthroughs or not Google might have made in this regard. I mean, have you got any perspective on that area of work and how far along that is maybe and what the challenges are to get to that point?</p>
<p><strong>Detlef Nauck</strong><br>
Well, Google has its own large language model, LaMDA. And we have seen an announcement that Microsoft wants to integrate ChatGPT into Bing, their search engine. And, but as I said before, what’s missing is the link to original sources. So you, coming up with a response is nice. But you need to be able to back it up, you need to say, Okay, this is my response, and I’m confident that this is correct, because here are some references. If I compare my response to these references, then they essentially mean the same thing. This is kind of what you need to be able to do. And we haven’t seen this step yet. But I’m certain that the search engine providers are hard at work at doing this because that’s essentially what they want. If you do a search in Google, in some instances, you’ll see a side panel where you get detailed information. Let’s say you ask about what’s the capital of Canada, you get a response, you get the information in more detail, you get links to Wikipedia, where they retrieve content from and present this as the response. And this is done through knowledge graphs. And so if these kinds of knowledge graphs grow together with these kind of large language models, then we will see new types of search engines.</p>
<p><strong>Brian Tarran</strong><br>
Okay. I guess final, my final question for you, Detlef, and there might be other angles that you want to explore. But it’s like, are there questions that, you know, if you if you could sit down with OpenAI to talk about ChatGPT and what they’ve done, and what they plan to do next with it, what are the kinds of things that are bubbling away at the top of your mind?</p>
<p><strong>Detlef Nauck</strong><br>
Well, one thing is controlling the use of these models, right? If you let them loose on the public, with an open API that anybody can use, you will see a proliferation of applications on top of it. If you go on YouTube, and you Google ChatGPT and health, you’ll already find discussions where GPs discuss, Oh, that is the next step of automated doctors that we can use. So they believe that the responses from these systems can be used for genuine medical advice. And that’s clearly a step too far. So we are seeing communities who don’t necessarily have the technical background to judge the capabilities of these models, but see the opportunities for their own domain and might be acting too fast in adopting them. So the producer of these models has a certain responsibility to make sure that this doesn’t happen. And I don’t know how they want to control this. And, so my question at the developers of these models would be how do you handle sustainability, because the trend goes to ever bigger models. So there’s, in some parts of the industry, there’s the belief, if you make them big enough you get artificial general intelligence, which I don’t believe is possible with these models. But this is definitely a trend that pushes the size of the models. The kind of, the idea of having just one model that can speak all the languages, can produce questions, answers, programming code, is obviously appealing. So you don’t want to build many models. Ideally, you have only one. But how is that supposed to work? And how do you embed actual word knowledge and word models into these systems so that you can verify what comes out?</p>
<p><strong>Brian Tarran</strong><br>
Yeah. I mean, the ethical dimension that you mentioned in the first part of your response is an important one, I think, in the sense that– but I guess maybe almost redundant in the sense that it’s already out there; you can’t put ChatGPT back in the box, can we, essentially?</p>
<p><strong>Detlef Nauck</strong><br>
Well, it’s expensive to run so charging enough for access will put a lid on some frivolous use cases, but still, it needs to be controlled better. And you can make a jump to an AI regulation. So far, we only thought about regulating automated decision making, or automated classification. We also have to think about the automatic creation of digital content or automatic creation of software, which is possible through these models or the other generative AI models like diffusers. So how do we handle the creation of artificial content that looks like real content?</p>
<p><strong>Brian Tarran</strong><br>
Yeah. And there’s also I think, something I picked up yesterday, there was reports of a case being filed by, I think, Getty Images against the creators of one of these generative art models because they’re saying, you know, that you’ve used our data or you’ve used our image repositories essentially to train this model and it is now producing, you know, it’s producing its own outputs that’s based on this, and I guess there’s an argument of it being a copyright infringement case. And I think that’ll be quite interesting to watch to see how that does change the conversation around - yeah - fair use of that data that is available. You can find these images publicly, but you have to pay to use them for purposes other than just browsing, I guess. Yeah, it’ll be interesting to watch.</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Have you got news for us?
</div>
</div>
<div class="callout-body-container callout-body">
<p>Is there a recent data science story you’d like our team to discuss? Do you have your own thoughts to share on a hot topic, or a burning question to put to the community? If so, either comment below or <a href="../../../../../../contact.html">contact us</a>.</p>
</div>
</div>
<div class="article-btn">
<p><a href="../../../../../../viewpoints/editors-blog/index.html">Back to Editors’ blog</a></p>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-6">
<dl>
<dt>Copyright and licence</dt>
<dd>
© 2023 Royal Statistical Society
</dd>
</dl>
<p><a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> <img style="height:22px!important;vertical-align:text-bottom;" src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/01/27/https:/mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/01/27/https:/mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"></a> This work is licensed under a Creative Commons Attribution 4.0 (CC BY 4.0) <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> International licence</a>, except where otherwise noted.</p>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>How to cite</dt>
<dd>
Tarran, Brian. 2023. “ChatGPT can hold a conversation, but lacks knowledge representation and original sources for verification.” Real World Data Science, January, 27 2023. <a href="https://realworlddatascience.net/news-and-views/editors-blog/posts/2023/01/27/talking-chatgpt.html">URL</a>
</dd>
</dl>
</div>
</div>
</div>


</section>


<div id="quarto-appendix" class="default"><section id="footnotes" class="footnotes footnotes-end-of-document"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p>I asked ChatGPT to write this article’s headline, for example. I typed in “Can you write a headline for this text:” and then copy/pasted the interview transcript into the dialogue box. It first came up with, “AI Chatbot ChatGPT Proves Capable in Sustaining Conversations but Lacks Knowledge Representation and Original Sources for Verification”. I then asked it to shorten the headline to 10 words. It followed up with, “ChatGPT: Large Language Model-Driven Chatbot Proves Capable But Limited”.↩︎</p></li>
</ol>
</section></div> ]]></description>
  <category>Machine learning</category>
  <category>Large language models</category>
  <category>AI</category>
  <guid>https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/01/27/talking-chatgpt.html</guid>
  <pubDate>Fri, 27 Jan 2023 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/01/27/images/Detlef.png" medium="image" type="image/png" height="156" width="144"/>
</item>
<item>
  <title>How to ‘Escape from Model Land’: an interview with Erica Thompson</title>
  <dc:creator>Brian Tarran</dc:creator>
  <link>https://realworlddatascience.net/viewpoints/interviews/posts/01/25/erica-thompson.html</link>
  <description><![CDATA[ 




<p>Erica Thompson’s new book, <a href="http://www.ericathompson.co.uk/books/"><em>Escape from Model Land</em></a>, offers a fascinating and important perspective on mathematical models as being not just models of the real world, or real processes or systems, but also “subjective versions of reality” that encode all sorts of assumptions and value judgements.</p>
<p>In this interview with Brian Tarran, editor of Real World Data Science, Thompson talks about the “social element of modelling” and how it manifests, how to counter the subjectivity of individual models with a diversity of models, and whether human-made models are held to the same standards of transparency that are expected of AI-“created” models.</p>
<p>Erica Thompson is a senior policy fellow in the ethics of modelling and simulation at the London School of Economics Data Science Institute.</p>
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/RB5CQW8lbEo" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<section id="timestamps" class="level2">
<h2 class="anchored" data-anchor-id="timestamps">Timestamps</h2>
<ul>
<li>What led Erica to write the book, and why now? (<a href="https://youtu.be/RB5CQW8lbEo?t=147">2:27</a>)</li>
<li>Critiquing climate models (<a href="https://youtu.be/RB5CQW8lbEo?t=450">7:30</a>)</li>
<li>Exploring the “social element” of modelling (<a href="https://youtu.be/RB5CQW8lbEo?t=696">11:36</a>)</li>
<li>Countering subjectivity with a diversity of perspectives (<a href="https://youtu.be/RB5CQW8lbEo?t=1211">20:11</a>)</li>
<li>AI models, human-made models, and questions of transparency (<a href="https://youtu.be/RB5CQW8lbEo?t=1554">25:54</a>)</li>
<li>Why write a popular science book about these issues? (<a href="https://youtu.be/RB5CQW8lbEo?t=1811">30:11</a>)</li>
<li>Will the UK Prime Minister’s “maths to 18” proposal help or hinder our <em>Escape from Model Land</em>? (<a href="https://youtu.be/RB5CQW8lbEo?t=2041">34:01</a>)</li>
</ul>
</section>
<section id="quotes" class="level2">
<h2 class="anchored" data-anchor-id="quotes">Quotes</h2>
<p>“Putting things in a mathematical language does tend to make people think that it is truth from on high. And so my book, in some way, goes towards saying actually, these models, obviously we hope that they’re based on facts and they’re based on data that we gather, but they also do have this value judgement content as well” (<a href="https://youtu.be/RB5CQW8lbEo?t=111">1:51</a>)</p>
<p>“It is arbitrary how we choose to model a situation. There are infinitely many different ways that you could choose to simplify reality - this huge, messy, complex thing in front of us, with physical laws that we don’t fully understand and things going on that we can only measure by proxy.” (<a href="https://youtu.be/RB5CQW8lbEo?t=729">12:09</a>)</p>
<p>“The choice of assumption has a very direct result in the model output and in the information and advice that you’re giving to policymakers… [In climate models] maybe we have a cost of however many dollars per tonne of carbon dioxide for nuclear electricity or for renewables. But what kind of price would you put on behaviour change? How many dollars per tonne of CO<sub>2</sub> avoided does it cost to change the behaviour of a population such that they use less energy? If you put it in at $2 per tonne of CO<sub>2</sub>, it would be heavily relied on [as a policy response]; if you put it in at $2,000 per tonne of CO<sub>2</sub>, it’ll never happen.” (<a href="https://youtu.be/RB5CQW8lbEo?t=1002">16:42</a>)</p>
<p>“There needs to be more frank discussion of values and value judgments, and politics and social assumptions within models. And I think we are starting to see that with the pandemic models, particularly because it’s been so high profile. [But] it’s really hard to unpick your own value judgments. It’s easier for somebody with a different perspective to come in and say, ‘Oh, actually, you know, you’ve assumed that. Why did you assume that?’ When we are embedded in a particular culture of modelling, it’s particularly hard to imagine that anything could possibly be done differently.” (<a href="https://youtu.be/RB5CQW8lbEo?t=1640">27:20</a>)</p>
<p>“I think some people maybe read the book and think, ‘Oh, this is just a sort of woke advertisement for diversity’. Well, it’s not; it’s a way of doing the maths better. The whole point is to do the maths better, make better forecasts, understand the future more effectively, and be able to make better decisions based on that information.” (<a href="https://youtu.be/RB5CQW8lbEo?t=2021">33:41</a>)</p>
</section>
<section id="transcript" class="level2">
<h2 class="anchored" data-anchor-id="transcript">Transcript</h2>
<div class="callout callout-style-simple callout-warning" style="margin-top: 0.75rem;">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-body-container">
<p>This transcript has been produced using speech-to-text transcription software. It has been only lightly edited to correct mistranscriptions and remove repetitions.</p>
</div>
</div>
</div>
<p><strong>Brian Tarran</strong><br>
Hello, and welcome to the very first instalment of the Real World Data Science interview series. I’m Brian Tarran, the editor of Real World Data Science, and I’m very pleased to be joined today by Erica Thompson, a senior policy fellow in ethics of modelling and simulation at the London School of Economics Data Science Institute, and the author of a fantastic new book - which I have a copy of here - Escape from Model Land, which is subtitled, How mathematical models can lead us astray and what we can do about it. So hello, Erica, thank you for joining us. I hope 2023 got off to a positive start for you.</p>
<p><strong>Erica Thompson</strong><br>
Yes, it has so far.</p>
<p><strong>Brian Tarran</strong><br>
Good, good. Because the book came out, is it just before Christmas or just after?</p>
<p><strong>Erica Thompson</strong><br>
Yeah, just before Christmas. So I’ve had all sorts of things flooding in saying, Oh, I liked your book, or I hated this bit or no, it’s exciting.</p>
<p><strong>Brian Tarran</strong><br>
Yeah, no, well, it’s, I have to say, I think, I thought it was a genuine– I finished reading it over, over Christmas. And I think it offers a genuinely fascinating and important perspective on mathematical models as being not just I guess, models of the real world, or, you know, real processes or systems, but subjective versions of reality, you know, encoding all sorts of assumptions and value judgments of the people who, who create the models. And I mean, I guess that shouldn’t really come as a surprise, right? But, but is it a point that is often lost in the discussion around models, particularly where decisions might be, like, informed or driven by model outputs?</p>
<p><strong>Erica Thompson</strong><br>
I think it is something that’s easy to miss. I mean, especially because we’re sort of, maybe as mathematicians were used to living in model land and doing things which, which we see as being logical consequences of previous things. And then more generally, the public look to science and mathematics and statistics as being objective arbiters, perhaps, of how things are and how things ought to be. And so, so yes, that that kind of putting things in a mathematical language does tend to make people think that it is truth from on high. And so my book, in some way goes towards saying actually, these models, they are, obviously we hope that they’re based on facts, and they’re based on data that we gather, but they also do have this value, judgement content, as well. And so we need to think about what that is and how we deal with it, and how we sort of express it and how we understand it.</p>
<p><strong>Brian Tarran</strong><br>
Right, yeah.</p>
<p><strong>Erica Thompson</strong><br>
Especially where we’re using those models to inform decision making or public policy, then it becomes particularly important.</p>
<p><strong>Brian Tarran</strong><br>
Yeah, yeah, no, and obviously, your book draws up quite a bit on the Covid-19 pandemic, and how models were used there. But I thought it was interesting, actually, that, you know, in reading the acknowledgments that you– that while the pandemic lent the topic, additional relevance, right, you actually started writing the book before that. So what led you to think now’s the time? What was the tipping point, if you like, of thinking, I want to write this book now?</p>
<p><strong>Erica Thompson</strong><br>
Yeah, okay. Well, that’s an interesting question. I mean, because it builds on the last sort of 10 or 15 years of my work. So I started out doing a PhD in climate physics. And my background before that was maths and physics. And so I was doing a PhD on the physics of North Atlantic storms, looking at how they would change given climate change. And so, obviously, the first thing you do is a literature review. And I started looking at different models and what the what they were saying about what would happen to North Atlantic storms. And what I found there was that there were models saying that the storm tracks would go north, they’d go south, they get stronger, they get weaker, they’d, you know, anything you name it. And interesting, particularly, interestingly, was that they, they had relatively small uncertainty ranges. So they they didn’t agree within their own uncertainty ranges. And that made me think, well, we this isn’t telling me very much about North Atlantic storms. But it’s telling me a great deal about modelling and the way that we do modelling and perhaps we need to start thinking more about how these uncertainty ranges are calculated, what does it mean? What, how can we end up in a situation where we have this level of disagreement between models. And so since then, I’ve been looking at, you know, those kinds of concepts in different areas I’ve been looking at sort of insurance and finance and weather and climate and humanitarian forecasting as well. And, and so in all of those application areas, I found the same questions about uncertainty and how we make inferences from model output to be particularly interesting and how common problems may be solved in different ways as well. So it’s interesting to do the compare and contrast. And so, yeah, then I guess I, I’d been on all these sorts of bitty little projects and thought actually, I’d really like to bring this together into something more coherent, you know, to actually say, look, there’s a, there is a common theme here and we need to be putting it together and drawing conclusions. And we can, we can learn a lot from doing that. And we can share the best practice throughout the sector.</p>
<p><strong>Brian Tarran</strong><br>
When you’re starting down this path of, I guess, looking into the, I guess, the ethics and process of modelling, did it, was there a lot of other work that you identify that you could kind of draw on a lot of other thinking around this area? Or was it kind of under studied, under researched sort of aspect of the literature?</p>
<p><strong>Erica Thompson</strong><br>
I think it’s under studied, I mean, of course, everybody who does some modelling, you know, you, you do your modelling, and then somebody says, Okay, we need to put some error bars on the outputs, and you go back and, and think about how we’re going to put the error bars on the outputs. And probably, I would say, most people doing that realise that it’s much more difficult than they have the time to do or the ability within the scope of whatever project they’re doing. But the aerobars, the uncertainties always ended up being tacked on at the end, you do it after you’ve done all the modelling, there’s less incentive to do it. And there’s less resource to do it than to make the model itself better. And I think that’s a very common story, that people realise that they ought to be doing more, but they just don’t have the time the resource, the ability to go and do that. So then yes, there are there are people, and there are particular areas that I think have taken more time to investigate this. So in physical science hydrology, I’d say in particular, has a very well developed history of thinking about the uncertainties in models, maybe because, you know, they are constantly being challenged by events happening, which were not within the models, you know, you’ve got your flood forecast model, and then something happens, and it goes way beyond what you were expecting. And you you have to go back and say, What does this mean for our modelling process. And other areas have much less well developed considerations of uncertainty. And so that’s where I think actually, we could we could really benefit by sharing good practice across these different application areas, because people have looked in different ways. And, you know, with with different levels of statistical interest, you know, some areas go into the stats, much more, some areas are very philosophical about sort of the conceptual foundations of how we should think about models and how we should think about the range of outputs that we get from models. And so what I’m trying to do is bring those together a bit. Yeah.</p>
<p><strong>Brian Tarran</strong><br>
Yeah, I think you certainly achieve that. It is really interesting, the different, the variety of examples that you present, and the ways you talk around these issues. I did want to focus in particular on climate models, though, because, you know, I was looking around your website, finding a bit more about about you, and I noticed on there that you talk about, you no longer fly to conferences, and that’s in order to kind of reduce your own ecological footprint. So I guess I wanted to ask, you know, when you set about writing a book, and it’s going to be a book that’s kind of critiquing models and the ways that they don’t often agree? Did you have like a nagging concern that, you know, the points you wanted to make about models in general, but climate models in particular, that that would kind of lend fodder to the kind of groups that might want to discredit climate models or downplay the risks? Or, indeed, the reality of climate change?</p>
<p><strong>Erica Thompson</strong><br>
I mean, yes, I did have that worry, I still have that worry. And I, but I hope that my book is clear throughout that, you know, that models are not irrelevant, you know, the answer is not to throw them away. If you come to it from this sort of sceptical position, saying, you know, we need to think more carefully about how we make inferences from models, you could go all the way down the rabbit hole and say, Oh, they’re all terrible, let’s just throw them away. But I think that would be completely unjustified. We have good evidence, sort of from from one end of the spectrum of relatively simple linear models, which are incredibly, wildly successful and form the foundation of modern life and modern technology. And, you know, with that, as a basis, we hope that we can, you know, work from there to find the limit of the knowledge that we can get from these more complex models, which are looking at making predictive statements in more extrapolatory domains where the underlying conditions are changing, and we therefore have less ability to rely on what I call the quantitative route of escape from model land, by challenging with relevant past data. You know, we’re looking at extrapolatory conditions like climate change, or social and economic systems, and therefore, we think that the data that we have, while they may be useful and indicative, are not, we can’t just calibrate with respect to past data and expect that to be enough to warrant performance in the future. And so, so I think that sort of one answer is that we shouldn’t be throwing away the models completely because they are demonstrable useful, and the question is to quantify the limits of what we can say, rather than just get rid of them. And then maybe the slightly more nuanced answer is that actually, if we have less confidence in the models, and our uncertainty ranges are wider, then because in many of these application areas and climate change, in particular, the damage function is convex, you know, we are expecting that as we go further from today’s climate, the consequence will be not just linearly worse, but sort of increasingly worse. And therefore, if you have, if you’re considering, you know, just to have a sketch of a kind of cost benefit analysis on some sort of expected utility from taking action to mitigate carbon emissions, for example, if you have more uncertainty, then your range is wider. And so the, the lack of quantification of the top tail becomes dominant in in the expected utility of the outcome. And therefore, you should be choosing to mitigate more, not less, because of that uncertainty. So, you know, the sceptics, I suppose the climate sceptics would say, oh, there’s a possibility that climate change might not be as bad as we expect, and therefore we shouldn’t bother doing anything. But I would say actually, that argument should be turned on its head, if we have greater uncertainty, that should be a bigger motivating factor to reduce carbon emissions rather than the opposite.</p>
<p><strong>Brian Tarran</strong><br>
Yeah, and I think you make that point quite clearly in the book. And the other point you make is that, I guess, building trust in models is about understanding their limitations. And the quote that I thought was really interesting was about acknowledging the social element of modelling. And I wonder, do you mind explaining what that social element is for people who are watching or listening? And how will that kind of manifests itself in models? Maybe you’ve got like a simple example that you might want to talk to? I don’t know.</p>
<p><strong>Erica Thompson</strong><br>
Yeah, okay. So, I mean, the social element of models is, because it is arbitrary how we choose to model a situation, there are infinitely many different ways that you could choose to simplify reality, this, you know, huge, messy, complex thing in front of us with physical laws that we don’t fully understand and things going on that we can only measure, sort of by proxy, with, you know, with models themselves to make many of our measurements of the system. And so, so you might choose to simplify a system in one way to model it. And I might choose to simplify it in a different way. And you might choose one programming language, and I might choose another and they would implement functions in different ways. And so all of our choices change the way that the model will then look at the end of the day. Now, then you say, okay, but supposing I’m modelling you know, what will happen to a ball when I throw it up in the air? Surely, that’s not a, you know, that has no social content, does it? And I’d say basically, no, it doesn’t really have any social content. It has some social content insofar as you’re deciding that this is what we want to make a model of. But ultimately, you and I would probably come up with very similar models, regardless of our background or our perspective, or our interests, or even our education to a large extent. And so, so those relatively simple linear situations, which I refer to as interpolatory models don’t have very much social content. Now, the ones that I’m particularly interested in and that I talk about in the book are things that are extrapolatory, where we’re interested in situations where we are trying to predict into the future a system where we expect the underlying conditions to be non-stationary, to be changing. So climate change is one example. Social and economic systems would be another example. And when we’re modelling systems like that, we have to be much more careful because we could choose to model them in radically different ways. We could, if you want to model an economic system, you might choose to disaggregate with respect to the social class of different households. And I might choose to make a sort of bulk model of the whole system with a representative household. And you could imagine hundreds of different ways to do these sorts of things. So maybe you think about pandemic models and how you could simplify it into individuals or you could make an agent-based model with, you know, actual agents walking around and infecting each other. Or you could just write some differential equations for how the transfer happens. So you could do it in, again, in many different ways. And the choice of simplification is then much more important, and it will have much larger first order effects on the outputs, and then on the framing of the question, you know. So you decide to model it in a certain way, with a certain kind of mathematics, and that changes the way that you might think about intervening in the system. If you’re presenting your model to a policymaker with the intent of informing them about their policy options, you might, if you have a model which can represent the effects of say, closing schools, or universities on pandemic transmission, then then that becomes a policy option. If you have a model which can’t represent those kinds of interventions, then it’s not a policy option. And similarly, with climate change, one of the examples that I talk about in the book is integrated assessment models of energy and climate. And so these are models which consider the energy system out to say 2100, and they put a price on nuclear electricity and renewables and all the other things that go into the energy system and basically say, how can we achieve our carbon targets at the lowest cost? Now, if you put in, if you choose to put in a certain price for a certain technology or assumptions about how that technology will develop in future, then you get a particular answer. And you put emphasis on certain kinds of policy options. And so that has, the choice of assumption has a very direct result in the model output and in the information and advice that you’re giving to policymakers. And of course, you might choose to put in something like behaviour change. So maybe we have a cost of however many dollars per tonne of carbon dioxide, for nuclear electricity or for renewables. But how much, what kind of price would you put on behaviour change? How many dollars per tonne of CO<sub>2</sub> avoided does it cost to change the behaviour of a population such that they use less energy? Well, that’s not really in the models. And if it was, it would, again, it would be first order because that would be you know, if you put it in at $2 per tonne of CO<sub>2</sub>, it would be heavily relied on, if you put it in at $2,000 per tonne of CO<sub>2</sub>, it’ll never happen. And where you choose to put that in between influences how it looks, and then that influences the pathway that’s projected, and it influences the advice that you give to policymakers.</p>
<p><strong>Brian Tarran</strong><br>
Yeah. You mentioned the example of school closures and stuff when you’re talking about Covid-19. I actually thought that, that one really helped me understand, I guess, and made it clear to me was that, there’s often been that argument about whether the lockdown was the right thing to do given the other impacts, but you actually say that if different types of people were doing the modelling, maybe if it was school aged people, and I guess encoding the impact that that would have had on them, and how much they value say not being able to go out and see their friends, the impacts potentially on mental health and things like that, it does change, I guess, the calculation of what the right intervention is or the right response is.</p>
<p><strong>Erica Thompson</strong><br>
Yeah, exactly. And I think I think we haven’t anywhere near bottomed out all of these impacts of the pandemic, you know, both the health impacts, and also, mental health and economic impacts will be rippling on for a very long time to come. So we, you know, we can’t even now retrospectively look back and say what was the right decision? It’s really not clear, depends how you value the different outputs, the different outcomes of a decision. And yes, we didn’t have economic models of what the impact of lockdown would be. And if we, if those had been available and developed the same kind of mathematical complexity and credibility as the models of infection and transmission we had in those early stages of the pandemic, which had essentially morbidity, mortality, and the, you know, the impact on the NHS, you know, number of hospital beds occupied. Those were the bottom lines, and there was nothing else. And so that was given as an input to the policymakers. Now, that’s, of course not everything that the policymakers rely on, they have to, their role is to weigh up everything else as well. But if we’d had models which contained more information about all of those other impacts, I think it’s quite plausible that we would have seen different kinds of decision making. And then there’s also the communication aspect, that these models were used to communicate and justify and persuade the public of the importance of the actions that were taken. And, you know, I think it’d be hard to disagree that the actions that were taken immediately where necessary, we certainly did need some kind of lockdown straight away. But then the question of exactly what you do thereafter is much more difficult.</p>
<p><strong>Brian Tarran</strong><br>
Yeah, yeah. So in the book, you kind of make the point that it’s somewhat of a fool’s errand to try and make models objective, and they can’t ever really achieve this, you know, principle of scientific objectivity. But that we instead should look to counter subjectivity of individual models with a diversity of models that do encode these different perspectives, like we’ve just been talking about. I wonder, you know, how would you see this working in practice? Or how would you like to see this working in practice?</p>
<p><strong>Erica Thompson</strong><br>
I mean, that’s a difficult question. So it’s, it’s nice to think that, you know, we have these models, and they are unavoidably subjective. Essentially, my view is that the model encapsulates the expert opinion of a particular expert, and it comes laden with their own perspectives, and biases and preconceptions, as well as their expertise and their education and their experience of a subject, you know, which shouldn’t be set aside. So if we are trying to understand a situation, then we want to get as many perspectives as possible. And so in theory, incorporating the widest possible diversity of different backgrounds into modelling and making a multiplicity of different models and trying to see the problem from these different perspectives will help us to understand it better. Now, then the statistician will jump in and say, Aha, can we, you know, can we in some way average those models or use some sort of statistical inference to take those models and put them together and come up with an even better answer? And I would, I would sort of counter that by saying that there’s no reason to believe that our, that a set of models generated as essentially just one set of opinions will be an independent and identically distributed sample from some distribution, underneath which will be an estimator of, of the truth, if that even exists. And so many of the formal statistical methods that we would quite like to apply to an ensemble of models, a large group of models put together aren’t really conceptually valid at all. I mean, that doesn’t stop people doing it. And maybe you get some interesting information from it, but you certainly can’t rely on it as an estimator. So there’s a sort of statistical problem there. And then the other question is your reference class. So, to what extent do you believe that these models are all equally valid or equally plausible? So that then brings the social question back to the forefront. Because then you say, you know, if I believe that, you know, somebody from Imperial College, say, who is the head of an institute for epidemiology, and has many, many years of experience making this kind of model, you know, is an expert and is qualified to create a model and for that to be recognised as a valid expert opinion, who else has got the credibility to do that? How do we define that? You know, what do you call a plausible model? So then it’s a question of the sort of scientific gatekeeping. What kind of qualifications do you expect from somebody or from an institution? What kind of expertise counts as being relevant and valid expertise? Does it have to be mathematical expertise? Can it be lived experience? Can it be, does the model have to be a mathematical model? What kinds of mathematics are appropriate for the situation? If we disagree about assumptions, does that mean that we can’t consider the the two sets of models in the same sort of class of plausible models? Or are we going to start pruning it by saying, I believe your assumptions, and I don’t believe your assumptions? And if so, who gets to do that? Who gets to decide what is plausible and what is not plausible? And what is allowed to enter into this set? Because as soon as we start pruning it, then we make the statistical inference more difficult. You know, if you want to say, if you want to start applying your methods that assume that the models are on, you know, that the models are independent, then you can’t start pruning because then that introduces huge dependencies on your own expert judgement. So it just becomes extremely difficult. And this is where all of then the social questions about expertise and credibility and sort of scientific gatekeeping and how we assign that credibility and trust, trust in science, you know, who has trust in which kinds of models? This is something, this is a theme that we see coming out of climate science and, you know, hopefully less now than maybe 10 years ago. But in the pandemic, of course, we’ve seen it coming right up again with questions about lockdowns, and about vaccination strategies, and all of that sort of thing. Trust in science is really important. And maybe one of my themes is that trust in science actually is first order in the modelling process itself. It’s not something that is sort of added on afterwards, I’m going to go away and make my model and then the question is whether or not you trust it. Actually, trust and expertise and credibility are in the modelling process directly.</p>
<p><strong>Brian Tarran</strong><br>
Do you mind if we segue to talking about artificial intelligence models, or models made by artificial intelligence? Because that’s, I think that touches on a lot of the same issues, right? And I wanted to think about, well, first of all, you say that, obviously, artificial intelligence models made by AI, they’re not objective, even though there’s like, they’re kind of building the models, if you like, those AIs have still been trained by people, been coded by individuals and those personal judgments and assumptions and all that get embedded into the artificial intelligence. But I think, I guess my question for you is, we’re starting, I think, to have a very frank and public debate about AI ethics, and to demand transparency and explainability of things like automated decision making systems. But do you think we’re kind of, are we falling short of holding ourselves as people to the same standards of transparency and being clear about the choices and decisions we make? And also documenting that subjectivity when we’re preparing these sorts of models and these sorts of decision making systems for policymakers to use?</p>
<p><strong>Erica Thompson</strong><br>
Yeah, so I mean, I suppose there are two questions there. And one’s about what we do and one’s about the AI. So for the humans, maybe, yes, I think that there needs to be more frank discussion of values and value judgments and politics and social assumptions within models. And I think we are starting to see that with the pandemic models, particularly because it’s been so high profile. I mean, remembering that actually, it’s really hard to unpick your own value judgments. And it’s easier for somebody with a different perspective to come in and say, Oh, actually, you know, you’ve assumed that, why did you assume that? And, you know, when we are embedded in a particular culture of modelling, it’s particularly hard to imagine that anything could possibly be done differently. And so I think that’s, again, where diversity is really important, because introducing those perspectives will help to challenge dominant strains of thinking which can end up in sort of accidentally, and not deliberately at all, in a form of groupthink. So that’s the humans and then the, with the AI, yes, you know, they inherit their value judgments from their creators. And so, for example, on the statistical side, one might think about the kinds of loss functions that are used to calibrate machine learning programmes, you know, how does the machine decide what is better and what is worse? You know, it is learning to model a situation, but there will be some kind of loss function in there, which it is minimising in order to decide what is the best model. And so, being explicit about that loss function, I think, actually is really interesting, you know, the fact that the model has got written down an explicit loss function which it is minimising means that we can then analyse that and think about what are the value judgments inherent in that choice of loss function, which is something that we don’t have when humans are calibrating a model and they’re twiddling a knob here and a knob there and saying, Oh, does it look realistic? Am I getting the right kind of behaviours, you know, does it match up with the map I have from observations or whatever. And so, having that I think we can then say, what are the implications of writing a loss function in this way? And what are the values that are implied? I mean, even just modelling itself, you know, like choosing to solve a problem with recourse to mathematical modelling is a value judgement and implies a certain kind of solution, doesn’t it? So if we say that we even can come to a decision, that the models input will be relevant and interesting and help us, that is a value judgement.</p>
<p><strong>Brian Tarran</strong><br>
Yeah, and perhaps we could return to that point a bit later, because there was a line again that jumped out in the book about decision makers needing to maybe curb some over enthusiasm for mathematical solutions. You do talk about documenting value judgments as being kind of one of five principles that you set out for mathematical modellers to adopt to support responsible modelling. I think it’s fascinating to me that you’ve used the vehicle of a popular science textbook to speak to this community, and to sort of set out these principles rather than, say, a journal paper or conference presentation. So I wanted to ask, is there a particular strategy to that decision? I mean, I have my own theory on that, but maybe I’ll let you go first.</p>
<p><strong>Erica Thompson</strong><br>
I’d love to hear your theory. I mean, I guess partly because I suppose I’m very interdisciplinary. And I’m, I’m hopping between these different areas, as we were discussing before, so I have sort of a climate science community and statistics and data science and other application areas in humanitarian forecasting, sort of hydrology, geophysics, weather and climate and all the rest of it. And actually, I find it really hard to get these thoughts published in journal form, because I suppose partly because it feels too general for any specific journal. And perhaps it feels too simplistic that, that the reviews I get tend to be either Oh, we’ve heard this all before it’s not new, or this is too radical and this isn’t an appropriate journal for it, you know, that sort of thing. And actually, I kind of got to the point of thinking, Well, you know, do people even read these journals anyway? Actually, maybe really what I need to be doing is trying to provoke a wider discussion about models. And I do tend to get a, you know, a really good response, when I speak at conferences or talk to people about these things. People go yes, yes, you know, this is really important. Actually, this is something I’ve really struggled with, we don’t know how to do it, the uncertainty is always just an add on at the end that doesn’t have enough time allocated for it. But I don’t have the resource to do it, I’m not able to grapple with these questions, because they’re so fundamental and so wide ranging, and it would be really helpful to have more of a sort of walkthrough of how people tackle these questions in different fields. And so, so I’ve been trying to do that. And I felt that the book was a good way to sort of spark the conversation and maybe also get it to some different audiences. So I’ve had people contacting me since the book came out saying, oh, you know, I’m working in, like, asset valuation for disputes between states, really random things, quite different. And they say, actually, your book really struck a chord, and we have difficulties with this in this particular area. And so I’m really hoping that, you know, the book will help me then to find, to bring together people working on these sorts of issues with common themes from really different application areas and try to make some headway on how we can actually go about practically changing modelling practice to make it to make it work better, and assess uncertainty better. So it’s not just– I think some people maybe read the book and think, Oh, this is just a sort of woke advertisement for diversity. Well, it’s not; it’s a way of doing the maths better. The whole point is to do the maths better, make better forecasts, understand the future more effectively, and be able to make better decisions based on that information.</p>
<p><strong>Brian Tarran</strong><br>
Yep, well, that’s not too far away from my theory on why you did it. I thought it was that it’s a great way of getting– if you can get policymakers and the public to read this, right, you can get them to hold modellers to these principles, rather than having it just be something that you kind of talk about within the community and it doesn’t really go outside that, right? It’s a way of people, you know, the next pandemic or whatever it might be, the next time a model is the focus of a debate, the public are equipped to ask the right sort of questions about the process. Okay, I’ve got one more question to you because we’re running out of time. And it’s back to that over enthusiasm for mathematical solutions point. I thought was somewhat serendipitous to read about, read that quote, in the same week that the UK Prime Minister Rishi Sunak announced a plan for all pupils in England to study maths to the age of 18. So, I wanted to ask you what you make of that plan, first of all, but also, I think, more importantly, does a more mathematically minded populace, are they better equipped to understand the mathematical descriptions of the world and that they are incomplete descriptions? Or is there kind of maybe some other curriculum that we need to tack on to this maths to 18, in order that people are able to better differentiate between model land and the real world?</p>
<p><strong>Erica Thompson</strong><br>
Yeah, so I mean, I’m not a fan of– I mean, I like the idea of people studying maths to 18. I think more maths is a good thing. I loved maths, I still love maths, I think if more people were more generally numerate then society would be better and life would be better. But if you haven’t enthused people about the value and the interest of maths by 16, forcing them to study it for another two years is absolutely not the answer. It will just put people off staying in school past 16. So I, you know, I think that we need better teaching of maths before 16, rather than forcing people to study maths post 16. And part of that is helping people to understand how mathematics is relevant to the real world that they live in and teaching them the kind of things that they will use in their adult life. You know, people, most people don’t use Pythagoras theorem, but most people do need to fill in a tax return, you know, these sorts of things. Understanding orders of magnitude, and the difference between millions and billions, would be incredibly helpful, wouldn’t it? So, yeah, I think there are more basic questions there that need to be answered before we go into the details of sort of complex maths. And then, so what was the next question?</p>
<p><strong>Brian Tarran</strong><br>
It was about whether whether you think, the more mathematically equipped we are, does that make us better able to understand the limitations of models? Or do we need something else to kind of train us or encourage us to think about these two separate realities, model land and the real world? And I say realities in inverted commas.</p>
<p><strong>Erica Thompson</strong><br>
Yeah, I mean, I think the general public has a good understanding that the model land and the real world are not the same. There is actually a healthy scepticism of models out there. And I think that’s probably a good thing. I give a couple of funny anecdotes in the book about that. So I mean, one was a, I think, a YouGov poll about people going to the moon and saying, you know, would you go to the moon if you could be guaranteed a safe return, blah, blah, blah, and like, a large percentage of those said, Well, no, I just don’t think you could give me a safe return, they reject the model land. And then there was another example about intelligence analysts being asked to sort of calibrate a probability language scale. So they say, like, likely, however many percent and very likely however many percent and unlikely however many percent. And so the study was looking at different ways of doing that. And one way was to accompany the word likely, or unlikely, or whatever, with a written number of what the probability it referred to was. So it would say, like, likely, I can’t remember the number, but sat it was, like 50 to 70%, written down in the question, and then the question was, what is the probability of an event, which is deemed to be likely brackets 50 to 70%? And what people write down was not 50 to 70%. You know, as a mathematician, that’s completely ridiculous. Because the answer was in the question, why wouldn’t you write that down? But of course, what you’re seeing there is the rejection of model land. Somebody has assessed it as 50-70%. The question is, do you believe it? Well, no, actually, you might write something like 40 to 80%, because you expect there to be, you know, the model to be generically overconfident. And so this is sort of what I mean, by curbing over enthusiasm for mathematical solutions is that, you know, we have to understand that the mathematical solutions are living in model land, and that we can, in order to get out of model land, we have to say, do we actually expect this result to refer to the real world? Or is it only saying what the next model run is going to tell us? And so the act of doing that is difficult, and it’s more difficult for mathematicians than for the general public because as mathematicians, we sort of are used to living within model land and noticing when the answer is in the question and then writing it down. And we’re not very good at saying, Well, what’s my subjective estimate of the probability of this model being inadequate in some way? That’s not something that you can necessarily do with respect to data and so it’s a tricky one. So in terms of the over enthusiasm, you know, it’s curbing over enthusiasm, not curbing enthusiasm, because as I said at the beginning, and I returned to a lot in the book, actually, mathematical models are incredibly valuable. And they contain a huge amount of information and insight that we’re, we would be fools to throw away. But we need to understand it, you know, in a more nuanced way and be clear about what it’s telling us and what it’s not telling us. And that answers in model land aren’t necessarily the answers that we need in reality, though they may be informative about them.</p>
<p><strong>Erica Thompson</strong><br>
Well, Erica, thank you very much for your time today, for talking through the book, which is out now. Do you have some some links or information about where people can find out more about the book?</p>
<p><strong>Erica Thompson</strong><br>
Yep, look on my on my website, ericathompson.co.uk. And it’s available through all the usual booksellers.</p>
<p><strong>Brian Tarran</strong><br>
Excellent, excellent. Well, I wish you the best of luck with the book. As I say, I think it’s fantastic. And well, I hope we get to talk again, maybe a bit further down the road and see whether some of these principles and this ethical framework that you talk about for mathematical modelling, whether that kind of comes to fruition because I think we need to watch that closely. So, Erica, thank you.</p>
<p><strong>Erica Thompson</strong><br>
Thank you very much. Thanks for having me.</p>
<div class="article-btn">
<p><a href="../../../../../viewpoints/interviews/index.html">Find more Interviews</a></p>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-6">
<dl>
<dt>Copyright and licence</dt>
<dd>
© 2023 Royal Statistical Society
</dd>
</dl>
<p><a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> <img style="height:22px!important;vertical-align:text-bottom;" src="https://realworlddatascience.net/viewpoints/interviews/posts/01/25/https:/mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://realworlddatascience.net/viewpoints/interviews/posts/01/25/https:/mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"></a> This work is licensed under a Creative Commons Attribution 4.0 (CC BY 4.0) <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> International licence</a>, except where otherwise noted.</p>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>How to cite</dt>
<dd>
Tarran, Brian. 2023. “How to ‘Escape from Model Land’: an interview with Erica Thompson.” Real World Data Science, January 25, 2023. <a href="https://realworlddatascience.net/news-and-views/interviews/posts/01/25/erica-thompson.html">URL</a>
</dd>
</dl>
</div>
</div>
</div>


</section>

 ]]></description>
  <category>Modelling</category>
  <category>Ethics</category>
  <guid>https://realworlddatascience.net/viewpoints/interviews/posts/01/25/erica-thompson.html</guid>
  <pubDate>Wed, 25 Jan 2023 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/viewpoints/interviews/posts/01/25/images/erica-thompson.png" medium="image" type="image/png" height="105" width="144"/>
</item>
<item>
  <title>Pulling patterns out of data with a graph</title>
  <dc:creator>Andrew Saydjari</dc:creator>
  <link>https://realworlddatascience.net/ideas/datasciencebites/posts/2023/01/24/pulling-patterns.html</link>
  <description><![CDATA[ 




<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-1-contents" aria-controls="callout-1" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
About the paper and this post
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-1" class="callout-1-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<p><strong>Title:</strong> Extracting the main trend in a data set: The Sequencer algorithm</p>
<p><strong>Author(s) and year:</strong> Dalya Baron and Brice Ménard (2021)</p>
<p><strong>Status:</strong> Published in <em>The Astrophysical Journal</em>, open access: <a href="https://iopscience.iop.org/article/10.3847/1538-4357/abfc4d">HTML</a>, <a href="https://iopscience.iop.org/article/10.3847/1538-4357/abfc4d/pdf">PDF</a>.</p>
<p><strong>Editor’s note:</strong> This post is republished with permission from <a href="https://mathstatbites.org/pulling-patterns-out-of-data-with-a-graph/">MathStatBites</a> to demonstrate the Bites concept. For more information about Bites articles and how to contribute to DataScienceBites, see our <a href="../../../../../../contributor-docs/datasciencebites.html" aria-label="Contributor notes for the Data Science Bites blog">notes for contributors</a>.</p>
</div>
</div>
</div>
<p>Large volumes of data are pouring in every day from scientific experiments like <a href="https://home.cern/">CERN</a> and the <a href="https://www.sdss5.org/">Sloan Digital Sky Survey</a>. Data is coming in so fast that researchers struggle to keep pace with the analysis and are increasingly developing automated analysis methods to aid in this herculean task. As a first step, it is now commonplace to perform dimension reduction in order to reduce a large number of measurements to a set of key values that are easier to visualize and interpret.</p>
<p>When working on the cutting edge, another problem scientists often face is that “we don’t know what we don’t know”. For this reason, we often want to simply ask the data, “What is interesting about you?” This is the realm of <a href="https://en.wikipedia.org/wiki/Unsupervised_learning">“unsupervised” methods</a>, where the data itself drives the analysis, with little to no guidance or human labeling of the data.</p>
<p>Many physical processes depend continuously on some driving parameter. For example, the evaporation rate of water increases with temperature. We call these continuous variations in datasets “trends”. Describing a dataset by a single trend reduces it to one dimension - an ordered list. Finding such a trend within a high-dimensional dataset is the aim of a method called “The Sequencer” introduced by Baron and Ménard.</p>
<section id="key-insight-a-tree" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="key-insight-a-tree">Key insight: A tree</h2>
<p>The key insight of Baron and Ménard was to relate trends in data to an object from graph theory called a <a href="https://en.wikipedia.org/wiki/Minimum_spanning_tree">minimum spanning tree</a>. Given a measure of distance between two data points, for example the usual (Euclidean) distance between two points, we can visualize a dataset as a graph. This graph consists of a node (a dot) for each data point. These nodes are then connected by an edge (a line), labeled by the distance between the two data points. The minimum spanning tree is a reduction of this graph to include only enough of the smallest distance edges so that no node is isolated.</p>
<p>What Baron and Ménard realized is that datasets that are “trendy” have elongated and narrow minimum spanning trees. As shown in Figure 1, a totally random dataset results in a graph with many branches while a perfect sequence results in a perfect linear graph. Then, they use connectivity of the nodes in the minimum spanning tree to return an ordering of the data that follows the main trend in the dataset. However, a sequence is all you get. It is up to us to understand and interpret what this trend represents.</p>
<div class="column-page">
<p><img src="https://realworlddatascience.net/ideas/datasciencebites/posts/2023/01/24/images/fig1.png" class="img-fluid" alt="Three examples - labelled 'random data', 'noisy sequence', and 'perfect sequence' - demonstrating that data with stronger trends ('noisy' and 'perfect sequence') have more narrow and elongated minimum spanning trees (adapted from Baron and Ménard, Figure 1)."></p>
</div>

<div class="no-row-height column-margin column-container"><div class="">
<p><strong>Figure 1:</strong> Examples demonstrating that data with stronger trends have more narrow and elongated minimum spanning trees. Adapted from <a href="https://iopscience.iop.org/article/10.3847/1538-4357/abfc4d" aria-label="Link to Baron and Ménard's 2021 paper, 'Extracting the main trend in a data set: The Sequencer algorithm'">Baron and Ménard (2021)</a>, Figure 1. Figure used under <a href="https://creativecommons.org/licenses/by/4.0/" aria-label="Link to Creative Commons licence">CC BY 4.0</a>.</p>
</div></div><p>Sometimes, the ordering of observations within a data point matters, like in time series data. Measurements taken close in time are more likely to be correlated than measurements taken after a long time delay. Baron and Ménard were careful to include a measure of distance that takes this ordering into account, unlike our usual notion of distance. They argue that this gives them an edge over other common dimension reduction techniques such as <a href="https://en.wikipedia.org/wiki/T-distributed_stochastic_neighbor_embedding">t-SNE</a> and <a href="https://umap-learn.readthedocs.io/en/latest/how_umap_works.html">UMAP</a>, and even go so far as to use The Sequencer to optimize the hyperparameters used by these other methods!</p>
</section>
<section id="when-does-it-fail" class="level2">
<h2 class="anchored" data-anchor-id="when-does-it-fail">When does it fail?</h2>
<p>It is important to acknowledge that no statistical or machine-learning tool is a cure-all. And, the authors themselves are quick to point out several limitations that can hinder the application of their method. The Sequencer can struggle when the data has a large dynamic range, a variety of signal strengths relative to noise, or there are multiple trends present in the data. In each case, Baron and Ménard propose ways to mitigate these problems, but practitioners still need to be wary when applying The Sequencer in those instances.</p>
</section>
<section id="what-discoveries-await" class="level2">
<h2 class="anchored" data-anchor-id="what-discoveries-await">What discoveries await?</h2>
<p>To demonstrate the power of their method, Baron and Ménard apply The Sequencer to several real datasets where a pattern was already known and show that The Sequencer recovers that pattern. Examples include ordering spectral measurements of stars by their temperature and <a href="https://en.wikipedia.org/wiki/Quasar">quasars</a> by their <a href="https://en.wikipedia.org/wiki/Redshift_survey">redshift</a>, a measure of their distance from us on Earth.</p>
<p>But, what about new patterns? The team has already applied The Sequencer to mine seismographic data and discover previously unknown formations deep within the earth, at the boundary between the core and <a href="https://en.wikipedia.org/wiki/Core%E2%80%93mantle_boundary">mantle</a>. By sequencing the seismic waves, they realized that the main trend was the amplitude of diffraction off of these structures, which they were then able to localize beneath Hawaii and the Marquesas (DOI: <a href="https://doi.org/10.1126/science.aba8972" aria-label="Link to article, 'Sequencing seismograms: A panoptic view of scattering in the core-mantle boundary region'">10.1126/science.aba8972</a>).</p>
<p>For more demonstrations and discoveries, or even to upload your own data for sequencing, <a href="http://sequencer.org/">check out the project website</a>. Data sleuths can also download all of the code directly from <a href="https://github.com/dalya/Sequencer">GitHub</a> and sequence to their hearts’ content!<br>
<br>
</p>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-6">
<dl>
<dt>About the author</dt>
<dd>
<strong>Andrew Saydjari</strong> is a graduate student in physics at Harvard researching the spatial and chemical variations of dust in the interstellar medium. He favors using interpretable statistics and large photometric and spectroscopic surveys.
</dd>
</dl>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>About DataScienceBites</dt>
<dd>
<a href="../../../../../../ideas/datasciencebites/index.html"><strong>DataScienceBites</strong></a> is written by graduate students and early career researchers in data science (and related subjects) at universities throughout the world, as well as industry researchers. We publish digestible, engaging summaries of interesting new pre-print and peer-reviewed publications in the data science space, with the goal of making scientific papers more accessible. Find out how to <a href="../../../../../../contributor-docs/datasciencebites.html">become a contributor</a>.
</dd>
</dl>
</div>
</div>
</div>


</section>

 ]]></description>
  <category>Data management</category>
  <category>Dimension reduction</category>
  <category>Graph theory</category>
  <guid>https://realworlddatascience.net/ideas/datasciencebites/posts/2023/01/24/pulling-patterns.html</guid>
  <pubDate>Tue, 24 Jan 2023 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/ideas/datasciencebites/posts/2023/01/24/images/signal-from-noise.png" medium="image" type="image/png" height="115" width="144"/>
</item>
<item>
  <title>We’re taking Real World Data Science on the road</title>
  <dc:creator>Brian Tarran</dc:creator>
  <link>https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/01/18/rwds-at-rss-conference.html</link>
  <description><![CDATA[ 




<p>Real World Data Science has booked its first conference appearance! This September, we’ll be part of the data science stream of the <a href="https://rss.org.uk/training-events/conference-2023/">RSS International Conference</a>.</p>
<p>Our session, “Real World Data Science Live”, will feature talks and discussions based on content published on this site. In particular, we’re looking to share compelling examples of how data science is being used to solve real-world problems.</p>
<p>If you’re thinking about <a href="https://realworlddatascience.net/contributor-docs/call-for-contributions.html">contributing to Real World Data Science</a>, or have already made a submission, do let us know whether you’d be interested in taking part in this in-person event. There are only a handful of speaker slots available, so please get in touch ASAP!</p>
<p>The conference takes place 4-7 September 2023, in Harrogate, Yorkshire. <a href="https://rss.org.uk/news-publication/news-publications/2023/general-news/first-keynote-speaker-announced-for-rss-2023-confe/">Keynote speakers include Anuj Srivastava</a>, a Florida State University professor with research interests in statistical computer vision, functional data analysis, and shape analysis, and other <a href="https://rss.org.uk/training-events/conference-2023/invited-session-topics/">invited topic sessions</a> in the data science stream are:</p>
<ul>
<li>GitHub: Version control for research, teaching and industry</li>
<li>Surrogate-assisted uncertainty quantification of complex computer models</li>
<li>Getting your work to work</li>
<li>Best practices for the analysis and visualisation of Google Trends data</li>
</ul>
<p>See the <a href="https://rss.org.uk/training-events/conference-2023/">RSS International Conference 2023 website</a> for more details.</p>
<div class="article-btn">
<p><a href="../../../../../../viewpoints/editors-blog/index.html">Back to Editors’ blog</a></p>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-6">
<dl>
<dt>Copyright and licence</dt>
<dd>
© 2023 Royal Statistical Society
</dd>
</dl>
<p><a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> <img style="height:22px!important;vertical-align:text-bottom;" src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/01/18/https:/mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/01/18/https:/mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"></a> This work is licensed under a Creative Commons Attribution 4.0 (CC BY 4.0) <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> International licence</a>, except where otherwise noted.</p>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>How to cite</dt>
<dd>
Tarran, Brian. 2023. “We’re taking Real World Data Science on the road.” Real World Data Science, January, 18 2023. <a href="https://realworlddatascience.net/news-and-views/editors-blog/posts/2023/01/18/rwds-at-rss-conference.html">URL</a>
</dd>
</dl>
</div>
</div>
</div>



 ]]></description>
  <category>Updates</category>
  <category>Events</category>
  <guid>https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/01/18/rwds-at-rss-conference.html</guid>
  <pubDate>Wed, 18 Jan 2023 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/01/18/images/rss-conf23.png" medium="image" type="image/png" height="94" width="144"/>
</item>
<item>
  <title>Explore the RSS Data Science &amp; AI Section newsletter, right here!</title>
  <dc:creator>Brian Tarran</dc:creator>
  <link>https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/01/05/newsletter.html</link>
  <description><![CDATA[ 




<p>Happy New Year from all of us at Real World Data Science. We hope you had a relaxing break over the holidays and are now refreshed and excited to see what 2023 has in store. We’re starting the year with a new addition to the site: a page dedicated to the excellent <a href="https://realworlddatascience.net/news-and-views/newsletter/">RSS Data Science &amp; AI Section newsletter</a>.</p>
<p>This monthly newsletter has been running since February 2020 and is well worth subscribing to as it features roundups of news, new developments, big picture ideas and practical tips.</p>
<p>You’ll find the full list of past newsletters in our <a href="https://realworlddatascience.net/news-and-views/"><strong>News and views</strong></a> section (click the “Newsletter” heading in the section menu). If you want to subscribe to the newsletter, head over to <a href="https://datasciencesection.org/about/">datasciencesection.org</a>. The Data Science &amp; AI Section also has a page on the <a href="https://rss.org.uk/membership/rss-groups-and-committees/sections/data-science-section/">RSS website</a>.</p>
<div class="article-btn">
<p><a href="../../../../../../viewpoints/editors-blog/index.html">Back to Editors’ blog</a></p>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-6">
<dl>
<dt>Copyright and licence</dt>
<dd>
© 2023 Royal Statistical Society
</dd>
</dl>
<p><a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> <img style="height:22px!important;vertical-align:text-bottom;" src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/01/05/https:/mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/01/05/https:/mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"></a> This work is licensed under a Creative Commons Attribution 4.0 (CC BY 4.0) <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> International licence</a>, except where otherwise noted.</p>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>How to cite</dt>
<dd>
Tarran, Brian. 2023. “Explore the RSS Data Science &amp; AI Section newsletter, right here!” Real World Data Science, January, 5 2023. <a href="https://realworlddatascience.net/news-and-views/editors-blog/posts/2023/01/05/newsletter.html">URL</a>
</dd>
</dl>
</div>
</div>
</div>



 ]]></description>
  <category>Updates</category>
  <category>Newsletters</category>
  <guid>https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/01/05/newsletter.html</guid>
  <pubDate>Thu, 05 Jan 2023 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/01/05/images/brett-jordan-LPZy4da9aRo-unsplash.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>Determining the best way to route drivers for ridesharing via reinforcement learning</title>
  <dc:creator>Brian King</dc:creator>
  <link>https://realworlddatascience.net/ideas/datasciencebites/posts/2022/12/13/ridesharing.html</link>
  <description><![CDATA[ 




<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-1-contents" aria-controls="callout-1" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
About the paper and this post
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-1" class="callout-1-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<p><strong>Title:</strong> Dynamic causal effects evaluation in A/B testing with a reinforcement learning framework</p>
<p><strong>Author(s) and year:</strong> Chengchun Shi, Xiaoyu Wang, Shikai Luo, Hongtu Zhu, Jieping Ye, Rui Song (2022)</p>
<p><strong>Status:</strong> Published in <em>Journal of the American Statistical Association, Theory and Methods</em>, open access: <a href="https://www.tandfonline.com/doi/full/10.1080/01621459.2022.2027776">HTML</a>, <a href="https://www.tandfonline.com/doi/epdf/10.1080/01621459.2022.2027776?needAccess=true&amp;role=button">PDF</a>, <a href="https://www.tandfonline.com/doi/epub/10.1080/01621459.2022.2027776?needAccess=true&amp;role=button">EPUB</a>.</p>
<p><strong>Editor’s note:</strong> This post is republished with permission from <a href="https://mathstatbites.org/determining-the-best-way-to-route-drivers-for-ridesharing-via-reinforcement-learning/">MathStatBites</a> to demonstrate the Bites concept. See <a href="../../../../../../contributor-docs/datasciencebites.html">here</a> for more information.</p>
</div>
</div>
</div>
<p>Companies often want to test the impact of one design decision over another, for example Google might want to compare the current ranking of search results (version A) with an alternative ranking (version B) and evaluate how the modification would affect users’ decisions and click behavior. An experiment to determine this impact on users is known as an A/B test, and many methods have been designed to measure the “treatment” effect of the proposed change. However, these classical methods typically assume that changing one person’s treatment will not affect others (known as the Stable Unit Treatment Value Assumption or SUTVA). In the Google example, this is typically a valid assumption — showing one user different search results shouldn’t impact another user’s click behavior. But in some situations, SUTVA is violated, and new methods must be introduced to properly measure the effect of design changes.</p>
<p>One such situation is that of ridesharing companies (Uber, Lyft, etc.) and how they determine which drivers are sent to which riders (the dispatch problem). Simply put, when a driver is assigned to a rider, this decision impacts the spatial distribution of drivers in the future. Hence the dispatch strategy (our treatment) at the present time will influence riders and drivers in the future, which violates SUTVA and hence invalidates many traditional methods for A/B testing. To tackle this problem, a group of researchers have recently employed a reinforcement learning (RL) framework which can accurately measure the treatment effect in such a scenario. Furthermore, their proposed approach allows for companies to terminate A/B tests earlier if the proposed version B is found to be clearly better. This early stopping can save time and money.</p>
<p>To better understand RL and how it can contribute to tackling the issue at hand, it’s first helpful to set some context. In typical RL problems, including the one in this paper, the scenario is modeled with something known as a Markov Decision Process (MDP). A MDP links three sets of variables across time: the state or environment, the treatment or action (the reaction to the environment), and the outcome (the response produced by the environment due to the action). These outcomes can be thought of as rewards which depend on the action taken and the state observed. Over time, the machine learns which actions produce more positive rewards and which bring about worse outcomes. Hence, the actions leading to higher rewards are positively reinforced, thus the name reinforcement learning. A causal diagram of an MDP is shown in Figure 1, where <em>S</em><sub><em>t</em></sub>, <em>A</em><sub><em>t</em></sub>, and <em>Y</em><sub><em>t</em></sub> are the <strong>state</strong>, <strong>action</strong>, and <strong>outcome</strong> at time <em>t</em>. As one can see, past treatments influence future outcomes by altering the state variables at the present (the so-called “carryover effect” which violates SUTVA).</p>
<div class="column-page">
<p><img src="https://realworlddatascience.net/ideas/datasciencebites/posts/2022/12/13/images/ridesharing-fig1.png" class="img-fluid" alt="A causal diagram of a Markov Decision Process is shown in this figure. Green circles represent states, with arrows leading to red diamonds and blue squares representing, respectively, actions and outcomes. Actions are linked to new states by arrows, and prior states are linked to new states by curved arrows. This illustration conveys how past treatments influence future outcomes by altering the state variables at the present (the so-called “carryover effect” which violates the stable unit treatment value assumption)."></p>
</div>

<div class="no-row-height column-margin column-container"><div class="">
<p><strong>Figure 1:</strong> Causal diagram of MDP, where the solid lines represent causal relationships.</p>
</div></div><p>Making this more concrete, consider an example where the decision-maker is a ridesharing company. The environment or <strong>state</strong> is whatever variables the decision-maker can measure about the world, like the spatial distribution of drivers, number of pickup requests, traffic, and weather. The company then makes some <strong>action</strong> on how to dispatch drivers. The combination of the state and action leads to an <strong>outcome</strong> that can be measured, for example passenger waiting time or driver’s income. The strategy which is used to determine an action is known as a policy. This policy could be designed to take the state into account or simply be fixed regardless of what environment is encountered. Much of the reinforcement learning literature focuses on the former (policies that depend on the state), but the authors argue that fixed designs are the de facto approach in industry A/B testing and hence they focus on that setting. In particular, a common treatment allocation design is the switchback design, where there are two policies of interest (the current dispatching strategy vs a proposed strategy) determined ahead of time and they are employed in alternating time intervals during the A/B test.</p>
<p>So how are policies compared to determine the treatment effect? The answer lies in what is known as the value function, which measures the total outcome that would have amassed had the decision-maker followed a given policy. The value function can put more value on short-term gain in outcome or long-term benefits. The two policies in an A/B test each have their own value functions, and a proposed policy is determined to be better if its value is (statistically) significantly higher. In the ridesharing setting, one possible outcome of interest is driver income. An A/B test in that scenario would thus look to see if a proposed policy had greater expected driver income vs the current policy.</p>
<p>A natural question is when to end the experiment and test for a difference in value. In practice, companies will often simply run the test for a prespecified amount of time, such as two weeks, and then perform an analysis. But if one policy is clearly better than another, that difference could be detectable much earlier and the company is wasting valuable resources by continuing the experiment. To address this issue, the authors take an idea from clinical trials, the “alpha-spending” approach, and adapt it to their framework. Alpha-spending is one way to distribute over time the prespecified “budget” of Type 1 error (the probability of falsely detecting that a new policy is better). In the article’s real-data example, the authors test once a day for each day after one week and are able to detect a significant difference on Day 12. Waiting until Day 14 would have resulted in poorer outcomes since a suboptimal policy would be implemented half the time for two more days.</p>
<p>Overall, the framework introduced allows for handling of carryover effects, is capable of modeling treatment allocation like the switchback design, and furthermore, allows for possible early stopping. With these three features, the authors argue their approach is highly applicable to the current practice of ridesharing companies (and possibly other industries as well). For interested readers wanting to dive deeper into the methodology presented, you can check out the <a href="https://www.tandfonline.com/doi/full/10.1080/01621459.2022.2027776">full article</a>, listen to the first author discuss the material at the <a href="https://www.youtube.com/watch?v=Zor1CmRyycw">Online Causal Inference Seminar</a> (embedded below), or explore the <a href="https://github.com/callmespring/CausalRL">Python implementation</a> available on GitHub.</p>
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/Zor1CmRyycw" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-6">
<dl>
<dt>About the author</dt>
<dd>
<strong>Brian King</strong> is a PhD candidate in the Department of Statistics at Rice University and a current NSF Graduate Research Fellow, with research focused on Bayesian modeling and forecasting for time series of counts. Prior to Rice, he graduated from Baylor University with a B.S. in Mathematics and Statistics alongside a secondary major in Spanish and a minor in Computer Science.
</dd>
</dl>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>About DataScienceBites</dt>
<dd>
<a href="../../../../../../ideas/datasciencebites/index.html"><strong>DataScienceBites</strong></a> is written by graduate students and early career researchers in data science (and related subjects) at universities throughout the world, as well as industry researchers. We publish digestible, engaging summaries of interesting new pre-print and peer-reviewed publications in the data science space, with the goal of making scientific papers more accessible. Find out how to <a href="../../../../../../contributor-docs/datasciencebites.html">become a contributor</a>.
</dd>
</dl>
</div>
</div>
</div>



 ]]></description>
  <category>A/B testing</category>
  <category>Reinforcement learning</category>
  <category>Statistics</category>
  <guid>https://realworlddatascience.net/ideas/datasciencebites/posts/2022/12/13/ridesharing.html</guid>
  <pubDate>Tue, 13 Dec 2022 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/ideas/datasciencebites/posts/2022/12/13/images/paul-hanaoka-D-qq7W751vs-unsplash.jpg" medium="image" type="image/jpeg"/>
</item>
</channel>
</rss>
