<?xml version="1.0" encoding="UTF-8"?>
<rss  xmlns:atom="http://www.w3.org/2005/Atom" 
      xmlns:media="http://search.yahoo.com/mrss/" 
      xmlns:content="http://purl.org/rss/1.0/modules/content/" 
      xmlns:dc="http://purl.org/dc/elements/1.1/" 
      version="2.0">
<channel>
<title>Real World Data Science</title>
<link>https://realworlddatascience.net/latest-content.html</link>
<atom:link href="https://realworlddatascience.net/latest-content.xml" rel="self" type="application/rss+xml"/>
<description></description>
<image>
<url>https://realworlddatascience.net/images/rwds-logo-150px.png</url>
<title>Real World Data Science</title>
<link>https://realworlddatascience.net/latest-content.html</link>
<height>83</height>
<width>144</width>
</image>
<generator>quarto-1.8.27</generator>
<lastBuildDate>Tue, 27 Jan 2026 00:00:00 GMT</lastBuildDate>
<item>
  <title>Why Data Quality Is the New Competitive Edge</title>
  <link>https://realworlddatascience.net/foundation-frontiers/posts/2026/01/27/data-qual-is-competitive-edge.html</link>
  <description><![CDATA[ 





<p><em>Note that this article is based on the following paper and contains some of the same ideas: Hoerl, Roger W. 2025. <a href="https://www.tandfonline.com/doi/full/10.1080/08982112.2025.2556222">“The Future of Statistics in an AI Era.”</a> Quality Engineering, published September 10, 2025.</em></p>
<section id="introduction-discipline-of-data-science" class="level2">
<h2 class="anchored" data-anchor-id="introduction-discipline-of-data-science">Introduction: Discipline of Data Science</h2>
<p>Data science is a relatively recent field compared to the disciplines that it consists of, namely statistics and computer science. New knowledge and disciplines often arise as combinations of existing fields and data science is no exception. Born into a world with increasingly large datasets, data science combined statistical methods with the tools of computer science to analyze large amounts of data.</p>
<p>As a discipline, data science gained popularity in industry and academia in the early 2000s and in part due to an influential paper published in the Harvard Business Review <span class="citation" data-cites="davenport2012sexiest">(1)</span>. This paper carried the provocative title of “Data Scientist: The Sexist Job of the Twenty-first Century”. After its publication, universities developed data science programs, governments poured funding into Big Data initiatives and organizations built data science teams to tackle problems. Powerful machine learning algorithms such as neural nets, random forests and ensemble methods provided ways to develop complex models that could be used on these large datasets.</p>
<p>As Hoerl noted in an earlier piece <span class="citation" data-cites="hoerl2025future">(2)</span>:</p>
<blockquote class="blockquote">
<p>“There was a hiring rush for data scientists, not just in technology companies, but in virtually all sectors of the economy. For example, GE hired a new Chief Digital Officer from Oracle, Bill Ruh, in 2011. Ruh opened a new Software Center (later renamed “GE Digital”) in San Ramon, California in 2012, and by 2016 had hired 1,400 data scientists there <span class="citation" data-cites="lohr2016">(<strong>lohr2016?</strong>)</span>.”</p>
</blockquote>
</section>
<section id="current-state-of-play-with-generative-ai" class="level2">
<h2 class="anchored" data-anchor-id="current-state-of-play-with-generative-ai">Current State of Play with Generative AI</h2>
<p>While data analyses based on text data such as NLP (natural language processing) have been around for a while, a new type of approach has quickly become widespread with the rapid rise of generative AI methods. These models, known as LLMs (large language models), have entered the everyday vernacular as all organizations grapple with how to use these tools. With the debut of ChatGPT in 2023, these LLMs have become increasingly sophisticated, trained on a wider variety of data sources and optimized for a variety of different scenarios.</p>
<p>The accuracy of these models depends on the quality of the training data used. While LLMs are known to hallucinate or give inaccurate answers, they tend to perform better in situations where the training data is precise and exact, with less nuance than language often carries. As a result, LLMs can produce large amounts of computer code based on large amounts of training data based on accurate computer code. Some specialized LLMs (e.g.&nbsp;<a href="https://claude.ai/">Claude Code</a>) have been specifically designed to generate accurate code that can access, clean, combine, analyze and visualize data. While LLMs are not perfect in code generation, they can increase the efficiency of an experienced coder.</p>
<p>As a result of these LLMs, less knowledge is required to analyze and work with large datasets. A user can provide a specific prompt on the business question or research objective, upload the relevant data and have an LLM provide a relevant data analysis, complete with the underlying code used to generate that analysis.</p>
</section>
<section id="the-new-data-scientist" class="level2">
<h2 class="anchored" data-anchor-id="the-new-data-scientist">The “New” Data Scientist</h2>
<p>As LLMs improve in their ability to quickly generate vast amounts of accurate code, what does that mean for a discipline which has prided itself on its code wrangling skills? As Davenport and Patil noted “data scientists’ most basic, universal skill is the ability to write code” <span class="citation" data-cites="davenport2012sexiest">(1)</span>. Data science has seen coding as a viable career path.</p>
<p>When a skill becomes accessible to a wider variety of people and can be automated, how does one distinguish themselves in an organization? When coding can be done by AI tools, what happens to those who are known for their coding abilities? For a discipline to be recognized as a discipline, it must have some distinguishing characteristic that defines it as different from other disciplines. In addition, disciplines become more valuable and prominent as their contribution to society grows.</p>
<p>So, what are the skills that data scientists have that can’t be done well by AI? While AI capabilities are rapidly increasing, we do believe there are things that may be beyond the reach of AI for the time being.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://realworlddatascience.net/foundation-frontiers/posts/2026/01/27/images/infographic.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:80.0%"></p>
</figure>
</div>
<p>We believe that the greatest factor limiting AI is data quality. There seems to be a growing consensus of the importance of data quality as noted in Davenport, Hoerl, and Redman <span class="citation" data-cites="davenport2025unstructured">(3)</span>, Davenport and Tiwari <span class="citation" data-cites="davenport2024generative">(4)</span>, and Redman <span class="citation" data-cites="redman2020source">(5)</span> — as well as <a href="https://realworlddatascience.net/foundation-frontiers/posts/2025/10/30/data-detectives.html">recent Real World Data Science pieces</a>. As the adage goes, “garbage in, garbage out”. With poor, inaccurate data used in training, the resulting AI output will also be poor and inaccurate. A related fear is that, as AI models start to use AI generated content as a data source, a recursive loop happens that degrades the quality of any AI output <span class="citation" data-cites="shumailov2024collapse">(6)</span>.</p>
<p>Discussions of data quality are limited in books, university courses and training programs. When they do occur, they are restricted to the question of “are the data right?” and discussions of data cleaning. Data cleaning is often focused on eliminating outliers or invalid points. While there is often a reason to remove invalid points, those outliers can sometimes be the source of valuable insights.</p>
<p>However, data quality is much more than data cleaning or checking to make sure the data are accurate. There is an element of contextual understanding and process knowledge that enables the data scientist to properly prepare the data for analysis. We are skeptical of AI’s ability to fully understand context and the nuances of assumptions that go into data analysis. In an earlier piece, Jensen provided some examples of the limitations of AI when it comes to proper data cleaning <span class="citation" data-cites="jensen2024cleaning">(7)</span>. For any set of data, subject matter knowledge of how the data were collected and what they represent is crucial to a proper analysis.</p>
<p>This creates an opportunity for data scientists to become more valuable. By employing probing questions to better understand the context of the data, they will be in a better position to identify data quality issues and ways to improve the data quality, thus leading to better model output.</p>
</section>
<section id="conclusion" class="level2">
<h2 class="anchored" data-anchor-id="conclusion">Conclusion</h2>
<p>As coding becomes easier in an AI-enabled world - where anyone can code and analyze data - the skill set of a data scientist becomes less unique. Data scientists were once in high demand because they set themselves apart as coding wizards who could wrangle large datasets and extract insights. To remain successful and continue to deliver value, data scientists must now pivot their skillset. The real limiting factor in successful data science is data quality. A renewed focus on owning, improving and governing data quality will not only strengthen outcomes but also provide future job security and increase the value data scientists bring to organisations.</p>
<div class="article-btn">
<p><a href="../../../../../foundation-frontiers/index.html">Explore more data science ideas</a></p>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-12">
<dl>
<dt>About the author:</dt>
<dd>
<a href="https://www.linkedin.com/in/roger-hoerl-6b6b3a5/">Roger Hoerl</a> is Brate-Peschel Professor of Statistics at Union College, after previously heading the Applied Statistics Laboratory at <a href="https://www.ge.com/news/reports/tag/ge%20global%20research">GE Global Research</a> for many years. He has been elected to the International Statistical Institute and the International Academy for Quality, recieved numerous statistic awards, and authored five books in the areas of statistics and business improvements.
</dd>
<dd>
<a href="https://www.linkedin.com/in/willis-jensen-305bba6/">Willis Jensen</a> is data and analytics expert, currently Senior Manager of People Analytics and Business Intelligence at <a href="https://chghealthcare.com/">CHG Healthcare</a>. He is an Adjunct Professor of Statistics at Brigham Young University, <a href="https://willisjensen.substack.com/">writes on Substack</a> and is a member of the Real World Data Science <a href="https://realworlddatascience.net/the-pulse/editors-blog/posts/2022/10/18/meet-the-team.html">editorial board</a>.
</dd>
</dl>
<div class="g-col-12 g-col-md-6">
<p><strong>Copyright and licence</strong> : © 2026 Roger Hoerl and Willis Jensen<br>
<a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> <img style="height:22px!important;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"> <img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"> </a> This article is licensed under a Creative Commons Attribution 4.0 (CC BY 4.0) <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;">International licence</a>.</p>
</div>
<div class="g-col-12 g-col-md-6">
<p><strong>How to cite</strong> :<br>
Hoerl, Roger. Jensen, Willis. 2026. “<strong>Why Data Quality Is the New Competitive Edge for Data Scientists</strong>.” <em>Real World Data Science</em>, 2026. <a href="https://realworlddatascience.net/foundation-frontiers/tutorials/posts/2026/12/data-qual-is-competetive-edge.html">URL</a></p>
</div>
</div>
</div>


</div>

</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body">
<div id="ref-davenport2012sexiest" class="csl-entry">
<div class="csl-left-margin">1. </div><div class="csl-right-inline">Davenport TH, Patil DJ. Data scientist: The sexiest job of the 21st century. Harvard Business Review. 2012 Oct;70–6. </div>
</div>
<div id="ref-hoerl2025future" class="csl-entry">
<div class="csl-left-margin">2. </div><div class="csl-right-inline">Hoerl RW. <a href="https://doi.org/10.1080/08982112.2025.2556222">The future of statistics in an AI era</a>. Quality Engineering. 2025; </div>
</div>
<div id="ref-davenport2025unstructured" class="csl-entry">
<div class="csl-left-margin">3. </div><div class="csl-right-inline">Davenport TH, Hoerl RW, Redman TC. To create value with AI, improve the quality of your unstructured data. Harvard Business Review [Internet]. 2025 May; Available from: <a href="https://hbr.org/2025/05/to-create-value-with-ai-improve-the-quality-of-your-unstructured-data">https://hbr.org/2025/05/to-create-value-with-ai-improve-the-quality-of-your-unstructured-data</a></div>
</div>
<div id="ref-davenport2024generative" class="csl-entry">
<div class="csl-left-margin">4. </div><div class="csl-right-inline">Davenport TH, Tiwari P. Is your company’s data ready for generative AI? Harvard Business Review [Internet]. 2024 Mar; Available from: <a href="https://hbr.org/2024/03/is-your-companys-data-ready-for-generative-ai">https://hbr.org/2024/03/is-your-companys-data-ready-for-generative-ai</a></div>
</div>
<div id="ref-redman2020source" class="csl-entry">
<div class="csl-left-margin">5. </div><div class="csl-right-inline">Redman TC. To improve data quality, start at the source. Harvard Business Review [Internet]. 2020 Feb; Available from: <a href="https://hbr.org/2020/02/to-improve-data-quality-start-at-the-source">https://hbr.org/2020/02/to-improve-data-quality-start-at-the-source</a></div>
</div>
<div id="ref-shumailov2024collapse" class="csl-entry">
<div class="csl-left-margin">6. </div><div class="csl-right-inline">Shumailov I, Shumaylov Z, Zhao Y, Papernot N, Anderson R, Gal Y. AI models collapse when trained on recursively generated data. Nature. 2024;631(8022):755–9. </div>
</div>
<div id="ref-jensen2024cleaning" class="csl-entry">
<div class="csl-left-margin">7. </div><div class="csl-right-inline">Jensen WA. Can data cleaning be automated? [Internet]. 2024. Available from: <a href="https://willisjensen.substack.com/p/can-data-cleaning-be-automated">https://willisjensen.substack.com/p/can-data-cleaning-be-automated</a></div>
</div>
</div></section></div> ]]></description>
  <category>Data quality</category>
  <guid>https://realworlddatascience.net/foundation-frontiers/posts/2026/01/27/data-qual-is-competitive-edge.html</guid>
  <pubDate>Tue, 27 Jan 2026 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/foundation-frontiers/posts/2026/01/27/images/thumb.png" medium="image" type="image/png" height="96" width="144"/>
</item>
<item>
  <title>RWDS Big Questions: What Are the Key Challenges Facing Data Scientists Today?</title>
  <dc:creator>Annie Flynn</dc:creator>
  <link>https://realworlddatascience.net/the-pulse/posts/2026/01/21/rwds-big-questions-challenges-today.html</link>
  <description><![CDATA[ 





<p>Data science is operating in a moment of paradox. We have more data, more tools, and more computational power than ever before — yet many of the core challenges feel stubbornly human.</p>
<p>In this video, experienced practitioners from varied backgrounds reflect on what they see as the biggest obstacles facing the profession today.</p>
<p>This video is part of our thought-leadership series, RWDS Big Questions, where members of our community answer one key question in multiple ways, offering diverse perspectives from across the industry.</p>
<p>Watch the video below to hear insights that span technical, organisational, and personal dimensions. Together, they reveal a set of deeply connected themes and, importantly, opportunities for the field to mature. Scroll down for analysis and practical takeaways.</p>
<hr>
<section id="video-what-are-the-key-challenges-facing-data-scientists-today" class="level2">
<h2 class="anchored" data-anchor-id="video-what-are-the-key-challenges-facing-data-scientists-today">Video: What Are the Key Challenges Facing Data Scientists Today?</h2>
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/4WgCvhkTCiQ" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://realworlddatascience.net/the-pulse/posts/2026/01/21/images/challengesinfo1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:80.0%"></p>
</figure>
</div>
</section>
<section id="the-patterns-behind-the-problems" class="level2">
<h2 class="anchored" data-anchor-id="the-patterns-behind-the-problems">The Patterns Behind the Problems</h2>
<p>Although the challenges raised span technical, organisational, and personal domains, they are connected by a small number of deeper themes that shape modern data science.</p>
<section id="the-gap-between-capability-and-understanding" class="level3">
<h3 class="anchored" data-anchor-id="the-gap-between-capability-and-understanding">The gap between capability and understanding</h3>
<p>Across multiple perspectives, there is a recurring mismatch between what our tools can do and how well we understand their limitations. From AI systems trained on poor-quality data to models built on artificial or incomplete datasets, technical capability is often outpacing validation, interpretation, and critical scrutiny.</p>
<p>This gap widens further as advanced tools become more accessible to non-specialists, increasing the risk of confident but flawed outputs.</p>
</section>
<section id="speed-amplifies-existing-weaknesses" class="level3">
<h3 class="anchored" data-anchor-id="speed-amplifies-existing-weaknesses">Speed amplifies existing weaknesses</h3>
<p>Pressure to move quickly doesn’t create new problems so much as it magnifies existing ones. Poor data quality, weak validation, and organisational silos become far more consequential when decisions must be made rapidly.</p>
<p>The demand for instant answers leaves little room for reflection, experimentation, or uncertainty — despite these being essential to good data science.</p>
</section>
<section id="data-science-is-constrained-by-its-environment" class="level3">
<h3 class="anchored" data-anchor-id="data-science-is-constrained-by-its-environment">Data science is constrained by its environment</h3>
<p>Many of the challenges raised point away from algorithms and towards the environments in which they are deployed. Organisational readiness, digital infrastructure, and especially incentive structures strongly shape how data science is practiced and whether it creates impact.</p>
<p>When teams are rewarded for control rather than collaboration, silos persist, data sharing becomes risky, and even the most robust models struggle to influence decisions.</p>
</section>
<section id="uncertainty-is-a-constant" class="level3">
<h3 class="anchored" data-anchor-id="uncertainty-is-a-constant">Uncertainty is a constant</h3>
<p>The personal experience of data scientists mirrors these structural challenges. In a field defined by rapid change, uncertainty about where to focus, what to learn, and how to stay relevant is common.</p>
<p>This is not just a skills issue, but a signal that data science is still evolving, without a single, stable definition of what “good” looks like.</p>
</section>
</section>
<section id="looking-ahead" class="level2">
<h2 class="anchored" data-anchor-id="looking-ahead">Looking Ahead</h2>
<p>Taken together, these themes suggest that the biggest challenges in data science are not isolated problems to be solved individually. They are interconnected tensions between speed and rigour, access and expertise, innovation and organisational inertia.</p>
<p>Addressing them requires interdisciplinary, systems-level thinking.</p>
<p>Which of these challenges resonates most with your own experience in data science? How can practitioners use these tensions as inflection points to actively shape the field, rather than simply react to it?</p>
<div class="article-btn">
<p><a href="../../../../../applied-insights/index.html">Explore more data science ideas</a></p>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-12">
<dl>
<dt>About the author:</dt>
<dd>
<a href="https://www.linkedin.com/in/annieroseflynn/">Annie Flynn</a> is Head of Content at the <a href="rss.org.uk">Royal Statistical Society</a>.
</dd>
</dl>
<div class="g-col-12 g-col-md-6">
<p><strong>Copyright and licence</strong> : © 2026 Annie Flynn<br>
<a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> <img style="height:22px!important;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"> <img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"> </a> This article is licensed under a Creative Commons Attribution 4.0 (CC BY 4.0) <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;">International licence</a>.</p>
</div>
<div class="g-col-12 g-col-md-6">
<p><strong>How to cite</strong> :<br>
Flynn, Annie 2026. “<strong>RWDS Big Questions: What are the Key Challenges Facing Data Scientists Today?</strong>” <em>Real World Data Science</em>, 2026. <a href="https://realworlddatascience.net/the-pulse/posts/2026/01/rwds-big-questions-challenges-today.html">URL</a></p>
</div>
</div>
</div>


</div>
</section>

 ]]></description>
  <category>Big Questions</category>
  <category>Data science</category>
  <category>Practice</category>
  <category>Careers</category>
  <guid>https://realworlddatascience.net/the-pulse/posts/2026/01/21/rwds-big-questions-challenges-today.html</guid>
  <pubDate>Wed, 21 Jan 2026 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/the-pulse/posts/2026/01/21/images/thumb.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>Why 95% Of AI Projects Fail and How to Change the Odds</title>
  <dc:creator>Lee Clewley</dc:creator>
  <link>https://realworlddatascience.net/applied-insights/case-studies/posts/2026/01/12/why-95-percent-of-ai-projects-fail.html</link>
  <description><![CDATA[ 





<p>Artificial intelligence is now capable of performing substantive work across scientific, medical, industrial and economic domains, yet organisational experience remains uneven. Most large firms have experimented with AI; very few report material gains. MIT’s NANDA study of enterprise generative AI estimates that only 5 percent of custom tools reach production with measurable impact on profit and loss <span class="citation" data-cites="mitnanda2025">(1)</span>. Early analysis from MIT’s Iceberg project points in the same direction at task level: current systems could already support far more work than they do today, but observed use remains shallow, concentrated in a narrow set of roles and often confined to standalone ‘copilot’ tools rather than embedded in core workflows <span class="citation" data-cites="chopra2025">(2)</span>.</p>
<p>For anyone who has sat through AI vendor demonstrations, the pattern is familiar: a procession of polished prototypes that rarely change how important decisions are made. As one Chief Information Officer put it <span class="citation" data-cites="mitnanda2025">(1)</span>: ‘We’ve seen dozens of demos this year. Maybe one or two are genuinely useful. The rest are wrappers or science projects.’</p>
<p>Two caveats matter here. Many pilots are exploratory by design, so failure to reach production may not necessarily be a failure in a scientific sense. Profit based metrics also miss scientific and operational learning, which often matters more in research intensive organisations <span class="citation" data-cites="ransbotham2020">(3)</span>; <span class="citation" data-cites="bcg2024">(4)</span>; <span class="citation" data-cites="deloitte2024">(5)</span>; <span class="citation" data-cites="schlegel2023">(6)</span>. Even allowing for those points, evidence across independent surveys is remarkably consistent: most organisations struggle to turn AI model capability into repeated value, and with an estimated 95% failure rate, the question becomes: how do we change the odds? <span class="citation" data-cites="mitnanda2025">(1)</span>; <span class="citation" data-cites="ransbotham2020">(3)</span>; <span class="citation" data-cites="bcg2024">(4)</span>; <span class="citation" data-cites="deloitte2024">(5)</span>; <span class="citation" data-cites="schlegel2023">(6)</span>.</p>
<section id="three-reasons-for-failure" class="level2">
<h2 class="anchored" data-anchor-id="three-reasons-for-failure">Three Reasons for Failure</h2>
<p>There are three important reasons why so many projects fail that are often overlooked in the literature. First, the problem is often mis-specified: it is framed by technologists or vendors rather than co-owned by the domain experts who understand the decision and bear the consequences. Second, leadership expectations are frequently misaligned, short time horizons and demands for certainty collide with a technology that improves through iteration and organisational learning. Third, many deployments are brittle: they assume stability in a domain defined by rapid model change and rising user expectations, when what is needed is an engineered system designed to adapt.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://realworlddatascience.net/applied-insights/case-studies/posts/2026/01/12/images/text1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:80.0%"></p>
</figure>
</div>
<p>This article draws on two decades of work building AI systems for medicine discovery at GSK <span class="citation" data-cites="gskjules2024">(7)</span> and at Tangram <span class="citation" data-cites="tangram2025">(8)</span> to argue that success rests on three principles, in roughly this order:</p>
<ul>
<li>integrated subject matter expertise;</li>
<li>patient and informed executive leadership;</li>
<li>and building AI systems that learn with the organisation.</li>
</ul>
<p>The sections that follow develop each element in the context of drug discovery and show how an AI platform can help move real projects into the small minority that deliver value.</p>
</section>
<section id="essential-contexts-outside-our-focus" class="level2">
<h2 class="anchored" data-anchor-id="essential-contexts-outside-our-focus">Essential Contexts Outside Our Focus</h2>
<p>Before turning to the three principles developed below, it is worth acknowledging four adjacent domains that I will not treat in detail here, each of which now has a substantial literature of its own. First, organisational scholars have long shown that new information systems reshape power, status and discretion, making the politics of implementation as important as the technology itself <span class="citation" data-cites="markus1983">(9)</span>; <span class="citation" data-cites="orlikowski1992">(10)</span>. Second, governance, regulation and responsible AI practice which includes everything from model documentation and auditability to privacy, robustness and safety, have become central determinants of what can be deployed in practice, especially in regulated sectors <span class="citation" data-cites="paleyes2022">(11)</span>; <span class="citation" data-cites="ey2025">(12)</span>; <span class="citation" data-cites="capgemini2024">(13)</span>. Third, there is an emerging body of work on workforce transformation: how AI complements or displaces skills, how hybrid human–AI roles are designed, and how training, trust and professional bodies mediate adoption <span class="citation" data-cites="chopra2025">(2)</span>; <span class="citation" data-cites="ransbotham2020">(3)</span>; <span class="citation" data-cites="bcg2024">(4)</span>; <span class="citation" data-cites="deloitte2024">(5)</span>. Finally, the question of how to measure value and learn at portfolio scale with existing legacy IT systems (through experimentation, counterfactuals and disciplined comparisons between use cases) is itself a rich field that extends well beyond any single organisation. <span class="citation" data-cites="ransbotham2020">(3)</span>; <span class="citation" data-cites="bcg2024">(4)</span>; <span class="citation" data-cites="deloitte2024">(5)</span>; <span class="citation" data-cites="schlegel2023">(6)</span>; <span class="citation" data-cites="davenport2018">(14)</span>. Each of these strands is critical to understanding why AI succeeds, stalls or remains at a proof-of-concept level.</p>
<p>To maintain focus, I concentrate on three overlooked questions arising from direct experience: how to organise subject matter expertise such that the enterprise owns its AI; how to cultivate genuine leadership ownership; and how to engineer systems that learn and adapt rather than remain isolated demonstrations.</p>
</section>
<section id="principle-1-the-importance-of-building-with-subject-matter-experts" class="level2">
<h2 class="anchored" data-anchor-id="principle-1-the-importance-of-building-with-subject-matter-experts">Principle 1: The importance of building with subject matter experts</h2>
<p>The hardest part of building an AI platform is not the models or the engineers but assembling the subject matter experts (SMEs) who will frame and judge the work. Most commentary treats SMEs as validators, brought in at the end to bless a prototype. It rarely explains how to organise a molecular biologist, a clinician and a chemist so that they can state, in plain terms, what counts as an acceptable outcome.</p>
<p>Most commentators are not operators. They observe patterns across organisations but do not live with the consequences of poor SME integration. This distance between writing and practice shows up in the surveys. Foundry’s 2024 State of the CIO, summarised in MIT Sloan Management Review, reports that 85% of IT leaders see the CIO role as a driver of change, yet only 28% list leading transformation as their top priority <span class="citation" data-cites="foundry2024">(15)</span>]. The people commenting on AI often sit with strategy decks rather than with the unglamorous work of managing technological change and cross-functional coordination.</p>
<p>Drug discovery starkly exposes the gap. The relevant team is wide and requires exceptional coordination. Business and portfolio leaders understand how projects absorb capital and create value whereas molecular biologists and geneticists judge whether a gene is plausibly causal for a disease. Clinicians think through trial design and patient risk. Chemists know what can be made and delivered. Statisticians, AI engineers and data scientists understand models, data pipelines, experimental design and evaluation. This diversity is a strength but requires a lot more from leaders of such teams. When these groups work as separate silos, the result is a generic set of tools whose outputs are not trusted by the users and whose inputs are irrelevant. When these experts can operate as a single team, the conversation starts with a simple set of questions. Which decisions are we trying to improve? How will we know if we have succeeded? What data and statistical methods count as acceptable evidence? Which risks are we prepared to take and which are not negotiable?</p>
<p>At Tangram, that joint framing often collapses into one critical choice: which disease do we want to target for drug development, and which gene is driving it? That decision already embeds genetics, hepatocyte biology, chemistry, clinical feasibility and commercial context. The role of AI and engineering is then precise. It is to help the group search the vast hypothesis space, structure the evidence and quantify uncertainty, while leaving the final judgement with experts who feel they own the AI platform, can see why the AI has come to the conclusions it has, and also own the consequences.</p>
</section>
<section id="principle-2-patient-and-strategic-executive-leadership." class="level2">
<h2 class="anchored" data-anchor-id="principle-2-patient-and-strategic-executive-leadership.">Principle 2: Patient and strategic executive leadership.</h2>
<p>The second element is executive patience. Research from MIT Sloan shows that firms gaining value from AI tend to run more projects, over more years, with a sustained focus on learning how people and AI work together. <span class="citation" data-cites="ransbotham2020">(3)</span> Leaders in these organisations accept that early returns are small and uneven. They invest in a pipeline of use cases rather than a single bet. They resist what researchers have called the “last mile problem”: AI projects that reach technical proof of concept but never change how work is done. <span class="citation" data-cites="davenport2018">(14)</span> In life sciences this is acute. Discovery timelines are long, data are messy and early signals are faint. Leaders who expect quick, clean returns tend to cycle through pilots without ever building an asset that scientists trust.</p>
<p>Patience does not mean passivity; actually, the opposite is true. It means choosing a small number of important decisions, funding cross-functional teams to attack them, and holding the bar for quality high. It requires senior sponsorship to unblock data access, align incentives across discovery, clinical and commercial groups, and shield long term work from quarterly fashion cycles. When those conditions are in place, AI stops being a sequence of demonstrations and starts to become part of how the organisation thinks: the informed leader knows the difference.</p>
</section>
<section id="principle-3-building-ai-systems-that-learn-with-the-organisation" class="level2">
<h2 class="anchored" data-anchor-id="principle-3-building-ai-systems-that-learn-with-the-organisation">Principle 3: Building AI Systems that learn with the organisation</h2>
<p>The third element is the AI engineering. The MIT findings on the 95 percent figure are instructive: most generative AI projects fail not because the models are weak but because the systems around them are brittle. <span class="citation" data-cites="mitnanda2025">(1)</span>; <span class="citation" data-cites="paleyes2022">(11)</span> Foundation models are dropped into existing workflows with minimal adaptation. There is limited monitoring. Data quality is assumed rather than measured. When something breaks (as it inevitably will in non-deterministic systems) teams revert to manual work.</p>
<p>Modern AI engineering starts from the opposite assumption. Models and tools will change quickly. The surrounding stack must absorb that change without being rebuilt each time. The strategy must be built so that, when the product director hears a new technology is built or an LLM improved, this is always a good day.</p>
<p><strong>Build only what you must.</strong></p>
<p>The sensible principle is to only build the components where your domain expertise creates defensible value. Everything else should be bought. But buying is not effortless. Integration, monitoring, and vendor management drains teams unless you are staffed for it. Organisations that succeed at scale partner with vendors offering systems that learn and adapt; they focus on workflow integration; they deploy tools where process alignment is easiest.</p>
<p>So assuming you have the right staff who are working together, supportive leaders and good vendor relationships the next problem is how to create a platform itself.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://realworlddatascience.net/applied-insights/case-studies/posts/2026/01/12/images/text2.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:80.0%"></p>
</figure>
</div>
<p><strong>A useful pattern for a modern AI platform has four parts:</strong></p>
<ul>
<li><strong>First, the data stack.</strong> Discovery teams need a small number of trusted stores for data with clear provenance and at least basic quality checks. For early target selection this means human genetics, expression data, interaction networks, preclinical phenotypes, clinical outcomes and internal experiments. Traceability and reproducibility is critical here. Any claim a model makes about a gene and disease pair should be traceable back to specific pieces of evidence.</li>
<li><strong>Second, the platform needs to be built on modular services rather than monoliths.</strong> Each service has a single responsibility and can be swapped when a better service appears. This keeps the cost of change low and allows teams to combine external tools with internal components in a controlled way.</li>
<li><strong>Third, the system needs to have continuous evaluation.</strong> Every component that answers questions is tested on held-out tasks, with simple metrics for accuracy, faithfulness, and recall, and monitored continually. There should be repeat measures and other tests of robustness. <span class="citation" data-cites="bolton2024">(16)</span> There is no reason not to report error bars in AI and yet they are rarely part of AI publications. Where this matters most is at the interface with non-determinism, inherent in large language models. A good medical AI assistant should give consistent answers even when questions are phrased differently. It should also say it does not know when the information is unclear or incomplete. <span class="citation" data-cites="bolton2024">(16)</span>; <span class="citation" data-cites="ji2023">(17)</span>; <span class="citation" data-cites="gskrambla2024">(18)</span></li>
<li><strong>Fourth, include memory and reinforcement learning so that the system learns.</strong> This is the most difficult component to implement and the one most often deferred. A system that cannot learn from use will make the same mistake repeatedly. Even the most patient users will lose trust and patience. But building memory into production systems, where the model retains context across sessions and improves from feedback, requires specialist expertise in reinforcement learning, retrieval-augmented generation with persistent stores, and the infrastructure to support online learning without catastrophic forgetting <span class="citation" data-cites="ouyang2022">(19)</span>. These skills are in high demand and short supply. The alternative is a system that feels potentially useful in demonstrations but frustrates users in daily work.</li>
</ul>
<p>For this to work, engineering teams need to stay in constant contact with biologists, geneticists, clinicians, chemists and portfolio managers. Together they decide what error rate is acceptable for a triage tool, what form of uncertainty estimate a portfolio board will respect and where human review is mandatory, for example before a new target enters serious preclinical work. Work on human–AI interaction design reinforces this point: systems should explain what they can and cannot do, expose their confidence and make it easy for users to correct them. The hardest part is that the first version is almost never right. Cross-functional teams need patience and ownership. They contribute real examples, refine prompts and evaluation sets, and expect the system to learn from its mistakes. The AI platform must be useful enough, early enough, that experts are willing to spend scarce attention improving it.</p>
</section>
<section id="a-worked-example-target-indication-pairing-in-sirna" class="level2">
<h2 class="anchored" data-anchor-id="a-worked-example-target-indication-pairing-in-sirna">A worked example: target-indication pairing in siRNA</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://realworlddatascience.net/applied-insights/case-studies/posts/2026/01/12/images/illu.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:80.0%"></p>
</figure>
</div>
<p>At Tangram we built LLibra OS, an internal system designed to surface and assess new small interfering RNA targets <span class="citation" data-cites="tangram2025">(8)</span>. siRNA refers to short double-stranded RNA molecules that can silence a specific gene via the RNA interference pathway. The purpose is narrow: the AI needs to help scientists identify medicines worth taking forward.</p>
<p>In early discovery, hypothesis generation often reduces to a single question: which target and disease pair should we move into the siRNA pipeline? The question sounds simple. It is not.</p>
<p>A purely data-driven approach can surface millions of candidates. Genome-wide association, expression atlases, and protein interaction networks will produce statistical associations at scale. But association is not mechanism. Two things can correlate because they share upstream causes, because they sit in the same pathway without being rate-limiting, or because of confounding in the data.</p>
<p>Plausibility requires a different kind of evidence. If we modulate this target, what functional change should we observe at the cellular or tissue level? Does that functional phenotype connect credibly to the disease we care about? For our purposes, the chain of reasoning must pass through liver biology: does knockdown of this gene alter a measurable secretory or metabolic function, and does that function relate to the clinical phenotype we wish to treat? Is there a real unmet need for your research for patients? <span class="citation" data-cites="crooke2021">(20)</span></p>
<p>The AI assists in answering these questions. It helps the team hold multiple threads of conditional evidence in view simultaneously. It retrieves, reasons and summarises over tens of millions of papers in the literature, joins and flags inconsistencies between thousands of data sources and quantifies uncertainty where the evidence is thin. Whilst the AI platform does the work of thousands of researchers and continually learns on the job, the expert judgement remains with the SMEs. The SME is central and is given all the reasons why and how the AI found a piece of evidence. The AI structures and expands the space in which that judgement operates. When it works well the AI platform uncovers the non-obvious connections that researchers may never have found.</p>
</section>
<section id="conclusions" class="level2">
<h2 class="anchored" data-anchor-id="conclusions">Conclusions</h2>
<p>Seen from this angle, the 95 percent figure is not a verdict on AI technology but a statistic about organisational design: how rarely good questions, high quality data, diverse experts and committed leaders are brought together at the same time. The systems described in this essay matter, but they are secondary. The primary determinant of value is whether biologists, clinicians, chemists, data scientists and portfolio leaders sit together, own the same objectives and are backed by executives willing to invest over years rather than quarters. Where that integrated team is absent, even elegant architectures will fail. Where they are present, imperfect tools still move the needle.</p>
<p>Much commentary on AI spends its energy on model choice, technical detail and tooling. This article has argued that the more important work is organisational: deciding which decisions to improve, agreeing what counts as acceptable evidence, and creating cross-functional teams that can live with the consequences. The few organisations that succeed treat AI as an experiment in decision making rather than a procurement exercise. They expect the stack to change and the vendors to turn over, but they hold fast to the team, the questions and the discipline.</p>
<p>For Real World Data Science readers, the implication is direct. AI projects fail when nobody owns the estimand, the counterfactual and the error bars. AI doesn’t need to be perfect, but it needs to be good enough. As the statistician George E. P. Box famously observed: “All models are wrong, but some are useful”. Usefulness here depends on design, discipline and humility as much as model choice. Statisticians, data scientists and methodologists can reclaim the narrative by insisting not only that every AI project begins with a clear question, a credible experiment and a plan to learn, but also that these are held collectively by an integrated team with visible executive backing. That is how more organisations move into the 5 percent.</p>
<div class="article-btn">
<p><a href="../../../../../../applied-insights/index.html">Explore more data science ideas</a></p>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-12">
<dl>
<dt>About the author:</dt>
<dd>
<a href="https://www.linkedin.com/in/lee-clewley-988bbb18/">Lee Clewley (PhD)</a> is VP of Applied AI &amp; Informatics at <a href="https://tangramtx.com/">Tangram Therapeutics</a>, where he led the design and deployment of LLibra, a multi-LLM, agentic system for early discovery. Formerly Head of Applied AI at <a href="https://www.gsk.com/en-gb/">GSK</a>, he is a member of the Real World Data Science <a href="https://realworlddatascience.net/the-pulse/editors-blog/posts/2022/10/18/meet-the-team.html">editorial board</a>.
</dd>
</dl>
<div class="g-col-12 g-col-md-6">
<p><strong>Copyright and licence</strong> : © 2026 Lee Clewley<br>
<a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> <img style="height:22px!important;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"> <img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"> </a> This article is licensed under a Creative Commons Attribution 4.0 (CC BY 4.0) <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;">International licence</a>.</p>
</div>
<div class="g-col-12 g-col-md-6">
<p><strong>How to cite</strong> :<br>
Clewley, Lee. 2026. “<strong>Why 95% Of AI Projects Fail and How to Change the Odds</strong>.” <em>Real World Data Science</em>, 2026. <a href="https://realworlddatascience.net/applied-insights/tutorials/posts/2026/12/why-95-percent-of-ai-projects-fail.html">URL</a></p>
</div>
</div>
</div>


</div>

</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body">
<div id="ref-mitnanda2025" class="csl-entry">
<div class="csl-left-margin">1. </div><div class="csl-right-inline">MIT NANDA. The GenAI divide: State of AI in business 2025. Massachusetts Institute of Technology; 2025. </div>
</div>
<div id="ref-chopra2025" class="csl-entry">
<div class="csl-left-margin">2. </div><div class="csl-right-inline">Chopra A et al. Measuring skills-centered exposure in the AI economy. MIT Project Iceberg; Oak Ridge National Laboratory; 2025. </div>
</div>
<div id="ref-ransbotham2020" class="csl-entry">
<div class="csl-left-margin">3. </div><div class="csl-right-inline">Ransbotham S, Khodabandeh S, Kiron D, Candelon F, Chu M, LaFountain B. Expanding AI’s impact with organizational learning. MIT Sloan Management Review. 2020; </div>
</div>
<div id="ref-bcg2024" class="csl-entry">
<div class="csl-left-margin">4. </div><div class="csl-right-inline">Bellefonds N de et al. Where’s the value in AI? Boston Consulting Group; 2024. </div>
</div>
<div id="ref-deloitte2024" class="csl-entry">
<div class="csl-left-margin">5. </div><div class="csl-right-inline">Deloitte AI Institute. The state of generative AI in the enterprise: Now decides next. Deloitte; 2024. </div>
</div>
<div id="ref-schlegel2023" class="csl-entry">
<div class="csl-left-margin">6. </div><div class="csl-right-inline">Schlegel D, Schuler K, Westenberger J. Failure factors of AI projects: Results from expert interviews. International Journal of Information Systems and Project Management. 2023;11(3):25–40. </div>
</div>
<div id="ref-gskjules2024" class="csl-entry">
<div class="csl-left-margin">7. </div><div class="csl-right-inline">GSK.ai. JulesOS: GSK’s agent-based operating system [Internet]. 2024. Available from: <a href="https://www.gsk.ai">https://www.gsk.ai</a></div>
</div>
<div id="ref-tangram2025" class="csl-entry">
<div class="csl-left-margin">8. </div><div class="csl-right-inline">Tangram Therapeutics. LLibra OS: Identifying the right targets. 2025. </div>
</div>
<div id="ref-markus1983" class="csl-entry">
<div class="csl-left-margin">9. </div><div class="csl-right-inline">Markus ML. Power, politics, and MIS implementation. Communications of the ACM. 1983;26(6):430–44. </div>
</div>
<div id="ref-orlikowski1992" class="csl-entry">
<div class="csl-left-margin">10. </div><div class="csl-right-inline">Orlikowski WJ. The duality of technology: Rethinking the concept of technology in organizations. Organization Science. 1992;3(3):398–427. </div>
</div>
<div id="ref-paleyes2022" class="csl-entry">
<div class="csl-left-margin">11. </div><div class="csl-right-inline">Paleyes A, Urma RG, Lawrence ND. Challenges in deploying machine learning: A survey of case studies. ACM Computing Surveys. 2022;55(6). </div>
</div>
<div id="ref-ey2025" class="csl-entry">
<div class="csl-left-margin">12. </div><div class="csl-right-inline">EY. How responsible AI translates investment into impact. Ernst<br>
&amp; Young; 2025. </div>
</div>
<div id="ref-capgemini2024" class="csl-entry">
<div class="csl-left-margin">13. </div><div class="csl-right-inline">Capgemini Research Institute. Generative AI in organizations 2024. Capgemini; 2024. </div>
</div>
<div id="ref-davenport2018" class="csl-entry">
<div class="csl-left-margin">14. </div><div class="csl-right-inline">Davenport TH, Ronanki R. Artificial intelligence for the real world. Harvard Business Review. 2018;96(1):108–16. </div>
</div>
<div id="ref-foundry2024" class="csl-entry">
<div class="csl-left-margin">15. </div><div class="csl-right-inline">Foundry. State of the CIO survey 2024. Foundry; 2024. </div>
</div>
<div id="ref-bolton2024" class="csl-entry">
<div class="csl-left-margin">16. </div><div class="csl-right-inline">Bolton WJ, Poyiadzi R, Morrell ER, Bergen Gonzalez Bueno G van, Goetz L. RAmBLA: A framework for evaluating the reliability of LLMs as assistants in the biomedical domain. arXiv preprint. 2024; </div>
</div>
<div id="ref-ji2023" class="csl-entry">
<div class="csl-left-margin">17. </div><div class="csl-right-inline">Ji Z, Lee N, Frieske R, et al. Survey of hallucination in natural language generation. ACM Computing Surveys. 2023;55(12). </div>
</div>
<div id="ref-gskrambla2024" class="csl-entry">
<div class="csl-left-margin">18. </div><div class="csl-right-inline">GSK.ai. RAmBLA: Evaluating the reliability of LLMs as biomedical assistants. 2024. </div>
</div>
<div id="ref-ouyang2022" class="csl-entry">
<div class="csl-left-margin">19. </div><div class="csl-right-inline">Ouyang L, Wu J, Jiang X, et al. Training language models to follow instructions with human feedback. In: Advances in neural information processing systems. 2022. p. 27730–44. </div>
</div>
<div id="ref-crooke2021" class="csl-entry">
<div class="csl-left-margin">20. </div><div class="csl-right-inline">Crooke ST, Liang XH, Baker BF, Crooke RM. Antisense technology: A review. Journal of Biological Chemistry. 2021;296:100416. </div>
</div>
</div></section></div> ]]></description>
  <category>Viewpoints</category>
  <category>AI</category>
  <guid>https://realworlddatascience.net/applied-insights/case-studies/posts/2026/01/12/why-95-percent-of-ai-projects-fail.html</guid>
  <pubDate>Mon, 12 Jan 2026 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/applied-insights/case-studies/posts/2026/01/12/images/thumb95.png" medium="image" type="image/png" height="96" width="144"/>
</item>
<item>
  <title>Deploying LLMs for Nonprofits: 10 Lessons from Knowbot</title>
  <dc:creator>Annie Flynn</dc:creator>
  <link>https://realworlddatascience.net/applied-insights/case-studies/posts/2025/12/17/deploying_llms_nonprofits.html</link>
  <description><![CDATA[ 





<p>*Based on <a href="https://realworlddatascience.net/foundation-frontiers/posts/2025/11/27/MHF-interview.html">our conversation</a> with <a href="https://www.mikehudsonfoundation.org/">Mike Hudson</a>, Founder of <a href="https://www.mikehudsonfoundation.org">MHF</a>, <a href="https://www.knowbot.uk/">Knowbot</a> and <a href="https://www.testramp.org/">TestRAMP.</a></p>
<p>Large language models (LLMs) are a form of generative artificial intelligence (AI) that offer transformative opportunities for organisations with complex information ecosystems. But deploying them responsibly requires technical pragmatism, cultural awareness, and a respect for context.</p>
<p>Specialist AI donor the <a href="https://www.mikehudsonfoundation.org/">Mike Hudson Foundation</a> has developed an LLM-powered ‘answer engine’ that sits on websites and answers users’ questions. Our recent conversation with MHF’s Foundersurfaced some valuable insights for data science practitioners working in this sphere.</p>
<section id="start-with-the-simplest-possible-use-case" class="level2">
<h2 class="anchored" data-anchor-id="start-with-the-simplest-possible-use-case">1. Start With the Simplest Possible Use Case</h2>
<p>One of Knowbot’s core design principles was <em>minimal friction</em>. MHF looked for a “gateway use case”: a low-risk, easy-to-understand tool that organisations could immediately see value in and adopt quickly.</p>
<p><strong>Practitioner takeaway:</strong> Don’t begin with the most ambitious AI project your organisation can imagine. Begin with an easy, low risk project that still delivers value and treat it as a learning experience..</p>
</section>
<section id="culture-matters-more-than-budget" class="level2">
<h2 class="anchored" data-anchor-id="culture-matters-more-than-budget">2. Culture Matters More Than Budget</h2>
<p>Hudson notes that AI readiness among nonprofits varies widely and isn’t correlated with organisational size. Some large charities are slow to innovate due to bureaucracy; some small ones are enthusiastic but unlikely to benefit.</p>
<p><strong>Practitioner takeaway:</strong> When planning an LLM deployment, assess <em>cultural readiness</em>, not just technical readiness. Ask:</p>
<ul>
<li><p>Who are the internal champions?</p></li>
<li><p>How much AI literacy exists?</p></li>
<li><p>How cautious is the organisation by default?</p></li>
</ul>
<p>This will drive adoption far more than infrastructure.</p>
</section>
<section id="build-for-trust-first-then-functionality" class="level2">
<h2 class="anchored" data-anchor-id="build-for-trust-first-then-functionality">3. Build for Trust First, Then Functionality</h2>
<p>The biggest obstacle MHF faced wasn’t the model, the infrastructure, or the code. It was <em>accessing the right decision-makers</em> and establishing trust with LLMs in general and Knowbot in particular.</p>
<p><strong>Practitioner takeaway:</strong> AI deployments in nonprofits are trust projects as much as technical ones. Practitioners should:</p>
<ul>
<li><p>Engage early with leadership.</p></li>
<li><p>Be explicit about risks and mitigations.</p></li>
<li><p>Provide clear, responsible documentation.</p></li>
<li><p>Avoid overclaiming what the model can do.</p></li>
</ul>
<p>The more transparent the process, the smoother the adoption.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://realworlddatascience.net/applied-insights/case-studies/posts/2025/12/17/images/LLM2.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:80.0%"></p>
</figure>
</div>
</section>
<section id="where-appropriate-restrict-the-models-knowledge-domain-to-reduce-risk" class="level2">
<h2 class="anchored" data-anchor-id="where-appropriate-restrict-the-models-knowledge-domain-to-reduce-risk">4. Where Appropriate, Restrict the Model’s Knowledge Domain to Reduce Risk</h2>
<p>Knowbot deliberately confines itself to the content on the host organisation’s website(s), plus general internal LLM knowledge. It doesn’t trawl the open internet. This dramatically limits opportunities for hallucinations, unsafe advice, or reputational risk.</p>
<p><strong>Practitioner takeaway:</strong> Whenever possible, design LLM answer engine systems that operate on <em>curated, organisation-owned content</em>. Domain restriction is one of the most effective forms of practical AI safety.</p>
</section>
<section id="expect-surprising-user-behaviour-and-design-for-it" class="level2">
<h2 class="anchored" data-anchor-id="expect-surprising-user-behaviour-and-design-for-it">5. Expect Surprising User Behaviour — And Design for It</h2>
<p>One of the unexpected patterns in early usage: people asked Knowbot, <em>“Who are you?”</em> This required the team to add a new prompt component and require every partner to host a <em>“What is Knowbot?”</em> page.</p>
<p><strong>Practitioner takeaway:</strong> Build processes for:</p>
<ul>
<li><p>Unexpected inputs</p></li>
<li><p>Prompt evolution</p></li>
<li><p>Iterative refinement</p></li>
</ul>
<p>LLM deployment is never “set and forget.”</p>
</section>
<section id="technological-timing-matters-and-keeps-improving" class="level2">
<h2 class="anchored" data-anchor-id="technological-timing-matters-and-keeps-improving">6. Technological Timing Matters — And Keeps Improving</h2>
<p>Hudson emphasised that many capabilities now considered standard (e.g.&nbsp;long context length, ring fenced access to specific types of knowledge, server deployment ease) would have been impossible even a year earlier. The tools needed to fulfil a nonprofit’s evolving needs often appear in the LLM ecosystem soon after the nonprofit requests new functionality - making the decision whether to ‘build custom’ or ‘wait’ a tricky one.</p>
<p><strong>Practitioner takeaway:</strong> Stay current. Model capabilities, guardrails, and hosting options evolve at high speed. What was impossible last quarter may be trivial today.</p>
</section>
<section id="value-impact-over-volume" class="level2">
<h2 class="anchored" data-anchor-id="value-impact-over-volume">7. Value Impact Over Volume</h2>
<p>Knowbot’s LLM processing costs MHF money, and soKnowbot’s team evaluates success not just by the number of questions answered but by the <em>relevance</em> of those questions to valuable decision-making. A tool that helps a policymaker or researcher retrieve something critical can have outsized impact.</p>
<p><strong>Practitioner takeaway:</strong>When measuring impact, develop metrics that capture qualitative value, not just quantitative usage. For example you might consider:</p>
<ul>
<li><p>Complexity of queries</p></li>
<li><p>Decision relevance</p></li>
<li><p>Equity of access</p></li>
<li><p>Whether the tool reduces burden on staff</p></li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://realworlddatascience.net/applied-insights/case-studies/posts/2025/12/17/images/LLM3.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:80.0%"></p>
</figure>
</div>
</section>
<section id="in-fast-moving-environments-admit-what-you-dont-know" class="level2">
<h2 class="anchored" data-anchor-id="in-fast-moving-environments-admit-what-you-dont-know">8. In Fast-Moving Environments, Admit What You Don’t Know</h2>
<p>Both Knowbot and TestRAMP were built in contexts where knowledge was changing daily. Hudson emphasises the importance of asking “naïve” questions, learning quickly, and not pretending expertise where there is none.</p>
<p><strong>Practitioner takeaway:</strong> Cultivate humility. Curiosity and fast learning beats early certainty. Pair technical exploration with organisational openness about unknowns.</p>
</section>
<section id="relationships-and-partnerships-are-everything" class="level2">
<h2 class="anchored" data-anchor-id="relationships-and-partnerships-are-everything">9. Relationships and Partnerships Are Everything</h2>
<p>Across both initiatives, success depended less on algorithms and more on building new human relationships.</p>
<p><strong>Practitioner takeaway: </strong>AI for public good is a team sport. Map stakeholders. Share progress transparently. Community buy-in creates technical resilience.</p>
</section>
<section id="the-next-frontier-agentic-ai" class="level2">
<h2 class="anchored" data-anchor-id="the-next-frontier-agentic-ai">10. The Next Frontier: Agentic AI</h2>
<p>Hudson argues we’re at a turning point where AI will expand from being “retrieval engines” to becoming “agentic systems that can do things.” With that shift comes both opportunity and new categories of risk.</p>
<p><strong>Practitioner takeaway:</strong> Prepare now for agentic systems. Start with controlled automation, clear constraints, auditable logs, and robust governance. Retrieval is only the beginning.</p>
<p><a href="https://realworlddatascience.net/foundation-frontiers/posts/2025/11/27/MHF-interview.html">Read our full conversation with Mike Hudson here.</a></p>
<p><a href="https://www.mikehudsonfoundation.org/">Find out more about the Mike Hudson Foundation here.</a></p>
<p><em>Mike Hudson is an entrepreneur in technology &amp; electronic markets. He now uses his expertise to help solve social problems. Mike founded TestRAMP, a pandemic nonprofit social market described as a “major contribution to Covid PCR testing &amp; genomic sequencing” &amp; donated its £2.4mn profits for charity. Mike is a Fellow of ZSL &amp; adviser to its CEO. He is an honorary Research Fellow at City, University of London. Mike is a member of the Responsible AI Institute. He is a Foundation Fellow at St Antony’s College, University of Oxford.</em></p>
<div class="article-btn">
<p><a href="../../../../../../applied-insights/index.html">Explore more data science ideas</a></p>
</div>


</section>

 ]]></description>
  <guid>https://realworlddatascience.net/applied-insights/case-studies/posts/2025/12/17/deploying_llms_nonprofits.html</guid>
  <pubDate>Wed, 17 Dec 2025 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/applied-insights/case-studies/posts/2025/12/17/images/LLMthumb.png" medium="image" type="image/png" height="96" width="144"/>
</item>
<item>
  <title>​Testing Multi-Agent Systems in the LLM Age: A Practical Guide for Data Scientists</title>
  <dc:creator>Peter Capsalis</dc:creator>
  <link>https://realworlddatascience.net/applied-insights/tutorials/posts/2025/12/12/MAS-guide.html</link>
  <description><![CDATA[ 





<p>Agentic AI has gained recent popularity with the emergence of Large-Language Models (LLMs) and the rapid growth of the AI technology sector. The reinvention of technology companies entering the ‘agentic age’ mirrors a profound shift in how people interact with technology. In this article, I share a structured approach for testing Multi-Agent Systems (MAS) and provide some key questions to start you thinking critically about how your systems may be working.</p>
<section id="history-and-background-defining-mas" class="level2">
<h2 class="anchored" data-anchor-id="history-and-background-defining-mas">History and Background: Defining MAS</h2>
<p>There has been more than 30 years of research into intelligent agents. Traditionally, Multi-Agent Systems (MAS) referred to collections of autonomous software agents that could communicate, coordinate, and collaborate to solve complex tasks, often in domains like robotics, logistics, or distributed control systems.</p>
</section>
<section id="the-mas-llm-shift" class="level2">
<h2 class="anchored" data-anchor-id="the-mas-llm-shift">The MAS + LLM Shift</h2>
<p>What’s new today is the emergence of LLM-powered agents, where each agent is a Large Language Model (or a wrapper around one) capable of generating language, and calling external tools. This shift marks a new phase: MAS + LLM, where agents are not just rule-based or symbolic, but generative and language-driven.</p>
<p>​This distinction is crucial:</p>
<ul>
<li><p>Traditional MAS Example (Rule-Based): A fleet of warehouse robots coordinate to move packages using pre-programmed rules and message-passing protocols.</p></li>
<li><p>MAS + LLM Example (Generative &amp; Tool-Enabled): That same warehouse might now use a set of LLM agents to plan a delivery route, query traffic data via APIs, and negotiate with each other in natural language to optimise timing, all while calling tools like maps, databases, and calculators.</p></li>
</ul>
<p>This new architecture introduces challenges and opportunities: LLM agents can be more flexible and adaptive, but also more prone to errors like hallucinations or inconsistent tool usage.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://realworlddatascience.net/applied-insights/tutorials/posts/2025/12/12/images/MAS.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:80.0%"></p>
</figure>
</div>
</section>
<section id="data-scientists-and-mas-a-new-mandate" class="level2">
<h2 class="anchored" data-anchor-id="data-scientists-and-mas-a-new-mandate">Data Scientists and MAS: A New Mandate</h2>
<p>​In traditional ML workflows, Data Scientists might train models and deploy them behind APIs for consumption by other services. In MAS + LLM setups, those models become tools that LLM agents can call as part of a broader reasoning process. Data Scientists may now be involved in designing these tools, defining agent roles, and testing how agents interact.</p>
<p>​Imagine, for example, that a Data Scientist is training a sentiment analysis model. Instead of embedding it in a web app, they expose it as a tool. A “Customer Feedback Agent” (LLM) calls this tool to analyse reviews, then passes results to a “Product Strategy Agent” to decide next steps. This new mandate means Data Scientists are uniquely positioned to ensure the reliability and responsible deployment of agentic systems by rigorously testing the individual tools and the complex communication logic.</p>
<p>​When using MAS + LLM, it is essential that Data Scientists ask the right questions to assess how well a system performs on a given task. Below is a proposed framework, based on established software testing hierarchies, adapted for MAS + LLM architectures:</p>
</section>
<section id="a-four-level-testing-approach" class="level2">
<h2 class="anchored" data-anchor-id="a-four-level-testing-approach">​A Four-Level Testing Approach</h2>
<section id="unit-level-checks-determinism-and-reproducibility" class="level3">
<h3 class="anchored" data-anchor-id="unit-level-checks-determinism-and-reproducibility">​1. Unit-Level Checks: Determinism and Reproducibility</h3>
<p>​These tests assess whether individual agents behave consistently when given identical inputs. This is foundational for debugging and validation.</p>
<p><strong>​Check</strong>: Does the agent produce the same output when given the same prompt?</p>
<p>Example: Recipe Planner Agent. A “Recipe Planner Agent” is asked: “Plan a healthy lunch under 500 calories.” If the response varies significantly each time, the agent may be hallucinating or poorly grounded.</p>
<p><strong>Check</strong>: Does the agent consistently call the same tool when prompted?</p>
<p>Example: Currency Conversion Tool.An agent is asked to convert $100 USD to GBP. Check: Does the agent consistently call the convert_currency(amount, from, to) tool with the correct parameters, and is the output reliably parsed?</p>
</section>
<section id="unit-integration-context-management-and-grounding" class="level3">
<h3 class="anchored" data-anchor-id="unit-integration-context-management-and-grounding">​2. Unit + Integration: Context Management and Grounding</h3>
<p>​These tests examine how well agents manage context and avoid hallucinations by properly utilizing their tools. Failures here often stem from insufficient or poorly structured information.</p>
<p><strong>​Check</strong>: Does the agent hallucinate outputs instead of calling tools?</p>
<p>​Example: Weather Forecast Agent. Prompt: “What’s the weather in London tomorrow?” If the agent guesses instead of calling the weather API, it may lack grounding or tool clarity.</p>
<p><strong>​Check</strong>: Does the agent fail due to context length limits?</p>
<p><strong>​Check</strong>: Does the agent fail to match the correct tool due to vague definitions?</p>
<p><strong>​Check</strong>: Does the agent handle tool errors gracefully?</p>
<p>​Example: Data Analysis Agent. Input: [“a”, “b”, “c”] provided to a calculate_mean() tool. If the agent fails to handle the non-numeric error output from the tool, it demonstrates poor context and error management.</p>
</section>
<section id="integration-testing-inter-agent-communication" class="level3">
<h3 class="anchored" data-anchor-id="integration-testing-inter-agent-communication">​3. Integration Testing: Inter-Agent Communication</h3>
<p>​These tests focus on how agents coordinate and hand off tasks. This layer is particularly tricky, as agents must operate independently while still collaborating effectively.</p>
<p><strong>​Check</strong>: Do agents successfully hand off tasks to one another?</p>
<p><strong>​Check</strong>: Does changing the prompt affect handover success (e.g., changing the tone or syntax)?</p>
<p><strong>​Check</strong>: Are agent roles and descriptions clear enough to support successful delegation?</p>
<p>​Example: Travel Planning Agents. A “Trip Planner Agent” delegates hotel booking to a “Hotel Booking Agent.” If the handover fails (e.g., the receiving agent doesn’t understand its input format), the receiving agent may be poorly defined or misnamed.</p>
</section>
<section id="system-level-validation-error-propagation-and-validation" class="level3">
<h3 class="anchored" data-anchor-id="system-level-validation-error-propagation-and-validation">​4. System-Level Validation: Error Propagation and Validation</h3>
<p>These tests assess how errors are surfaced, handled, and communicated across the entire system. They also include strategies for validating the final outputs.​</p>
<p><strong>Check:</strong> Do the underlying tools include error checking and format validation on their outputs?</p>
<p><strong>Check:</strong> Can agents detect and communicate null or failed outputs from other agents or tools?</p>
<p><strong>Check:</strong> Is there a mechanism (e.g., human-in-the-loop or a designated reviewer agent) to validate final results against expected metrics?</p>
<p>Example: Reviewer Agent for Expense Reports. A “Finance Agent” calculates total expenses, and a “Reviewer Agent” checks the result. If the Finance Agent returns £400 instead of £350 for the input “£100 travel, £200 meals, £50 misc.,” the Reviewer Agent can flag the discrepancy.</p>
</section>
</section>
<section id="summary" class="level2">
<h2 class="anchored" data-anchor-id="summary">Summary</h2>
<p>MAS + LLM is becoming an increasingly essential part of a Data Scientist’s toolkit. With the numerous agentic orchestration frameworks available (LangGraph, Autogen, CrewAI, etc.) and that number increasing over time, understanding how to assess MAS and actions to improve them is necessary for their development. I encourage you to use this framework as a starting point to establish robust testing pipelines and governance standards within your teams.</p>
<div class="article-btn">
<p><a href="../../../../../../applied-insights/index.html">Explore more data science ideas</a></p>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-12">
<dl>
<dt>About the author:</dt>
<dd>
<a href="https://www.linkedin.com/in/peter-capsalis-37795958/">Peter Capsalis (MBA, MSc, AdvDSP)</a> is an AI and Data Senior Manager at Ernst and Young where he leads teams of data professionals in the government and energy resources sectors to solve data challenges and deliver transformational change. He sits on the <a href="https://rss.org.uk/policy-campaigns/policy-groups/ai-task-force/">RSS AI Taskforce</a>, and the Society’s <a href="https://rss.org.uk/about/equity-diversity-and-inclusion-(edi)/">EDI committee</a>.
</dd>
</dl>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>Copyright and licence</dt>
<dd>
© 2025 Capsalis, Peter. “​Testing Multi-Agent Systems in the LLM Age: A Practical Guide for Data Scientists”, Real World Data Science, December 12, 2025. <a href="https://realworlddatascience.net/applied-insights/tutorials/posts/2025/12/12/MAS-guide.html">URL</a>
</dd>
</dl>
</div>


</div>
</div>
</section>

 ]]></description>
  <guid>https://realworlddatascience.net/applied-insights/tutorials/posts/2025/12/12/MAS-guide.html</guid>
  <pubDate>Fri, 12 Dec 2025 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/applied-insights/tutorials/posts/2025/12/12/images/MAS.png" medium="image" type="image/png" height="96" width="144"/>
</item>
<item>
  <title>Keeping the Science in Data Science</title>
  <dc:creator>Willis Jensen, Fatemeh Torabi, Monnie McGee, Isabel Sassoon</dc:creator>
  <link>https://realworlddatascience.net/foundation-frontiers/posts/2025/12/03/scienceindatascience.html</link>
  <description><![CDATA[ 





<p>Have you ever run an elegant ML model that landed flat with those who were supposed to use the insights? Do you find yourself deep into building hundreds of features for your model without knowing exactly what they all mean? Do you spend the bulk of your time tweaking your algorithms while aiming for incremental improvements in accuracy? If so, you might be focused more on the “data” aspects of “data science” than the “science” aspects.</p>
<section id="two-foundational-elements-of-data-science" class="level2">
<h2 class="anchored" data-anchor-id="two-foundational-elements-of-data-science">Two Foundational Elements of Data Science</h2>
<p>“Data Science” contains two essential components, “data” and “science”. The field of Data Science requires holding both components in equilibrium. Data is the raw material molded in the service of Science. While Data is first, Science is no less important. Data is the foundation and Science gives it purpose.</p>
<p>What do we mean by Science? We’re referring specifically to the scientific method as an approach to gain knowledge. It is the process of formulating ideas and hypotheses about the world around us and collecting data to determine the validity of those ideas. By hypotheses we’re not limiting the definition to strict statistical hypothesis tests, but rather the general process of formulating a research question, gathering appropriate data and advancing human knowledge, regardless of the statistical techniques or machine learning algorithms employed. Science, at its core, is about using data to gain insights and understanding about the complex universe we inhabit.</p>
<p>The scientific method has a long history and is generally defined in terms of steps such as these <a href="https://en.wikipedia.org/wiki/Scientific_method?utm_source=chatgpt.com">noted in Wikipedia</a> (Scientific Method, 2025) as:</p>
<ol type="1">
<li><p>Characterizations (observations, definitions, and measurements of the subject of inquiry)</p></li>
<li><p>Hypotheses (theoretical, hypothetical explanations of observations and measurements of the subject)</p></li>
<li><p>Predictions (inductive and deductive reasoning from the hypothesis or theory)</p></li>
<li><p>Experiments (tests of all of the above)</p></li>
</ol>
<p>The relationship between Data and Science is cyclical. Performing good science requires gathering good data, informed by proper experimental design techniques, which in turn requires appropriate analysis and interpretation in the context of the science. And good research (science) often generates more questions than it answers, giving way to the need to gather more data, and so on. As such, data science is more than just confirming hypotheses or generating insights, it becomes the application of the scientific method.</p>
<p>The scientific method should be the scaffold supporting what data scientists do. While data scientists come from a variety of backgrounds, many have more training in computer science than statistical methodology, and have more experience in software tools than they do in executing the scientific method.</p>
<p>In an influential, relevant paper Shmueli (2010) described two major types of statistical modeling, I) explanatory models which attempt to determine causal effects, and II) predictive models which seek accurate predictions. While predictive models can lead to understanding and possible explanatory models, explanatory models tend to be preferred by those seeking more scientific explanations for phenomena.</p>
</section>
<section id="data-modeling-culture-versus-algorithmic-culture" class="level2">
<h2 class="anchored" data-anchor-id="data-modeling-culture-versus-algorithmic-culture">Data Modeling Culture Versus Algorithmic Culture</h2>
<p>Leo Breiman <a href="https://projecteuclid.org/journals/statistical-science/volume-16/issue-3/Statistical-Modeling--The-Two-Cultures-with-comments-and-a/10.1214/ss/1009213726.full">in a famous paper</a> described two paradigms: I) the data modelling approach, which assumes the model that generates the data, and II) the algorithm approach, which relies on flexible methods without making assumptions about an underlying data generating model or how the data are generated. Breiman(2001a) felt that the statistics discipline was missing out on opportunities by focusing more on data modeling approaches and not using algorithmic approaches. He practiced what he preached, developing new algorithmic approaches and encouraging the field to increase its focus on algorithms. For example, he introduced <a href="https://link.springer.com/article/10.1023/A:1010933404324">Random Forests</a>, starting a cascade of more algorithmic approaches to modeling (Breiman, 2001b).</p>
<p>This wise counsel from Breiman encouraged those working with data to build more expertise in algorithms, promoting the algorithmic culture as a way to harness the power of new computational techniques. We would equate Breiman’s algorithmic approach with a greater focus on the Data side of Data Science and the data modeling approach with a greater focus on the Science side of Data Science.</p>
</section>
<section id="balancing-data-and-science" class="level2">
<h2 class="anchored" data-anchor-id="balancing-data-and-science">Balancing Data and Science</h2>
<p>Just as pendulums slowly swing back and forth, so too has the pendulum swung too hard towards predictive accuracy (the Data side) at the expense of contextual interpretation (the Science side) . This pendulum swing is evidenced by the growing demand for explainable ML methods (see Alangariret al.&nbsp;2023 as an example) . One such method is the use of Shapley values to elicit and rank the most important features in a ML model (see Rozemberczkiet al 2022 for an introduction). It seems ironic that, in the rush to gain model accuracy with sophisticated models containing hundreds of features, end users of the models still want something they can understand and explain. In other words, they still want scientific knowledge and understanding of cause and effect, even for complicated problems.</p>
<p>So what is the best approach from a scientific perspective? Throw as many features into a model that you can think of and see which ones show up to be the most important? Or is there some thought and care that can go into feature selection, considering what might be important given your knowledge of the science behind a problem?</p>
<p>We’re not suggesting that it is bad to include many features in a model. We’re suggesting that considering the context of the problem can provide insight on features that might matter. Of course, we don’t want to jump to conclusions on what we think is important and miss opportunities to learn. We seek to maintain some balance between using our previous knowledge and experience while not increasing the risk of confirmation bias in the feature selection process.</p>
<p>In software engineering, there is a well-known warning: “premature optimisation is the root of all evil”. The same applies in Data Science. Too often, teams rush to optimise models, tuning hyper-parameters, stacking architectures, and searching for marginal gains, before clearly defining the scientific question or validating whether the data and assumptions are appropriate. This tendency leads to models that are mathematically elegant but scientifically ungrounded. Optimisation should follow understanding, not precede it. A model that captures the right question with moderate accuracy is far more valuable than one that optimises the wrong target to perfection. This limitation of models is reflected in the famous aphorism “All models are wrong, but some are useful,” most commonly associated with the British Statistician George Box, who wrote (Box 1976):</p>
<p><em>“Since all models are wrong, the scientist cannot obtain a”correct” one by excessive elaboration. On the contrary, following William of Occam, he should seek an economical description of natural phenomena. Just as the ability to devise simple but evocative models is the signature of the great scientist, so overelaboration and overparameterisation is often the mark of mediocrity.”</em></p>
<p>Is it okay to use black box models where the model accuracy is paramount and ignore the explainability of the model? Yes, for some problems. But should we use black box models for all problems? No.&nbsp;The key to being a good data scientist/statistician is to recognize when one provides more value than another and use the best approach for the problem at hand.</p>
<p>So how does one give more attention to the Science side of Data Science? It starts with more attention on the question of interest. It doesn’t matter so much the type of question - whether it is a research question, a business problem to solve, or something sparked by curiosity. And it is often more than a single question. Often, it is not a single question but a series of cascading questions, each one digging deeper to get at the root causes. To manage this complexity effectively, it helps to adopt a modular approach, structuring analytical work into well-defined, interlinked components that mirror the scientific process. Each module focuses on a specific purpose: formulating and refining hypotheses, understanding data provenance and quality, developing and validating models, and translating findings into meaningful actions. Such modularisations keep the process transparent and iterative, prevents premature optimisation, and ensures that model development remains anchored to the underlying scientific inquiry rather than drifting towards technical over-engineering. With this increased attention, we believe sampling methods and experimental design will continue to be fundamental.</p>
<p>Here’s one example loosely based on our work experience. A business executive has some reports that show an increase in turnover at their organization, which is driving up hiring and recruiting costs, making the company less profitable. We find that the turnover is higher for those who are newer to the company, which leads to the question: “Why these new ones?” This leads to an additional hypothesis that perhaps these newer employees are not getting the leadership support they need, which leads to questions about the effectiveness of leadership training programs, which in turn leads to questions around how we measure the effectiveness of training programs. By continuing to ask questions, we can get a more targeted effort at a root cause and thus increase the impact of our work.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://realworlddatascience.net/foundation-frontiers/posts/2025/12/03/images/businessexec.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:80.0%"></p>
</figure>
</div>
<p>With the availability of many algorithms and approaches that are able to process large amounts of data, it can be tempting to gravitate towards them. When teaching analysis/ applied statistics courses, it is important to look beyond the methods and consider the overall aim. There are a set of frameworks that have been around for a while that can be helpful in finding the right balance. One example is PPDAC (Mckayet al.&nbsp;2000) that emphasises all the steps beyond the modelling part and the importance of considering them all. Using such frameworks can help decide whether a black box approach is suitable in the situation or whether this won’t achieve the overall intended aim.</p>
</section>
<section id="finding-balance" class="level2">
<h2 class="anchored" data-anchor-id="finding-balance">Finding Balance</h2>
<p>So how do we ensure a good balance between Data and Science in Data Science?</p>
<p>One way is to ask “so what” with any analysis that you do and any model that you build. Ideally, you would ask that at the beginning of a project to reduce wasted effort, but it should be clear how the analysis output will be used. And it would not be sufficient to say “so that we can publish the output in a paper”. You have to think about the impact of the analysis. Will it change a decision that is being made? Does it create a new insight that can be acted upon? Does it lead to a process improvement or a new product innovation? Does it lead to a new way of running an organization? Data science that doesn’t lead to some action or insight is just computation for computations sake. Vance et al.&nbsp;(2022) provides additional resources and advice for how to ask good questions.</p>
<p>A second way is to consider the potential explanations and meaning behind any model. Don’t become too enamored with the predictive accuracy of the model (which isn’t inherently a bad thing) at the expense of asking whether there are potential scientific explanations based on the features used in any model. Use a predictive model as a starting point for digging deeper and finding a smaller set of features that provide deeper insight on potential causal relationships to explore.Sometimes a simpler model that is easier to “explain” or one that uses trusted data provides more value than the latest and greatest algorithm.</p>
<p>A third way is continuing emphasis on the reproducibility of the results. Clean code, documentation of results, version control of analysis code and open sharing of the code with its underlying assumptions are best practices to ensure that others can replicate the findings of any data science output. <a href="https://realworlddatascience.net/foundation-frontiers/posts/2023/11/06/how-to-open-science.html">Sassoon (2023)</a> provides additional guidance for ensuring reproducibility and transparency of results.</p>
<p>A final way to find the balance is to better understand how the data are generated. Hoerl (2025) touched on this issue in calling for statisticians to focus more on data quality. <a href="https://realworlddatascience.net/foundation-frontiers/posts/2025/10/30/data-detectives.html">We believe this advice to be equally relevant for data scientists.</a> By recognizing the crucial importance of the data generation process, data scientists will better be able to use the right data that matches the problem of interest and push for changes as needed to ensure high quality data.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://realworlddatascience.net/foundation-frontiers/posts/2025/12/03/images/balance.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:80.0%"></p>
</figure>
</div>
</section>
<section id="conclusions" class="level2">
<h2 class="anchored" data-anchor-id="conclusions">Conclusions</h2>
<p>We encourage data scientists to live up to their name and become experts in both Data and Science. As they find a proper balance between those two areas, their impact and influence will increase and the quality of their rigorous work will stand up to scrutiny and advance human knowledge.</p>
<p><strong>References</strong></p>
<p>Alangari, N., Menai, M. E. B.,Mathkour, H., &amp;Almosallam, I. (2023).Exploring evaluation methods for interpretable machine learning: A survey.<em>Information</em>,<em>14</em>(8), 469.</p>
<p>Box, George (December 1976). “Science and Statistics”. Journal of the American Statistical Association. 71 (356): 791–799. doi:10.1080/01621459.1976.10480949. Retrieved 2025-11-28.</p>
<p>Breiman, L. (2001a). Statistical modeling: The two cultures (with comments and a rejoinder by the author).<em>Statistical Science</em>,<em>16</em>(3), 199-231.</p>
<p>Breiman, L. (2001b). Random forests.<em>Machine Learning</em>,<em>45</em>, 5-32.</p>
<p>Hoerl, R. W. (2025). The future of statistics in an AI era.<em>Quality Engineering</em>. Advance online publication.</p>
<p>Hyde, R. (2009). The fallacy of premature optimization.<em>Ubiquity</em>,<em>2009</em>(February).</p>
<p>MacKay, R. J., &amp; Oldford, R. W. (2000). Scientific method, statistical method and the speed of light.<em>Statistical Science</em>,<em>15</em>(3), 254-278.</p>
<p>Rozemberczki, B., Watson, L., Bayer, P., Yang, H. T., Kiss, O., Nilsson, S., &amp; Sarkar, R. (2022). Theshapleyvalue in machine learning. In<em>The 31st International Joint Conference on Artificial Intelligence and the 25th European Conference on Artificial Intelligence</em>(pp.&nbsp;5572-5579). International Joint Conferences on Artificial Intelligence Organization.</p>
<p>Sassoon, I. (2023, November 6). How to ‘open science’: A brief guide to principles and practices.<em>Real World Data Science</em>. https://realworlddatascience.net/foundation-frontiers/posts/2023/11/06/how-to-open-science.html</p>
<p>Scientific method. (2025, November). In<em>Wikipedia</em>.</p>
<p>Shmueli, G. (2010). To explain or to predict?<em>Statistical Science</em>,<em>25</em>(3), 289-310.</p>
<p>Vance, E. A., Trumble, I. M., Alzen, J. L., &amp; Smith, H. S. (2022). Asking great questions.<em>Stat</em>,<em>11</em>(1), e471.</p>
<div class="article-btn">
<p><a href="../../../../../foundation-frontiers/index.html">Explore more data science ideas</a></p>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-12">
<dl>
<dt>About the authors</dt>
<dd>
This article was authored by some of our editorial board members. You can find their bios <a href="https://realworlddatascience.net/the-pulse/editors-blog/posts/2022/10/18/meet-the-team.html">on our team page</a>.
</dd>
</dl>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>Copyright and licence</dt>
<dd>
© 2025 Willis Jensen, Fatemeh Torabi, Monnie McGee, Isabel Sassoon.
</dd>
</dl>
</div>
<div class="g-col-12 g-col-md-6">
<p>: Jensen, Willis. Torabi, Fatemeh. McGee, Monnie. Sassoon, Isabel. “Keeping the Science in Data Science,” Real World Data Science, December 04, 2025. <a href="https://realworlddatascience.net/foundation-frontiers/posts/2025/11/27/scienceindatascience.html">URL</a></p>
</div>


</div>
</div>
</section>

 ]]></description>
  <guid>https://realworlddatascience.net/foundation-frontiers/posts/2025/12/03/scienceindatascience.html</guid>
  <pubDate>Thu, 04 Dec 2025 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/foundation-frontiers/posts/2025/12/03/images/thumbnail2.png" medium="image" type="image/png" height="96" width="144"/>
</item>
<item>
  <title>AI for Social Good: Interview with the Founder of Mike Hudson Foundation</title>
  <dc:creator>Annie Flynn</dc:creator>
  <link>https://realworlddatascience.net/foundation-frontiers/posts/2025/11/27/MHF-interview.html</link>
  <description><![CDATA[ 





<p>Since the emergence of generative AI such as OpenAI’s ChatGPT at the end of 2022, data science practitioners have watched large language models (LLMs) become both a transformative capability and a source of organisational anxiety. Few people sit closer to this intersection than <strong>Mike Hudson</strong>, a former fintech entrepreneur who now leads initiatives deploying AI for social good through the <a href="https://www.mikehudsonfoundation.org/">Mike Hudson Foundation</a>. MHF’s current projects include <a href="https://www.knowbot.uk/">Knowbot</a>, an LLM-powered tool designed to make complex websites more accessible. Knowbot uses LLMs to read and distill curated information to answer users’ complex questions.</p>
<p>Previously, MHF created <a href="https://www.testramp.org/">TestRAMP</a>, an ambitious effort during the COVID-19 pandemic to mobilise private lab PCR capacity for public benefit which also identified <a href="https://www.smf.co.uk/publications/testramp-marketplace-covid-testing/">potential lessons for future crisis situations</a>.</p>
<p>In this interview, Mike speaks candidly about the challenges and opportunities of deploying AI in nonprofit settings, and the lessons learned from building responsible, high-impact technology during moments of rapid change.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://realworlddatascience.net/foundation-frontiers/posts/2025/11/27/images/simplequestion.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:80.0%"></p>
</figure>
</div>
<section id="the-appetite-for-ai-in-the-third-sector" class="level2">
<h2 class="anchored" data-anchor-id="the-appetite-for-ai-in-the-third-sector">The Appetite for AI in the Third Sector</h2>
<p><strong>Q: What led you to start working on Knowbot in the first place?</strong></p>
<p>I used to be a business entrepreneur with several tech and fintech businesses. That came to an end when I sold those businesses and then, when Covid started, it seemed like there was an opportunity to give something back. I founded TestRAMP, my first nonprofit, and that experience was so enjoyable and so productive. Once the pandemic eased, we had a foundation in place but no clear mission. Then ChatGPT launched, the world got excited about large language models, and we thought: could we use our tech backgrounds and some funding to build something for the social good?</p>
<p>Knowbot grew out of a simple question: Is there an appetite within the world of nonprofits for LLMs —and is there a use case for them? We needed a very simple, low-risk, easy-to-grasp AI use case that could act as a gateway for organisations cautiously exploring LLMs. Knowbot became that gateway.</p>
<p>We pushed it out to some of the non-profits we were already working with and it’s been interesting. There is some appetite for it, and the appetite is increasing. We use Knowbot as a jumping-off point to start a conversation about AI.</p>
<p><strong>Q: Are there patterns in which charities are more open to adopting AI?</strong></p>
<p>The biggest differentiator isn’t size or budget — it’s culture. We are finding it most productive to work with medium-to-large nonprofits with a scientific or research-oriented culture, where the internal decision-makers tend to “get” AI more quickly. Because our single biggest challenge, far and away above any technical or scaling challenges, or anything to do with IT or LLM, has been accessing the right decision-makers inside organisations.</p>
<p>The sector is understandably cautious and we are new kids on the block — Knowbot didn’t exist a year ago. And we have realised that word of mouth recommendations will be key to our growth: credibility has to be built one relationship at a time with the right nonprofit partners.</p>
</section>
<section id="designing-for-maximum-ease" class="level2">
<h2 class="anchored" data-anchor-id="designing-for-maximum-ease">Designing for Maximum Ease</h2>
<p><strong>Q: How did you approach technical deployment?</strong></p>
<p>From day one, we knew getting anything onto a nonprofit’s website would be difficult. So, technically speaking, we’ve made it as easy as we possibly can. Knowbot runs almost entirely on our servers. On a partner’s website, it appears as a javascript button in the corner of a user’s screen which when clicked loads a small Knowbot window, where they can ask questions. Knowbot loads its interface from our servers in Frankfurt.There’s no client-side coding or backend integration required. That was deliberately done to allow a very straightforward deployment, and it should only take new partners a couple of hours to implement. We’ve recently made an even simpler option: some partners now just link to a branded page that looks like their website but which actually exists on our servers.</p>
<p>Behind the scenes, Knowbot is written mostly in Python and uses LLMs from Anthropic, OpenAI, Meta, Google, and Perplexity. We don’t develop our own models — few organisations on Earth have the budget for that. Instead, we “build the car around the engine,” and it’s a slightly different car for each non-profit that we work with.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://realworlddatascience.net/foundation-frontiers/posts/2025/11/27/images/thumbnailsocial.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:80.0%"></p>
</figure>
</div>
</section>
<section id="ethics-by-design-domain-restriction-as-a-safety-mechanism" class="level2">
<h2 class="anchored" data-anchor-id="ethics-by-design-domain-restriction-as-a-safety-mechanism">Ethics by Design: Domain Restriction as a Safety Mechanism</h2>
<p><strong>Q: As an AI-for-good nonprofit, how do you approach issues of risk, bias, and governance?</strong></p>
<p>With nonprofits, we are hyper-aware of these issues. Some of the organisations we work with handle sensitive information, so we need to be sure we’re not introducing new risks. With a non-profit that is working in healthcare, for example, if there is a possibility that Knowbot may be used for medical-adjacent questions, then we need to think carefully about whether that is something we should be doing and, if so, whether we can do it safely.</p>
<p>One major choice we made early on was domain restriction. Whereas most of the big answer engines out there, like ChatGPT, search the full public internet, Knowbot will only use its internal knowledge and specific website(s) upon which it’s based (i.e.&nbsp;the non-profit’s own website(s)). That means the knowledge is curated and the nonprofit knows exactly what information Knowbot can draw on. That dramatically reduces the risk of hallucination, misinformation, or unsafe advice.</p>
<p>We also adjust our prompts continually based on feedback. For example, we hadn’t anticipated that users would ask questions like “Who are you?” or “What is Knowbot?” Because the model had no context, it responded unpredictably. So we now require partners to include a “What is Knowbot?” page on their site, which Knowbow can reference.</p>
</section>
<section id="evolving-with-the-technology" class="level2">
<h2 class="anchored" data-anchor-id="evolving-with-the-technology">Evolving with the Technology</h2>
<p><strong>Q: What technical challenges have you encountered?</strong></p>
<p>I think we have been really lucky in terms of timing. To do what we’re doing now five years ago would have been completely impossible, because the LLMs weren’t there. From an infrastructure perspective, newer services such as cloud hosting tools like Render now let us deploy servers in minutes. That’s just a breath of fresh air. It takes away a lot of the operational heartache. And coding has become dramatically easier—AI assistance means we can build things now that would have taken us weeks before.</p>
<p>We’ve also been lucky in that LLM technology has improved fast enough that we’ve been able to incorporate new functionality almost as quickly as our nonprofit partners have requested it. For example, we now allow partners to restrict Knowbot to particular sections or topics within a website, or to sit across multiple websites. This has only become practical as models and retrieval tools have matured. Development has become faster, too: for example, we can now submit an entire codebase into our coding LLMs and ask questions about it. By comparison, when ChatGPT first launched we could only submit a small section of a program at a time.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://realworlddatascience.net/foundation-frontiers/posts/2025/11/27/images/impact.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:80.0%"></p>
</figure>
</div>
</section>
<section id="impact-what-knowbot-is-changing" class="level2">
<h2 class="anchored" data-anchor-id="impact-what-knowbot-is-changing">Impact: What Knowbot Is Changing</h2>
<p><strong>What impact have you seen so far?</strong></p>
<p>There hasn’t been anybody who has stopped and decided that it’s not for them, which is encouraging. Most of our nonprofit partners have started small — monitoring answers, getting staff comfortable — and have then expanded deployment. Feedback has been invaluable and very positive.</p>
<p>We can measure impact partly by usage volume, but more importantly by value. Getting 1,000 questions about “where is the ice cream stall?” on a venue website is fine, but the real impact is when researchers or decision-makers can extract complex information from, say, a conservation charity or a healthcare resource site. That’s where AI becomes transformational.</p>
<p>We want to add more value with more nonprofits and other for-good actors. We think there are some obvious things that should be done more generally. Whether we do them through Knowbot or whether we flag other suitable tech partners isn’t clear yet, and probably isn’t that important. But, for example, long-term, we would like to see tools like Knowbot become standard on sites like NHS.uk, gov.uk, NICE, and others. These sites hold high-quality knowledge but can be very difficult to navigate due to the sheer volume of information they contain. Traditional on-website search tools simply aren’t up to the job and LLM-based retrieval is a natural upgrade. The sooner these sites start adopting tools such as Knowbot, the better information people are going to get. Whether that means members of the public, or whether it means professionals that are looking for technical advice, the biggest wins come from the right information helping people make valuable decisions.</p>
</section>
<section id="advice-for-nonprofits-considering-llms" class="level2">
<h2 class="anchored" data-anchor-id="advice-for-nonprofits-considering-llms">Advice for Nonprofits Considering LLMs</h2>
<p><strong>What advice would you give nonprofits thinking about adopting LLMs?</strong></p>
<p>Start small. Don’t try to design a global solution from day one. There is so much hype around AI — some justified, some not — that it feels like a high-risk decision. LLM AI is still new and evolving rapidly. Understand that you don’t know what you don’t know, and be prepared to experiment on a small scale, before building out.</p>
<p>Use low-impact tools first. Let different teams build familiarity. Learn what the models can and can’t do in your context. Build internal confidence gradually.</p>
<p>And for practitioners inside nonprofits facing resistance: the conversation is the same one we have externally. Be clear about risks, mitigation, and the fact that this is a learning process. Build trust.</p>
<p><strong>Q: Where do you see the next big opportunity for AI in the public interest?</strong></p>
<p>We’re at the beginning of another new chapter in generative AI. Until now, most LLMs have been about retrieval and synthesis. The next transformational phase is agentic AI: systems that can do things - take actions autonomously, or semi-autonomously. That will be incredibly consequential for society, with new risks and huge potential benefits. Getting that right is absolutely essential. Future technology aside, there remain enormous public interest opportunities even for today’s tech. There is always a lag between new technology and its adoption and implementation.</p>
<p><strong>Q: Anything you’d like readers to know about Knowbot?</strong></p>
<p>Yes! Come and talk to us. Every conversation teaches us something new, whether or not the organisation ends up using Knowbot. We’re eager to collaborate with nonprofits and with tech companies building the next generation of models.</p>
<p><em>Mike Hudson is an entrepreneur in technology &amp; electronic markets. He now uses his expertise to help solve social problems. Mike founded TestRAMP, a pandemic nonprofit social market described as a “major contribution to Covid PCR testing &amp; genomic sequencing” &amp; donated its £2.4mn profits for charity. Mike is a Fellow of ZSL &amp; adviser to its CEO. He is an honorary Research Fellow at City, University of London. Mike is a member of the Responsible AI Institute. He is a Foundation Fellow at St Antony’s College, University of Oxford.</em></p>
<div class="article-btn">
<p><a href="../../../../../foundation-frontiers/index.html">Explore more data science ideas</a></p>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-12">
<dl>
<dt>About the authors</dt>
<dd>
<strong>Annie Flynn</strong> is Head of Content at the RSS.
</dd>
</dl>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>Copyright and licence</dt>
<dd>
© 2025 Annie Flynn
</dd>
</dl>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>How to cite</dt>
<dd>
Flynn, Annie 2025. “AI for Social Good: Interview with the Founder of the Mike Hudson Foundation,” Real World Data Science, November 27, 2025. <a href="https://realworlddatascience.net/foundation-frontiers/posts/2025/11/27/MHF-interview.html">URL</a>
</dd>
</dl>
</div>
</div>
</div>


</section>

 ]]></description>
  <guid>https://realworlddatascience.net/foundation-frontiers/posts/2025/11/27/MHF-interview.html</guid>
  <pubDate>Thu, 27 Nov 2025 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/foundation-frontiers/posts/2025/11/27/images/thumbnailsocial.png" medium="image" type="image/png" height="96" width="144"/>
</item>
<item>
  <title>Beyond Quantification: Navigating Uncertainty in Professional AI Systems</title>
  <dc:creator>Annie Flynn</dc:creator>
  <link>https://realworlddatascience.net/foundation-frontiers/datasciencebites/posts/2025/11/21/uncertainty.html</link>
  <description><![CDATA[ 





<div class="callout callout-style-default callout-note callout-titled" style="margin-top: 0rem;">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-1-contents" aria-controls="callout-1" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Note</span>About the paper and this post
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-1" class="callout-1-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<p><strong>Title:</strong> Beyond Quantification: Navigating Uncertainty in Professional AI Systems</p>
<p><strong>Author(s) and year:</strong> Sylvie Delacroix, Diana Robinson, Umang Bhatt, Jacopo Domenicucci, Jessica Montgomery, Gaël Varoquaux, Carl Henrik Ek, Vincent Fortuin, Yulan He, Tom Diethe, Neill Campbell, Mennatallah El-Assady, Søren Hauberg, Ivana Dusparic12 and Neil D. Lawrence (2025)</p>
<p><strong>Status:</strong> Published in <em>RSS: Data Science and Artificial Intelligence</em>, open access: <a href="https://academic.oup.com/rssdat/article/1/1/udaf002/8317136">HTML</a></p>
</div>
</div>
</div>
<p>As artificial intelligence systems—especially large language models (LLMs)—become woven into everyday professional practice, they increasingly influence sensitive decisions in healthcare, education, and law. These tools can draft medical notes, comment on student essays, propose legal arguments, and summarise complex documents. But while AI can now answer many questions confidently, professionals know that confidence is not always what matters most.</p>
<p>Consider a doctor who suspects a patient may be experiencing domestic abuse, or a teacher trying to distinguish between a student’s misunderstanding and a culturally shaped interpretation of a text. These are situations where uncertainty isn’t just about missing data—it’s about interpretation, ethics, and human judgment.</p>
<p>Yet much current AI research focuses on quantifying uncertainty: assigning probability scores, confidence levels, or error bars. The authors of this paper argue that while such numbers help in some cases, they miss the forms of uncertainty that truly matter in professional decision-making. If AI systems rely only on numeric confidence, they risk eroding the very expertise they aim to support.</p>
<p>This paper asks a simple but transformative question: <strong>What if uncertainty isn’t always something to quantify, but something to communicate?</strong></p>
<section id="why-quantification-isnt-enough" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="why-quantification-isnt-enough">Why quantification isn’t enough</h2>
<p>The authors highlight a fundamental mismatch between the way today’s AI systems handle uncertainty and the way real professionals experience it. They distinguish between:</p>
<ul>
<li><p>Epistemic uncertainty – when we simply don’t know enough yet (e.g., missing data, incomplete measurements). <em>This can often be quantified.</em></p></li>
<li><p>Hermeneutic uncertainty – when a situation allows multiple legitimate interpretations, often shaped by culture, ethics, or context. <em>This cannot meaningfully be reduced to a percentage.</em></p></li>
</ul>
<div class="column-page">
<p><img src="https://realworlddatascience.net/foundation-frontiers/datasciencebites/posts/2025/11/21/images/uncertaintykinds.png" class="img-fluid"></p>
</div>
<p>Professional judgment often depends on this second kind. Teachers, doctors, and lawyers rely on tacit skills: subtle perceptions, ethical intuitions, and context-sensitive interpretation. AI systems trained on statistical patterns struggle to reflect this nuance.</p>
<p>When an AI model gives a probability score — “I’m 70% sure this infection is bacterial” — it communicates something useful. But if the real uncertainty stems from ethical or contextual complexity (e.g., whether asking a patient certain questions might put them at risk), probability scores offer a false sense of clarity.</p>
<p>The paper gives practical examples:</p>
<ul>
<li><p>A medical AI might be highly confident about symptoms but blind to the social dynamics suggesting abuse.</p></li>
<li><p>An educational AI may accurately flag grammar issues but miss culturally sensitive interpretations in a student essay.</p></li>
</ul>
<p>In both cases, the most important uncertainties are precisely the ones that cannot be captured by numbers.</p>
</section>
<section id="why-this-matters-now" class="level2">
<h2 class="anchored" data-anchor-id="why-this-matters-now">Why this matters now</h2>
<p>The authors warn that the problem becomes even more serious as we move toward agentic AI systems—multiple AI agents interacting and making decisions together. If one system miscommunicates uncertainty, the error may ripple through an entire network.</p>
<p>To address this, the authors propose shifting away from trying to algorithmically “solve” uncertainty, and instead enabling professionals themselves to shape how AI expresses it.</p>
</section>
<section id="takeaways-and-implications" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="takeaways-and-implications">Takeaways and implications</h2>
<p><strong>1. Uncertainty expression is part of professional expertise, not just a technical feature</strong></p>
<p>AI should not simply output probabilities. It should help preserve and enhance the ways professionals reason through complex, ambiguous situations. That means:</p>
<ul>
<li><p>highlighting when interpretation is required</p></li>
<li><p>surfacing multiple plausible perspectives</p></li>
<li><p>signalling when ethical judgment is involved</p></li>
<li><p>encouraging expanded inquiry rather than false certainty</p></li>
</ul>
<p>For example, instead of producing a diagnosis score, an AI assistant might say: “This pattern warrants attention to social context. Consider asking open-ended questions to understand the patient’s circumstances.”</p>
<p>This kind of prompting respects and supports professional judgment.</p>
<p><strong>2. Professionals—not engineers—must define how uncertainty is communicated</strong></p>
<p>The authors propose participatory refinement, a process where communities of practitioners (teachers, doctors, judges, etc.) collectively shape:</p>
<ul>
<li><p>the categories of uncertainty that matter in their field</p></li>
<li><p>the language and formats AI systems should use</p></li>
<li><p>how these systems should behave in ethically sensitive scenario</p></li>
</ul>
<p>This differs from typical user feedback loops. Instead of individuals clicking “thumbs down,” whole professions deliberate on what kinds of uncertainty an AI system should express and how.</p>
<p><strong>3. This requires new technical and organisational approaches</strong></p>
<div class="column-page">
<p><img src="https://realworlddatascience.net/foundation-frontiers/datasciencebites/posts/2025/11/21/images/futureai.png" class="img-fluid"></p>
</div>
<p>To make participatory refinement possible, future AI systems need:</p>
<ul>
<li><p>architectures that can incorporate community-defined uncertainty frameworks</p></li>
<li><p>interfaces designed for collective sense-making, not just individual use</p></li>
<li><p>institutional support (e.g., workshops, governance processes, professional committees)</p></li>
</ul>
<p>While this takes more time than simply deploying an AI system “out of the box,” the authors argue that in fields like healthcare or law, these deliberative processes are essential, not optional.</p>
<p><strong>4. Preserving “productive uncertainty” is key for ethical, adaptive professional practice</strong></p>
<p>If AI tools flatten complex uncertainty into simple numbers, they may unintentionally narrow the space for professional judgment and ethical debate. The authors suggest that sustained ambiguity—open questions, competing interpretations, ethical reflection—is not a flaw in human reasoning but a feature of high-quality professional work.</p>
<p>Well-designed AI should help maintain that reflective space, not close it down.</p>
<p><strong>Further reading</strong></p>
<p>For readers interested in exploring more:</p>
<ul>
<li><p>David Spiegelhalter – The Art of Uncertainty (accessible introduction to uncertainty in science)</p></li>
<li><p>Iris Murdoch – The Sovereignty of Good (on moral perception)</p></li>
<li><p>Participatory AI frameworks such as STELA (Bergman et al., 2024)</p></li>
<li><p>Visual analytics research on human-in-the-loop data interpretation</p></li>
<li><p>Discussions of agentic AI systems and coordinated AI in healthcare</p></li>
<li><p>Delacroix’s work on LLMs in ethical and legal decision-making</p></li>
</ul>
</section>
<section id="in-summary" class="level2">
<h2 class="anchored" data-anchor-id="in-summary">In summary</h2>
<p>This paper argues that if AI is to genuinely assist professionals, it must go beyond quantification. Numbers alone cannot capture the ethical, interpretive, and contextual uncertainties that define professional practice. Instead, AI should help preserve and enrich human judgment by communicating uncertainty in ways co-designed with the communities who rely on it. AI should not just be <em>accurate</em> —it should be <em>appropriately uncertain</em>.</p>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-6">
<dl>
<dt>About the author</dt>
<dd>
<strong>Annie Flynn</strong> is Head of Content at the RSS.
</dd>
</dl>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>About DataScienceBites</dt>
<dd>
<a href="../../../../../../foundation-frontiers/datasciencebites/index.html"><strong>DataScienceBites</strong></a> is written by graduate students and early career researchers in data science (and related subjects) at universities throughout the world, as well as industry researchers. We publish digestible, engaging summaries of interesting new pre-print and peer-reviewed publications in the data science space, with the goal of making scientific papers more accessible. Find out how to <a href="../../../../../../contributor-docs/datasciencebites.html">become a contributor</a>.
</dd>
</dl>
</div>
</div>
</div>


</section>

 ]]></description>
  <guid>https://realworlddatascience.net/foundation-frontiers/datasciencebites/posts/2025/11/21/uncertainty.html</guid>
  <pubDate>Fri, 21 Nov 2025 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/foundation-frontiers/datasciencebites/posts/2025/11/21/images/thumb.png" medium="image" type="image/png" height="96" width="144"/>
</item>
<item>
  <title>Why We Should All Be Data Quality Detectives</title>
  <dc:creator>A. Rosemary Tate and Roger Halliday</dc:creator>
  <link>https://realworlddatascience.net/foundation-frontiers/posts/2025/10/30/data-detectives.html</link>
  <description><![CDATA[ 





<p>At the <a href="https://rss.org.uk/news-publication/news-publications/2025/general-news/president-s-blog-reflections-on-a-record-breaking/">2025 Royal Statistical Society conference</a> in Edinburgh, a lively group of statisticians and data scientists gathered to tackle a quietly critical issue: data quality. Our workshop, titled “Why we should all be data quality detectives”, drew around 40 participants into a dynamic conversation about why data quality is often overlooked and what we can do to change that.</p>
<div id="thumbnail.png" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="https://realworlddatascience.net/foundation-frontiers/posts/2025/10/30/images/thumbnail.png" class="img-fluid figure-img" alt="The workshop drew 40 participants."></p>
<figcaption>The workshop drew 40 participants.</figcaption>
</figure>
</div>
<section id="the-case-for-data-quality" class="level2">
<h2 class="anchored" data-anchor-id="the-case-for-data-quality">The Case for Data Quality</h2>
<p>If you search for “data quality disasters” on any search engine, you will find many results. Similarly, literature on data quality measures offers abundant advice. But within the scientific research community, data quality is often ignored. For example, how often have you encountered the term “data quality” in the guidelines when submitting or reviewing an academic paper? We would venture to say, hardly ever (or never).</p>
<p>This is puzzling, because high-quality data (i.e., data that is fit for purpose) is essential; without it, results become almost meaningless. Data serves as the foundation of our work. So why isn’t its quality given the prominence it deserves? Why aren’t we, as statisticians and data scientists, advocating data quality more vocally?</p>
<p>Recent publications may shed some light: it appears that “Everyone wants to do the model work, not the data work” [1]<sup>1</sup>, and that statisticians may feel uneasy with elements that are not easily quantifiable [2]<sup>2</sup>. Or perhaps we are all guilty of “premature enumeration” (as Tim Harford puts it), rushing into data analysis without having a good look at the data first. Whatever the case, data quality work or “data cleaning/wrangling” is not seen as fun.</p>
<p>For us, as self-confessed “data quality detectives”, the reverse is true, and we began the workshop by reframing data quality not as a tedious chore, but as an empowering and even enjoyable part of the analytical process. We spend hours looking at the data, enjoying the delayed gratification of finally getting to (trustable) results.</p>
<p>In Rosemary’s case, her attitude was shaped by key experiences early in her statistical career. Her doctoral research focused on developing methods to automatically classify magnetic resonance spectra of human leg adipose tissue based on diet—specifically distinguishing between vegans and omnivores. The study recruited 33 vegans, while the control group included 34 omnivores and 8 vegetarians, primarily staff from the MRI unit at Hammersmith Hospital. With limited experience at the time, she began experimenting with various techniques, starting with k-means cluster analysis. Although she hoped the clusters would reflect dietary groups, the analysis instead produced two distinct clusters—one containing just two spectra and the other containing the rest. After consulting colleagues, she learned that the two outlier spectra had been acquired using a different protocol and were mistakenly included in the dataset. While she may have identified the error later, catching it early saved her several weeks of work — and won her some kudos with colleagues.</p>
<div id="kudos.png" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="https://realworlddatascience.net/foundation-frontiers/posts/2025/10/30/images/kudos.png" class="img-fluid figure-img" alt="Catching it early saved her several weeks of work."></p>
<figcaption>Catching it early saved her several weeks of work.</figcaption>
</figure>
</div>
</section>
<section id="detective-work-at-the-tables" class="level2">
<h2 class="anchored" data-anchor-id="detective-work-at-the-tables">Detective Work at the Tables</h2>
<p>During the workshop, we split into six groups to investigate two questions: Why does data quality get overlooked? What strategies can raise its profile?</p>
<p>The discussions were rich and revealing. Many pointed to organisational gaps — no clear strategy, limited training, and confusion over who is responsible for data quality. Others highlighted cultural issues: time pressures, lack of curiosity, and a tendency to assume someone else has already checked the data.</p>
<p>Simple Excel errors are also common. We heard an example case of a study comparing a new, advanced imaging machine with an older model. The results were presented in a spreadsheet, which included several measurements. As expected, the correlation matrix showed strong correlations between most columns—except for the first, which was the main measure of interest. It quickly became apparent that the sort function had been applied to that column, scrambling the values and rendering them effectively random. Unfortunately, the researcher had not kept a backup of the original data, meaning the entire experiment was compromised. During the COVID-19 pandemic, a similar technical mistake involving Excel led to <a href="https://www.bbc.co.uk/news/technology-54423988#:~:text=The%20badly%20thought%2Dout%20use,than%20a%20third%2Dparty%20contractor.">thousands of positive cases being omitted from the UK’s official daily figures</a>. These are the kinds of simple issues that could have been caught with a basic data check.</p>
<div id="excel-errors.png" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="https://realworlddatascience.net/foundation-frontiers/posts/2025/10/30/images/excel-errors.png" class="img-fluid figure-img" alt="Simple Excel errors are also common."></p>
<figcaption>Simple Excel errors are also common.</figcaption>
</figure>
</div>
<p>Other examples were given of data quality issues arising when datasets were used for a specific research focus, and the quality checks applied were tailored too narrowly to that focus. Additional problems only became apparent when the same data was later used for a different research purpose. Conclusion: you can’t be complacent about the quality of the data you’re using.</p>
</section>
<section id="strategies-for-change" class="level2">
<h2 class="anchored" data-anchor-id="strategies-for-change">Strategies for Change</h2>
<p>The second question sparked even more ideas. Suggestions ranged from embedding data quality education early (even at school level) to implementing cultural changes that lead to great transparency. Participants called for:</p>
<ul>
<li>Training and upskilling across roles</li>
<li>Transparent reporting of errors and limitations</li>
<li>Positive feedback loops for data collectors</li>
<li>Rewarding quality work and error detection</li>
<li>Modernising systems and improving interoperability</li>
<li>Using AI and automation to support quality checks</li>
<li>Publications including recommendations for more transparent reporting of “initial data analysis” in their guidelines.</li>
</ul>
<p>One standout idea: organisations could promote a “data amnesty” culture where errors can be acknowledged without blame. This is something Roger experienced during his time as Chief Statistician for the Scottish Government. There, he occasionally encountered serious data quality issues that required official statistics to be revised or delayed. Being transparent with users about these issues was a key principle of the Code of Practice for Official Statistics. A conscious effort was made — through training and through taking a certain approach to handling such situations — to foster a culture of openness and accountability. Staff were supported to create and implement plans to address the problems, learn from them, and communicate clearly with users. This transparency was essential to maintaining trust in both our processes and the statistics we produced.</p>
</section>
<section id="a-call-to-action" class="level2">
<h2 class="anchored" data-anchor-id="a-call-to-action">A Call to Action</h2>
<p>We walked away from the workshop with a clear conclusion: data quality needs a culture shift. It’s not enough to care — we need to prioritise and celebrate the work of those who keep our data trustworthy, while educating other stakeholders about what it involves.</p>
<p>Shaping the next steps will require keeping this conversation going within the data community and Real World Data Science can play an integral role in that. As a direct result of this piece, we have <a href="https://realworlddatascience.net/contributor-docs/call-for-contributions.html">updated our submission guidelines</a> to include recommendations for transparent data reporting and we would like to publish more stories of data disasters – or disasters averted through careful attention to data quality.</p>
<p>As one attendee put it, “We need to challenge the data and learn best practice from the get-go.” It’s time to embrace our inner data detectives; the integrity of our insights depends on it.</p>
<p>Please share your own data disaster stories in the comments, or in the <a href="mailto:rwds@rss.org.uk">Real World Data Science inbox</a>.</p>
<div class="article-btn">
<p><a href="../../../../../foundation-frontiers/index.html">Explore more data science ideas</a></p>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-12">
<dl>
<dt>About the authors</dt>
<dd>
<strong>Rosemary Tate</strong> is a Chartered Biostatistician and Computer Scientist with over 30 years of experience in medical research and statistical consulting. She has a BSC in mathematics and a DPhil in Computer Science and AI, and an MSc in Medical Statistics. She has been scientific manager of a large EU-funded project and held lectureships at the Institutes of Child Health and Psychiatry. An independent statistical consultant since 2016, she now spends most of her time as a “Data Quality Agent Provocateur”.
</dd>
<dd>
<strong>Roger Halliday</strong> CEO at Research Data Scotland, providing leadership to improving public wellbeing through transforming how data is used in research, innovation and insight. Roger was Scotland’s Chief Statistician from 2011 to 2022. During that time he was also Scottish Government Chief Data Officer (2017-20), and jointly led Scottish Government Covid Analytical Team during the pandemic. Before that, he worked in the Department of Health in England as a policy analyst managing evidence for decision making across NHS issues. He became an honorary Professor at the University of Glasgow in 2019.
</dd>
</dl>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>Copyright and licence</dt>
<dd>
© 2025 A. Rosemary Tate and Roger Halliday
</dd>
</dl>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>How to cite</dt>
<dd>
Tate, Rosemary A. and Halliday, Roger. 2025. “Why We Should All Be Data Quality Detectives” Real World Data Science, October 30, 20245. <a href="https://realworlddatascience.net/foundation-frontiers/posts/2024/10/31/data-detectives.html">URL</a>
</dd>
</dl>
</div>
</div>
</div>


</section>


<div id="quarto-appendix" class="default"><section id="footnotes" class="footnotes footnotes-end-of-document"><h2 class="anchored quarto-appendix-heading">References</h2>

<ol>
<li id="fn1"><p>Nithya Sambasivan, Shivani Kapania, Hannah Highfill, Diana Akrong, Praveen Paritosh, and Lora M Aroyo. Everyone wants to do the model work, not the data work: Data cascades in High-Stakes AI. In proceedings of the 2021 CHI Conference on Human Factors in Computing Systems, pages 1–15, 2021.↩︎</p></li>
<li id="fn2"><p>Thomas Redman and Roger Hoerl. Data quality and statistics: Perfect together? Quality Engineering, 35(1):152–159, 2023.↩︎</p></li>
</ol>
</section></div> ]]></description>
  <guid>https://realworlddatascience.net/foundation-frontiers/posts/2025/10/30/data-detectives.html</guid>
  <pubDate>Thu, 30 Oct 2025 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/foundation-frontiers/posts/2025/10/30/images/thumbnail.png" medium="image" type="image/png" height="96" width="144"/>
</item>
<item>
  <title>Code, Calculate, Change - How Statistics Fuels AI’s Real World Impact: EICC Live</title>
  <link>https://realworlddatascience.net/foundation-frontiers/posts/2025/09/17/EICC_Live.html</link>
  <description><![CDATA[ 





<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/CeZpkZzWcuo" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<p>Artificial Intelligence (AI) is transforming how we live, work, and make decisions every day – from the content we see on social media to how we’re hired, navigate to work, or how spam is filtered from our inboxes. But what exactly is AI? How does it work, where did it come from, and where is it taking us?</p>
<p>Dr Sophie Carr, chair of the <em>Real World Data Science</em> <a href="https://realworlddatascience.net/the-pulse/editors-blog/posts/2022/10/18/meet-the-team.html">board of editors</a>, was joined by a panel of expert speakers for a public lecture in Edinburgh at the beginning of the month. <em>Real World Data Science</em> <a href="https://realworlddatascience.net/the-pulse/posts/2025/07/28/NHS-foundation-AI.html">contributor</a> Will Browne delivered “a hitchhiker’s guide to the history of AI”, taking us from the first ever algorithm (coded by “poetical scientist” Ada Lovelace) to today’s large langugage models, via a counting horse and a US naval invention.</p>
<p>Parwez Diloo, a data scientist at <a href="https://baysconsulting.co.uk/">Bays Consulting</a>, talked about how to balance technology with a human touch in recruitment processes (and the difference between maths and magic!)</p>
<p>And Amy Wilson, a lecturer in industrial mathematics at the University of Edinburgh, spoke about graphical modelling for decision-making in criminal contexts, touching on the legal failures of probabilistic reasoning in high profile cases like that of Lucy Letby and Amanda Knox.</p>
<p>The talk was rounded off by a lively Q&amp;A session which covered the viability of AI-designed graphical models, remedies to the so-called inappropriate uses of AI, and collective action we can take to ensure AI bias does not entrench existing inequalities.</p>
<p>This talk was part of the <a href="https://www.eicc.co.uk/eicc-live/">EICC Live</a> programme, a series of free public talks held by the <a href="https://www.eicc.co.uk/">EICC</a> as part of a commitment to community engagement and quality education. The talk was filmed by EICC and is published here with thanks to them. It took place at the RSS 2025 International Conference.</p>
<div class="g-col-12 g-col-sm-6">
<div class="nav-btn">
<p><a href="../../../../../foundations-frontiers/index.qmd">Back to Foundations &amp; Frontiers</a></p>
</div>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-12">

</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>Copyright and licence</dt>
<dd>
© 2025 EICC
</dd>
</dl>
</div>


</div>
</div>

 ]]></description>
  <category>AI</category>
  <category>Communication</category>
  <category>Skills</category>
  <guid>https://realworlddatascience.net/foundation-frontiers/posts/2025/09/17/EICC_Live.html</guid>
  <pubDate>Wed, 17 Sep 2025 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/foundation-frontiers/posts/2025/09/17/images/ELgraphic.png" medium="image" type="image/png" height="144" width="144"/>
</item>
<item>
  <title>All Creatures, Great, Small, and Artificial</title>
  <dc:creator>Robyn Lowe and Edward Rochead</dc:creator>
  <link>https://realworlddatascience.net/foundation-frontiers/posts/2025/08/26/new veterinary medicine.html</link>
  <description><![CDATA[ 





<p>This article had its genesis when co-author Ed’s dog, Sparkle, was treated for pneumonia in the summer of 2024. Ed, a mathematician and chair of the <a href="https://alliancefordatascienceprofessionals.com/">Alliance for Data Science Professionals</a>, was intrigued by the surgery’s use of data in Sparkle’s treatment and decided to find out more about the use of data and AI in veterinary medicine. His exploration led to a guest appearance on the <a href="https://www.vetvoices.co.uk/podcasts">Vet Voices on Air</a> podcast hosted by co-author Robyn. She is a registered veterinary nurse (RVN) and the director of <a href="https://www.vetvoices.co.uk/">Veterinary Voices UK</a>. Inspired by that conversation, this article explores the ways veterinary professionals are currently applying data science principles and how professions adapt and evolve in the face of these developments.</p>
<div id="fig-1" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center" alt="Sparkle. Credit: Edward Rochead.">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="https://realworlddatascience.net/foundation-frontiers/posts/2025/08/26/images/Sparkle.png" class="img-fluid quarto-figure quarto-figure-center figure-img" alt="Sparkle. Credit: Edward Rochead.">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;1: Sparkle. Credit: Edward Rochead
</figcaption>
</figure>
</div>
<p>The use of AI and the data science that underpins and enables it are growing in ubiquity, and one area that is embracing these approaches is veterinary medicine.</p>
<p>Unlike human medicine in the UK, veterinary medicine is not organised under a centralised system such as the National Health Service (NHS). Instead, veterinary care is delivered through a variety of business structures, including Joint Venture Practices, Independent, Corporate, and Charity. These structures differ not only in ownership and funding but also in the scope and services that the practices provide. In many cases,the availability of more specialised care may depend on the expertise of individual(s) within the practice. Broadly speaking, practices tend to include: farm animals; exotics; equine; small animal; and mixed. Some practices will cover zoological work, conservation work and invertebrate work among other specialties.</p>
<p>Veterinary surgeons and RVNs are also employed in academia, conducting applied research in industry or government, and as advisors in government agencies.</p>
<section id="data-in-the-veterinary-profession-challenges-and-opportunities" class="level2">
<h2 class="anchored" data-anchor-id="data-in-the-veterinary-profession-challenges-and-opportunities">Data in the Veterinary Profession: Challenges and Opportunities</h2>
<p>If Artificial Intelligence (AI) is to be used in any sphere, it needs to be trained on data. The data used to train should be relevant, complete, structured, accurate, consistently formatted, and labelled. Achieving this standard is a challenge not only in veterinary medicine but also in many other fields where data are fragmented and inconsistently recorded. In the veterinary profession, unlike centralised NHS data, the veterinary data are often stored in individual practices or farms. These may use different formats and scales (such as imperial or metric), US or UK date formats, and twelve or twenty-four hour clocks. These records may also fail to follow the animal if it is sold or moves to a new practice. Such inconsistencies mirror the difficulties faced in other domains, and can make the adoption of AI in veterinary medicine particularly complex..</p>
<p>On the other hand, animal data has fewer constraints than human data. Article 4 of the <a href="https://www.gov.uk/data-protection">UK General Data Protection Regulation</a> (GDPR) makes it clear that the act applies to ‘personal data’ and specifies that ‘an identifiable natural person is one who can be identified’, which means that there is potentially more freedom to use data related to animals than humans. (It is worth noting that the GDPR would apply to the farmer, pet owner, or veterinary staff involved, so some consideration might still be required.) Given this data is an asset, it is worth considering whether it is owned by the animal’s owner or the veterinary professional (or their employer) in any given circumstance.</p>
</section>
<section id="how-ai-is-already-transforming-veterinary-practice" class="level2">
<h2 class="anchored" data-anchor-id="how-ai-is-already-transforming-veterinary-practice">How AI is Already Transforming Veterinary Practice</h2>
<p>AI is becoming an affordable and widely used tool in veterinary medicine. It’s now commonly applied in areas like diagnostics, treatment, and disease monitoring and prediction, despite the misconception that it’s rarely used. Preventative healthcare has always been a key aim within veterinary medicine. The obligation to ensure that both animal health and welfare and public health are accounted for is reflected by point 6.1 of the <a href="https://www.rcvs.org.uk/setting-standards/advice-and-guidance/code-of-professional-conduct-for-veterinary-surgeons/#public">Code of Professional Conduct for Veterinary Surgeons</a> and <a href="https://www.rcvs.org.uk/setting-standards/advice-and-guidance/code-of-professional-conduct-for-veterinary-nurses/#public">RVNs</a>: ‘6.1 Veterinary surgeons must seek to ensure the protection of public health and animal health and welfare’.</p>
<p><strong>Diagnostics</strong><br>
Diagnosis and prediction of diseases is one key area where AI is being used in veterinary medicine in farm animals, companion animals and beyond.</p>
<p>For example, in companion animals AI has been used to assist in the diagnosis of canine <a href="https://pubmed.ncbi.nlm.nih.gov/32006871/">hypoadrenocorticism</a>, an endocrine disease. Additionally, machine learning algorithms have potential for improving the <a href="https://pubmed.ncbi.nlm.nih.gov/40440642/">prediction and diagnosis</a> of leptospirosis, an infectious zoonotic disease. Additionally, by combining MRI data with facial image analysis, an AI tool can assist in predicting the likelihood of <a href="https://onlinelibrary.wiley.com/doi/full/10.1111/jvim.15621">chiari like malformation (CM) and syringomyelia (SM)</a> from images of the dog’s head obtained via an owner’s smartphone. And finally, AI can also assist with faecal analysis: images are analysed by proprietary <a href="https://dugganvet.ie/ovacyte/">Artificial Intelligence models</a> which reference the images against the Telenostic Reference Library, a company specialising in parasitology diagnostic solutions. The image recognition software identifies each specific parasite species and the number of parasitic eggs or oocysts present.</p>
<p>These are just a few examples of AI use in companion animals currently.</p>
<p><strong>Disease Monitoring and Prediction</strong> Disease monitoring and prediction are exciting because they can help us act earlier—sometimes even preventing illness. This not only improves animal health and welfare, but also supports <a href="https://www.skeptic.org.uk/2024/05/agr-tech-will-technology-help-or-hinder-food-production-and-animal-welfare/">antimicrobial stewardship</a> by reducing unnecessary treatments, helping to combat antimicrobial resistance—a serious global threat to both animals and humans.</p>
<p>An area that demonstrates compelling evidence of these positive outcomes is <a href="https://www.skeptic.org.uk/2024/05/agr-tech-will-technology-help-or-hinder-food-production-and-animal-welfare/">farming and agriculture</a>, where farmers are able to use AI to monitor herds, and act promptly to treat disease, before it would have been evident and notable by human monitoring. Examples, which will be explored in more detail below, include body condition technology, lameness technology, disease recognition, grazing, land and pasture management, biosensors and biochips and more.</p>
<div id="fig-2" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center" alt="Technology that measures body condition each time the cow passes under the camera, reporting the changes in Body Condition Score directly to the farmer via app and online portal, helping to support individual cow treatment, group rationing and herd management.">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="https://realworlddatascience.net/foundation-frontiers/posts/2025/08/26/images/herdvision1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" alt="Technology that measures body condition each time the cow passes under the camera, reporting the changes in Body Condition Score directly to the farmer via app and online portal, helping to support individual cow treatment, group rationing and herd management.">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2: Technology that measures body condition each time the cow passes under the camera, reporting the changes in Body Condition Score directly to the farmer via app and online portal, helping to support individual cow treatment, group rationing and herd management.
</figcaption>
</figure>
</div>
<p><strong>Body Condition Technology</strong> The agricultural industry typically relies on subjective visual observation, human recording and manual reporting of all the key health and welfare traits, including Body Condition Score (BCS). Despite these individuals being highly skilled professionals, there is inevitable human error, paired with the constraints of busy farm management which can lead to cases getting picked up later in their disease process. BCS is a major indicator of metabolic performance in dairy cows and directly related to fertility performance and health traits. Technologies such as <a href="https://herd.vision/">Herdvision</a> use a 2D and 3D camera system to monitor BCS, resulting in improvement in cattle heath and fertility, less premature culling, and savings on feeding costs.</p>
<p><strong>Lameness Technology</strong><br>
Lameness is considered one of the <a href="https://www.frontiersin.org/articles/10.3389/fvets.2019.00094/full">top cattle health and welfare challenges</a>. A <a href="https://www.sciencedirect.com/science/article/abs/pii/S1871141313001698">2013 study</a> noted that almost 70% of the dairy farmers expressed an intention to take action for improving dairy cow foot health. Cattle naturally mask the signs of pain, and as with body condition scoring we have relied on subjective visual observation, human recording and manual reporting of all the key health and welfare traits. Technology that can pick up lameness earlier, with more objectivity and with less labour intensity is hugely beneficial to both the animals’ health and welfare and the farm’s profitability.</p>
<div id="fig-3" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center" alt="Images that produce prioritisation list for vets and hoof trimmers, ranking cows according to severity of immobility and identifying small changes in mobility and BCS before they are visible to the human eye.">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-3-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="https://realworlddatascience.net/foundation-frontiers/posts/2025/08/26/images/herdvision2.png" class="img-fluid quarto-figure quarto-figure-center figure-img" alt="Images that produce prioritisation list for vets and hoof trimmers, ranking cows according to severity of immobility and identifying small changes in mobility and BCS before they are visible to the human eye.">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-3-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;3: Images that produce prioritisation list for vets and hoof trimmers, ranking cows according to severity of immobility and identifying small changes in mobility and BCS before they are visible to the human eye.
</figcaption>
</figure>
</div>
<p><strong>Disease Recognition</strong> As with lameness assessments, monitoring of pain in the UK pig industry relies on human observation, either in person or via video footage, to detect disease.</p>
<p>An interdisciplinary team at the Newcastle University have <a href="https://www.ukri.org/who-we-are/how-we-are-doing/research-outcomes-and-impact/bbsrc/ai-based-monitoring-aids-on-farm-disease-detection/">used artificial intelligence to develop automated systems</a> to analyse and monitor pig behaviour and health. The algorithm was tested in a controlled environment where infection and disease were present, assessing footage of pigs captured by cameras and pinpointing and quantifying changes in behaviours to identify links to disease.</p>
<p>Other computer vision and AI-based approaches have allowed the <a href="https://www.sciencedirect.com/science/article/abs/pii/S0168169920300673">automatic scoring</a> of pigs in relation to posture, aggressive episodes, tail-biting episodes, fouling, diarrhoea, stress prediction in piglets, weight estimation, and body size – all providing animal farmers increased insight into the health of their population.</p>
<p><strong>Grazing, Land and Pasture Management</strong> The use of AI has allowed more efficient pasture and grazing management, allowing movement of livestock onto new pastures when the grazing quality and quantity depletes below a certain threshold.</p>
<p>There are numerous methods of using Agri-Tech to monitor animals, such as the <a href="https://www.mdpi.com/1424-8220/19/3/603">SheepIT</a> project, an initiative where an automated IoT-based system controls grazing sheep. Typically, such solutions are split into two main groups: location monitoring and behaviour and activity monitoring. Location monitoring allows farmers to keep track of animals, inferring preferred pasturing areas and grazing times, and even detecting absent animals. Behaviour and activity monitoring focuses on detecting the type and duration of an animal’s activities – for example resting, eating or running - based on accelerometry and audiometry.</p>
<p><strong>Biosensors and Biochips</strong> In human medicine, advances in molecular medicine and cell biology have <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3270855/">driven the interest in electrochemical systems to detect disease biomarkers</a> and therapeutic compounds (medications for example). Currently in human literature, implantable biosensors have been noted in <a href="https://www.sciencedirect.com/science/article/abs/pii/S0956566305003544">glucose monitoring</a>, <a href="https://ieeexplore.ieee.org/abstract/document/4118162/">DNA detection</a> and <a href="https://www.sciencedirect.com/science/article/abs/pii/S0003269708007264">cultures</a>, among others. Microelectronic technology offers powerful circuits and systems to develop innovative and miniaturised biochips for sensing at the molecular level; these have numerous applications in veterinary medicine from hormone detection, pathogenic microorganism and infection monitoring and homeostatic mechanism surveillance (homeostasis being the bodies regulatory mechanisms that controls many functions and maintain stability) such as being applied to <a href="https://www.anl.gov/article/biochips-to-investigate-cattle-disease-win-entrepreneurial-challenge">pathogen detection</a> in cattle mastitis.</p>
<p>Paul Horwood, Farm Vet and Founder of <a href="https://www.bsas.org.uk/events/ailive/">AI(Live)</a>, a conference on the development of AI applications in the livestock industry, sees this as a time of opportunity for the profession:</p>
<p><em>“The farm vet’s role continues to evolve from”problem-solver after the fact” to “strategic advisor at the heart of herd health planning.” Technology is helping us get there by giving us earlier insights, better data, and stronger evidence for the decisions we make every day. We’re at a pivotal moment. The technology is here. The challenge is knowing how to use it and how to lead with it. As a farming nation, we have always been innovative; as farm animal veterinary surgeons, we can either wait to be brought in at the end of the conversation, or step forward now to shape how AI is used on UK farms. Let’s choose the latter.”</em></p>
<p><strong>Shared Frontiers: Common Threads in AI Adoption Across Sectors</strong></p>
<p>The veterinary sector, like every other industry, is on a journey when it comes to the use of artificial intelligence, and many of the themes that are emerging are common to other sectors.</p>
<p>For veterinary professionals this includes:</p>
<ul>
<li>The need to radically change training of new vets and RVNs to ensure that they are prepared to embrace the new opportunities that AI will bring.<br>
</li>
<li>The need to upskill existing vets and RVNs to enable them to use these new opportunities.</li>
<li>Working with stakeholders, such as in this case farmers and pet owners, to evolve the business model to ensure that all parties benefit from the change.</li>
<li>A change in the attitude to data, in which it becomes seen as a business asset when it is well managed, with the ultimate benefit in this sector of promoting the wellbeing of animals.</li>
</ul>
<p>These recurring patterns offer a blueprint for understanding how professions evolve in response to developments in the field, and a reminder that AI isn’t just transforming high-tech labs and Fortune 500 boardrooms – it is quietly revolutionising industries across every sector. By looking at how specific professions, like veterinary, are navigating this shift, we can better understand the broader dynamics at play when machine learning meets existing practice.</p>
</section>
<section id="bridging-disciplines-unlocking-value-through-interdisciplinary-collaboration" class="level2">
<h2 class="anchored" data-anchor-id="bridging-disciplines-unlocking-value-through-interdisciplinary-collaboration">Bridging Disciplines: Unlocking Value Through Interdisciplinary Collaboration</h2>
<p>This is a pivotal moment where the intersection of data science and veterinary medicine offers a unique opportunity for cross-sector collaboration, driving progress in both fields.</p>
<p>The field of data science has much to offer industries currently experiencing these inflection points. Although many data scientists come from ‘traditional’ backgrounds such as statistics, mathematics, or computer science graduates, many more diverse routes to data science roles now exist. These routes include people who wouldn’t necessarily call themselves data scientists who work in other professions who use data science in their working life, upskilling themselves through training, or even trial and error. The authors are already aware of veterinary professionals who are skilled data scientists, even if they may not identify as such, applying data science to veterinary research in academia or industry. The RSS, other professional bodies within the Alliance for Data Science Professionals, and Data Science departments in universities may find offering Continuous Professional Development opportunities to the veterinary profession worthwhile. Certainly, the certifications offered by the RSS of Data Science Practitioner and Advanced Data Science Practitioner are open to veterinary professionals who have developed such skills.</p>
<p>The veterinary profession may also provide benefits to the data science community, by providing data sets that can be applied in many ways without major GDPR issues, as well as opportunities to showcase the benefits of data science to society and animal health and welfare through examples similar to those above.</p>
<p>One vehicle for more cross-pollination could be joint conferences. A near-term opportunity is <a href="https://www.ailive.farm/">AI (Live)</a> in September 2025, which aims to start the debate and establish the principles by which AI and livestock farming can derive the maximum benefits, with a focus on education, governance and application.</p>
<p>By fostering collaboration across disciplines, we can ensure that the benefits of this data revolution are shared—by all creatures, great, small, and artificial. And we are happy to report that Sparkle, whose illness sparked this article, has made a full recovery and in fact recently celebrated her ninth birthday!</p>
<div class="article-btn">
<p><a href="../../../../../foundation-frontiers/index.html">Explore more data science ideas</a></p>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-12">
<dl>
<dt>About the author</dt>
<dd>
<a href="https://www.linkedin.com/in/robyn-lowe-7274a596/"><strong>Robyn Lowe, BSc (Hons), Dip AVN (Surgery, Medicine, Anaesthesia), Dip HE CVN, RVN</strong></a>, is a registered veterinary nurse and Director of <a href="https://www.vetvoices.co.uk/">Veterinary Voices UK</a>, a community of veterinary professionals fostering public understanding of veterinary and animal welfare issues. She hosts the organisation’s <a href="https://open.spotify.com/show/2DcdmAMJrwRf2RdgUPcYCP">Vet Voices on Air</a> podcast.
</dd>
<dd>
<a href="https://www.linkedin.com/in/prof-edward-r-17768847/"><strong>Professor Edward Rochead, M.Math (Hons), PGDip, CMath, FIMA</strong></a> is a mathematician employed by the government, currently leading work on STEM Skills and Data. Ed is chair of the Alliance for Data Science Professionals, a Visiting Professor at Loughborough University, an Honorary Professor at the University of Birmingham, Chartered Mathematician, and Fellow of the IMA and RSA.
</dd>
</dl>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>Copyright and licence</dt>
<dd>
© 2025 Robyn Lowe and Edward Rochead.
</dd>
</dl>
<p><a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> <img style="height:22px!important;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"></a> Text, code, and figures are licensed under a Creative Commons Attribution 4.0 (CC BY 4.0) <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;">International licence</a>, except where otherwise noted. Thumbnail image by <a href="https://www.shutterstock.com/image-photo/cattle-cow-animal-farm-veterinary-agriculture-1463752661">Shutterstock/g/fotopanorama360</a> <a href="https://creativecommons.org/licenses/by/4.0/">Licenced by CC-BY 4.0</a>.</p>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>How to cite</dt>
<dd>
Lowe, Robyn and Rochead, Edward. 2025. “All Creatures, Great, Small, and Artificial” Real World Data Science, August 22nd, 2025. <a href="https://realworlddatascience.net/foundation-frontiers/posts/2025/08/22/veterinary-medicine.html">URL</a>
</dd>
</dl>
</div>
</div>
</div>


</section>

 ]]></description>
  <category>AI</category>
  <category>Algorithms</category>
  <category>Machine Learning</category>
  <guid>https://realworlddatascience.net/foundation-frontiers/posts/2025/08/26/new veterinary medicine.html</guid>
  <pubDate>Tue, 26 Aug 2025 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/foundation-frontiers/posts/2025/08/26/images/vet.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>Deploying Agentic AI - What Worked, What Broke, and What We Learned</title>
  <link>https://realworlddatascience.net/applied-insights/case-studies/posts/2025/08/12/deploying-agentic-ai.html</link>
  <description><![CDATA[ 





<section id="we-built-agentic-systems.-heres-what-broke." class="level2" data-number="1">
<h2 data-number="1" class="anchored" data-anchor-id="we-built-agentic-systems.-heres-what-broke."><span class="header-section-number">1</span> We Built Agentic Systems. Here’s What Broke.</h2>
<p>When Agentic AI started dominating research papers, demos, and conference talks, I was curious but cautious. The idea of intelligent agents, autonomous systems powered by large language models that can plan, reason, and take actions using tools, sounded brilliant in theory. But I wanted to know what happened when you used them. Not in a toy notebook or a slick demo, but in real projects, with real constraints, where things needed to work reliably and repeatably.</p>
<p>In my role as Clinical AI &amp; Data Scientist at Bayezian Limited, I work at the intersection of data science, statistical modelling, and clinical AI governance, with a strong emphasis on regulatory-aligned standards such as CDISC. I have been directly involved in deploying agentic systems into environments where trust and reproducibility are not optional. These include real-time protocol compliance, CDISC mapping, and regulatory workflows. We gave agents real jobs. We let them loose on messy documents. And then we watched them work, fail, learn, and (sometimes) recover.</p>
<p>This article is not a critique of Agentic AI as a concept. I believe Agentic AI has potential value, but I also believe it demands more critical evaluation. That means assessing these systems in conditions that mirror the real world, not in benchmark papers filled with sanitised datasets. It means observing what happens when agents are under pressure, when they face ambiguity, and when their outputs have real consequences. What follows is not speculation about what Agentic AI might become a decade from now. It is a candid reflection on what it feels like to use these systems today. It is about watching a chain of prompts unravel or a multi-agent system drop the baton halfway through a task. If we want Agentic AI to be trustworthy, robust, and practical, then our standards for evaluating it must be shaped by lived experience rather than theoretical ideals.</p>
</section>
<section id="what-agentic-ai-looks-like-in-practice" class="level2" data-number="2">
<h2 data-number="2" class="anchored" data-anchor-id="what-agentic-ai-looks-like-in-practice"><span class="header-section-number">2</span> What Agentic AI Looks Like in Practice</h2>
<p>If you’re imagining robots in lab coats, that’s not quite what this is. It is more like releasing a highly motivated intern into a complex archive with partial instructions, limited supervision, and the freedom to decide which filing cabinets, databases, or tools to open next. It is messy. It is unpredictable. And it sometimes surprises you with just how resourceful or confused it can get. Agentic AI systems are purpose-built setups where a large language model is given a task and enough autonomy to decide how to approach it. That might mean choosing which tools to use, when to use them, and how to adapt when things go off-script. You are not just sending one prompt and getting an answer. You are watching a system reason, remember, call APIs, retry when things go wrong, and ideally, get to a useful result.</p>
<p>At Bayezian, we have explored this in several internal projects, including generating clinical codes from statistical analysis plans and study specifications, monitoring synthetic Electronic Health Records (EHRs) for rule violations, and running chained reasoning loops to validate document alignment. These efforts reflect the reality of building LLM agents into safety-critical and compliance-heavy workflows. Across these deployments, the question is never just “can it do the task” but “can it do the task reliably, interpretably, and safely in context”.</p>
<p>Broader research has followed similar directions. In clinical pharmacology and translational sciences, researchers have explored how AI agents can automate modelling and trial design while keeping a human in the loop, and offering blueprints for scalable, compliant agentic workflows link. In the context of patient-facing systems, agentic retrieval-augmented generation has improved the quality and safety of educational materials, with LLMs acting as both generators and validators of content link. Other teams have used multi-agent systems to simulate cross-disciplinary collaboration, where each AI agent brings a different scientific role to design and validate therapeutic molecules like SARS-CoV-2 nanobodies link.</p>
<p>Some of the systems we built used agent frameworks like LangChain or LlamaIndex. Others were bespoke combinations of APIs, function libraries, memory stores, and prompt stacks wired together to mimic workflow behavior. Regardless of the architecture, the core structure remained the same. The agent was given a task, a bit of autonomy, and access to tools, and then left to figure things out. Sometimes it worked. Sometimes it did not. That gap between intention and execution is where most of the interesting lessons sit.</p>
<p>In the next section, I describe one of those deployments in more detail: a multi-agent system used to monitor data flow in a simulated clinical trial setting.</p>
</section>
<section id="case-study-monitoring-protocol-deviations-with-agentic-ai" class="level2" data-number="3">
<h2 data-number="3" class="anchored" data-anchor-id="case-study-monitoring-protocol-deviations-with-agentic-ai"><span class="header-section-number">3</span> Case Study: Monitoring Protocol Deviations with Agentic AI</h2>
<p><strong>Why We Built It</strong></p>
<p>Clinical trials generate a stream of complex data, from scheduled lab results to adverse event logs. Hidden in that stream are subtle signs that something may be off: a visit occurred too late, a test was skipped, or a dose changed when it shouldn’t have. These are protocol deviations, and catching them quickly matters. They can affect safety, skew outcomes, and trigger regulatory scrutiny.</p>
<p>Traditionally, reviewing these events is a painstaking task. Study teams trawl through spreadsheets and timelines, cross-referencing against lengthy protocol documents. It is time-consuming, easy to miss context, and prone to delay. We wondered whether an AI-driven approach could act like a vigilant reviewer. Not to replace the team, but to help it focus on what truly needed attention.</p>
<p>Our motivation was twofold. First, to introduce earlier, more consistent detection without relying on rule-based systems that often buckle under real-world variability. Second, to test whether a group of coordinated language model agents, each with a clear focus, could carry out this work at scale while still being interpretable and auditable.</p>
<p>To do that, we built the system from the ground up. We designed a pipeline that could ingest clinical documents, extract key protocol elements, embed them for semantic search, and store them in structured form. That created the foundation for agents to work not just as readers of data, but as context-aware monitors. Understanding whether a missed Electrocardiogram (ECG) or a delayed Day 7 visit violated the protocol required more than lookup tables. It required reasoning. It required memory. It required agents built with intent.</p>
<p>What emerged was a system designed not just to scan data, but to think with constraints, assess context, and escalate issues when the boundaries of the trial were breached. The goal was not perfection, but partnership. A system that could flag what mattered, explain why, and stay open to human feedback.</p>
<p><strong>How It Was Set Up</strong></p>
<p>The system was built around a group of focused agents, each responsible for checking a specific type of protocol rule. Rather than relying on one large model to do everything, we broke the task into smaller parts. One agent reviewed visit timing. Another checked medication use. Others handled inclusion criteria, missed procedures, or serious adverse events. This made each agent easier to understand, easier to test, and less likely to be overwhelmed by conflicting information.</p>
<p>Before any agents could be activated, however, an early classifier was introduced to determine what type of document had arrived. Was it a screening form or a post-randomisation visit report? That initial decision shaped the downstream path. If it was a screening file, the system activated the inclusion and exclusion criteria checker. If it was a visit document, it was handed off to agents responsible for tracking timing, treatment exposure, scheduled procedures, and adverse events.</p>
<p>These agents did not operate in isolation. They worked on top of a pipeline that handled the messy reality of clinical data. Documents in different formats were extracted, cleaned, and converted into structured representations. Tables and free text were processed together. Key elements from study protocols were embedded and stored to allow flexible retrieval later. This gave the agents access to a searchable memory of what the trial actually required.</p>
<p>While many agentic systems today rely heavily on frameworks like LangChain or LlamaIndex, our system was built from the ground up to suit the demands of clinical oversight and regulatory traceability. We avoided packaged orchestration frameworks. Instead, we constructed a lightweight pipeline using well-tested Python tools, giving us more control over transparency and integration. For semantic memory and search, protocol content was indexed using FAISS, a vector store optimised for fast similarity-based retrieval. This allowed each agent to fetch relevant rules dynamically and reason through them with appropriate context.</p>
<p>When patient data flowed in, the classifier directed the document to the appropriate agents. If any agent spotted something unusual, it could escalate the case to a second agent responsible for suggesting possible actions. That might mean logging the issue, generating a report, or prompting a review from the study team. Throughout, a human remained involved to validate decisions and interpret edge cases that needed nuance.</p>
<p>We did not assume the agents would get everything right. The idea was to create a process where AI could handle the repetitive scanning and flagging, leaving people to focus on the work that demanded clinical judgement. The combination of structured memory, clear responsibilities, document classification, and human oversight formed the backbone of the system.</p>
<p>Figure 1 illustrates a two-phase agentic system architecture, where protocol documents are first parsed, structured, and embedded into a searchable memory (green), enabling real-time agents (orange) to classify incoming clinical data from the Clinical Trial Management System (CTMS), reason over protocol rules, detect deviations, and escalate issues with human oversight.</p>
<div id="fig-cde" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-cde-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="https://realworlddatascience.net/applied-insights/case-studies/posts/2025/08/12/images/figure-1-sa.png" class="img-fluid quarto-figure quarto-figure-center figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-cde-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;1: System Architecture and Agent Flow
</figcaption>
</figure>
</div>
<p><strong>Where It Got Complicated</strong></p>
<p>In early tests, the system did what it was built to do. It scanned incoming records, spotted missing data, flagged unexpected medication use, and pointed out deviations that might otherwise have slipped through. On structured examples, it handled the checks with speed and consistency.</p>
<p>But as we moved closer to real trial conditions, the gaps started to show. The agents were trained to recognise rules, but real-world data rarely plays by the book. Information arrived out of order. Visit dates overlapped. Exceptions buried in footnotes became critical. Suddenly, a task that looked simple in isolation became tangled in edge cases.</p>
<p>One of the most frequent problems was handover failure. A deviation might be correctly identified by the first agent, only to be lost or misunderstood by the next. A flagged issue would travel halfway through the chain and then disappear or be misclassified because the follow-up agent missed a piece of context. These were not coding errors. They were coordination breakdowns, small lapses in memory between steps that led to big differences in outcome.</p>
<p>We also found that decisions based on time windows were especially fragile. An agent could recognise that a visit was missing, but not always remember whether the protocol allowed a buffer. That kind of reasoning depended on holding specific details in working memory. Without it, the agents began to misfire, sometimes raising the alarm too early, other times not at all.</p>
<p>None of this was surprising. We had built the system to learn from its own limitations. But seeing those moments play out across agents, in ways that were subtle and sometimes difficult to trace, helped surface the exact places where autonomy met ambiguity and where structure gave way to noise.</p>
<p><strong>A Glimpse Into the Details</strong></p>
<p>One case brought the system’s limits into focus. A monitoring agent flagged a protocol deviation for a missing lab test on Day 14. On the surface, it looked like a valid call. The entry for that day was missing, and the protocol required a test at that visit. The alert was logged, and the case moved on to the next agent in the chain.</p>
<p>But there was a catch.</p>
<p>The protocol did call for a Day 14 lab, but it also allowed a two-day window either side. That detail had been extracted earlier and embedded in the system’s memory. However, at the moment of evaluation, that context was not carried through. The agent saw an empty cell for Day 14 and treated it as a breach. It did not recall that a test on Day 13, which had already been recorded, fulfilled the requirement.</p>
<p>This was not a failure of logic. It was a failure of coordination. The information the agent needed was available, but not in the right place at the right time. The memory had thinned just enough between steps to turn a routine variation into a false positive.</p>
<p>From a human perspective, the decision would have been easy. A reviewer would glance at the timeline, check the visit window, and move on. But for the agent, the absence of a test on the exact date triggered a response. It did not understand flexibility unless that flexibility was made explicit in the prompt it received.</p>
<p>That small oversight rippled through the process. It triggered an unnecessary escalation, pulled attention away from genuine issues, and reminded us that autonomy without memory is not the same as understanding.</p>
<p><strong>How We Measured Success</strong></p>
<p>To understand how well the system was performing, we needed something to compare it against. So we asked clinical reviewers to go through a set of patient records and mark any protocol deviations they spotted. This gave us a reference set, a gold standard, that we could use to test the agents.</p>
<p>We then ran the same data through the system and tracked how often it matched the human reviewers. When the agent flagged something that was also noted by a reviewer, we counted it as a hit. If it missed something important or raised a false alarm, we marked it accordingly. This gave us basic measures like sensitivity and specificity, in plain terms, how good the system was at picking up real issues and how well it avoided false ones.</p>
<p>But we also looked at the process itself. It was not just about whether a single agent made the right call, but whether the information made it through the chain. We tracked handovers between agents, how often a detected issue was correctly passed along, whether follow-up steps were triggered, and whether the right output was produced in the end.</p>
<p>This helped us see where the system worked as intended and where things broke down, even when the core detection was accurate. It was never just a question of getting the right answer. It was also about getting it to the right place.</p>
<p><strong>What We Changed Along the Way</strong></p>
<p>Once we understood where things were going wrong, we made a few targeted changes to steady the system.</p>
<p>First, we introduced structured memory snapshots. These acted like running notes that captured key protocol rules and exceptions at each stage. Rather than expecting every agent to remember what came before, we gave them a shared space to refer back to. This made it easier to hold onto details like visit windows or exemption clauses, even as the task moved between agents.</p>
<p>We also moved beyond rigid prompt templates. Early versions of the system leaned heavily on predefined phrasing, which limited the agents’ flexibility. Over time, we allowed the agents to generate their own sets of questions and reason through the answers independently. This gave them more space to interpret ambiguous situations and respond with a clearer sense of context, rather than relying on tightly scripted instructions. Alongside this, we rewrote prompts to be clearer and more grounded in the original trial language. Ambiguity in wording was often enough to derail performance, so small tweaks, phrasing things the way a study nurse might, made a noticeable difference. We then added stronger handoff signals. These were markers that told the next agent what had just happened, what context was essential, and what action was expected. It was a bit like writing a handover note for a colleague. Without that, agents sometimes acted without full context or missed the point altogether. Finally, we built in simple checks to track what happened after an alert was raised. Did the follow-up agent respond? Was the right report generated? If not, where did the thread break? These checks gave us better visibility into system behaviour and helped us spot patterns that weren’t obvious from the output alone.</p>
<p>None of these changes made the system perfect. But they helped close the loop. Errors became easier to trace. Fixes became faster to test. And confidence grew that when something went wrong, we would know where to look.</p>
<p><strong>What It Taught Us</strong></p>
<p>The system did not live up to the hype, and it was not flawless, but it proved genuinely useful. It spotted patterns early. It highlighted things we might have overlooked. And, just as importantly, it changed how people interacted with the data. Rather than spending hours checking every line, reviewers began focusing on the edge cases and thinking more critically about how to respond. The role shifted from manual detective work to something closer to intelligent triage.</p>
<p>What agentic AI brought to the table was not magic, but structure. It added pace to routine checks, consistency to decisions, and visibility into what had been flagged and why. Every alert came with a traceable rationale, every step with a record. That made it easier to explain what the system had done and why, which in turn made it easier to trust.</p>
<p>At the same time, it reminded us what agents still cannot do. They do not infer the way people do. They do not fill in blanks or read between the lines. But they do follow instructions. They do handle repetition. They do maintain logic across complex checks. And in clinical research, where consistency matters just as much as cleverness, that counts for a lot.</p>
<p>This experience did not make us think agentic systems were ready to run trials alone. But it did show us they could support the process in a way that was measurable, transparent, and worth building on.</p>
<p><strong>What This Taught Us About Evaluation</strong></p>
<p>Working with agentic systems made one thing especially clear. The way most people assess language models does not prepare you for what happens when those models are placed inside a real workflow.</p>
<p>It is easy enough to test for accuracy or coherence in response to a single prompt. But those surface checks do not reflect what it takes to complete a task that unfolds over time. When an agent is making decisions, juggling memory, switching between tools, and coordinating with others, a different kind of evaluation is needed.</p>
<p>We began paying attention to the sorts of things that rarely make it into research papers. Could the agent perform the same task consistently across repeated attempts? Did it remember what had just happened a few steps earlier? When one component passed information to another, did it land correctly? Did the agent use the right tool when the moment called for it, even without being told explicitly?</p>
<p>These were not academic concerns. They were practical indicators of whether the system would hold up under pressure. So we built simple ways to track them.</p>
<p>We looked at how stable the agent remained from one run to the next. We measured how often a person needed to step in. We checked whether the agent could retrieve details it had already encountered. And we monitored how information moved through the system, from one part to another, without being lost or altered along the way.</p>
<p>None of this required complex metrics. But each of these signals told us more about how the system behaved in real use than any benchmark ever did.</p>
</section>
<section id="a-call-for-practical-evaluation-standards" class="level2" data-number="4">
<h2 data-number="4" class="anchored" data-anchor-id="a-call-for-practical-evaluation-standards"><span class="header-section-number">4</span> A Call for Practical Evaluation Standards</h2>
<p>If we want reliable ways to judge these systems, we need to start from what happens when they are used in the real world. Much of the current thinking around evaluating agentic AI remains too abstract. It often focuses on what the system is supposed to do in principle, not what it manages to do in practice. But the most useful insights emerge when things fall apart. When an agent loses track of its task, forgets what just happened, or takes an unexpected turn under pressure.</p>
<p><a href="https://sakana.ai/ai-scientist/">A recent assessment of Sakana.ai’s AI Scientist</a> made this point sharply. The system promised end-to-end research automation, from forming hypotheses to writing up results. It was an ambitious step forward. But <a href="https://arxiv.org/html/2502.14297v1">when tested</a>, it fell short in important ways. It skimmed literature without depth, misunderstood experimental methods, and stitched together reports that looked complete but were riddled with basic errors. One reviewer said it read like something written in a hurry by a student who had not done the reading. The outcome was not a failure of intent, but a reminder that sophisticated language does not always reflect sound reasoning.</p>
<p>Instead of designing evaluation methods in isolation, we should begin with real scenarios. That means observing where agents stumble, how they recover, and whether they can carry through when steps are long and outcomes matter. It means showing the messy bits, not just polished results. Tools that help us retrace decisions, inspect memory, and understand what went wrong are just as important as the outputs themselves.</p>
<p>Only by starting from lived use with its uncertainty, complexity, and human oversight, can we build evaluation methods that truly reflect what it means for these systems to be useful.</p>
</section>
<section id="closing-thoughts-from-the-field" class="level2" data-number="5">
<h2 data-number="5" class="anchored" data-anchor-id="closing-thoughts-from-the-field"><span class="header-section-number">5</span> Closing Thoughts from the Field</h2>
<p>Agentic AI carries genuine promise, but even a single deployment can reveal how much distance there is between ambition and execution. These systems can be impressively capable in some moments and surprisingly brittle in others. And in domains where decisions must be precise and timelines matter, that brittleness is more than an inconvenience; it introduces real risk.</p>
<p>The lessons from our experience were not abstract. They came from watching one system try to handle a demanding, high-context task and seeing where it stumbled. It was not a matter of poor design or unrealistic expectations. The complexity was built in, the kind that only becomes visible once a system moves beyond isolated prompts and into continuous workflows.</p>
<p>That is why evaluation needs to begin with real use. With lived attempts, not controlled tests. With unexpected behaviours, not just benchmark scores. As practitioners, we have a front-row seat to what breaks, what improves with small tweaks, and what truly helps. That view should help shape how the field evolves.</p>
<p>If agentic systems are to mature, the stories of where they struggled and how we adapted cannot sit on the sidelines. They are part of how progress happens. And they may be the clearest indicators of what needs to change next.</p>
<div class="article-btn">
<p><a href="../../../../../../applied-insights/case-studies/index.html">Find more case studies</a></p>
</div>
<dl>
<dt>About the authors</dt>
<dd>
<a href="https://www.linkedin.com/in/francis-osei-b2b02116a/"><strong>Francis Osei</strong></a> is the Lead Clinical AI Scientist and Researcher at Bayezian Limited, where he designs and builds intelligent systems to support clinical trial automation, regulatory compliance, and the safe, transparent use of AI in healthcare. His work brings together data science, statistical modelling, and real-world clinical insight to help organisations adopt AI they can understand, trust, and act on.
</dd>
</dl>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>Copyright and licence</dt>
<dd>
© 2025 Francis Osei
</dd>
</dl>
<p><a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> <img style="height:22px!important;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"></a> This article is licensed under a Creative Commons Attribution 4.0 (CC BY 4.0) <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> International licence</a>. Thumbnail photo by <a href="https://www.shutterstock.com/g/donut8449">khunkornStudio</a> on <a href="https://www.shutterstock.com/image-photo/ai-chatbot-technology-virtual-assistant-customer-2582430481">Shutterstock</a>.</p>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>How to cite</dt>
<dd>
Osei, F. (2025). “Deploying Agentic AI: What Worked, What Broke, and What We Learned”, Real World Data Science, August 12, 20245. <a href="https://realworlddatascience.net/applied-insights/case-studies/posts/2025/08/12/deploying-agentic-ai.html">URL</a>
</dd>
</dl>
</div>
<p>::: :::</p>


</section>

 ]]></description>
  <category>Reproducibility</category>
  <category>Data Analysis</category>
  <category>Machine learning</category>
  <category>Statistics</category>
  <guid>https://realworlddatascience.net/applied-insights/case-studies/posts/2025/08/12/deploying-agentic-ai.html</guid>
  <pubDate>Tue, 12 Aug 2025 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/applied-insights/case-studies/posts/2025/08/12/images/agentic-ai.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>Book Review: AI in Business: Towards the Autonomous Enterprise by Sarah Burnett</title>
  <link>https://realworlddatascience.net/the-pulse/posts/2025/08/04/AI-in-Bus-Review.html</link>
  <description><![CDATA[ 





<center>
As AI continues to reshape industries, business leaders are increasingly seeking guidance on how to harness its potential responsibly and effectively. Keeping abreast of these conversations is crucial for data practitioners seeking to guide their non-technical stakeholders and foster cross-functional collaboration. The recently released second edition of <strong><a href="https://shop.bcs.org/page/detail/ai-in-business/?SF1=work_exact&amp;ST1=AIINBUSINESS2">AI in Business: Towards the Autonomous Enterprise</a></strong> (BCS, 2024) aims to help decision-makers understand the strategic opportunities and challenges of AI in a business context. We asked Ed Rochead, Chair of the <a href="https://alliancefordatascienceprofessionals.com/">Alliance for Data Science Professionals</a>, to reflect on the themes, frameworks and case studies it offers.
</center>
<div id="fig-cde" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-cde-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="https://realworlddatascience.net/the-pulse/posts/2025/08/04/Images/bookcover.jpg" class="img-fluid quarto-figure quarto-figure-center figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-cde-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;1: AI in Business: Towards the Autonomous Enterprise
</figcaption>
</figure>
</div>
<p>The key words in the title of the book are ‘autonomous enterprise’: this is a book about using AI to make enterprises more effective with autonomy (AI), rather than (as the cover picture of a robot might suggest) embed autonomous robotic systems in a business.</p>
<p>The volume is in three main parts. The first introduces AI, with useful explanations of terms like “generative AI” and gives some thoughts about how AI might be used for innovation and efficiency in a business. The second part gives some case studies on how real, recognisable organisations have successfully used AI to automate their operations with some success. The third part reflects upon the future, focusing on how an organisation might start the journey towards autonomy, as well as some thoughts on the impact of autonomy on society.</p>
<p>A chapter I found particularly helpful is ‘What You Need to Know About AI.’ It seeks to explain the relevant terms at the level required by an industry or business leader, rather than giving an in-depth technical account of the concepts, and in this the author achieved their intent.</p>
<p>At the heart of the book are the case studies, involving organisations that include international companies, an NHS Trust, and a district council. The reader is likely to have some personal experience of these types of organisations, for instance as a patient or resident. This made the case studies even more engaging, at least to me, as not only could I put myself in the shoes of a leader in the organisation concerned, it was also possible to empathise with those involved in the system. This knowledge and interest really brought the content to life, and this made the author’s choice of case studies inspired.</p>
<p>The closing section is intriguing. The chapter introducing the first steps an organisation might take towards autonomy is helpful, as it illustrates example of the stages of autonomy as applied to buying a car (spoiler alert – in the last stage it is manufactured and then drives itself to the consumer’s home!) The second chapter in this section, looking towards the future, gets the reader thinking more broadly about the impact of automation on society. This includes the thorny issues of ethics and impact on things like (un)employment; both areas were covered engagingly and thought provokingly.</p>
<p>Although impressed with the content of the book, I found the typeface very cramped and small, and joked with friends that 200 pages of material is crammed into 160. This makes the contents a harder read than they might otherwise be.</p>
<p>In one sense, each of the three sections would make a good, if short, book but, read together in the sequence provided, they become more than the sum of their parts, with the first part informative, the second part engaging, and the third thought provoking. <em>AI in Business</em> is an excellent read for an organisational leader seeking inspiration to automate. It gives enough language and concept familiarity to enable such a reader to ask sensible questions of technical experts, and an idea of the art of the possible. Someone with an interest in how AI might change the world around us could also find this a fascinating and informative read.</p>
<div class="article-btn">
<p><a href="../../../../../the-pulse/index.html">Discover more The Pulse</a></p>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-6">
<dl>
<dt>About the author</dt>
<dd>
<a href="https://www.linkedin.com/in/prof-edward-r-17768847/">Professor Edward Rochead, M.Math (Hons), PGDip, CMath, FIMA</a> is a mathematician employed by the government, currently leading work on STEM Skills and Data. Ed is chair of the <a href="https://alliancefordatascienceprofessionals.com/">Alliance for Data Science Professionals</a>, a Visiting Professor at Loughborough University, an Honorary Professor at the University of Birmingham, Chartered Mathematician, and Fellow of the IMA and RSA. Copyright and licence
</dd>
<dd>
© 2025 Royal Statistical Society
</dd>
<dd>
Thumbnail image by <a href="https://www.bcs.org/">BCS</a> <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> <img style="height:22px!important;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"></a> This article is licensed under a Creative Commons Attribution (CC BY 4.0) <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;">International licence</a>.
</dd>
</dl>
</div>
<div class="g-col-12 g-col-md-6">

</div>
</div>
</div>



 ]]></description>
  <category>AI</category>
  <category>Data Science</category>
  <category>Machine learning</category>
  <category>Collaboration</category>
  <guid>https://realworlddatascience.net/the-pulse/posts/2025/08/04/AI-in-Bus-Review.html</guid>
  <pubDate>Mon, 04 Aug 2025 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/the-pulse/posts/2025/08/04/Images/bookcover2.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>From medical history to medical foresight: why the NHS needs its own foundation AI model for prevention</title>
  <link>https://realworlddatascience.net/the-pulse/posts/2025/07/28/NHS-foundation-AI.html</link>
  <description><![CDATA[ 





<p>The point of this article is to, in a mildly entertaining way, persuade you that developing a sovereign foundation AI model should be a priority for the NHS, professional bodies and patients but we need to get the research right.</p>
<p><strong>Risk is personal</strong></p>
<p>How do we move from treating disease to preventing disease? The traditional approach has been to publicise well evidenced public health interventions; don’t smoke, drink less, eat vegetables, exercise, vaccinate, wear sunscreen. This is all very good advice at the population level but for the individual it’s hard to know what to worry about and what to prioritise. I, being a clumsy man with bad ankles and a lack of spatial awareness, am at risk of going to A&amp;E with (another) concussion. You will be different.</p>
<p><strong>A little bit of history</strong></p>
<p>Individualised risk models in healthcare are not new. Traditional statistical approaches have used tabular data to predict healthcare events and have done a good job. These models are converted into questionnaires that clinicians can use to make decisions based on your risk. If you have had the NHS health check; a clinician will have measured blood pressure, cholesterol, height, weight and a few questions on your medical history. They will then feed this into a model and the output is the risk of you having a heart attack or stroke over the next ten years (1). There are also automated approaches built into the systems your GP uses that help stratify the population based on individual risk of things like frailty (2).</p>
<p>These kind of models are usually based on a snapshot of data and require bespoke data pipelines and engineering to massage the data into the right shape for the model, wonderful news for data scientists and statisticians as it leads to a proliferation of finely tuned models which can keep us in gainful employment for many years. However, each one has significant costs to develop, test, validate, deploy and integrate into clinical practice.</p>
<p>Another issue with these traditional models is that they squash a medical history into a single row of data for each patient, losing the chronology of health. Intuitively, we would expect that the sequence of events matters in predicting healthcare outcomes and traditional approaches struggle to capture this.</p>
<p><strong>Using a sequence of events to predict a sequence of events</strong></p>
<p>Sequences of events are easier for data engineers too. It’s much simpler to join together all the data into a sequence than perform a series of complex aggregations and transformations for every model. The simpler the data engineering needed to create the inputs the easier it is to scale as you are making fewer assumptions about the data.</p>
<p>So, if they are easier to engineer, and they capture more information why are they not the standard way of predicting health outcomes? Because modelling sequences is harder than modelling a row of data. As the model sees more of a sequence it has to hold that memory somewhere so that the model can accumulate the appropriate information. Models that could do this started appearing in machine learning literature in the early 1990’s (3) but for a long time we had neither the data, the computing power nor quite the right kind of algorithms to make them useful. Today they have become feasible in healthcare due to the rise in electronic healthcare records, standardised codes for classifying events and the rise of the transformer model. Transformer models combine the ability to hold an internal “memory” of the sequence with the capacity to pay attention to different aspects of the sequence, which basically make them magic.</p>
<p>These models have demonstrated state of the art accuracy in predicting future events using electronic patient histories. Examples for those interested in reading more include BEHRT (4), Med-Bert (5), TransformerEHR (6) and the more recent generative transformer model ETHOS (7). These can be used for a range of healthcare prediction tasks whilst delivering state of the art predictive accuracy, again, magic.</p>
<p>A recent preprint (8) from Microsoft has also demonstrated that these EHR models act in a similar way to the large language models like those backing ChatGPT; their performance scales predictably with processing power, data and the size of the model. This means that more data will probably lead to a better model and we can optimise this model performance to a given computational budget.</p>
<p><strong>So what?</strong></p>
<p>Why should you care about this? If we can take these architectures and train them on data at the scale of the NHS then each individual patient could have a relatively accurate prediction of their most likely next healthcare events(9). It would be your medical history projected forward, providing a narrative that is easier to understand than a page of risk scores. It’s your potential medical future. This could help with changing behaviour to reduce future risk, something we all struggle with. I think of it like the medical version of the ghost of Christmas future but using a chain of events rather than clinking ghost chains.</p>
<p>We are already seeing heavy usage of publicly available large language models for healthcare. 10% of a representative sample of Australians used ChatGPT for medical advice rising to 26% of 25-34 year olds (10) , I assume the UK is similar. It seems that the public is much more ready than the health system to use these models and regulation is struggling to keep up, and for good reason, they may not actually help.</p>
<p><strong>The underwhelming evidence</strong></p>
<p>As of August 2024 there were 950 AI models approved by the FDA, with a significant proportion of those for clinical decision support, but only 2.4% of these are supported by randomised controlled trials (11).</p>
<p>This is important, as what works on a machine learning researcher’s infrastructure may not work in a clinical setting. In 2018, a comprehensive health economic evaluation of a risk prediction model for identifying people at risk of hospital admission found that those in the treatment arm had a higher healthcare cost and there was no significant impact on the number of people being admitted to hospital, despite accurate predictions (12). Some prediction models even cause harmful self-fulfilling prophecies when used for decision making (the paper is well worth a read) (13).</p>
<p><strong>The prize</strong></p>
<p>The UK government is clear about the ambition to be an “AI maker” not an “AI taker”. Given the expected improvement in accuracy from scaling these EHR models, there is an opportunity for the UK to leverage what should be one of its greatest data assets (decades of longitudinal electronic healthcare records from cradle to grave) and create a sovereign foundational model that supports patient care. These are being developed now in the US and elsewhere. A meta-analysis in 2023 found over 80 foundational healthcare models, there are many more today and there is concern that at some point it will be cheaper for the NHS to bring one in and pay for it than to train its own.</p>
<p><strong>Foresight</strong></p>
<p>Fortunately we have made some progress in the UK with NHS data. Foresight (14), a transformer model developed in London on data from 1.4 million patients has demonstrated impressive results . This model has been taken on for covid research to see if the same approach can better predict disease/COVID-19 onset, hospitalisation and death, for all individuals, across all backgrounds and diseases using national data made available during the pandemic for research specifically on covid. This is being done through the British heart foundation’s collaboration with NHS England’s secure data environment (15).</p>
<p>However, just because we can do this, it does not mean that we should. Researchers need to be careful to stay within the bounds of their project and make extraordinary efforts to engage with the public. We have to ensure that our data is not being exploited inappropriately for commercial gain. The Royal College of General Practitioners has raised concerns that this model goes beyond what they agreed to, Professor Kamila Hawthorne, Chair of the Royal College of GPs, said “As data controllers, GPs take the management of their patients’ medical data very seriously, and we want to be sure data isn’t being used beyond its scope, in this case to train an AI programme.” The project has been paused for the time being despite being approved and specifically targeted at covid for research.</p>
<p>The best model for predicting outcomes from covid or the risk factors involved in covid is likely to be a population scale generative transformer model. This research will determine whether that hypothesis is true and whether this kind of data could provide more accurate predictions for patients. The NHS data and the model are kept inside a secure data environment with personal identifiers stripped out. No patient details are passed to researchers and no data or code leaves that environment without explicit permission. This research seems like something we should do.</p>
<p>Despite the potential of AI assisted clinicians for differential diagnosis (with recent evidence that they perform better than both clinicians alone and clinicians using search (16) and the attractiveness of having your medical history and your medical future in your pocket, we are a way off this reality. The gap between research and demonstrating the cost-effectiveness of AI solutions in the real world is significant but all the component parts needed to close this gap exist; the data, the models, the research capability and the political will.</p>
<p>We will get there. Foundational models in healthcare are no longer a theoretical possibility, but an imminent reality. The UK has a rare opportunity to lead, not follow, by building a sovereign AI model trained on NHS data to accelerate the transition from treating disease to preventing disease. To get there, we must confront hard questions about patient engagement and real-world benefit. But to stop research based solely on the sophistication of the method is to misunderstand the moment. I think patients expect us to do better.</p>
<div class="keyline">
<hr>
</div>
<p><strong>References</strong></p>
<ol type="1">
<li><p>Hippisley-Cox, J., Coupland, C.A.C., Bafadhel, M. et al.&nbsp;Development and validation of a new algorithm for improved cardiovascular risk prediction. Nat Med 30, 1440–1447 (2024). https://doi.org/10.1038/s41591-024-02905-y</p></li>
<li><p>Clegg A, Bates C, Young J, Ryan R, Nichols L, Ann Teale E, Mohammed MA, Parry J, Marshall T. Development and validation of an electronic frailty index using routine primary care electronic health record data. Age Ageing, May;45(3):353-60, (2016) https://doi.org/10.1093/ageing/afw039.</p></li>
<li><p>Jeffrey L. Elman,Finding structure in time,Cognitive Science,Volume 14, 179-211, (1990). https://doi.org/10.1016/0364-0213(90)90002-E</p></li>
<li><p>Li, Y., Rao, S., Solares, J.R.A. et al.&nbsp;BEHRT: Transformer for Electronic Health Records. Sci Rep 10, 7155 (2020). https://doi.org/10.1038/s41598-020-62922-y</p></li>
<li><p>Rasmy, L., Xiang, Y., Xie, Z. et al.&nbsp;Med-BERT: pretrained contextualized embeddings on large-scale structured electronic health records for disease prediction. npj Digit. Med. 4, 86 (2021). https://doi.org/10.1038/s41746-021-00455-y</p></li>
<li><p>Yang, Z., Mitra, A., Liu, W. et al.&nbsp;TransformEHR: transformer-based encoder-decoder generative model to enhance prediction of disease outcomes using electronic health records. Nat Commun 14, 7857 (2023). https://doi.org/10.1038/s41467-023-43715-z</p></li>
<li><p>Renc, P., Jia, Y., Samir, A.E. et al.&nbsp;Zero shot health trajectory prediction using transformer. npj Digit. Med. 7, 256 (2024). https://doi.org/10.1038/s41746-024-01235-0</p></li>
<li><p>Grout R, Gupta R, Bryant R, Elmahgoub MA, Li Y, Irfanullah K, Patel RF, Fawkes J, Inness C. Predicting disease onset from electronic health records for population health management: a scalable and explainable Deep Learning approach. Front Artif Intell. 2024 Jan 8;6:1287541. doi: 10.3389/frai.2023.1287541.</p></li>
<li><p>Sheng Zhang et al.&nbsp;Exploring Scaling Laws for EHR Foundation Models (2025) arXiv:2505.22964v1</p></li>
<li><p>Julie Ayre, Erin Cvejic and Kirsten J McCaffery. Use of ChatGPT to obtain health information in Australia, 2024: insights from a nationally representative survey Med J Aust (2025). doi: 10.5694/mja2.52598</p></li>
<li><p>Windecker D, Baj G, Shiri I, Kazaj PM, Kaesmacher J, Gräni C, Siontis GCM. Generalizability of FDA-Approved AI-Enabled Medical Devices for Clinical Use. JAMA Netw Open. 2025 Apr 1;8(4):e258052. doi: 10.1001</p></li>
<li><p>Snooks H et al.&nbsp;Predictive risk stratification model: a randomised stepped-wedge trial in primary care (PRISMATIC). Southampton (UK): NIHR Journals Library; 2018 Jan.&nbsp;PMID: 29356470.</p></li>
<li><p>van Amsterdam WAC, van Geloven N, Krijthe JH, Ranganath R, Cinà G. When accurate prediction models yield harmful self-fulfilling prophecies. Patterns (N Y). 2025 Apr 11;6(4):101229. doi: 10.1016/j.patter.2025.101229.</p></li>
<li><p>Kraljevic, Zeljko et al.&nbsp;Foresight—a generative pretrained transformer for modelling of patient timelines using electronic health records: a retrospective modelling study. The Lancet Digital Health, Volume 6, Issue 4, e281 - e290</p></li>
<li><p>CVD-COVID-UK/COVID-IMPACT: Projects CCU078: Foresight: a generative AI model of patient trajectories across the COVID-19 pandemic https://bhfdatasciencecentre.org/projects/ccu078/</p></li>
<li><p>McDuff, D., Schaekermann, M., Tu, T. et al.&nbsp;Towards accurate differential diagnosis with large language models. Nature 642, 451–457 (2025). https://doi.org/10.1038/s41586-025-08869-4</p></li>
</ol>
<div class="article-btn">
<p><a href="../../../../../the-pulse/index.html">Discover more The Pulse</a></p>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-6">
<dl>
<dt>About the author</dt>
<dd>
<a href="https://www.linkedin.com/in/will-browne-391b1930/">Will Browne</a> is co-founder of healthcare technology company <a href="https://www.emrys.health/">Emrys Health</a>, where he works on the development of infrastructure for transformative, equitable and accessible healthcare. He is Events Secretary of the <a href="https://rss.org.uk/membership/rss-groups-and-committees/sections/data-science-section/">RSS Data Science and AI section</a> and a member of the <a href="https://rss.org.uk/policy-campaigns/policy-groups/ai-task-force/">RSS AI Taskforce</a>. Copyright and licence
</dd>
<dd>
© 2025 Royal Statistical Society
</dd>
<dd>
Thumbnail image by <a href="https://unsplash.com/@tugcegungormezler?utm_content=creditCopyText&amp;utm_medium=referral&amp;utm_source=unsplash">Tugce Gungormezler</a> / on Unsplash. <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> <img style="height:22px!important;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"></a> This article is licensed under a Creative Commons Attribution (CC BY 4.0) <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;">International licence</a>.
</dd>
</dl>
</div>
<div class="g-col-12 g-col-md-6">

</div>
</div>
</div>



 ]]></description>
  <category>AI</category>
  <category>Data Science</category>
  <category>Machine learning</category>
  <category>Deep learning</category>
  <category>Econometrics</category>
  <guid>https://realworlddatascience.net/the-pulse/posts/2025/07/28/NHS-foundation-AI.html</guid>
  <pubDate>Mon, 28 Jul 2025 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/the-pulse/posts/2025/07/28/Images/NHS.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>Call for Submissions</title>
  <dc:creator>Editorial Board</dc:creator>
  <link>https://realworlddatascience.net/the-pulse/editors-blog/posts/2025/07/08/relaunch-CFS.html</link>
  <description><![CDATA[ 





<p>Get ready to engage with Real World Data Science as we unveil an exciting editorial refresh! We’re thrilled to announce that submissions are now open across our four dynamic sections: The Pulse, Applied Insights, Foundations &amp; Frontiers, and People &amp; Pathways. Join us as we redefine the conversation in data science with fresh perspectives and insights. Real World Data Science is relaunching to meet the pace and complexity of today’s data-driven world in real time, with the RSS’s trademark steadying presence. We will be publishing high-quality case-studies, tutorials and think-pieces that bridge the gap between rigorous analysis and real-time relevance, and that speak directly to latest events and emerging trends.</p>
<p>All submissions will be peer-reviewed by members of the Real World Data Science <a href="https://realworlddatascience.net/the-pulse/editors-blog/posts/2022/10/18/meet-the-team.html">Editorial Board</a>.</p>
<section id="our-audience" class="level2">
<h2 class="anchored" data-anchor-id="our-audience">Our Audience:</h2>
<p>People working in data science looking for practical insights, methodological rigour and thought-leadership that informs their work and decision-making.</p>
</section>
<section id="our-voice" class="level2">
<h2 class="anchored" data-anchor-id="our-voice">Our Voice:</h2>
<p>Authoritative, Trustworthy, Cutting Edge</p>
</section>
<section id="our-editorial-sections" class="level2">
<h2 class="anchored" data-anchor-id="our-editorial-sections">Our Editorial Sections:</h2>
<p>Real World Data Science has four editorial sections. Please read through and consider where your piece would fit best. Each piece we publish needs to be tailored towards the focus of one of these sections.</p>
<p><a href="https://realworlddatascience.net/the-pulse/">THE PULSE</a></p>
<p>News, updates and real time commentary.</p>
<p>Purpose: To respond to current events, trends and debates in the data science world with rigour, insight and relevance.</p>
<p>Content Types: Articles that speak directly to current events/trends/launches</p>
<p>Example Call To Action: Invite readers to share your commentary with their networks as a trusted voice in the space. Invite engagement, discussion and debate over the topics.</p>
<p><a href="https://realworlddatascience.net/applied-insights/">APPLIED INSIGHTS</a><br>
How data science is used to solve real-world problems in business, public policy and beyond.</p>
<p>Purpose: To showcase real-world applications of data science, including hands-on tutorials, project walk-throughs, and case studies from industry, academia, or public service.</p>
<p>Content Types:</p>
<ul>
<li>High-quality step-by-step tutorials with code<br>
</li>
<li>Case studies detailing a problem, approach, and outcome<br>
</li>
<li>Lessons learned from real-world deployments</li>
</ul>
<p>Example Call To Action: Readers should walk away with something to try.</p>
<p><a href="https://realworlddatascience.net/foundation-frontiers/">FOUNDATIONS &amp; FRONTIERS</a><br>
The ideas behind the impact: the concepts, tools and methods that make data science possible.</p>
<p>Purpose: To deepen understanding of the theoretical and ethical foundations of data science, and to spotlight thought leadership and emerging ideas.</p>
<p>Content Types:</p>
<ul>
<li>Think-piece style articles with an engaging angle on methodology, ethics and standards<br>
</li>
<li>Interviews with thought-leaders<br>
</li>
<li><a href="https://realworlddatascience.net/foundation-frontiers/datasciencebites/">Data Science Bites</a> - our handy summaries/explainers of academic papers</li>
</ul>
<p>Example Call To Action: Invite discussion and engagement – pose questions and challenges to the reader.</p>
<p><a href="https://realworlddatascience.net/people-paths/">PEOPLE &amp; PATHS</a><br>
Strategic reflections on careers, leadership and professional evolution in data science.</p>
<p>Purpose: To explore the evolving nature of data science careers through the lens of experience, leadership, and long-term impact. This section highlights how professionals shape and are shaped by the field—through roles, decisions, and philosophies.</p>
<p>Content Types:</p>
<ul>
<li>Profiles of/interviews with senior professionals reflecting on career philosophy and leadership<br>
</li>
<li>Roundtables with experts on hiring, mentoring, or organisational design</li>
<li>Commentary on career-defining trends, such as the rise of AI governance or the shift toward interdisciplinary teams</li>
</ul>
<p>Example Call To Action: Encourage readers to share our strategic insights with their community.</p>
</section>
<section id="use-of-ai-in-submissions" class="level2">
<h2 class="anchored" data-anchor-id="use-of-ai-in-submissions">Use of AI in Submissions</h2>
<p>We recognise that LLMs and other generative AI tools are increasingly part of the data science workflow, from code generation and data cleaning to drafting documentation and shaping analysis. We welcome a transparent approach in submissions that have made use of these tools, and ask that authors include a declaration outlining where and how AI was used in the development of their submission. This helps us maintain transparency, uphold standards of reproducibility, and better understand the evolving role of AI in real-world data science practice.</p>
<p>To make your submission, please review our <a href="https://realworlddatascience.net/contributor-docs/contributor-guidelines.html">contributor guidelines</a> and email us at rwds@rss.org.uk</p>
<div class="article-btn">
<p><a href="../../../../../../the-pulse/editors-blog/index.html">Back to Editors’ blog</a></p>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-6">
<dl>
<dt>Copyright and licence</dt>
<dd>
© 2025 Royal Statistical Society
</dd>
</dl>
<p><a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> <img style="height:22px!important;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"></a> This article is licensed under a Creative Commons Attribution 4.0 (CC BY 4.0) <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> International licence</a>. Thumbnail photo by <a href="https://unsplash.com/@johnsonvr?utm_content=creditCopyText&amp;utm_medium=referral&amp;utm_source=unsplash">Virgina Johnson</a> on <a href="https://unsplash.com/photos/turned-on-red-open-neon-sigange-QmNnZj_Ok-M?utm_content=creditCopyText&amp;utm_medium=referral&amp;utm_source=unsplash">Unsplash</a>.</p>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>How to cite</dt>
<dd>
Real World Data Science Editorial Board. 2025. “Call for Submissions” Real World Data Science, July 7, 2025. <a href="https://realworlddatascience.net/the-pulse/editors-blog/posts/2025/07/07/relaunch-CFS.html">URL</a>
</dd>
</dl>
</div>
</div>
</div>


</section>

 ]]></description>
  <category>Call for contributions</category>
  <category>Updates</category>
  <guid>https://realworlddatascience.net/the-pulse/editors-blog/posts/2025/07/08/relaunch-CFS.html</guid>
  <pubDate>Mon, 07 Jul 2025 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/the-pulse/editors-blog/posts/2025/07/08/Images/open.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>We’re Back: Real World Data Science Relaunches</title>
  <dc:creator>Editorial Board</dc:creator>
  <link>https://realworlddatascience.net/the-pulse/editors-blog/posts/2025/07/07/editors-relaunch.html</link>
  <description><![CDATA[ 





<p>You may have noticed our brief hiatus. Since publishing our series on AI - which covered <a href="https://realworlddatascience.net/foundation-frontiers/posts/2024/04/29/gen-ai-human-intel.html">the quest for human-level intelligence</a>, <a href="https://realworlddatascience.net/foundation-frontiers/posts/2024/05/07/ai-series-3.html">data-set risks</a>, <a href="https://realworlddatascience.net/foundation-frontiers/posts/2024/05/14/ai-series-2.html">ethical considerations</a> and much more - the ongoing deluge of content and commentary on AI in the wider world has continued to accelerate. This year has seen a surge in developments that sit at the intersection of data science and AI: from the growing use of synthetic data to overcome privacy and bias challenges, to the rise of multi-modal models that demand increasingly sophisticated data engineering and integration techniques. The emergence of Agentic AI has sparked new conversations around data provenance, model interpretability, and the reproducibility crisis in machine learning. Meanwhile, the meteoric rise of open-source disruptor DeepSeek triggered stock-market ruptures and industry panic, before <a href="https://www.theguardian.com/technology/2025/jan/27/deepseek-cyberattack-ai">cyber-attacks</a>, <a href="https://www.wiz.io/blog/wiz-research-uncovers-exposed-deepseek-database-leak">data leaks</a> and a <a href="https://gizmodo.com/deepseek-gets-an-f-in-safety-from-researchers-2000558645?utm_source=pocket_shared">failed safety test</a> complicated its standing - a parable for the volatility of the space, where data governance failures and safety oversights can rapidly derail innovation. Meanwhile, governments worldwide are <a href="https://www.aa.com.tr/en/europe/macron-announces-112b-in-ai-investment-over-coming-years/3477218?utm_source=pocket_saves">investing heavily</a> in <a href="https://assets.publishing.service.gov.uk/media/67851771f0528401055d2329/ai_opportunities_action_plan.pdf?utm_source=substack&amp;utm_medium=email">national data infrastructure</a> and advanced analytics capabilities, while grappling with how best to regulate a field that is evolving faster than policy can keep up.</p>
<p>The world of data science has been a dizzying place over the last few months, so we took a moment to pause and take stock. In the face of rapid change and constant noise, it felt important to reflect with intention on the role Real World Data Science can and should play in this evolving landscape. Now we’re back - ready to rejoin the conversation with renewed clarity and purpose.</p>
<p>As a project from the <a href="https://rss.org.uk/">Royal Statistical Society</a>, in partnership with the <a href="https://www.amstat.org/">American Statistical Association</a>, we are backed by organisations with nearly two centuries of history in championing sound evidence, rigorous methodology and ethical data use. These values form the foundation of our next phase - distilled into the essential pillars: data, evidence and decision. With an esteemed editorial board representing the cutting-edge of industry and academia, and an international network of practitioners working at the coalface of modern data science, we are uniquely placed to navigate the pace and complexity of today’s data-driven world. Real World Data Science will meet that world in real time with the RSS’s trademark steadying presence, bridging the gap between rigorous analysis and real-time relevance.</p>
<p>We are now returning with a slightly refreshed site, encompassing four editorial sections:<br>
<a href="https://realworlddatascience.net/the-pulse/">The Pulse</a> - covering news, updates and real-time commentary<br>
<a href="https://realworlddatascience.net/applied-insights/">Applied Insights</a> - exploring how data science is used to solve real-world problems in business, public policy and beyond<br>
<a href="https://realworlddatascience.net/foundation-frontiers/">Foundations &amp; Frontiers</a> - unpicking the ideas behind the impact: the concepts, tools and methods that make data science possible<br>
<a href="https://realworlddatascience.net/people-paths/">People &amp; Paths</a> - offering strategic reflections on careers, leadership and professional evolution in data science.</p>
<p>You can find the full details of these sections, plus guidance around submitting to them, in our new <a href="https://realworlddatascience.net/the-pulse/editors-blog/posts/2025/07/08/relaunch-CFS.html">Call for Submissions</a>.</p>
<p>Despite these updates, we remain committed to providing content that is useful and relevant for practicing data scientists seeking to learn good practices in the field and new potential applications.</p>
<p>The choices we make now will shape how data and AI serve society for years to come. If you’re working on the front lines of these changes, whether through research, practice, or critical reflection, we invite you to share your insights and help us build a future for data science that is thoughtful, transparent and grounded in real world understanding.</p>
<p><a href="https://realworlddatascience.net/the-pulse/editors-blog/posts/2022/10/18/meet-the-team.html">Meet the Team</a></p>
<div class="article-btn">
<p><a href="../../../../../../the-pulse/editors-blog/index.html">Back to Editors’ blog</a></p>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-6">
<dl>
<dt>Copyright and licence</dt>
<dd>
© 2025 Royal Statistical Society
</dd>
</dl>
<p><a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> <img style="height:22px!important;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"></a> This article is licensed under a Creative Commons Attribution 4.0 (CC BY 4.0) <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> International licence</a>.</p>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>How to cite</dt>
<dd>
Real World Data Science Editorial Board. 2025. “We’re Back: Real World Data Science Relaunches” Real World Data Science, July 7, 2025. <a href="https://realworlddatascience.net/the-pulse/editors-blog/posts/2025/07/07/editors-relaunch.html">URL</a>
</dd>
</dl>
</div>
</div>
</div>



 ]]></description>
  <category>Call for contributions</category>
  <category>Updates</category>
  <guid>https://realworlddatascience.net/the-pulse/editors-blog/posts/2025/07/07/editors-relaunch.html</guid>
  <pubDate>Mon, 07 Jul 2025 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/the-pulse/editors-blog/posts/2025/07/07/images/team.png" medium="image" type="image/png" height="77" width="144"/>
</item>
<item>
  <title>RSS: Data Science and Artificial Intelligence - showcase your research</title>
  <link>https://realworlddatascience.net/foundation-frontiers/datasciencebites/posts/2025/02/05/DSAI-journal.html</link>
  <description><![CDATA[ 





<p><img src="https://realworlddatascience.net/foundation-frontiers/datasciencebites/posts/2025/02/05/images/RSS-DSAI-Logo-blue.png" class="img-fluid" style="width:80.0%" alt="RSS Data Science and AI logo"><br>
</p>
<p><em>RSS: Data Science and Artificial Intelligence</em> provides a new forum for research of interest to a broad readership, spanning the data science fields. Created in recognition of the growing importance of data science and artificial intelligence in science and society, the new journal aims to fill the need for a venue that truly spans the relevant fields.</p>
<div class="img-float">
<p><img src="https://realworlddatascience.net/foundation-frontiers/datasciencebites/posts/2025/02/05/images/RSS-DSAI-cover.jpg" class="img-fluid" style="float: left; margin-right: 25px;;width:25.0%"></p>
</div>
<p>This new open access journal joins the RSS family of world class statistics journals and is published by Oxford University Press.</p>
<section id="scope-and-type-of-papers" class="level2">
<h2 class="anchored" data-anchor-id="scope-and-type-of-papers">Scope and type of papers</h2>
<p><em>RSS: Data Science and Artificial Intelligence</em> is seeking high quality papers from across the breadth of these disciplines which encompass statistics, machine learning, deep learning, econometrics, bioinformatics, engineering, computational social sciences and beyond.</p>
<p>As well as three primary paper types - method papers, applications papers and behind-the-scenes papers - <em>RSS: Data Science and Artificial Intelligence</em> will publish editorials, op-eds, interviews, and reviews/perspectives in line with its goal to become a primary destination for data scientists</p>
</section>
<section id="why-publish" class="level2">
<h2 class="anchored" data-anchor-id="why-publish">Why Publish?</h2>
<p><em>RSS: Data Science and Artificial Intelligence</em> offers an exciting open access venue for your work with a broad reach and is peer reviewed by editors esteemed in their field. Discover more about <a href="https://academic.oup.com/rssdat/pages/why-publish" target="_blank">why the new journal is the ideal platform for showcasing your research</a></p>
</section>
<section id="submit-a-paper" class="level2">
<h2 class="anchored" data-anchor-id="submit-a-paper">Submit a paper</h2>
<p>Find out how to <a href="https://academic.oup.com/jrsssa/pages/general-instructions" target="_blank">prepare your manuscript</a> for submission and visit our submission site to <a href="https://mc.manuscriptcentral.com/rssdat" target="_blank">submit your paper</a></p>
<div class="keyline">
<hr>
</div>
</section>
<section id="editors" class="level2">
<h2 class="anchored" data-anchor-id="editors">Editors</h2>
<p>&nbsp;</p>
<div class="grid">
<div class="g-col-12 g-col-md-4">
<p><img src="https://realworlddatascience.net/foundation-frontiers/datasciencebites/posts/2025/02/05/images/Mukherjee_Sach.jpg" class="img-fluid" alt="Photo of Mukherjee, Director of Research in Machine Learning for Biomedicine at the MRC"></p>
<p><strong>Sach Mukherjee</strong> is Director of Research in Machine Learning for Biomedicine at the Medical Research Council (MRC) Biostatistics Unit, University of Cambridge, and Head of Statistics and Machine Learning at the German Center for Neurodegenerative Diseases.</p>
</div>
<div class="g-col-12 g-col-md-4">
<p><img src="https://realworlddatascience.net/foundation-frontiers/datasciencebites/posts/2025/02/05/images/silvia-chiappa.jpeg" class="img-fluid" alt="Silvia Chiappa, Research Scientist at Google DeepMind"></p>
<p><strong>Silvia Chiappa</strong> is a Research Scientist at <a href="https://deepmind.com/" target="_blank">Google DeepMind</a> London, where she leads the Causal Intelligence team, and Honorary Professor at the <a href="https://www.ucl.ac.uk/computer-science/" target="_blank">Computer Science Department</a> of University College London.</p>
</div>
<div class="g-col-12 g-col-md-4">
<p><img src="https://realworlddatascience.net/foundation-frontiers/datasciencebites/posts/2025/02/05/images/neil-lawrence.png" class="img-fluid" alt="Neil Lawrenece, DeepMind Professor of Machine Learning at the University of Cambridge"></p>
<p><strong>Neil Lawrenece</strong> is the inaugural DeepMind Professor of Machine Learning at the University of Cambridge. He has been working on machine learning models for over 20 years. He recently returned to academia after three years as Director of Machine Learning at Amazon.</p>
</div>
</div>
<p><br>
</p>
<p><strong>View the full editorial board here:</strong> <a href="https://academic.oup.com/rssdat/pages/editorial-board" target="_blank">Editorial Board | RSS Data Science | Oxford Academic (oup.com)</a></p>
</section>
<section id="open-access" class="level2">
<h2 class="anchored" data-anchor-id="open-access">Open Access</h2>
<p><em>RSS: Data Science and Artificial Intelligence</em> is fully open access (OA) and is published by Oxford University Press (OUP). Your research will be free to read and can be accessed globally. An OA license increases the visibility of your research and creates more opportunities for fellow researchers to read, share, cite, and build upon your findings.</p>
<p>The cost of publishing Open Access may be covered under a Read and Publish agreement between OUP and the corresponding author’s institution. <a href="https://academic.oup.com/pages/open-research/read-and-publish-agreements/participating-journals-and-institutions" target="_blank">Find out if your institution is participating</a>. Members of the Royal Statistical Society can submit papers at a reduced cost.</p>
<p>Explore the journal’s website now <a href="https://www.academic.oup.com/rssdat" target="_blank">www.academic.oup.com/rssdat</a></p>
<div class="article-btn">
<p><a href="../../../../../../foundation-frontiers/index.html">Explore more data science ideas</a></p>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-6">
<dl>
<dt>Copyright and licence</dt>
<dd>
© 2023 Royal Statistical Society
</dd>
</dl>
<p><a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> <img style="height:22px!important;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"></a> This article is licensed under a Creative Commons Attribution (CC BY 4.0) <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;">International licence</a>.</p>
</div>
<div class="g-col-12 g-col-md-6">

</div>
</div>
</div>


</section>

 ]]></description>
  <category>AI</category>
  <category>Data Science</category>
  <category>Machine learning</category>
  <category>Deep learning</category>
  <category>Econometrics</category>
  <guid>https://realworlddatascience.net/foundation-frontiers/datasciencebites/posts/2025/02/05/DSAI-journal.html</guid>
  <pubDate>Wed, 05 Feb 2025 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/foundation-frontiers/datasciencebites/posts/2025/02/05/images/RSS-DS-AI-cover.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>Defining Purposes and Uses to Support the Development of Statistical Products in a 21st Century Census Curated Data Enterprise Environment</title>
  <link>https://realworlddatascience.net/applied-insights/case-studies/posts/2024/11/22/development-plan-2.html</link>
  <description><![CDATA[ 





<center>
Acknowledgments: This research was sponsored by the: <br> Unites States Census Bureau Agreement No.&nbsp;01-21-MOU-06 and <br> Alfred P. Sloan Foundation Grant No.&nbsp;G-2022-19536
</center>
<p><br> <br> <em>The views expressed in this article are those of the authors and not the Census Bureau.</em></p>
<section id="summing-it-up" class="level2" data-number="1">
<h2 data-number="1" class="anchored" data-anchor-id="summing-it-up"><span class="header-section-number">1</span> Summing it up</h2>
<p>We end where we began in the first article of our series. Through this four-part series, we introduced a Curated Data Enterprise (CDE) Framework (see Figure&nbsp;1) that can guide the development and dissemination of statistics broadly applicable to addressing social and economic issues while ensuring replicability and reusability. The CDE provides the scaffold for scaling the statistical product development of interest to the US Census Bureau and broadly applies to official statistics agencies <span class="citation" data-cites="keller2022bold">(Keller et al. 2022)</span>. We illustrated this through a use case on climate resiliency of skilled nursing facilities, highlighting the replicability and reusability of the capabilities that would benefit inclusion in a CDE.</p>
<div id="fig-cde" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-cde-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="https://realworlddatascience.net/applied-insights/case-studies/posts/2024/11/22/images/figure-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-cde-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;1: The CDE Framework starts with the purposes &amp; uses of the statistical products. The outer rectangle identifies the guiding principles for ethical, transparent, reproducible statistical product development and dissemination. The inner rectangle identifies the statistical product development steps.
</figcaption>
</figure>
</div>
<p>As noted in the first three articles, the process begins with articulating purposes and uses through stakeholder engagement and continues by leveraging that engagement, including subject matter expertise, to inform statistical product development. Eliciting purposes and uses from stakeholders and data users is facilitated by asking questions such as: &nbsp;</p>
<ol type="1">
<li><p>What questions keep you awake at night because you don’t have data insights to address them? What are those purposes and uses that you need statistical products to support?</p></li>
<li><p>How do we collaborate and engage with you to better understand your needs and help you identify gaps in understanding regarding purpose and use?</p></li>
<li><p>How do we prioritize what statistical products to develop first?</p></li>
</ol>
<p>Examples of purposes and uses that drive new statistical products include accurately measuring gig employment <span class="citation" data-cites="salvo2022gig">(Salvo, Shipp, and Zhang 2022a)</span>, migration due to extreme climate events <span class="citation" data-cites="salvo2022migration">(Salvo, Shipp, and Zhang 2022b)</span>, the various dimensions of housing affordability <span class="citation" data-cites="wu2023housing">(Wu et al. 2023)</span>, and addressing the undercount of young children <span class="citation" data-cites="Salvo2023children">(Salvo, Lancaster, and Shipp 2023)</span>. Other topics that require multiple sources and types of data include creating a household living budget based on the minimum necessary to ensure an adequate standard of living <span class="citation" data-cites="lancaster2023HLB">(Lancaster et al. 2023)</span> and using this budget as a starting point for measuring insecurity across components such as food or housing <span class="citation" data-cites="montalvo2023">(Montalvo et al. 2023)</span>.</p>
</section>
<section id="developing-an-end-to-end-e2e-curation-system" class="level2" data-number="2">
<h2 data-number="2" class="anchored" data-anchor-id="developing-an-end-to-end-e2e-curation-system"><span class="header-section-number">2</span> Developing an end-to-end (E2E) curation system</h2>
<p>Purposes and uses defined in use cases are important to support the rapid development of statistical products. These use cases will capture the imagination of those working to address today’s critical issues and advance public understanding and trust in federal statistics.&nbsp;The above paragraph provides examples of purposes and uses for which we have developed use cases.</p>
<p>Use cases are a powerful mechanism to promote methodological research to develop and implement capabilities needed in a CDE. The objectives are to undertake research projects that have the potential to create statistical products with explicit purposes and uses that will exercise the end-to-end (E2E) curation components.</p>
<p>When implemented, these proposed use cases will demonstrate a sequence of capabilities needed to build the CDE, such as agile data discovery, reusing modules and data (including synthetic data), tracking the provenance of collected and generated data, reusing synthetic data and methods to integrate many types of data, conducting statistical analysis involving heterogeneous data integration, and reviewing data and statistical results with an equity and ethics lens. These steps will be captured in an end-to-end curation system.</p>
<ol type="1">
<li><strong>Criteria for developing and evaluating use cases that will uncover the capabilities and research necessary to develop the CDE</strong></li>
</ol>
<p>Criteria are needed to evaluate, and partner with researchers and stakeholders in developing and implementing the capabilities to capture in the CDE. The choice of use cases, when curated, needs to provide unique insight into CDE capabilities and statistical product development. The capabilities to be developed include addressing some purpose and use that no single source of information can resolve, generating practical diagnostics to improve existing methods, creating pilot software, and validating new and improved statistical products. These criteria, developed through listening sessions and discussions with experts, guide the prioritization and selection of use cases and their evaluation after curation (see Table 2) <span class="citation" data-cites="keller2022bold">(Keller et al. 2022)</span>.</p>
<table class="caption-top table">
<caption>Table 2. Criteria for Selecting and Prioritizing Use Cases to Identify CDE Capabilities</caption>
<colgroup>
<col style="width: 100%">
</colgroup>
<tbody>
<tr class="odd">
<td><strong>Value and feasibility of the CDE approach described in the existing research (potential use case)</strong> to address emerging or long-standing issues, ie, its purpose and use over and above existing approaches to address high-priority problems. | | <strong>Stakeholders’</strong> challenges and issues as the source of purposes and uses. | | <strong>Subject matter experts</strong> to advise on the approach and implementation. | | <strong>Partners to access data</strong> from local and state governments, non-profit organizations, and the private sector, and strategies to overcome legal and administrative barriers to such access that benefits to both the providers and recipients of the data. | <strong>Survey, administrative, opportunity, and procedural data</strong> from multiple sources (eg, local, state, federal, third-party) to address the purpose and use (issue) in an integrated way. There are well-defined data ingestion and governance requirements. | | <strong>Computation and measurement requirements for statistical products include</strong> the unit(s) of analysis and their characteristics, temporal sequence, geocoded location data, and methods for imputations, projections, and statistical analysis. | | <strong>Equity and ethical dimensions are considered</strong> at each step to ensure that the use case provides fair and accurate representation across groups and an assessment that the potential benefits outweigh the potential harm. | | <strong>Evidence of CDE capabilities</strong> to be built, including the code, data, and documentation to create the statistical products, which can be described in the curation step. | | <strong>Statistical products</strong> include integrated data sources, indicators, maps, visualizations, storytelling and analysis. | | Potential viability of proposed <strong>dissemination platforms</strong> for interactive access to data products at all levels of data acumen <span class="citation" data-cites="keller2021acumen">(Keller and Shipp 2021)</span> while adhering to confidentiality and privacy rules. |</td>
</tr>
</tbody>
</table>
<ol start="2" type="1">
<li><strong>An end-to-end curation process</strong></li>
</ol>
<p>Curation is an end-to-end process defined by the context of the purposes and uses that document the decisions and trade-offs at each step in the CDE Framework. The following curation definition will be used as it serves the CDE’s vision.</p>
<p><strong><em>Curation</em></strong> involves documenting, for each statistical product, the <strong>inputs</strong> from which the product is derived, the <strong>wrangling</strong> used to transform the information into product, and the <strong>statistical product</strong> itself. Purposes and uses provide the context for each statistic and statistical product.</p>
<p>This definition has evolved from numerous stakeholder discussions via listening sessions and discussions with Census Bureau staff. <span class="citation" data-cites="nusser2024curation faniel2019context nasem2022transparency">(Nusser et al. forthcoming; Faniel, Frank, and Yakel 2019; NASEM 2022)</span>.</p>
<p>As use cases are curated, the CDE capabilities will evolve to quickly develop statistical products. These curated use cases are integral to developing an E2E curation process for the CDE. &nbsp;</p>
<ol start="3" type="1">
<li><strong>Invitation to contribute purpose and use ideas for developing new statistical products</strong></li>
</ol>
<p>The CDE development aims to curate a significant number of use cases that address social and economic issues that have the potential to define capabilities to be built in the CDE. Initially, they are seeking ideas for purposes and uses to define these use cases and statistical products.</p>
<p>The skilled nursing facility use case included code, data, and documentation to calculate the probability of workers getting to work during a weather event, resilience indicators at the county or sub-county level, alternative skilled nursing home deficiency measures, and other capabilities.</p>
<p><strong>Incorporating capabilities in the CDE</strong></p>
<p>To accelerate the development of statistical products, the Census Bureau will develop use cases to articulate and create CDE capabilities. This requires identifying those valuable nuggets for learning and quickly translating and incorporating this information into the CDE. Examples of critical capabilities of interest are learning about the utility of synthetic data, the ability to aggregate data into custom geographies, and combining different units of analysis. The expected outcome is the creation of an innovative 21<sup>st</sup> Century Census Curated Data Enterprise focused on purposes and uses that overcome the limitations and challenges of today’s survey-alone model. &nbsp;</p>
<p>The 21<sup>st</sup> Century Census Curated Data Enterprise development presents an opportunity for researchers to help drive the development of the CDE as the foundation for creating new statistical products. The US Census Bureau is seeking ideas for purposes and uses that will define new statistical products. They are interested in research projects (use cases) that are guided by the CDE framework as potential new statistical products. They want to learn from and understand your experiences in using the CDE framework, for example, what worked well, what challenges you faced, how each step in the framework was curated, and what capabilities are replicable and reusable for developing and enhancing statistical products.</p>
<div class="nav-btn-container">
<div class="grid">
<div class="g-col-12 g-col-sm-6">
<div class="nav-btn">
<p><a href="../../../../../../applied-insights/case-studies/posts/2024/11/19/use-case-2.html">← Part 3: Climate resiliency of skilled nursing facilities</a></p>
</div>
</div>
</div>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-12">
<dl>
<dt>About the authors</dt>
<dd>
<strong>Stephanie Shipp</strong> leads the Curated Data Enterprise research portfolio and collaborates with the US Census. She is an economist with experience in data science, survey statistics, public policy, innovation, ethics, and evaluation.
</dd>
<dd>
<strong>Joseph Salvo</strong> is a demographer with experience in US Census Bureau statistics and data. He makes presentations on demographic subjects to a wide range of groups about managing major demographic projects involving the analysis of large data sets for local applications.
</dd>
<dd>
<strong>Vicki Lancaster</strong> is a statistician with expertise in experimental design, linear models, computation, visualizations, data analysis, and interpretation.
</dd>
</dl>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>Copyright and licence</dt>
<dd>
© 2024 Stephanie Shipp
</dd>
</dl>
<p><a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> <img style="height:22px!important;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"></a> This article is licensed under a Creative Commons Attribution 4.0 (CC BY 4.0) <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> International licence</a>. Thumbnail photo by <a href="https://unsplash.com/@goumbik">Lukas Blazek</a> on <a href="https://unsplash.com/photos/turned-on-black-and-grey-laptop-computer-mcSDtbWXUZU">Unsplash</a>.</p>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>How to cite</dt>
<dd>
Shipp S, Salvo J, Lancaster V (2024). “Statistical Products in a 21<sup>st</sup> Century Census Curated Data Enterprise Environment” Real World Data Science, November 22, 2024. <a href="https://realworlddatascience.net/applied-insights/case-studies/posts/2024/11/22/development-plan-2.html">URL</a>
</dd>
</dl>
</div>
</div>
</div>



</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0">
<div id="ref-faniel2019context" class="csl-entry">
Faniel, Ixchel M, Rebecca D Frank, and Elizabeth Yakel. 2019. <span>“Context from the Data Reuser’s Point of View.”</span> <em>Journal of Documentation</em> 75 (6): 1274–97. <a href="https://doi.org/10.1108/JD-08-2018-0133">https://doi.org/10.1108/JD-08-2018-0133</a>.
</div>
<div id="ref-keller2022bold" class="csl-entry">
Keller, Sallie, Kenneth Prewitt, John Thompson, Steve Jost, Christopher Barrett, Sarah Nusser, Joseph Salvo, and Stephanie Shipp. 2022. <span>“A 21st Century Census Curated Data Enterprise. A Bold New Approach to Create Official Statistics. Technical Report.”</span> <em>Proceedings of the Biocomplexity Institute</em> BI-2022-1115: 297–323. <a href="https://doi.org/10.18130/r174-yk24">https://doi.org/10.18130/r174-yk24</a>.
</div>
<div id="ref-keller2021acumen" class="csl-entry">
Keller, Sallie, and Stephanie Shipp. 2021. <span>“Data Acumen in Action.”</span> <em>Notices of the American Mathematical Society</em>. <a href="https://www.ams.org/journals/notices/202109/noti2353/noti2353.html?adat=October%202021&amp;trk=2353&amp;galt=feature&amp;cat=feature&amp;pdfissue=202109&amp;pdffile=rnoti-p1468.pdf
  ">https://www.ams.org/journals/notices/202109/noti2353/noti2353.html?adat=October%202021&amp;trk=2353&amp;galt=feature&amp;cat=feature&amp;pdfissue=202109&amp;pdffile=rnoti-p1468.pdf </a>.
</div>
<div id="ref-lancaster2023HLB" class="csl-entry">
Lancaster, V., M. Montalvo, J. Salvo, and S. Shipp. 2023. <span>“The Importance of Household Living Budget in the Context of Measuring Economic Vulnerability: A Census Curated Data Enterprise Use Case Demonstration.”</span> <em>Proceedings of the Biocomplexity Institute</em> Technical Report. TR# BI-2023-258. <a href="https://doi.org/10.18130/p43z-c742">https://doi.org/10.18130/p43z-c742</a>.
</div>
<div id="ref-montalvo2023" class="csl-entry">
Montalvo, Cesar, Vicki Lancaster, Joseph Salvo, and Stephanie Shipp. 2023. <span>“The Importance of Household Living Budget in the Context of Food Insecurity: A Census Curated Data Enterprise Use Case Demonstration.”</span> <em>Proceedings of the Biocomplexity Institute, Technical Report BI-2023-261</em>. <a href="https://doi.org/10.18130/2kgx-tv50">https://doi.org/10.18130/2kgx-tv50</a>.
</div>
<div id="ref-nasem2022transparency" class="csl-entry">
NASEM. 2022. <span>“Transparency in Statistical Information for the National Center for Science and Engineering Statistics and All Federal Statistical Agencies.”</span> <em>National Academies of Science, Engineering, and Medicine</em>. <a href="https://doi.org/10.1162/99608f92.17405bb6">https://doi.org/10.1162/99608f92.17405bb6</a>.
</div>
<div id="ref-nusser2024curation" class="csl-entry">
Nusser, S., S. Keller, S. Shipp, Z. Zhu, and E. Wu. forthcoming. <span>“Curation in the Context of the Census Curated Data Enterprise (CDE).”</span> <em>TBD</em>, forthcoming.
</div>
<div id="ref-Salvo2023children" class="csl-entry">
Salvo, J., V. Lancaster, and S. Shipp. 2023. <span>“The Net Undercount of Children Under 5 Years of Age in the Decennial Census: An Art of the Possible Use Case.”</span> <em>Proceedings of the Biocomplexity Institute</em> Technical Report. TR# BI-2023-000. <a href="https://doi.org/10.18130/nzyj-m621">https://doi.org/10.18130/nzyj-m621</a>.
</div>
<div id="ref-salvo2022migration" class="csl-entry">
Salvo, J., S. Shipp, and S. Zhang. 2022b. <span>“Building a Case Study of Domestic Migration and the Curated Data TR# 2022-027 - Essential Elements.”</span> <em>Proceedings of the Biocomplexity Institute</em> Technical Report BI 2022-027 (2022b). <a href="https://doi.org/10.18130/bcwa-gt69">https://doi.org/10.18130/bcwa-gt69</a>.
</div>
<div id="ref-salvo2022gig" class="csl-entry">
———. 2022a. <span>“Defining the Role of Gig Employment in the Post-Pandemic World of Work.”</span> <em>Proceedings of the Biocomplexity Institute</em> Technical Report BI 2022-026 (2022a).<a href=".&nbsp;https://doi.org/10.18130/wkx0-4y46">&nbsp;https://doi.org/10.18130/wkx0-4y46</a>.
</div>
<div id="ref-wu2023housing" class="csl-entry">
Wu, E., J. Salvo, V. Lancaster, and S. Shipp. 2023. <span>“Housing Affordability – an Art of the Possible Use Case to Develop the 21st Century Census Curated Data Enterprise.”</span> <em>Proceedings of the Biocomplexity Institute</em> Technical Report BI-2023-262. <a href="https://doi.org/10.18130/qgkd-va29">https://doi.org/10.18130/qgkd-va29</a>.
</div>
</div></section></div> ]]></description>
  <category>Public Policy</category>
  <category>Data Analysis</category>
  <category>Data Integration</category>
  <category>Curation</category>
  <category>Statistical Products</category>
  <guid>https://realworlddatascience.net/applied-insights/case-studies/posts/2024/11/22/development-plan-2.html</guid>
  <pubDate>Fri, 22 Nov 2024 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/applied-insights/case-studies/posts/2024/11/22/images/figure-1.png" medium="image" type="image/png" height="81" width="144"/>
</item>
<item>
  <title>Translating the Curated Data Model into Practice - Climate resiliency of skilled nursing facilities</title>
  <dc:creator>Vicki Lancaster, Stephanie Shipp, Sallie Keller, Henning Mortveit, Samarth Swarup, Aaron Schroeder, and Dawen Xie &lt;br /&gt; University of Virginia, Biocomplexity Institute</dc:creator>
  <link>https://realworlddatascience.net/applied-insights/case-studies/posts/2024/11/19/use-case-2.html</link>
  <description><![CDATA[ 





<center>
Acknowledgments: This research was sponsored by the: <br> Unites States Census Bureau Agreement No.&nbsp;01-21-MOU-06 and <br> Alfred P. Sloan Foundation Grant No.&nbsp;G-2022-19536
</center>
<p><br> <br></p>
<section id="introduction" class="level2" data-number="1">
<h2 data-number="1" class="anchored" data-anchor-id="introduction"><span class="header-section-number">1</span> Introduction</h2>
<p>Here, we demonstrate how the CDE Framework can be implemented for a research use case related to skilled nursing facilities. The framework provides the guiding principles for ethical, transparent, and reproducible research and dissemination and the research process for developing the statistical product.</p>
<p>Across the US, federally regulated skilled nursing facilities (SNFs) provide essential care, rehabilitation, and related health services to about 1.3 million people. An SNF is a facility that meets specific federal regulatory certification requirements that enable it to provide short-term inpatient care and services to patients who require medical, nursing, or rehabilitative services. Their patients can be among the most vulnerable members of our society, and yet, historically, SNFs have not been incorporated into existing emergency response systems. For example, during the 2004 Florida hurricane season, SNFs were given the same priority as day spas for restoring electricity, telephones, water, and other essential services <span class="citation" data-cites="hyer2006establishing">(Hyer et al. 2006)</span>. Even worse are the deaths of SNF residents in Louisiana following Hurricanes Katrina and Rita in 2005 <span class="citation" data-cites="dosa2008controversy">(Dosa et al. 2008)</span>. This was still an issue in 2021. In Louisiana, 15 SNF residents died when evacuated to a warehouse during Hurricane Ida (2021), and 12 died in Florida as a result of Hurricane Irma (2017). In both instances, the deaths were attributed to extreme heat and lack of electricity <span class="citation" data-cites="skarha2021association">(Skarha et al. 2021)</span>.</p>
<p>These events prompted the <span class="citation" data-cites="sheet2022protecting">(The White House 2022)</span> initiative, <em>Protecting Seniors by Improving Safety and Quality of Care in the Nation’s Nursing Homes</em>, stating, ‘All people deserve to be treated with dignity and respect and to have access to quality medical care.’</p>
<p>However, there are questions that need to be addressed to best protect SNFs and their residents. For example, how resilient are SNFs in extreme climate events? This use case demonstration shows how we built a new statistical product to address this question using the CDE Framework <span class="citation" data-cites="lancaster2023CDE">(Lancaster et al. 2023)</span>.</p>
</section>
<section id="purposes-and-uses" class="level2" data-number="2">
<h2 data-number="2" class="anchored" data-anchor-id="purposes-and-uses"><span class="header-section-number">2</span> Purposes and uses</h2>
<p>A skilled nursing facility (SNF) is a federally regulated nursing facility with the staff and equipment to provide skilled nursing care, skilled rehabilitation services, and other related health services <span class="citation" data-cites="cmsglossary">(Medicare &amp; Medicaid Services 2023)</span>. The context of this use case is to create a baseline picture of SNFs in Virginia and then integrate information on the risk of extreme flood events to assess facility and community preparedness – for example, how likely are the nursing staff<sup>1</sup> to make it to the facility in the event of a flood?</p>
<p>This use case has two parts. The first creates a baseline data picture of SNFs, bringing together data about the residents, nursing staff, and SNF characteristics. The second addresses two issues raised in the <span class="citation" data-cites="sheet2022protecting">(The White House 2022)</span> initiative: emergency preparedness and nurse staffing. We frame these issues into three purpose and use questions with the ultimate goal of creating statistical products that address these questions:</p>
<ol type="1">
<li><p>Can SNF workers get to work during an extreme flood event?</p></li>
<li><p>Are SNFs prepared for a flood emergency?</p></li>
<li><p>Can communities support SNFs during an emergency?</p></li>
</ol>
</section>
<section id="statistical-product-development-stages" class="level2" data-number="3">
<h2 data-number="3" class="anchored" data-anchor-id="statistical-product-development-stages"><span class="header-section-number">3</span> Statistical product development stages</h2>
<p><strong>Subject matter input and literature review</strong></p>
<p>The subject matter experts consulted included nursing facility administrators, SNF resident advocates, demographers, and researchers. Our discussions and literature review informed us of the many federal policies governing SNFs regarding inspections and data reporting requirements (procedural data). In addition, we were told about non-public data sources on residents and SNF staff that were aggregated to the SNF level and provided to the public under a grant from the National Institute on Aging. This information was important since we had yet to come across this source in our data discovery process. The dialogue with experts and our literature review helped us generate a ‘wish list’ of variables we used to inform our data discovery process that we visualized into a conceptual data map (see Figure&nbsp;1).</p>
<div id="fig-data" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-data-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="https://realworlddatascience.net/applied-insights/case-studies/posts/2024/11/19/images/figure-3.png" class="img-fluid quarto-figure quarto-figure-center figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-data-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;1: Conceptual Data Map Aligned to Purpose and Use: The conceptual data map displays the results of our data discovery. The team identifies the data needs informed by expert elicitation and literature review. For this use case the data discovery took three phases: (1) create a data picture of SNF owners, nursing staff, and residents, and the communities the facilities reside in; (2) identify the potential risks of a severe flood events, coastal and riverine; and (3) identify the potential weakness in the SNF’s and community’s ability to respond.
</figcaption>
</figure>
</div>
<p><strong>Data discovery</strong></p>
<p>Data discovery focused on identifying data sources to address the purpose and use questions and was informed by the conceptual data map.</p>
<p>For the first question – Can SNF workers get to work during an extreme flood event? – we discovered and used proprietary synthetic population, transportation routes, building data sources, and publicly available flood data. The <a href="https://developer.here.com/documentation">HERE Premium Streets</a> proprietary data includes information about roads, such as type of road, speed limits, number of lanes, etc. The proprietary synthetic population data, Building Knowledge Base (BKB), are used to identify where SNF workers live and work to map transportation routes from home to work <span class="citation" data-cites="mortveitNSSAC">(Mortveit, Xie, and Marathe 2023)</span>. Publicly available data from the Federal Emergency Management Administration (FEMA) provided flooding risk estimates along the routes from nursing staff homes to the SNF.</p>
<p>For the second question – Are SNFs prepared for a flood emergency? – we used Center for Medicare and Medicaid (CMS) SNF inspection and deficiency data as a proxy for preparedness. We also examined SNF residents’ physical and mental health to assess SNF emergency preparedness. For example, if most residents faced mobility challenges, the SNF would need more resources available during an emergency to move residents to a safer facility. We used data about residents from the Long Term Care Focus <span class="citation" data-cites="brown2022ltcfocus">(LTCFocus 2022)</span> Public Use Data sponsored by the National Institute on Aging (Brown University 2022).</p>
<p>We used data to measure community resilience, assets, and risks by geography at the county, city, and census tract levels to address the third question, Can communities support SNFs during an emergency? These data included:</p>
<ul>
<li>Health professional shortages area (HRSA 2022)</li>
<li>Shelter facilities and emergency service providers data <span class="citation" data-cites="dhs2022hifld">(Homeland Security: Geospatial Management Office 2022)</span></li>
<li>Community Resilience Indicator Analysis and National Risk Index for Natural Hazards <span class="citation" data-cites="FEMA2022a">(FEMA 2022)</span>.</li>
</ul>
<p>All data are provided in a <a href="https://github.com/uva-bi-sdad/census_cde_demo_2/tree/main/data">GitHub</a> repository along with their metadata, except for the three proprietary data sources. Articles about how the synthetic estimates are constructed are provided for two of these proprietary data sources. The third data source was obtained from a private-sector vendor whose data and documentation are proprietary; a link is provided to their website.</p>
<p><strong>Data ingest and governance</strong></p>
<p>All the public data, metadata, code, statistical products, data processes, and relevant literature on SNF policies and regulations are stored in a <a href="https://github.com/uva-bi-sdad/census_cde_demo_2/tree/main">GitHub</a> repository.</p>
<p>In our experience, data wrangling is the most time-consuming and challenging part of product development. This speaks directly to the benefit of the CDE; once a researcher has wrangled together multiple data sources, it can be made available to other researchers.</p>
<p>The two predominant issues with data wrangling for this Use Case included reconciling data sources that contain data on the same topic and creating linkages between data sources. For example, we reviewed three hospital data sources:</p>
<ol type="1">
<li><a href="https://hifld-geoplatform.opendata.arcgis.com/">Homeland Security Infrastructure Foundation-Level Data</a> (HIFLD) (DHS 2022)</li>
<li><a href="https://healthdata.gov/dataset/COVID-19-Reported-Patient-Impact-and-Hospital-Capa/6xf2-c3ie">HealthData.gov - COVID-19 Reported Patient Impact and Hospital Capacity by State</a> (HHS 2022)</li>
<li><a href="https://vhha.com/about-virginia-hospitals/">Map of VHHA Hospital and Health System Members</a> (Virginia Hospital &amp; Healthcare Association 2022)</li>
</ol>
<p>We observed inconsistences and omissions across the three data sources including:&nbsp;</p>
<ul>
<li>non-standard hospital names and hospital classification types</li>
<li>inconsistent availability of hospital IDs (such as Medicare Provider Number) &nbsp;</li>
<li>conflicting geographic information, including address, latitude, and longitude.</li>
</ul>
<p>We did not attempt to reconcile these inconsistencies for the demonstration but decided to use a single source for shelter facility and emergency service provider data. We used <a href="https://hifld-geoplatform.opendata.arcgis.com/">HIFLD</a> data since they provided the most current data (DHS 2022). The use of these data reinforces the purpose of the use case – to illuminate the challenges in creating statistical products and what the Census Bureau would need to consider.</p>
<p>Similar inconsistencies made it difficult to link data sources using geographic variables. For example, we used shelter facility and emergency service provider data sources from the HIFLD – including hospitals, Red Cross chapter facilities, National Shelter System Facilities, emergency medical service stations, fire stations, and urgent care facilities – to calculate a metric for potential community support. The goal was to place each facility in a Virginia county or independent city. Virginia is divided into 95 counties, and 38 independent cities considered county-equivalents for census purposes, and in some cases, there is a county and a city with the same name (eg, Richmond County and Richmond City, each in different locations in Virginia). It was necessary to <a href="https://en.wikipedia.org/wiki/Canonicalization">canonicalize</a> the county and city names (when available), which meant aligning upper and lower cases, removing unnecessary characters, and distinguishing between county and city.<sup>2</sup></p>
<p>The challenge with locating shelter facilities and emergency service providers within a county or independent city was using different variables to identify their location (latitude and longitude, address, ZIP code<sup>3</sup>, Federal Information and Processing Standard (FIPS) code, and county/city name). In cases where the data source only had a ZIP or FIPS code, a Department of Housing and Urban Development crosswalk was used to link the two codes; in other cases, a crosswalk that linked non-independent cities and towns to counties was used; and in others, a crosswalk that linked FIP codes to counties and independent cities. Researchers would benefit from exhaustive crosswalks between all variables on the same topic, such as location variables, facility names, and identification numbers, to reduce the time spent on data wrangling.</p>
<p>Regarding data products related to popular indices, such as climate disaster risks and community resilience, they are operationalized differently across the various departments and agencies within the federal and state governments and private and non-profit sectors. It is an enormous task to review the methodology and technology reports (if available) to understand their differences and decide which versions are most relevant (fitness-for-purpose) for a particular use case. Again, after reviewing the options for this use case, we determined that the National Risk Index for riverine and coastal floods from FEMA was the best option for climate risk estimates. The detailed technical report, <em>National Risk Index Technical Document</em> <span class="citation" data-cites="FEMA2021risk">(FEMA 2021)</span>, provides a clear assessment of the assumptions and limitations of the data and a description of how the risk estimates were derived. Researchers would benefit from guidance on the numerous constructions of indices on the same topic. A use case on a specific index topic could be used to highlight differences and similarities among indices, which would help with data wrangling and fitness-for-use. Ideally, the use case could benchmark the various constructions and provide a statistical assessment.</p>
<section id="question-1-can-snf-workers-get-to-work-during-an-extreme-flooding-event" class="level3" data-number="3.1">
<h3 data-number="3.1" class="anchored" data-anchor-id="question-1-can-snf-workers-get-to-work-during-an-extreme-flooding-event"><span class="header-section-number">3.1</span> <strong>Question 1: Can SNF workers get to work during an extreme flooding event?</strong></h3>
<p>Sufficient nursing staff is of significant concern to assure resident safety and quality of care.</p>
<p>Since proprietary synthetic population data and commercial sector digitized mapping data were used to construct the routes SNF nursing staff are likely to take from home to work, only an outline of the computational process used to identify the routes is provided. Publicly available data from FEMA were used to estimate flooding risk along a particular route. Below is a general description of the modeling steps and the proprietary data used to assess SNF vulnerability as a function of the nursing staff’s inability to report to work due to the transportation infrastructure <span class="citation" data-cites="choupani2016population">(Choupani and Mamdoohi 2016)</span>.</p>
<p><strong>Computational modules</strong></p>
<p>Here is the basic outline of the process that uses proprietary data that starts at network construction and ends with routes. For more details, see the GitHub repository: <a href="https://github.com/uva-bi-sdad/census_cde_demo_2/blob/main/documents/products/processes/commute_vulnerability/algorithm.md">Vulnerability of SNFs concerning Commuting</a>.</p>
<ol type="1">
<li>Extract network data from HERE (2021 Q1 in this use case).</li>
<li>Process the extracted data to form a network suitable for routing. This includes inference of speed limits for road links where such data is missing.</li>
<li>Prepare origin-destination pairs. In this case, the list of locations pairs a worker’s home and work locations. The person is constructed in the synthetic population pipeline, and residences and workplaces are derived through the data fusion process used to construct the NSSAC building database.</li>
<li>Construct routes using the Quest router.</li>
</ol>
<p>Once the routes to an SNF were established, the expected number of nursing staff at an SNF during a flood event could be calculated as the sum of the probabilities of each worker being able to commute to work during a flood event. A computational model was developed using the following data:</p>
<ul>
<li>SNF locations in Virginia from the Centers for Medicare &amp; Medicaid Services (CMS);</li>
<li>Home locations of workers at each SNF assigned from the synthetic population and Building Knowledge Base <span class="citation" data-cites="beckman1996creating mortveitNSSAC">(Beckman, Baggerly, and McKay 1996; Mortveit, Xie, and Marathe 2023)</span>;</li>
<li>Virginia road networks; and</li>
<li>FEMA census tract-level riverine and coastal flood risks.</li>
</ul>
<p>Using router software, the Virginia road network was used from the HERE map data to compute each nursing staff’s likely route to their SNF. Routers are commonly used within transportation and traffic simulators. The router software used for this demonstration is a highly parallelizable router previously developed in BI NSSAC, known as the Simba router <span class="citation" data-cites="barrett2013planning">(Barrett et al. 2013)</span>.</p>
<p>The FEMA risk data provide the riverine and coastal flood risks for each census tract in Virginia. Given the routes, the FEMA riverine and coastal flood risks were used to estimate the probability of the nursing staff making it to work. The FEMA technical document <em>National Risk Index Technical Document</em> <span class="citation" data-cites="FEMA2021risk">(FEMA 2021)</span> provides information on how natural hazard risks are calculated. We use these risk estimates ranging from 0 to 100 as a proxy for the probability a worker can reach the SNF by dividing by 100. For example, we assume a risk is zero if there is zero probability of being unable to reach the SNF due to an extreme flood event.</p>
<p>In contrast, a risk of 100 indicates the roads are underwater, and the probability of being unable to reach the SNF is one. The maximum risks along transportation routes leading to an SNF range from 0 to 47 for riverine flooding and 0 to 40 for coastal flooding. We assume the combined value of the maximum riverine and coastal flood risks along a worker’s transportation routes, divided by 100, is the worker’s probability of not getting to work during a flooding event.</p>
<p>Since we do not have data on the exact home locations of the nursing staff, we estimated how many could reach the facility by taking a random sample (whose size is the CMS average daily nursing staff<sup>4</sup> for an SNF) from the possible routes identified using the HERE Virginia road network. We calculated the average with a 95% nonparametric confidence interval. The 283 SNFs used in our research have an average daily nursing staff of 12,609. Using the above approach, we estimated that 10,005 (95% CI: 9,013, 10,700) or 79% can get work during an extreme flood event. The individual SNF nursing staff percentage who can make it to work ranges from 48% to 93%.</p>
<p>Figure&nbsp;2 visualizes this analysis for the 283 SNFs ordered by the observed average daily nursing staff numbers at the facility from smallest to largest, displayed using the orange line. The black line indicates the expected number in an extreme flood event and the 95% nonparametric confidence interval (grey band). The code for Figure&nbsp;2 is provided in the <a href="https://github.com/uva-bi-sdad/census_cde_demo_2/blob/main/source_code/analyses/VA_Probability_of_Getting_to_SNF.R">GitHub</a> repository.</p>
<div id="fig-ns" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-ns-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="https://realworlddatascience.net/applied-insights/case-studies/posts/2024/11/19/images/figure-4.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="2000">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-ns-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2: SNF Average Observed and Expected Average Daily Nursing Staff Numbers: The horizontal axis is ordered by the size of the nursing staff at the facility from smallest to largest. The orange line displays the observed average daily nursing staff numbers. The black line displays the estimated numbers in the event of an extreme coastal and/or riverine flood event. The grey band is the 95% nonparametric confidence interval.
</figcaption>
</figure>
</div>
<p>For example, in King George County, the SNF is Heritage Hall King George (Federal Provider Number 495300 in Figure&nbsp;3), located near the Potomac River, which opens to the Chesapeake Bay. According to CMS, the Heritage Hall King George facility has an average daily skilled nursing staff of 41. Using the HERE Virginia road network, we identified 101 routes the staff could use to reach the facility. The combined maximum coastal and riverine flood risks along these routes ranged from 5.6 to 66.7; a random sample of 41 from the 101 routes gives an average probability of reaching the facility of 0.74 with a 95% nonparametric confidence interval of [0.65, 0.80]. These were used to estimate the average number of nursing staff at the facility, 30, during a flood event, along with a 95% nonparametric confidence interval [14, 38]. Publicly available data from the Federal Emergency Management Administration (FEMA) provided flooding risk estimates along the routes from the nursing staff home to the SNF along with proprietary road and building information<strong>.</strong></p>
<div id="fig-map" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-map-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="https://realworlddatascience.net/applied-insights/case-studies/posts/2024/11/19/images/figure-5.png" class="img-fluid quarto-figure quarto-figure-center figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-map-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;3: An Example of Nursing Staff Routes to Heritage Hall King George SNF: Routes that workers can take to work at Heritage Hall  King George SNF FPN 495300 (identified with the black oval). The risk levels of each road are identified with colors, from low risk (blue), medium-low (yellow), orange (medium), red (medium-high), to high risk (dark red). The risk scores are used to calculate the probability of a worker getting to work during an extreme flood event using publicly available FEMA data and proprietary road and building data.
</figcaption>
</figure>
</div>
</section>
<section id="question-2.-are-snfs-prepared-for-emergencies" class="level3" data-number="3.2">
<h3 data-number="3.2" class="anchored" data-anchor-id="question-2.-are-snfs-prepared-for-emergencies"><span class="header-section-number">3.2</span> <strong>Question 2. Are SNFs prepared for emergencies?</strong></h3>
<p>To address this question, we examined how prepared SNFs are for emergencies using annual inspection and deficiency data as a proxy for preparedness. CMS issues deficiencies to SNFs that fail to meet federal Medicare and Medicaid preparedness standards. Every deficiency is classified into one of 12 categories based on the scope and severity of the deficiency. There are two broad types of non-health-related deficiencies:</p>
<ul>
<li><p>Emergency Preparedness Deficiencies – There are four elements of emergency preparedness. They cover an emergency plan, policies and procedures, a communication plan, and training and testing.</p></li>
<li><p>Fire Life Safety Code – The set of fire protection requirements are designed to provide a reasonable degree of safety from fire. They cover construction, protection, and operational features designed to provide safety from fire, smoke, and panic.</p></li>
</ul>
<p>We calculated separate Emergency Preparedness and Fire Life Safety Code deficiency indices to combine them to create a single index to measure SNF preparedness and distinguish between high and low performing SNFs. The computation of the indices has four steps.</p>
<ol type="1">
<li><p><em>Number of deficiencies</em>: For each SNF, the total number of deficiencies during the past four years, 2018-2022, was divided by the number of SNF inspections over the same period to estimate the average number of deficiencies per inspection.</p></li>
<li><p><em>Time to resolve deficiencies</em>: We next computed the average number of days it took to resolve each deficiency.</p></li>
<li><p><em>Scope and severity of deficiencies</em>: We then transformed the deficiency letter inspection rating for scope and severity to a numerical weight using the CMS technical guide, <em>Care Compare Nursing Home Five-Star Quality Rating System</em> <span class="citation" data-cites="CMS2022design">(Medicare &amp; Medicaid Services 2022)</span>,and averaged the ratings.</p></li>
<li><p>The estimates from these three steps were summed to compute separate Emergency Preparedness and Fire Life Safety Code deficiency indices (see Figure&nbsp;4) and are provided for reuse in a .csv file on <a href="https://github.com/uva-bi-sdad/census_cde_demo_2/blob/main/documents/products/processes/derived_variables/va_snf_deficiency_indices_k_e.csv">GitHub</a>.</p></li>
</ol>
<p>Figure&nbsp;4 displays the results of an exploratory data analysis for each index. These analyses assessed fitness-for-use; we wanted to construct an indicator with sufficient variability to discriminate between high and low-performing SNFs. It is evident we accomplished this in Figure&nbsp;4 there are SNFs with indices outside the main body of the data. We summed the Emergency Preparedness and Fire Life Safety Code indices and categorized them into high, medium, low, and no deficiencies.</p>
<div id="fig-def" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-def-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="https://realworlddatascience.net/applied-insights/case-studies/posts/2024/11/19/images/figure-6.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="900">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-def-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4: Exploratory Data Analysis Visualizations for the Emergency Preparedness and Fire Life Safety Code Deficiencies
</figcaption>
</figure>
</div>
</section>
<section id="question-3-can-communities-support-snfs-during-emergencies" class="level3" data-number="3.3">
<h3 data-number="3.3" class="anchored" data-anchor-id="question-3-can-communities-support-snfs-during-emergencies"><span class="header-section-number">3.3</span> <strong>Question 3: Can communities support SNFs during emergencies?</strong></h3>
<p>To answer this question, we computed a community resiliency index using the US Census American Community Survey and the guidance provided by the <em>Homeland Security document Community Resilience Indicator Analysis: County-Level Analysis of Commonly Used Indicators from Peer-Reviewed Research</em> <span class="citation" data-cites="edgemon2018community">(Edgemon et al. 2018)</span><em>.</em> The index was constructed by summing the county (census tract) level percentages for the following variables:</p>
<ul>
<li>fraction employed</li>
<li>fraction with no disability</li>
<li>fraction with a high school diploma or greater</li>
<li>fraction of households with at least one vehicle</li>
<li>reverse GINI Index – so all indicators are in a positive direction.</li>
</ul>
<p>Figure&nbsp;5 displays the combined deficiency indices, Emergency Preparedness + Fire Life Safety Code, for each SNF with the choropleth map for the community resilience index at the census tract level. We also examined the number of shelter facilities and emergency service providers and the availability of medical staff per 10,000 residents. We constructed isochrones to establish the distance from the SNF to these potential sources of support. Working on this component of the use case highlighted the need for cross-agency data, pointing to the utility of future strategic partnering between the US Census Bureau, CMS, and FEMA.</p>
<div id="fig-cri" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-cri-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="https://realworlddatascience.net/applied-insights/case-studies/posts/2024/11/19/images/figure-7.png" class="img-fluid quarto-figure quarto-figure-center figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-cri-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;5: 2020 Population Resilience Composite Index for Virginia Census Tracts: The light yellow tracts are the least resilient, and the dark green are the most resilient. The locations of the 283 SNFs are identified with filled circles, orange circles with the highest
</figcaption>
</figure>
</div>
<p>In addition to describing the population using a resilience index, we also developed a measure to present the number of shelter facilities and emergency service providers (data from Homeland Security / Homeland Infrastructure Foundation Level Data) and the availability of medical doctors (MDs) and Doctor of Osteopathic Medicine (ODs) who provide direct patient care (HRSA 2022) (Figure&nbsp;6).&nbsp;</p>
<p>The number of MDs and ODs is described as a primary care health professional shortage area. HRSA defines these contiguous areas where primary medical care professionals are overutilized, excessively distant, or inaccessible to the population of the area under consideration. Figure&nbsp;6 (bottom) shows that approximately one-third of the counties and independent cities have health professional shortage areas across their entire boundary, and another 40 percent have shortages within parts of their boundaries.</p>
<div id="fig-help" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-help-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="https://realworlddatascience.net/applied-insights/case-studies/posts/2024/11/19/images/figure-8.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="1000">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-help-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;6: Assessment of the number of shelter facilities and emergency service providers per 10,000 population (top) and medically underserved areas (bottom): On both maps, the lighter the color, the more in need is the population of shelter facilities and emergency services (top chart) or health professionals (bottom chart). The location of the 283 SNFs are identified with filled circles, orange circles are those with the highest deficiency index and grey circles are those with no deficiencies.
</figcaption>
</figure>
</div>
</section>
</section>
<section id="guiding-principles-for-ethical-transparent-reproducible-statistical-product-development-and-dissemination." class="level2" data-number="4">
<h2 data-number="4" class="anchored" data-anchor-id="guiding-principles-for-ethical-transparent-reproducible-statistical-product-development-and-dissemination."><span class="header-section-number">4</span> Guiding principles for ethical, transparent, reproducible statistical product development and dissemination.</h2>
<p><strong>Communication</strong></p>
<p>We communicated results throughout the Demonstration Use Case research with our Census CDE Working Group (composed of former Census Bureau Directors and Communication Director, and academic and industry census experts), with the Census Bureau, at conferences such as the annual Federal Statistical Committee on Methodology, and sharing drafts to seek input and ideas. The discussions and presentations helped to shape ideas and advance our thinking about how best to address the purpose and use questions.</p>
<p><strong>Stakeholder engagement</strong></p>
<p>We engaged stakeholders by sharing our research and results through conference presentations at the American Community Survey Data Users Conference and the Applied Public Data Users Conference.&nbsp;We also shared this demonstration project at Listening Sessions with stakeholders as an example of statistical product development. The Listening Sessions bring together 7 to 12 stakeholders by topic (e.g., children’s health) or function (e.g., state demographers) to seek their ideas for new statistical products.</p>
<p><strong>Equity and ethics</strong></p>
<p>As described in the Introduction, there are ethics and equity issues that drew us to develop this Use Case. Here we focus on equity and ethics vis-a-vis the data choices and analyses. With regard to ethical considerations with our data discovery process, fitness-for-purpose evaluation, and analyses, two questions arose:</p>
<ol type="1">
<li><p>What role does synthetic data have to play, and how do you benchmark it to evaluate fitness-for-purpose?</p></li>
<li><p>How do you construct and evaluate an index with the goal of identifying vulnerable populations?</p></li>
</ol>
<p>Realizing the importance of nursing staff levels, we discussed and questioned whether the synthetic data had biases and were not representative of SNF residents and employees. We benchmarked the synthetic SNF nursing staff numbers against those submitted quarterly to CMS and observed they were biased low, so we decided to use the CMS data. These data were used to estimate the average number of nursing staff that could reach the facility during an extreme flood event (Figure&nbsp;2).</p>
<p>In this use case, we were fortunate to have the “truth” to benchmark the synthetic data for the average daily nursing staff at each SNF. But this was not the case for the home locations of the nursing staff, therefore, the synthetic locations were not used since we had no way to benchmark them. Ideally, we would use the actual addresses of SNF employees. Instead, we used a simulation to estimate the average risks over routes leading to the SNF. This approach could be replaced with (or benchmarked against) the Census commuting data sets (eg, <a href="https://www.census.gov/topics/employment/commuting/guidance/flows.html">Commuting Flows</a> or the <a href="https://lehd.ces.census.gov/data/">LEHD Origin-Destination Employment Statistics</a>) and the home census tract used as the starting point for each worker. For the number of nursing staff and their home locations, it is impossible to identify potential biases that would result in the inequitable allocation of emergency rescue resources without a thorough understanding of how the synthetic data were generated.</p>
<p>How one evaluates the equity of an index is a more challenging task. Questions that need to be addressed include:</p>
<ol type="1">
<li><p>How do you select the variables used to construct an indicator to guide an equitable allocation of technical assistance?</p></li>
<li><p>What relationship between these variables is important?</p></li>
<li><p>What are the differences across the numerous publicly available resilience estimators? Do some lead to a more equitable allocation of technical assistance in the event of an extreme clime event?</p></li>
<li><p>How do you validate a resilience estimator?</p></li>
</ol>
<p>The technical document <em>Community Resilience Indicator Analysis: County-Level Analysis of Commonly Used Indicators from Peer-Reviewed Research</em> <span class="citation" data-cites="edgemon2018community">(Edgemon et al. 2018)</span> identified the 20 most commonly selected variables for constructing resilience estimators from peer-reviewed research. Future research will need to validate these indices against past extreme climate events.</p>
<p><strong>Privacy and confidentiality</strong></p>
<p>We did not do a full disclosure review. However, some data are proprietary, and we could not release those data. We discuss how we used these data.</p>
<p><strong>Dissemination</strong></p>
<p>We disseminated the final version of the use case in the University of Virginia Libra Open repository <span class="citation" data-cites="lancaster2023CDE">(Lancaster et al. 2023)</span>.</p>
<p><strong>Curation</strong></p>
<p>Curation involves documenting all steps of the process so that they can be repeated, validated, reused, or extended. The final report explains the process in words. Curation must also provide the data, metadata, source code, and products. This led us to construct a GitHub repository. A <a href="https://github.com/uva-bi-sdad/census_cde_demo_2/blob/main/README.pdf">README</a> file guides the reader through the material and provides instructions for replicating the research results. Note that the README file must be downloaded for the hyperlinks to work.</p>
</section>
<section id="using-the-snf-statistical-product" class="level2" data-number="5">
<h2 data-number="5" class="anchored" data-anchor-id="using-the-snf-statistical-product"><span class="header-section-number">5</span> Using the SNF statistical product</h2>
<p>This potential statistical product has many uses. Federal policymakers and administrators regulate SNFs; however, they only sometimes realize the impacts on costs and the need for increased resources to meet these regulations. For example, by reviewing the aggregate inspection deficiency metrics, policymakers can target resources where they are most needed. Providing additional funding to pay workers more, improve their facilities, and address inspection deficiencies would improve the quality of SNFs.&nbsp;</p>
<p>The media and advocacy groups play a role in highlighting good and bad cases of SNF care or where communities do not have adequate assets to support SNFs during an emergency event. For example, a <em>New Yorker</em> article <span class="citation" data-cites="rafiei2022private">(Rafiei 2022)</span> highlighted how nursing homes decline dramatically when bought by private equity owners. The GAO (September 22, 2023) recently identified the need for more information about private equity ownership in CMS data – a gap that CMS needs to address. And, of course, researchers and analysts are essential for conducting research that leads to creating and improving statistical products around SNFs. By releasing a regularly scheduled SNF statistical product, the changes in SNFs over time can be monitored.</p>
</section>
<section id="what-cde-capabilities-have-this-use-case-demonstrated" class="level2" data-number="6">
<h2 data-number="6" class="anchored" data-anchor-id="what-cde-capabilities-have-this-use-case-demonstrated"><span class="header-section-number">6</span> What CDE capabilities have this use case demonstrated?</h2>
<p>As demonstrated by this use case, the CDE Framework is a powerful process for guiding and curating the development of statistics to address complex purposes and uses. Additionally, use cases help illuminate technical capabilities that should be present in the data enterprise to facilitate and accelerate the reuse of data and methods in the development and dissemination of new statistical products.</p>
<p>This CDE demonstration is the first of many use cases needed to define and develop CDE capabilities. Underlying each use case is the curation process. Curation documents each step, including decisions that may involve trade-offs. Curation preserves and adds value to the data. This includes organizing to facilitate data discovery and easy access; providing metadata to enable the reuse in scientific and programmatic research; enhancing the value of the data enterprise through linkages between datasets; and mapping the network of interconnections between datasets, research outputs, researchers, and institutions. Over time, a searchable curation system will be needed as a foundation for creating statistical products in the CDE.</p>
<p>The types of products from a use case that can benefit the larger community are only limited by the creativity of the researchers and stakeholders carrying out the use case. The products from this use case are re-useable code; integrated data sets across diverse topics for each SNF; maps and other visualizations; statistical products such as SNF deficiency indices and various indices that measure community and SNF resilience; the probability of a worker reaching an SNF in the event of extreme flooding; and a GitHub repo that provides easy access to all these products plus relevant metadata, literature, and government documents and regulations.</p>
<p>Conducting this use case has been an eye-opening experience as to the amount and quality of publicly available data to address our research questions. The statistical capabilities and products flowing from diverse use cases can only be identified as the program progresses.</p>
<div class="nav-btn-container">
<div class="grid">
<div class="g-col-12 g-col-sm-6">
<div class="nav-btn">
<p><a href="../../../../../../applied-insights/case-studies/posts/2024/11/08/what-is-CDE-2.html">← Part 2: What is the CDE?</a></p>
</div>
</div>
<div class="g-col-12 g-col-sm-6">
<div class="nav-btn">
<p><a href="../../../../../../applied-insights/case-studies/posts/2024/11/22/development-plan-2.html">Part 4: Census Curated Data Enterprise Environment →</a></p>
</div>
</div>
</div>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-12">
<dl>
<dt>About the authors</dt>
<dd>
<strong>Vicki Lancaster</strong> is a statistician with expertise in experimental design, linear models, computation, visualizations, data analysis, and interpretation. She works with scientists at federal agencies on projects requiring statistical skills and creativity, eg, defining skilled technical workforce using novel data sources.
</dd>
<dd>
<strong>Stephanie Shipp</strong> leads the Curated Data Enterprise research portfolio and collaborates with the US Census. She is an economist with experience in data science, survey statistics, public policy, innovation, ethics, and evaluation.
</dd>
<dd>
<strong>Sallie Keller</strong> is the Chief Scientist and Associate Director of Research and Methodology at the US Census Bureau. She is a statistician with research interest in social and decision informatics, statistics underpinnings of data science, and data access and confidentiality. Sallie Keller was at the University of Virginia when this work was conducted.
</dd>
<dd>
<strong>Aaron Schroeder</strong> has experience in the technologies and related policies of information and data integration and systems analysis, including policy and program development and implementation.
</dd>
<dd>
<strong>Henning Mortveit</strong> develops massively interacting systems and the mathematics supporting rigorous analysis and understanding of their stability and resiliency.
</dd>
<dd>
<strong>Samarth Swarup</strong> conducts research in computational social science, resiliency and sustainability, and stimulation analytics.
</dd>
<dd>
<strong>Dawen Xie</strong> develops geographic information systems, visual analytics, information management systems, and databases, with a current focus on building dynamic web systems.
</dd>
</dl>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>Copyright and licence</dt>
<dd>
© 2024 Stephanie Shipp
</dd>
</dl>
<p><a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> <img style="height:22px!important;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"></a> This article is licensed under a Creative Commons Attribution 4.0 (CC BY 4.0) <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> International licence</a>. Thumbnail photo by <a href="https://www.shutterstock.com/g/Ground+Picture">Ground Picture</a> on <a href="https://www.shutterstock.com/image-photo/lovely-nurse-assisting-senior-man-get-2006404274">Shutterstock</a>.</p>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>How to cite</dt>
<dd>
Lancaster V, Shipp S, Keller S et al.&nbsp;(2024). “Translating the Curated Data Model into Practice - climate resiliency of skilled nursing facilities” Real World Data Science, November 19, 2024. <a href="https://realworlddatascience.net/applied-insights/case-studies/posts/2024/11/19/use-case-2.html">URL</a>
</dd>
</dl>
</div>
</div>
</div>



</section>


<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0">
<div id="ref-barrett2013planning" class="csl-entry">
Barrett, Christopher, Keith Bisset, Shridhar Chandan, Jiangzhuo Chen, Youngyun Chungbaek, Stephen Eubank, Yaman Evrenosoğlu, et al. 2013. <span>“Planning and Response in the Aftermath of a Large Crisis: An Agent-Based Informatics Framework.”</span> In <em>2013 Winter Simulations Conference (WSC)</em>, 1515–26. IEEE.
</div>
<div id="ref-beckman1996creating" class="csl-entry">
Beckman, Richard J, Keith A Baggerly, and Michael D McKay. 1996. <span>“Creating Synthetic Baseline Populations.”</span> <em>Transportation Research Part A: Policy and Practice</em> 30 (6): 415–29.
</div>
<div id="ref-choupani2016population" class="csl-entry">
Choupani, Abdoul-Ahad, and Amir Reza Mamdoohi. 2016. <span>“Population Synthesis Using Iterative Proportional Fitting (IPF): A Review and Future Research.”</span> <em>Transportation Research Procedia</em> 17: 223–33.
</div>
<div id="ref-dosa2008controversy" class="csl-entry">
Dosa, David M, Kathryn Hyer, Lisa M Brown, Andrew W Artenstein, LuMarie Polivka-West, and Vincent Mor. 2008. <span>“The Controversy Inherent in Managing Frail Nursing Home Residents During Complex Hurricane Emergencies.”</span> <em>Journal of the American Medical Directors Association</em> 9 (8): 599–604. <a href="https://pubmed.ncbi.nlm.nih.gov/19083295/">https://pubmed.ncbi.nlm.nih.gov/19083295/</a>.
</div>
<div id="ref-edgemon2018community" class="csl-entry">
Edgemon, Lesley, Carol Freeman, Carmella Burdi, Trail, and Kyle Pfeiffer. 2018. <span>“Community Resilience Indicator Analysis: County-Level Analysis of Commonly Used Indicators from Peer-Reviewed Research.”</span> <em>Argonne National Laboratory</em>. <a href="https://www.researchgate.net/publication/331232094_Community_Resilience_Indicator_Analysis_County-Level_Analysis_of_Commonly_Used_Indicators_From_Peer-Reviewed_Research">https://www.researchgate.net/publication/331232094_Community_Resilience_Indicator_Analysis_County-Level_Analysis_of_Commonly_Used_Indicators_From_Peer-Reviewed_Research</a>.
</div>
<div id="ref-FEMA2021risk" class="csl-entry">
FEMA. 2021. <span>“National Risk Index Technical Documentation.”</span> Federal Emergency Management Agency. 2021. <a href="https://www.fema.gov/sites/default/files/documents/fema_national-risk-index_technical-documentation.pdf
  ">https://www.fema.gov/sites/default/files/documents/fema_national-risk-index_technical-documentation.pdf </a>.
</div>
<div id="ref-FEMA2022a" class="csl-entry">
———. 2022. <span>“Community Resilience Indicator Analysis: Commonly Used Indicators from Peer-Reviewed Research: Updated for Research Published 2003-2021.”</span> Federal Emergency Management Agency. 2022. <a href="hhttps://www.fema.gov/sites/default/files/documents/fema_2022-community-resilience-indicator-analysis.pdf
  ">hhttps://www.fema.gov/sites/default/files/documents/fema_2022-community-resilience-indicator-analysis.pdf </a>.
</div>
<div id="ref-dhs2022hifld" class="csl-entry">
Homeland Security: Geospatial Management Office, Department of. 2022. <span>“Homeland Security Infrastructure Foundation-Level Data Open Data.”</span> 2022. <a href="https://hifld-geoplatform.opendata.arcgis.com/">https://hifld-geoplatform.opendata.arcgis.com/</a>.
</div>
<div id="ref-hyer2006establishing" class="csl-entry">
Hyer, Kathryn, Lisa M Brown, Amy Berman, and LuMarie Polivka-West. 2006. <span>“Establishing and Refining Hurricane Response Systems for Long-Term Care Facilities: The John a. Hartford Foundation Was the Lead Funder of a Hurricane Summit to Focus on the Neglected Needs of the Elderly.”</span> <em>Health Affairs</em> 25 (Suppl1): W407–11. <a href="https://www.healthaffairs.org/doi/full/10.1377/hlthaff.25.w407?casa_token=XbJ2j-CdtssAAAAA:USJMJsZq_jlYlQlASQt4O4OYJcq_AOKjpXOx5tTMUIZxoNVXZCzj1_ejtQyLHrnTg6B1BygFuuGZ">https://www.healthaffairs.org/doi/full/10.1377/hlthaff.25.w407?casa_token=XbJ2j-CdtssAAAAA:USJMJsZq_jlYlQlASQt4O4OYJcq_AOKjpXOx5tTMUIZxoNVXZCzj1_ejtQyLHrnTg6B1BygFuuGZ</a>.
</div>
<div id="ref-lancaster2023CDE" class="csl-entry">
Lancaster, V., S. Shipp, S. Keller, A. Schroeder, H. Mortveit, S. Swarup, and D. Xie. 2023. <span>“Census Curated Data Enterprise Use Case Demonstration: Climate Resiliency of Skilled Nursing Facilities”</span> TR 2023-53. <a href="https://doi.org/10.18130/ce97-sp05">https://doi.org/10.18130/ce97-sp05</a>.
</div>
<div id="ref-brown2022ltcfocus" class="csl-entry">
LTCFocus, Brown University. 2022. <span>“Who We Are.”</span> 2022. <a href="https://ltcfocus.org/about">https://ltcfocus.org/about</a>.
</div>
<div id="ref-CMS2022design" class="csl-entry">
Medicare &amp; Medicaid Services, Centers for. 2022. <span>“Design for Care Compare Nursing Home Five-Star Quality Rating System: Technical Users’ Guide.”</span> 2022. <a href="https://www.cms.gov/medicare/provider-enrollment-and-certification/certificationandcomplianc/downloads/usersguide.pdf">https://www.cms.gov/medicare/provider-enrollment-and-certification/certificationandcomplianc/downloads/usersguide.pdf</a>.
</div>
<div id="ref-cmsglossary" class="csl-entry">
———. 2023. <span>“CMS Glossary.”</span> 2023. <a href="https://www.cms.gov/glossary?term=skilled+nursing+facility&amp;items_per_page=10&amp;viewmode=grid ">https://www.cms.gov/glossary?term=skilled+nursing+facility&amp;items_per_page=10&amp;viewmode=grid </a>.
</div>
<div id="ref-mortveitNSSAC" class="csl-entry">
Mortveit, H., D. Xie, and M. Marathe. 2023. <span>“NSSAC Building Knowledge Base: Modeling and Implementation.”</span>
</div>
<div id="ref-rafiei2022private" class="csl-entry">
Rafiei, Y. 2022. <span>“When Private Equity Takes over a Nursing Home.”</span> <em>New Yorker</em> 2022: 333. <a href="https://www.newyorker.com/news/dispatch/when-private-equity-takes-over-a-nursing-home">https://www.newyorker.com/news/dispatch/when-private-equity-takes-over-a-nursing-home</a>.
</div>
<div id="ref-skarha2021association" class="csl-entry">
Skarha, Julianne, Lily Gordon, Nazmus Sakib, Joseph June, Dylan J Jester, Lindsay J Peterson, Ross Andel, and David M Dosa. 2021. <span>“Association of Power Outage with Mortality and Hospitalizations Among Florida Nursing Home Residents After Hurricane Irma.”</span> In <em>JAMA Health Forum</em>, 2:e213900–213900. 11. American Medical Association. <a href="https://jamanetwork.com/journals/jama-health-forum/fullarticle/2786665">https://jamanetwork.com/journals/jama-health-forum/fullarticle/2786665</a>.
</div>
<div id="ref-sheet2022protecting" class="csl-entry">
The White House. 2022. <span>“Protecting Seniors by Improving Safety and Quality of Care in the Nation’s Nursing Homes.”</span> 2022. <a href="https://www.whitehouse.gov/briefing-room/statements-releases/2022/02/28/fact-sheet-protecting-seniors-and-people-with-disabilities-by-improving-safety-and-quality-of-care-in-the-nations-nursing-homes/
  ">https://www.whitehouse.gov/briefing-room/statements-releases/2022/02/28/fact-sheet-protecting-seniors-and-people-with-disabilities-by-improving-safety-and-quality-of-care-in-the-nations-nursing-homes/ </a>.
</div>
</div></section><section id="footnotes" class="footnotes footnotes-end-of-document"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p>Nursing staff includes medical aides and technicians, certified nursing assistants, licensed practical nurses (LPNs), LPNs with administrative duties, registered nurses (RNs), RNs with administrative duties, and the RN director of nursing.↩︎</p></li>
<li id="fn2"><p>For example, distinguishing county from city when the name is the same could be done using State/County FIPS codes. Richmond County is 51159; Richmond City is 51760.↩︎</p></li>
<li id="fn3"><p><em>ZIP code is a system of postal codes used by the United States Postal Service. ZIP</em> was chosen to indicate mail travels more quickly when senders use the postal code.↩︎</p></li>
<li id="fn4"><p>Average Daily Nursing Staff is the daily number of Medical Aides and Technicians, CNAs, LPNs, LPNs with administrative duties, RNs, RNs with administrative duties, and RN Director of Nursing averaged over three months.↩︎</p></li>
</ol>
</section></div> ]]></description>
  <category>Public Policy</category>
  <category>Data Analysis</category>
  <category>Data Integration</category>
  <category>Curation</category>
  <category>Statistical Products</category>
  <guid>https://realworlddatascience.net/applied-insights/case-studies/posts/2024/11/19/use-case-2.html</guid>
  <pubDate>Tue, 19 Nov 2024 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/applied-insights/case-studies/posts/2024/11/19/images/nurse-thumbnail.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>Advancing Data Science in Official Statistics – What is the Curated Data Enterprise?</title>
  <dc:creator>Sallie Keller, Stephanie Shipp, Vicki Lancaster, and Joseph Salvo &lt;br /&gt; University of Virginia</dc:creator>
  <link>https://realworlddatascience.net/applied-insights/case-studies/posts/2024/11/08/what-is-CDE-2.html</link>
  <description><![CDATA[ 





<center>
Acknowledgments: This research was sponsored by the: <br> Unites States Census Bureau Agreement No.&nbsp;01-21-MOU-06 and <br> Alfred P. Sloan Foundation Grant No.&nbsp;G-2022-19536
</center>
<p><br> <br></p>
<p><em>The views expressed in this perspective are those of the authors and not the Census Bureau.</em></p>
<section id="introduction" class="level2">
<h2 class="anchored" data-anchor-id="introduction">Introduction</h2>
<p>Today, official statistics – tables, reports and microdata – are produced using data from a single survey. These surveys are foundational for researchers and policymakers. However, many issues cannot be answered by surveys alone. For example, creating a picture of how prepared skilled nursing facilities (SNFs) are for climate emergencies requires wrangling all types of data about the facilities and their communities.(<em>Note: A skilled nursing facility is a facility that meets specific federal regulatory certification requirements that enable it to provide short-term inpatient care and services to patients who require medical, nursing, or rehabilitative services.</em>) This includes SNF data on the number and dates of inspections, deficiencies, residents’ mental and physical health, the number of nursing staff and where they live, community assets data on the number of shelter facilities, health professionals and emergency service providers, and community risks data on the probability of an extreme climate event. How can we create new statistical products useful to policymakers, emergency responders, skilled nursing facility staff, and others to inform their decisions?</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Note</span>Official statistics
</div>
</div>
<div class="callout-body-container callout-body">
<p>Official statistics are essential for a democratic society as they provide economic, demographic, social, and environmental data about the government, the economy, and the environment. Official statistical agencies should compile and make these statistics available impartially to honor the right to public information.</p>
<p>Objective, reliable, and accessible official statistics instill confidence in the integrity of government and public decision-making regarding a country’s economic, social, and environmental situation at national and international levels. They should be widely available and meet the needs of various users <span class="citation" data-cites="UnitedNations2024">(United Nations 2024)</span>.</p>
</div>
</div>
<p>With the explosion of available data, there is an opportunity to combine all types of information to create statistical products that address cross-cutting topics for a wide range of purposes and uses. The US Census Bureau is modernizing and transforming its enterprise system to accommodate a new way to produce statistical products that take advantage of all data types: designed surveys and censuses, public and private administrative data, opportunity data scraped from the internet, and procedural data <span class="citation" data-cites="keller2022bold">(Keller et al. 2022)</span>.</p>
<blockquote class="blockquote">
<p><em>‘We are moving towards a single enterprise, data-centric operation that enables us to funnel data from many sources in a single data lake using common collection and ingestion platforms… This is the essence of <strong>a curated data approach</strong> — assemble, assess, and fill in the gaps to create quality statistical data.’</em></p>
</blockquote>
<blockquote class="blockquote">
<p><strong>Robert Santos,</strong> Director, US Census Bureau</p>
</blockquote>
<p>This curated approach is embodied in the Curated Data Enterprise (CDE). The Curated Data Enterprise Framework in Figure&nbsp;1 provides a guide for creating statistical products that enable the full integration of data from many sources <span class="citation" data-cites="keller2020doing">(Keller et al. 2020)</span>. At the heart of the framework are the purposes and uses that provide the context and driving force for developing the statistical product. The outer rectangle in Figure&nbsp;1 identifies the guiding principles for ethical, transparent and reproducible product development and dissemination. The inner rectangle identifies the steps in the statistical product development, including integrating primary and secondary data sources. The arrows convey that this process may only sometimes be linear. Instead, the process is iterative, where new information may be discovered at any point, requiring reevaluating and updating prior steps. Our Social and Decision Analytics research group in the Biocomplexity Institute developed, tested, and refined the CDE (data science) Framework in our research since 2013 <span class="citation" data-cites="keller2017building keller2020doing">(Keller, Lancaster, and Shipp 2017; Keller et al. 2020)</span>. The proposed use of the CDE to develop statistical products at the US Census Bureau is in its early stages.</p>
<div id="fig-cde" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-cde-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="https://realworlddatascience.net/applied-insights/case-studies/posts/2024/11/08/images/figure-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-cde-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;1: The CDE Framework starts with the purposes &amp; uses of the statistical products. The outer rectangle identifies the guiding principles for ethical, transparent, reproducible statistical product development and dissemination. The inner rectangle identifies the statistical product development steps.
</figcaption>
</figure>
</div>
<p>The next article in this series will put the CDE Framework into practice by demonstrating the use case on skilled nursing facilities’ preparedness for emergencies during extreme climate events. As a prelude to that article, we have created a visual for the statistical product development component of how that process works in action in Figure&nbsp;2.</p>
<div id="fig-ex" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-ex-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="https://realworlddatascience.net/applied-insights/case-studies/posts/2024/11/08/images/figure-2.png" class="img-fluid quarto-figure quarto-figure-center figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-ex-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2: Example: Steps in the statistical product development for the skilled nursing facility use case. The diagram describes the steps applied to a use case on the resilience of skilled nursing facilities. Section 3 of this series describes the steps in detail.
</figcaption>
</figure>
</div>
<p>The CDE Framework’s guiding principles and research steps are described below. To find out more click on a cross reference.</p>
<p><strong>Guiding principles</strong>:</p>
<ul>
<li>Purposes and uses</li>
<li>Stakeholders</li>
<li>Curation</li>
<li>Equity and ethics</li>
<li>Privacy and confidentiality</li>
<li>Communications and dissemination</li>
</ul>
<p><strong>Research steps</strong>:</p>
<ul>
<li>Subject matter input</li>
<li>Data discovery</li>
<li>Data ingestion &amp; Governance</li>
<li>Data wrangling</li>
<li>Fitness-for-purpose</li>
<li>Statistics development</li>
</ul>
</section>
<section id="guiding-principles" class="level2">
<h2 class="anchored" data-anchor-id="guiding-principles">Guiding principles</h2>
<section id="sec-gp1" class="level3">
<h3 class="anchored" data-anchor-id="sec-gp1">Purposes and uses</h3>
<p>The CDE is centered on developing statistical products to meet specific purposes and uses. Researchers and stakeholders propose the purposes and uses, defining the ‘why’ for developing statistics and statistical products. They include questions or issues that the statistics should be designed to support and are clarified by documented best practices, literature reviews and conversations with subject matter experts.</p>
</section>
<section id="sec-gp2" class="level3">
<h3 class="anchored" data-anchor-id="sec-gp2">Stakeholders</h3>
<p>Stakeholders include individuals, groups, and organizations that have the potential to affect or be affected by the outcome of the research. Engaging stakeholders is crucial for fostering the connection and trust that can lead to better decision making. <span class="citation" data-cites="kujala2022stakeholder">Kujala et al. (2022)</span> best described the principle of stakeholder engagement: ‘Stakeholder engagement refers to the aims, activities, and impacts of stakeholder relations in a moral, strategic, and pragmatic manner.’ When placed within the CDE context and represented in the Framework, collaborative engagement with stakeholders occurs at all stages of product development to better understand what the final product needs to look like. Further, product development is not a linear process but occurs through successive waves of iteration with users.</p>
<p>Forming partnerships with stakeholders is instrumental in identifying requirements and implementing statistical products. This requires listening to community voices in an active engagement strategy.<sup>1</sup> Of necessity, these partnerships entail collaboration, such as creative and collaborative problem-solving workshops and the development of innovative digital tools vetted by networks of users.<sup>2</sup></p>
</section>
<section id="sec-gp3" class="level3">
<h3 class="anchored" data-anchor-id="sec-gp3">Curation</h3>
<p>The broad meaning of curation is the act of organizing, documenting and maintaining a collection of artifacts. The artifacts of the development and dissemination of statistics or statistical products include all the components in Figure&nbsp;1, from meeting with stakeholders to formulating the purposes and uses to creating and disseminating the statistical products. Maintaining the artifacts is the essence of the CDE. <em>Every step in the process should be documented and easily accessible in a repository, for example, GitHub, for the work to be transparent and reproducible</em>. Curation in the context of the CDE is an end-to-end activity. It involves documenting the purpose and use, providing the context for acquiring, wrangling, and archiving data from many sources to support the development of statistical products. It will include metadata <span class="citation" data-cites="cannon2013">(Cannon 2013)</span>, the code used to read and write the data, and the code that ingested the data from the source and prepared it for analysis.</p>
<p><em>Curation steps</em></p>
<ul>
<li>Document the development of the research questions, why this research is important, and how it supports the purposes and uses and resulting statistical product.</li>
<li>Document the context for the purposes and uses, ie, a policy directive, stakeholder request, policy evaluation, etc.</li>
<li>What stakeholder engagement and transparency are built into the process?</li>
</ul>
</section>
<section id="sec-gp4" class="level3">
<h3 class="anchored" data-anchor-id="sec-gp4">Equity and ethics</h3>
<p>An ethics review ensures dialogue on this topic throughout the statistical product development and dissemination life cycle. This involves teams of researchers and stakeholders across many areas of expertise, each with its own research integrity norms and practices. This requires that ethics be woven into every aspect of the CDE. An <em>equity</em> review ensures that underserved groups are represented and biases inherent in various data sources are acknowledged.</p>
<p><em>Curation questions</em></p>
<ul>
<li>What are the project’s expected benefits to the ‘public good’? Do they outweigh potential risks to specific sub-populations, eg, individuals, firms and their locations by different levels of geography?</li>
<li>Are there implicit assumptions and biases regarding the studied communities in framing the project and associated data sources? If yes, how will they be addressed?</li>
<li>What type of institutional approval process and contracts are needed? What statistical quality standards and confidentiality standards will be needed? For an explanation of the Institution Review Board see Note&nbsp;1.</li>
</ul>
<p>An ethics checklist can help with this process. Links to ethics checklists are provided below.</p>
<ul>
<li>University of Virginia, Biocomplexity Institute, <a href="https://biocomplexity.virginia.edu/sites/default/files/sda/UVA%20SDAD%20EthicsChecklist%2018May2022.pdf">Social and Decision Analytics Division Data Science Project Ethics Tool</a></li>
<li>United Kingdom Government, <a href="https://www.gov.uk/government/publications/data-ethics-framework#full-publication-update-history">Data Ethics Framework</a></li>
</ul>
</section>
<section id="sec-gp5" class="level3">
<h3 class="anchored" data-anchor-id="sec-gp5">Privacy and confidentiality</h3>
<p>Privacy is about the individual, whereas confidentiality is about the individual’s information. Privacy refers to an individual’s desire to control their information. Confidentiality refers to the researcher’s agreement with the individual, which could be an agency like the Census Bureau, regarding how their information will be handled, managed, and disseminated <span class="citation" data-cites="keller2016does">(Keller, Shipp, and Schroeder 2016)</span>. This is a guiding principle because it needs to be considered and embraced at the earliest possible stages of statistical product development and will impact dissemination choices.</p>
<p><em>Curation questions</em></p>
<ul>
<li>What steps are taken to ensure the privacy and confidentiality of the data?</li>
<li>What statistical methods (if any) are used to ensure the privacy and confidentiality of the data?</li>
<li>How do the methods chosen to protect confidentiality affect the purposes and uses of the data?</li>
<li>What stakeholder engagement and transparency are built into the process?</li>
<li>Does the context surrounding the purposes, uses, and anticipated data sources require an Institutional Review Board (IRB) review and approval? If yes, is it archived?</li>
</ul>
<div id="nte-irb" class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note&nbsp;1: Institutional Review Board
</div>
</div>
<div class="callout-body-container callout-body">
<p>In the United States, institutional review boards (IRBs) assess the ethics and safety of research studies involving human subjects, such as behavioral studies or clinical trials for new drugs or medical devices. Today, the definition of human subjects has evolved to include secondary data, such as administrative data collected for other purposes, eg, local property data collected for tax purposes.</p>
<p>The Belmont Commission was convened in the late 1970s after the ethical failures of many research projects that involved vulnerable populations surfaced. The Belmont Commission issued three principles for the conduct of ethical research:</p>
<ul>
<li><p><strong>Respect for people</strong> — treating people as autonomous and honoring their wishes</p></li>
<li><p><strong>Beneficence</strong> — understanding the risks and benefits of the study and weighing the balance between (1) doing no harm and (2) maximizing possible benefits and minimizing possible harms</p></li>
<li><p><strong>Justice</strong> — deciding if the risks and benefits of research are distributed fairly.</p></li>
</ul>
<p>These principles were translated to a set of regulations called the Common Rule that govern federally-funded research. The Belmont Commission provided the foundation for IRB principles and focused on research involving human subjects in experiments and studies. IRB approval is required to be eligible for federal grants and contracts. Many universities also require IRB review for research conducted by faculty, students, and researchers <span class="citation" data-cites="shipp2023making">(Shipp, LaLonde, and Martinez 2023)</span>.</p>
</div>
</div>
</section>
<section id="sec-gp6" class="level3">
<h3 class="anchored" data-anchor-id="sec-gp6">Communication and dissemination</h3>
<p>Communication involves sharing data, statistical method choices, well-documented code, working papers, and <em>dissemination</em> through research team meetings, stakeholder engagements, conference presentations, publications, webinars, websites, and social media. As a principle, communication and dissemination are critical to ensure that statistical product development processes and findings are transparent and reproducible <span class="citation" data-cites="berman2016realizing">(Berman et al. 2016)</span>. An essential facet of this step is to tell the story of the analysis by conveying the context, purpose, and implications of the research and findings <span class="citation" data-cites="berinato2019data wing2019data nasem2022transparency">(Berinato 2019; Wing 2019; NASEM 2022)</span>.</p>
<p><em>Curation questions</em></p>
<ul>
<li>Are the meeting notes, statistical products, code, reports, and presentations archived in a repository?</li>
<li>Briefly describe what did not work in this process, eg, data wrangling challenges where data sources could not be integrated, data source changes after a fitness-for-purpose assessment, analyses that were changed because assumptions were not met, etc.</li>
<li>Have project methods and outputs been made as transparent as possible?</li>
<li>Are the potential limitations of the research clearly presented?</li>
<li>Why or why not should the research be used as the basis for an institutional or policy action?</li>
<li>Have the predicted benefits and social costs to all potentially affected communities been considered?</li>
</ul>
</section>
</section>
<section id="research-steps" class="level2">
<h2 class="anchored" data-anchor-id="research-steps">Research steps</h2>
<section id="sec-rs1" class="level3">
<h3 class="anchored" data-anchor-id="sec-rs1">Subject matter input</h3>
<p>Subject matter (domain) expertise plays a role in translating the information acquired into understanding the underlying phenomena in the data <span class="citation" data-cites="box1978statistics">(Box et al. 1978)</span>. Domain knowledge provides the context to define, evaluate and interpret the findings at each research stage <span class="citation" data-cites="leonelli2019data snee2014follow">(Leonelli 2019; Snee, DeVeaux, and Hoerl 2014)</span>. Subject matter input can be obtained through a review of the literature, talking to experts, or learning about their work at conferences or other convenings. Subject matter experts are different than stakeholders. Both provide important input to identifying and clarifying purposes and uses.</p>
<p><em>Curation steps</em></p>
<ul>
<li>Document the meetings with subject matter experts and stakeholders.</li>
<li>Document the literature search methods and the results of the literature review.</li>
<li>Document choices are made during the development of the products.</li>
<li>Were subject matter experts and stakeholders recruited from underrepresented groups?</li>
</ul>
</section>
<section id="sec-rs2" class="level3">
<h3 class="anchored" data-anchor-id="sec-rs2">Data discovery</h3>
<p>Data discovery identifies potential sources that address the research goals defined by purposes and uses. Data sources include the following types <span class="citation" data-cites="keller2020doing">(Keller et al. 2020)</span>.</p>
<ol type="1">
<li><p>Designed data are collected using statistically designed methods, such as surveys, censuses, and data generated from an experimental or quasi-experimental design, such as a clinical trial or agricultural field study.</p></li>
<li><p>Administrative data are collected for the administration of an organization or program by entities such as government agencies.</p></li>
<li><p>Opportunity data are derived from internet-based information, such as websites, wearable and other sensor devices, and social media, and captured through application programming interfaces (APIs) and web scraping, eg, geocoded place-based data, transportation routes, and other data sources.</p></li>
<li><p>Procedural data are processes and policies, such as a change in health care coverage, a data repository policy outlining procedures and the metadata required to store data, or a responsible AI policy.</p></li>
</ol>
<p>The goal of the data discovery process is to think broadly and imaginatively about all data types and to capture the variety of data sources that could be useful for the problem. There are three steps in the data discovery process <span class="citation" data-cites="keller2016does">(Keller, Shipp, and Schroeder 2016)</span>.</p>
<ol type="1">
<li><p>Identify potential data sources and make an inventory.</p></li>
<li><p>Create a set of questions to screen the data sources to ensure the data meet the criteria for use.</p></li>
<li><p>Select and acquire the data sources that meet the screening criteria.</p></li>
</ol>
<p><em>Curation steps</em></p>
<ul>
<li>Describe your data discovery process and reasoning behind the selected data sources.
<ul>
<li>Do underrepresented groups have adequate geographic coverage? If not, are there methods, such as synthetic data, you can use to provide adequate coverage?</li>
<li>Have checks and balances been established to identify and address implicit biases in the data and interpretation of the data? Has the team engaged in discussion and provided insights across their diverse perspectives?</li>
</ul></li>
<li>Describe the assumptions that need to be made to use these data sources.</li>
<li>Identify and document the paradata and metadata that describe each data source. Paradata describe how the data were collected, while metadata are ‘data about data’. It includes information about the data’s content, data dictionaries and technical documents that will help the user assess its fitness for purpose <span class="citation" data-cites="cannon2013 nasem2022transparency">(Cannon 2013; NASEM 2022)</span>.</li>
<li>Discuss data sources you would have used if they were available.</li>
</ul>
</section>
<section id="sec-rs3" class="level3">
<h3 class="anchored" data-anchor-id="sec-rs3">Data ingest and governance</h3>
<p>Data ingestion is the process of bringing data into the data management platform(s) for use. Data governance establishes and adheres to rules and procedures regarding data access, dissemination and destruction.</p>
<p><em>Curation steps</em></p>
<ul>
<li>Document policies and institutional agreements for data use.
<ul>
<li>Have team members reviewed data use agreements, standard operating procedures (SOPs), and data management plans? Are they fair?</li>
<li>Do additional procedures need to be defined for this project?</li>
</ul></li>
<li>Document the code and processes used to ingest the data sources and manage governance.</li>
</ul>
</section>
<section id="sec-rs4" class="level3">
<h3 class="anchored" data-anchor-id="sec-rs4">Data wrangling</h3>
<p>Data wrangling includes the activities of data profiling, preparing, linking and exploring used to assess the data’s quality and representativeness and what analyses the data can support.</p>
<table class="caption-top table">
<caption>Table 1. Activities of data wrangling</caption>
<colgroup>
<col style="width: 31%">
<col style="width: 14%">
<col style="width: 30%">
<col style="width: 21%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: center;">Profiling</th>
<th style="text-align: center;">Preparing</th>
<th style="text-align: center;">Linking</th>
<th style="text-align: center;">Exploring</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;"><ul>
<li>data quality</li>
<li>data structure</li>
<li>meta data, paradata, and provenance</li>
</ul></td>
<td style="text-align: center;"><ul>
<li>cleaning</li>
<li>transforming</li>
<li>structuring</li>
</ul></td>
<td style="text-align: center;"><ul>
<li>ontology selection &amp; alignment</li>
<li>entity resolution / harmonization</li>
</ul></td>
<td style="text-align: center;"><ul>
<li>visualizations</li>
<li>descriptive statistics</li>
<li>characterizations</li>
</ul></td>
</tr>
</tbody>
</table>
<p><em>Curation steps</em></p>
<ul>
<li>Describe any data quality issues within the stated purpose and use context and how they were resolved. This can include statistical solutions like imputing missing data, identifying outliers or constructing synthetic populations.
<ul>
<li>How representative are the data?</li>
<li>What populations are and are not covered?</li>
</ul></li>
<li>Describe any issues with the wrangling process and how they were resolved.</li>
<li>Document the code used to wrangle the data and describe how it was validated.</li>
<li>Document assumptions made regarding the transformation and use of the data.</li>
</ul>
</section>
<section id="sec-rs5" class="level3">
<h3 class="anchored" data-anchor-id="sec-rs5">Fitness-for-purpose</h3>
<p>Fitness-for-purpose starts with assessing the constraints imposed on the data by the particular statistical methods used and the population to which the inferences extend. It is a function of the modeling, data quality needs of the models, and data coverage (representativeness) needs of the models. The statistical product’s ‘fitness-for-purpose’ involves those on the receiving end of the data helping identify issues germane to the data application, such as identifying biases affecting equity. For example, given known differences in their availability, does using administrative records lead to better modeling outcomes for some groups more than others? What can be done to compensate for such bias?</p>
<p><em>Curation steps</em></p>
<ul>
<li>Document the constraints and limitations of the data.&nbsp;
<ul>
<li>What are the limitations of the results? Are the results useful, given the purpose of the study?</li>
</ul></li>
<li>Discuss the populations to which any inferences will generalize.
<ul>
<li>Do the statistical results support the potential benefits of the study previously stated?</li>
<li>Do any data require revisiting the question of potential biases being introduced through the choice of data sets and variables?</li>
</ul></li>
</ul>
</section>
<section id="sec-rs6" class="level3">
<h3 class="anchored" data-anchor-id="sec-rs6">Statistics development</h3>
<p>The development of statistics and statistical products for dissemination is a function of the research questions, the data’s limitations and the assumptions of the statistical method(s) used.</p>
<p><em>Curation steps</em></p>
<ul>
<li>Describe the statistical methods planned and used and how the method assumptions were evaluated.</li>
<li>Discuss the conclusions of the statistical analyses and any inferences that can be made from the disseminated statistical products.</li>
<li>Discuss how the statistics support the purposes and uses driving the development of the products.</li>
</ul>
<p>Here, we have defined the CDE and provided a conceptual walk through of the framework from Figure&nbsp;1. In the next article, we will put the CDE Framework into practice through a demonstration use case on the resilience of skilled nursing facilities.</p>
<div class="nav-btn-container">
<div class="grid">
<div class="g-col-12 g-col-sm-6">
<div class="nav-btn">
<p><a href="../../../../../../applied-insights/case-studies/posts/2024/11/01/policy-problem.html">← Part 1: The policy problem</a></p>
</div>
</div>
<div class="g-col-12 g-col-sm-6">
<div class="nav-btn">
<p><a href="../../../../../../applied-insights/case-studies/posts/2024/11/19/use-case-2.html">Part 3: Climate resiliency of skilled nursing facilities →</a></p>
</div>
</div>
</div>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-12">
<dl>
<dt>About the authors</dt>
<dd>
<p><strong>Sallie Keller</strong> is the Chief Scientist and Associate Director of Research and Methodology at the US Census Bureau. She is a statistician with research interest in social and decision informatics, statistics underpinnings of data science, and data access and confidentiality. Sallie Keller was at the University of Virginia when this work was conducted.</p>
</dd>
<dd>
<p><strong>Stephanie Shipp</strong> leads the Curated Data Enterprise research portfolio and collaborates with the US Census. She is an economist with experience in data science, survey statistics, public policy, innovation, ethics, and evaluation.</p>
</dd>
<dd>
<p><strong>Vicki Lancaster</strong> is a statistician with expertise in experimental design, linear models, computation, visualizations, data analysis, and interpretation. She works with scientists at federal agencies on projects requiring statistical skills and creativity, eg, defining skilled technical workforce using novel data sources.</p>
</dd>
<dd>
<p><strong>Joseph Salvo</strong> is a demographer with experience in US Census Bureau statistics and data. He makes presentations on demographic subjects to a wide range of groups about managing major demographic projects involving the analysis of large data sets for local applications.</p>
</dd>
</dl>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>Copyright and licence</dt>
<dd>
<p>© 2024 Stephanie Shipp</p>
</dd>
</dl>
<p><a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> <img src="https://mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1" style="height:22px!important;vertical-align:text-bottom;"><img src="https://mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1" style="height:22px!important;margin-left:3px;vertical-align:text-bottom;"></a> This article is licensed under a Creative Commons Attribution 4.0 (CC BY 4.0) <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> International licence</a>. Thumbnail photo by <a href="https://www.shutterstock.com/g/Chaay_Tee">Chay_Tee</a> on <a href="https://www.shutterstock.com/image-photo/back-rear-view-young-asian-woman-2170748613">Shutterstock</a>.</p>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>How to cite</dt>
<dd>
<p>Keller S, Shipp S, Lancaster V, Salvo J (2024). “Advancing Data Science in Official Statistics – What is the Curated Data Enterprise?” Real World Data Science, November 8, 2024. <a href="https://realworlddatascience.net/applied-insights/case-studies/posts/2024/11/08/what-is-CDE-2.html">URL</a></p>
</dd>
</dl>
</div>
</div>
</div>



</section>
</section>


<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0">
<div id="ref-berinato2019data" class="csl-entry">
Berinato, Scott. 2019. <span>“Data Science and the Art of Persuasion: Organizations Struggle to Communicate the Insights in All the Information They’ve Amassed. Here’s Why, and How to Fix It.”</span> <em>Harvard Business Review</em> 97 (1). <a href="https://hbr.org/2019/01/data-science-and-the-art-of-persuasion">https://hbr.org/2019/01/data-science-and-the-art-of-persuasion</a>.
</div>
<div id="ref-berman2016realizing" class="csl-entry">
Berman, Francine, Rob Rutenbar, Henrik Christensen, Susan Davidson, Deborah Estrin, Michael Franklin, Brent Hailpern, et al. 2016. <span>“Realizing the Potential of Data Science: Final Report from the National Science Foundation Computer and Information Science and Engineering Advisory Committee Data Science Working Group.”</span> <em>National Science Foundation Computer and Information Science and Engineering Advisory Committee Report</em>.
</div>
<div id="ref-box1978statistics" class="csl-entry">
Box, George EP, William H Hunter, Stuart Hunter, et al. 1978. <em>Statistics for Experimenters</em>. Vol. 664. John Wiley; sons New York.
</div>
<div id="ref-cannon2013" class="csl-entry">
Cannon, Sandra. 2013. <span>“Defining <span>‘Core’</span> Metadata: What Is Needed to Make Data Discoverable. Paper Presented at the Federal CASIC Workshops (Survey Uses of Metadata).”</span> <a href="https://www.census.gov/fedcasic/fc2013/">https://www.census.gov/fedcasic/fc2013/</a>.
</div>
<div id="ref-keller2017building" class="csl-entry">
Keller, Sallie, Vicki Lancaster, and Stephanie Shipp. 2017. <span>“Building Capacity for Data-Driven Governance: Creating a New Foundation for Democracy.”</span> <em>Statistics and Public Policy</em> 4 (1): 1–11.
</div>
<div id="ref-keller2022bold" class="csl-entry">
Keller, Sallie, Kenneth Prewitt, John Thompson, Steve Jost, Christopher Barrett, Sarah Nusser, Joseph Salvo, and Stephanie Shipp. 2022. <span>“A 21st Century Census Curated Data Enterprise. A Bold New Approach to Create Official Statistics. Technical Report.”</span> <em>Proceedings of the Biocomplexity Institute</em> BI-2022-1115: 297–323. <a href="https://doi.org/10.18130/r174-yk24">https://doi.org/10.18130/r174-yk24</a>.
</div>
<div id="ref-keller2020doing" class="csl-entry">
Keller, Sallie, Stephanie S Shipp, Aaron D Schroeder, and Gizem Korkmaz. 2020. <span>“Doing Data Science: A Framework and Case Study.”</span> <em>Harvard Data Science Review</em> 2 (1). <a href="https://doi.org/10.1162/99608f92.2d83f7f5">https://doi.org/10.1162/99608f92.2d83f7f5</a>.
</div>
<div id="ref-keller2016does" class="csl-entry">
Keller, Sallie, Stephanie Shipp, and Aaron Schroeder. 2016. <span>“Does Big Data Change the Privacy Landscape? A Review of the Issues.”</span> <em>Annual Review of Statistics and Its Application</em> 3: 161–80. <a href="https://www.annualreviews.org/content/journals/10.1146/annurev-statistics-041715-033453
  ">https://www.annualreviews.org/content/journals/10.1146/annurev-statistics-041715-033453 </a>.
</div>
<div id="ref-kujala2022stakeholder" class="csl-entry">
Kujala, Johanna, Sybille Sachs, Heta Leinonen, Anna Heikkinen, and Daniel Laude. 2022. <span>“Stakeholder Engagement: Past, Present, and Future.”</span> <em>Business &amp; Society</em> 61 (5): 1136–96. <a href="https://doi.org/10.1177/00076503211066595">https://doi.org/10.1177/00076503211066595</a>.
</div>
<div id="ref-leonelli2019data" class="csl-entry">
Leonelli, Sabina. 2019. <span>“Data Governance Is Key to Interpretation: Reconceptualizing Data in Data Science.”</span> <a href="https://doi.org/10.1162/99608f92.17405bb6">https://doi.org/10.1162/99608f92.17405bb6</a>.
</div>
<div id="ref-nasem2022transparency" class="csl-entry">
NASEM. 2022. <span>“Transparency in Statistical Information for the National Center for Science and Engineering Statistics and All Federal Statistical Agencies.”</span> <em>National Academies of Science, Engineering, and Medicine</em>. <a href="https://doi.org/10.1162/99608f92.17405bb6">https://doi.org/10.1162/99608f92.17405bb6</a>.
</div>
<div id="ref-shipp2023making" class="csl-entry">
Shipp, Stephanie, Donna LaLonde, and Wendy Martinez. 2023. <span>“Making Ethical Decisions Is Hard!”</span> <em>CHANCE</em> 36 (4): 42–50. <a href="https://www.tandfonline.com/eprint/D5KR3XFRUG2QV4FVCKQI/full?target=10.1080/09332480.2023.2290955">https://www.tandfonline.com/eprint/D5KR3XFRUG2QV4FVCKQI/full?target=10.1080/09332480.2023.2290955</a>.
</div>
<div id="ref-snee2014follow" class="csl-entry">
Snee, Ronald D, Richard D DeVeaux, and Roger W Hoerl. 2014. <span>“Follow the Fundamentals.”</span> <em>Quality Progress</em> 47 (1): 24–28. <a href="https://search-proquest-com.proxy01.its.virginia.edu/docview/1491963574?accountid=14678">https://search-proquest-com.proxy01.its.virginia.edu/docview/1491963574?accountid=14678</a>.
</div>
<div id="ref-UnitedNations2024" class="csl-entry">
United Nations. 2024. <span>“Development of a National Statistical System, Principle 1 - Relevance, Impartiality and Equal Access.”</span> <a href="https://unstats.un.org/unsd/goodprac/bpaboutpr.asp?RecId=1">https://unstats.un.org/unsd/goodprac/bpaboutpr.asp?RecId=1</a>.
</div>
<div id="ref-wing2019data" class="csl-entry">
Wing, Jeannette M. 2019. <span>“The Data Life Cycle.”</span> <em>Harvard Data Science Review</em> 1 (1): 6. <a href="https://doi.org/10.1162/99608f92.e26845b4">https://doi.org/10.1162/99608f92.e26845b4</a>.
</div>
</div></section><section id="footnotes" class="footnotes footnotes-end-of-document"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p><a href="https://www.census.gov/newsroom/blogs/director/2023/01/a-look-ahead-2023.html" class="uri">https://www.census.gov/newsroom/blogs/director/2023/01/a-look-ahead-2023.html</a>&nbsp;↩︎</p></li>
<li id="fn2"><p><a href="https://www.census.gov/partners/act.html" class="uri">https://www.census.gov/partners/act.html</a>↩︎</p></li>
</ol>
</section></div> ]]></description>
  <category>Public Policy</category>
  <category>Data Analysis</category>
  <category>Data Integration</category>
  <category>Curation</category>
  <category>Statistical Products</category>
  <guid>https://realworlddatascience.net/applied-insights/case-studies/posts/2024/11/08/what-is-CDE-2.html</guid>
  <pubDate>Fri, 08 Nov 2024 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/applied-insights/case-studies/posts/2024/11/08/images/screen.thumbnail.jpg" medium="image" type="image/jpeg"/>
</item>
</channel>
</rss>
