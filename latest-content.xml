<?xml version="1.0" encoding="UTF-8"?>
<rss  xmlns:atom="http://www.w3.org/2005/Atom" 
      xmlns:media="http://search.yahoo.com/mrss/" 
      xmlns:content="http://purl.org/rss/1.0/modules/content/" 
      xmlns:dc="http://purl.org/dc/elements/1.1/" 
      version="2.0">
<channel>
<title>Real World Data Science</title>
<link>https://realworlddatascience.net/latest-content.html</link>
<atom:link href="https://realworlddatascience.net/latest-content.xml" rel="self" type="application/rss+xml"/>
<description></description>
<image>
<url>https://realworlddatascience.net/images/rwds-logo-150px.png</url>
<title>Real World Data Science</title>
<link>https://realworlddatascience.net/latest-content.html</link>
<height>83</height>
<width>144</width>
</image>
<generator>quarto-1.4.549</generator>
<lastBuildDate>Thu, 08 Feb 2024 00:00:00 GMT</lastBuildDate>
<item>
  <title>£10m for UK regulators to ‘jumpstart’ AI capabilities, as government commits to white paper approach</title>
  <dc:creator>Brian Tarran</dc:creator>
  <link>https://realworlddatascience.net/viewpoints/editors-blog/posts/2024/02/08/llms-whitepaper-response.html</link>
  <description><![CDATA[ 





<p>The UK government this week announced a £10 million investment to “jumpstart regulators’ AI capabilities” as part of its commitment to a “pro-innovation approach to AI regulation.” But will this be sufficient to answer criticisms that it has so far been “too slow” to give regulators the tools they need to police the growing usage of AI?</p>
<p>It was March last year when a Department for Science, Innovation and Technology (DSIT) white paper first set out the government’s <a href="https://www.gov.uk/government/publications/ai-regulation-a-pro-innovation-approach/white-paper">principles- and context-based approach to regulating artificial intelligence</a>. This proposed to focus regulatory attention on “the context in which AI is deployed” rather than target specific technologies. Under this model, existing regulators, including the Information Commissioner’s Office, Ofcom, and the Competition and Markets Authority, would be responsible for ensuring that technologies deployed within their domains adhered to established rules – e.g., data protection regulation – and a common set of principles:</p>
<ul>
<li>Safety, security and robustness.</li>
<li>Appropriate transparency and explainability.</li>
<li>Fairness.</li>
<li>Accountability and governance.</li>
<li>Contestability and redress.</li>
</ul>
<p>The approach was broadly well received, as was clear from a debate at techUK’s <a href="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/12/08/digital-ethics-summit.html">Digital Ethics Summit</a> last December. However, concerns were expressed about whether regulators would be funded sufficiently to meet the expectations set out in the March white paper. Also, the Royal Statistical Society, in <a href="https://rss.org.uk/RSS/media/File-library/Policy/2023/RSS-AI-white-paper-response-v2-2.pdf">its response to the white paper</a>, worried that “splitting responsibilities for regulating the use of AI between existing regulators does not meet the scale of the challenge,” and that “central leadership is required to give a clear, coherent and easily communicable framework that can be applied to all sectors.”</p>
<p>While the DSIT white paper proposed that a range of “central functions” be created to support regulators, <a href="https://committees.parliament.uk/committee/170/communications-and-digital-committee/news/199728/uk-will-miss-ai-goldrush-unless-government-adopts-a-more-positive-vision/">evidence presented to a House of Lords inquiry</a> last November suggested that regulators “did not appear to know what was happening” with these mooted teams and were “keen to see progress” on this front.</p>
<p>In reporting the outcomes of its inquiry last week, the House of Lords Communications and Digital Committee concluded that government was being “too slow” to give regulators the tools required to meet the objectives set out in the white paper, and that “speedier resourcing of government‑led central support teams is needed.”</p>
<p>“Relying on existing regulators to ensure good outcomes from AI will only work if they are properly resourced and empowered,” the committee said.</p>
<p>The £10 million funding for regulators announced this week is therefore likely to be welcomed. Money is earmarked to “help regulators develop cutting-edge research and practical tools to monitor and address risks and opportunities in their sectors, from telecoms and healthcare to finance and education,” according to <a href="https://www.gov.uk/government/news/uk-signals-step-change-for-regulators-to-strengthen-ai-leadership">a DSIT press release</a>. Speaking on February 6 at <a href="https://parliamentlive.tv/event/index/68ecee17-2896-4002-8736-1608229db364?in=15:27:41">a hearing of the Lords Communications and Digital Committee</a>, Michelle Donelan, Secretary of State for Science, Innovation and Technology, said that the government would “stay on top” of what regulators need to be able to fulfil their responsibilities for regulating the use of AI in their sectors.</p>
<section id="consultation-response" class="level2">
<h2 class="anchored" data-anchor-id="consultation-response">Consultation response</h2>
<p>News of the funding for regulators came as part of <a href="https://www.gov.uk/government/consultations/ai-regulation-a-pro-innovation-approach-policy-proposals/outcome/a-pro-innovation-approach-to-ai-regulation-government-response">a long-awaited response by the government to the consultation on its AI regulation white paper</a>. The response essentially confirmed that the government was proceeding with its principles- and context-based approach to regulating AI, having received “strong support from stakeholders across society.”</p>
<p>This approach is right for today, the government said, “as it allows us to keep pace with rapid and uncertain advances in AI.” However, it acknowledged that “the challenges posed by AI technologies will ultimately require legislative action in every country once understanding of risk has matured.”</p>
<p>“Highly capable general-purpose AI systems” would, for example, present a particular challenge to the government’s current approach. It explained: “Even though some regulators can enforce existing laws against the developers of the most capable general-purpose systems within their current remits, the wide range of potential uses means that general-purpose systems do not currently fit neatly within the remit of any one regulator, potentially leaving risks without effective mitigations.”</p>
<p>As a next step in delivering on the white paper approach, the government is asking key regulators to publish an update on their strategic approach to AI by the end of April. This was welcomed by Royal Statistical Society (RSS) president Andrew Garrett, who said:</p>
<blockquote class="blockquote">
<p>“Urgency is certainly warranted, and the directive for key regulators to disclose their approach in the coming months is a positive development. Ensuring consistency and coherence not only among key regulators but also those who follow is crucial.”</p>
</blockquote>
<p>Garrett also <a href="https://realworlddatascience.net/viewpoints/interviews/posts/2023/10/25/evaluating-ai.html">reiterated the need for government to engage with statisticians and data scientists</a>, particularly through its <a href="https://realworlddatascience.net/viewpoints/posts/2023/12/06/ai-fringe.html">new AI Safety Institute</a> (AISI). In the white paper consultation response, AISI is billed as being “fundamental to informing the UK’s regulatory framework”: it will “advance the world’s knowledge of AI safety by carefully examining, evaluating, and testing new frontier AI systems” and will also “research new techniques for understanding and mitigating AI risk.” Garrett said:</p>
<blockquote class="blockquote">
<p>“As always, fostering diversity of representation within government and regulatory bodies remains paramount; it cannot solely rely on input from major tech companies. It is especially important that the AI Safety Institute engages with a diverse array of voices, including statisticians and data scientists who play a pivotal role in both the development of AI systems and novel evaluation methodologies.”</p>
</blockquote>
</section>
<section id="risks-and-opportunities" class="level2">
<h2 class="anchored" data-anchor-id="risks-and-opportunities">Risks and opportunities</h2>
<p>Calls for a “diversity of representation within government and regulatory bodies” certainly chime with a warning bell sounded by the Lords Communications and Digital Committee last week, in the February 2 release of its <a href="https://committees.parliament.uk/committee/170/communications-and-digital-committee/news/199728/uk-will-miss-ai-goldrush-unless-government-adopts-a-more-positive-vision/">inquiry report into large language models and generative AI</a>. “Regulatory capture” by big commercial interests was highlighted as a danger to be avoided, amid concern that “the AI safety debate is being dominated by views narrowly focused on catastrophic risk, often coming from those who developed such models in the first place” and that “this distracts from more immediate issues like copyright infringement, bias and reliability.”<sup>1</sup></p>
<p>The committee called for enhanced governance and transparency measures in DSIT and AISI to guard against regulatory capture, and for a rebalancing away from a “narrow focus on high-stakes AI safety” toward a “more positive vision for the opportunities [of AI] and a more deliberate focus on near-term risks” including cyber security and disinformation.</p>
<p>It also wants to see greater action by the government in support of copyright. “Some tech firms are using copyrighted material without permission, reaping vast financial rewards,” reads the report. “The legalities of this are complex but the principles remain clear. The point of copyright is to reward creators for their efforts, prevent others from using works without permission, and incentivise innovation. The current legal framework is failing to ensure these outcomes occur and the Government has a duty to act. It cannot sit on its hands for the next decade and hope the courts will provide an answer.”</p>
<p>Again, here’s RSS president Andrew Garrett’s take on the Lords committee report:</p>
<center>
<iframe src="https://www.linkedin.com/embed/feed/update/urn:li:share:7159583475350585344" height="1091" width="504" frameborder="0" allowfullscreen="" title="Embedded post">
</iframe>
</center>
<div class="article-btn">
<p><a href="../../../../../../viewpoints/editors-blog/index.html">Back to Editors’ blog</a></p>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-6">
<dl>
<dt>Copyright and licence</dt>
<dd>
© 2024 Royal Statistical Society
</dd>
</dl>
<p><a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> <img style="height:22px!important;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"></a> This article is licensed under a Creative Commons Attribution 4.0 (CC BY 4.0) <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> International licence</a>. Thumbnail photo by <a href="https://unsplash.com/@yaopey?utm_content=creditCopyText&amp;utm_medium=referral&amp;utm_source=unsplash">Yaopey Yong</a> on <a href="https://unsplash.com/photos/white-concrete-building-near-body-of-water-during-night-time-flmPTUCjkto?utm_content=creditCopyText&amp;utm_medium=referral&amp;utm_source=unsplash">Unsplash</a>.</p>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>How to cite</dt>
<dd>
Tarran, Brian. 2024. “£10m for UK regulators to ‘jumpstart’ AI capabilities, as government commits to white paper approach.” Real World Data Science, February 8, 2024. <a href="https://realworlddatascience.net/viewpoints/editors-blog/posts/2024/02/08/llms-whitepaper-response.html">URL</a>
</dd>
</dl>
</div>
</div>
</div>


</section>


<div id="quarto-appendix" class="default"><section id="footnotes" class="footnotes footnotes-end-of-document"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p>See, for example, <a href="https://realworlddatascience.net/viewpoints/posts/2023/06/05/no-AI-probably-wont-kill-us.html">“No, AI probably won’t kill us all – and there’s more to this fear campaign than meets the eye.”</a>↩︎</p></li>
</ol>
</section></div> ]]></description>
  <category>AI</category>
  <category>Large language models</category>
  <category>Public policy</category>
  <category>Risk</category>
  <category>Regulation</category>
  <guid>https://realworlddatascience.net/viewpoints/editors-blog/posts/2024/02/08/llms-whitepaper-response.html</guid>
  <pubDate>Thu, 08 Feb 2024 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/viewpoints/editors-blog/posts/2024/02/08/images/parliament-and-thames.png" medium="image" type="image/png" height="105" width="144"/>
</item>
<item>
  <title>UK government sets out 10 principles for use of generative AI</title>
  <dc:creator>Brian Tarran</dc:creator>
  <link>https://realworlddatascience.net/viewpoints/editors-blog/posts/2024/01/22/gen-ai-framework.html</link>
  <description><![CDATA[ 





<p>The UK government has published <a href="https://www.gov.uk/government/publications/generative-ai-framework-for-hmg/generative-ai-framework-for-hmg-html">a framework for the use of generative AI</a>, setting out 10 principles for departments and staff to think about if using, or planning to use, this technology.</p>
<p>It covers the need to understand what generative AI is and its limitations, the lawful, ethical and secure use of the technology, and a requirement for “meaningful human control.”</p>
<p>The focus is on large language models (LLMs) as, according to the framework, these have “the greatest level of immediate application in government.”</p>
<p>It lists a number of promising use cases for LLMs, including the synthesise of complex data, software development, and summaries of text and audio. However, the document cautions against using generative AI for fully automated decision-making or in contexts where data is limited or explainability of decision-making is required. For example, it warns that:</p>
<blockquote class="blockquote">
<p>“although LLMs can give the appearance of reasoning, they are simply predicting the next most plausible word in their output, and may produce inaccurate or poorly-reasoned conclusions.”</p>
</blockquote>
<p>And on the issue of explainability, it says that:</p>
<blockquote class="blockquote">
<p>“generative AI is based on neural networks, which are so-called ‘black boxes’. This makes it difficult or impossible to explain the inner workings of the model which has potential implications if in the future you are challenged to justify decisioning or guidance based on the model.”</p>
</blockquote>
<p>The framework goes on to discuss some of the practicalities of building generative AI solutions. It talks specifically about the value a multi-disciplinary team can bring to such projects, and emphasises the role of data scientists:</p>
<blockquote class="blockquote">
<p>“data scientists … understand the relevant data, how to use it effectively, and how to build/train and test models.”</p>
</blockquote>
<p>It also speaks to the need to “understand how to monitor and mitigate generative AI drift, bias and hallucinations” and to have “a robust testing and monitoring process in place to catch these problems.”</p>
<p>What do you make of the <a href="https://www.gov.uk/government/publications/generative-ai-framework-for-hmg/generative-ai-framework-for-hmg-html">Generative AI Framework for His Majesty’s Government</a>? What does it get right, and what needs more work?</p>
<div class="callout callout-style-simple callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
And in case you missed it…
</div>
</div>
<div class="callout-body-container callout-body">
<p>New York State issued a policy on the <a href="https://its.ny.gov/acceptable-use-artificial-intelligence-technologies">Acceptable Use of Artificial Intelligence Technologies</a> earlier this month. Similar to the UK government framework, it references the need for human oversight of AI models and rules out use of “automated final decision systems.” There is also discussion of fairness, equity and explainability, and AI risk assessment and management.</p>
</div>
</div>
<div class="article-btn">
<p><a href="../../../../../../viewpoints/editors-blog/index.html">Back to Editors’ blog</a></p>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-6">
<dl>
<dt>Copyright and licence</dt>
<dd>
© 2024 Royal Statistical Society
</dd>
</dl>
<p><a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> <img style="height:22px!important;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"></a> This article is licensed under a Creative Commons Attribution 4.0 (CC BY 4.0) <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> International licence</a>. Thumbnail photo by <a href="https://unsplash.com/@therawhunter?utm_content=creditCopyText&amp;utm_medium=referral&amp;utm_source=unsplash">Massimiliano Morosinotto</a> on <a href="https://unsplash.com/photos/brown-tower-clock-under-cloudy-sy-paINk01G8Xk?utm_content=creditCopyText&amp;utm_medium=referral&amp;utm_source=unsplash">Unsplash</a>.</p>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>How to cite</dt>
<dd>
Tarran, Brian. 2024. “UK government sets out 10 principles for use of generative AI.” Real World Data Science, January 22, 2024. <a href="https://realworlddatascience.net/viewpoints/editors-blog/posts/2024/01/22/gen-ai-framework.html">URL</a>
</dd>
</dl>
</div>
</div>
</div>



 ]]></description>
  <category>AI ethics</category>
  <category>Large language models</category>
  <category>Monitoring</category>
  <category>Public policy</category>
  <category>Risk</category>
  <guid>https://realworlddatascience.net/viewpoints/editors-blog/posts/2024/01/22/gen-ai-framework.html</guid>
  <pubDate>Mon, 22 Jan 2024 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/viewpoints/editors-blog/posts/2024/01/22/images/uk-parliament.png" medium="image" type="image/png" height="105" width="144"/>
</item>
<item>
  <title>When will the cherry trees bloom? Get ready to make and share your predictions!</title>
  <dc:creator>Brian Tarran</dc:creator>
  <link>https://realworlddatascience.net/viewpoints/editors-blog/posts/2024/01/18/cherry-blossom.html</link>
  <description><![CDATA[ 





<p>The <a href="https://competition.statistics.gmu.edu/">2024 International Cherry Blossom Prediction Competition</a> will open for entries on February 1, and Real World Data Science is once again proud to be a sponsor.</p>
<p>Contestants are invited to submit predictions for the date cherry trees will bloom in 2024 at five different locations – Kyoto, Japan; Liestal-Weideli, Switzerland; Vancouver, Canada; and Washington, DC and New York City, USA.</p>
<p>The competition organisers will provide all the publicly available data they can find for the bloom dates of cherry trees in these locations, and contestants will then be challenged to use this data “in combination with any other publicly available data (e.g., climate data) to provide reproducible predictions of the peak bloom date.”</p>
<p>“For this competition, we seek accurate, interpretable predictions that offer strong narratives about the factors that determine when cherry trees bloom and the broader consequences for local and global ecosystems,” say the organisers. “Your task is to predict the peak bloom date for 2024 and to estimate a prediction interval, a lower and upper endpoint of dates during which peak bloom is most probable.”</p>
<p>So that organisers can reproduce the predictions, entrants must submit all data and code in a <a href="https://quarto.org/">Quarto document</a>.</p>
<p>There’s cash and prizes on offer for the best entries, including having your work featured on Real World Data Science. <a href="https://competition.statistics.gmu.edu/">Head on over to the competition website for full details and rules</a>.</p>
<p>And, if you are looking for some inspiration, check out this <a href="https://realworlddatascience.net/ideas/tutorials/posts/2023/04/13/flowers.html">tutorial on the law of the flowering plants</a>, written by Jonathan Auerbach, a co-organiser of the prediction competition.</p>
<p>Good luck to all entrants!</p>
<div class="article-btn">
<p><a href="../../../../../../viewpoints/editors-blog/index.html">Back to Editors’ blog</a></p>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-6">
<dl>
<dt>Copyright and licence</dt>
<dd>
© 2024 Royal Statistical Society
</dd>
</dl>
<p><a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> <img style="height:22px!important;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"></a> This article is licensed under a Creative Commons Attribution 4.0 (CC BY 4.0) <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> International licence</a>. Photo by <a href="https://unsplash.com/@ajny?utm_content=creditCopyText&amp;utm_medium=referral&amp;utm_source=unsplash">AJ</a> on <a href="https://unsplash.com/photos/pink-flowers-McsNra2VRQQ?utm_content=creditCopyText&amp;utm_medium=referral&amp;utm_source=unsplash">Unsplash</a>.</p>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>How to cite</dt>
<dd>
Tarran, Brian. 2024. “When will the cherry trees bloom? Get ready to make and share your predictions!” Real World Data Science, January 18, 2024. <a href="https://realworlddatascience.net/viewpoints/editors-blog/posts/2024/01/18/cherry-blossom.html">URL</a>
</dd>
</dl>
</div>
</div>
</div>



 ]]></description>
  <category>Coding</category>
  <category>Prediction</category>
  <category>Reproducible research</category>
  <category>Statistics</category>
  <guid>https://realworlddatascience.net/viewpoints/editors-blog/posts/2024/01/18/cherry-blossom.html</guid>
  <pubDate>Thu, 18 Jan 2024 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/viewpoints/editors-blog/posts/2024/01/18/images/cherry-blossom.png" medium="image" type="image/png" height="105" width="144"/>
</item>
<item>
  <title>‘We absolutely have to transform and modernise our operation’ – US Census Bureau director Robert Santos</title>
  <dc:creator>Brian Tarran (with Anna Britten)</dc:creator>
  <link>https://realworlddatascience.net/viewpoints/interviews/posts/2024/01/15/census-bureau.html</link>
  <description><![CDATA[ 





<p>A month ago now, Real World Data Science published <a href="https://realworlddatascience.net/viewpoints/interviews/posts/2023/12/15/ian-diamond.html">an interview with UK national statistician Professor Sir Ian Diamond</a>. In the process of preparing the text of that interview for publication, I found myself reflecting on a conversation I’d been part of earlier in the year with Robert Santos, director of the US Census Bureau.</p>
<p>I met Santos in Toronto, Canada, in August – a few hours before his <a href="https://www.youtube.com/watch?v=SmljZLfqIbI">President’s Invited Address at the 2023 Joint Statistical Meetings</a>. The meeting was arranged as a joint interview with Anna Britten, editor of our sister publication <em>Significance</em> magazine, and Santos was joined by Sallie Ann Keller, the Census Bureau’s chief scientist and associate director for research and methodology, and Michael Hawes, senior advisor for data access and privacy.</p>
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/SmljZLfqIbI?si=QEAN6QpbTlwPs20" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<p>The interview with Santos, Keller, and Hawes was published in <a href="https://academic.oup.com/jrssig/article/20/5/40/7296065">the October issue of <em>Significance</em></a>, so you may have already read it. But, following on from our Sir Ian Diamond interview, I thought it worth highlighting some of what Santos <em>et al.</em> had to say, particularly where key themes, challenges, and opportunities seem to resonate across both the US Census Bureau and the UK Office for National Statistics.</p>
<p>I’ve also gone back to the original interview recording to pick out some previously unpublished comments.</p>
<div class="keyline">
<hr>
</div>
<section id="on-the-scale-of-the-challenge-santos-inherited-on-becoming-director-of-the-us-census-bureau-in-january-2022" class="level3">
<h3 class="anchored" data-anchor-id="on-the-scale-of-the-challenge-santos-inherited-on-becoming-director-of-the-us-census-bureau-in-january-2022">On the scale of the challenge Santos inherited on becoming director of the US Census Bureau in January 2022</h3>
<p><strong>Robert Santos:</strong> Certainly it was formidable – although I’m comforted in knowing, after a year and a half, that the career staff [of the Census Bureau] were well positioned to accept this challenge anyway, and were working on it. But the challenge was real. We had the pandemic. We had to, basically, not redesign but scramble and adapt to a really threatening situation where the entirety of the 2020 census was conducted before there was a vaccine, and when people didn’t know the nature of the beast. A huge chunk of this operation was conducted when society was shut down. And not only did the Census Bureau need to rethink, nimbly and quickly, how to do its operation, but so did all of the different community partners – which was really enlightening because we realised that, at the end of the day, we could not have completed this job alone. And now our position is that we cannot complete our mission without the external community. They’re the extra folks we need in order to understand better what the needs are, and therefore improve our methods and data and the relevance of what we’re doing.</p>
<p>So, we see our role now as having a continuous engagement with the entire country at all levels – be it elected officials, universities and professors and the research community, or data users like policy users and policy researchers, or local community organisations that are doing neighbourhood stuff. And so we’re actively working between censuses to engage them and show them the value of the data that we’ve collected – not just decennial [census data], but also our flagship American Community Survey and our Current Population Study and all the 130 other business, economic as well as household types of studies that we’re doing.</p>
</section>
<section id="on-the-need-to-transform-census-bureau-operations" class="level3">
<h3 class="anchored" data-anchor-id="on-the-need-to-transform-census-bureau-operations">On the need to transform Census Bureau operations</h3>
<p><strong>Robert Santos:</strong> We absolutely have to transform and modernise our operation, from what was historically this transactional survey type of data collection – where we go to somebody that’s randomly sampled and we say, “Please give me your information” – and realise the value of taking that information, blending it with existing data, administrative data, even third-party private sector data, into a huge data pool and linking it together, and that will create new data products that will serve the public in ways that we never imagined before. And we already have some great examples of that. So, that transformation process is an incredible priority that we have to do, regardless of what our funding situation is. If we don’t do that, we’re not going to be able to serve the public in the way that we need to.</p>
</section>
<section id="on-laying-the-groundwork-for-the-2030-census-and-an-increased-use-of-administrative-data" class="level3">
<h3 class="anchored" data-anchor-id="on-laying-the-groundwork-for-the-2030-census-and-an-increased-use-of-administrative-data">On laying the groundwork for the 2030 census and an increased use of administrative data</h3>
<p><strong>Robert Santos:</strong> There are a couple of things going on. One is that we’re obliged, because of our values of scientific integrity, objectivity, transparency, and independence, to let folks know what we’re doing in terms of our use of administrative records, and we’ve done that and we will continue doing that. The big lift was really in preparing for the last decennial [census], where we took the use of administrative records to new heights in terms of their utility – not only to help us for some enumeration of households, but, more importantly, to help us predict which households were occupied or not, or to predict which households would benefit from the use of administrative record enumeration versus which ones wouldn’t, or how many times should we knock on the door before we do something else. And now, with that knowledge, we’re looking back at 2020 and saying, what worked? What didn’t? How can we exploit it? And we’re kind of moving the dial to say, “What can we take more advantage of for 2030?”, with full recognition that there were some subpopulations, there’s some segments of society, that we really need to focus and hone in on to make sure we get a good count.</p>
<div class="pullquote-container">
<div class="grid">
<div class="g-col-12 g-col-lg-4">
<div class="quarto-figure quarto-figure-left">
<figure class="figure">
<p><img src="https://realworlddatascience.net/viewpoints/interviews/posts/2024/01/15/images/robert-santos-sq.png" class="img-fluid quarto-figure quarto-figure-left figure-img" alt="Official photograph of US Census Bureau director Robert Santos, with US flag in background."></p>
<figcaption>Robert Santos, director, US Census Bureau</figcaption>
</figure>
</div>
</div>
<div class="g-col-12 g-col-lg-8 pullquote-grid pullquote">
<p><img src="https://realworlddatascience.net/images/pullquote-purple.png" class="img-fluid" width="50"></p>
<p>We absolutely have to transform and modernise our operation, and realise the value of taking [survey] information, blending it with existing data, administrative data, even third-party private sector data, into a huge data pool and linking it together, and that will create new data products that will serve the public in ways that we never imagined before.</p>
</div>
</div>
</div>
</section>
<section id="on-addressing-public-concerns-about-data-collection-and-data-privacy" class="level3">
<h3 class="anchored" data-anchor-id="on-addressing-public-concerns-about-data-collection-and-data-privacy">On addressing public concerns about data collection and data privacy</h3>
<p><strong>Michael Hawes:</strong> Even though the decennial census is mandatory under law, we rely on voluntary participation. We’re relying on people being willing to respond to their census. In the lead up to each census, we do an extensive survey of what are the attitudes or motivators that will encourage people to respond or to not respond. And one of the recurring themes in that is concerns about privacy, concerns about how their data can be used. So, in order to help encourage people who have those concerns – and this is a sizable percentage of the population – we do need to have strong messaging about how their data are protected, how they can only be used for statistical purposes, and so on. But that has to be in very easy-to-consume sound bites, because a lot of people don’t have a background in statistical disclosure control or even in the legal conceptions about what privacy is. So, that is a real challenge for us. How do we convey the fact that we are taking this very seriously, and that their data are protected, in a way that people can kind of internalise and respond to?</p>
</section>
<section id="on-making-sure-statistics-serve-the-public-good-and-the-role-of-the-census-bureau-in-supporting-data-literacy" class="level3">
<h3 class="anchored" data-anchor-id="on-making-sure-statistics-serve-the-public-good-and-the-role-of-the-census-bureau-in-supporting-data-literacy">On making sure statistics serve the public good, and the role of the Census Bureau in supporting data literacy</h3>
<p><strong>Sallie Ann Keller:</strong> In the US over the last decade, there’s been a really large movement around data for the public good, data science for the public good, and it’s really focused at trying to engage researchers and scholars – and we’re talking about high school students, community college students, undergraduates, graduate students – trying to engage them with civic engagement around data and data insights. That’s happening all over the country – really trying to democratise data and bring it in service of the public good. And I think that’s very exciting.</p>
<p><strong>Michael Hawes:</strong> We have a whole programme called Statistics in Schools which is about taking census data and making it valuable to teachers in the classroom, and allowing students at various levels – from elementary school through high school – to be able to engage with the data and use it to inform their own learning, and to learn about their own communities. That is especially profound in the years around the actual census, because that also serves as a catalyst for getting households to respond. If the kids are using the census data within the classroom, then they go home and say, “Hey, have you filled out your census form?”</p>
<p><strong>Robert Santos:</strong> It’s really important to start young, but then there’s also folks who want to use the data who are adults. So, we have something called the Census Academy, where you can go on to YouTube and get tutorials that show you visually somebody trying to use census data. And the second thing we do is, we really have a strong commitment for creating easier platforms for folks to access and utilise various types of data produced by the Census Bureau. We’re creating these data visualisation tools that bring together the demographic data that we collect, the economic data that we collect, and visualise it down to the census tract level so that local communities can pull that up. And then finally, in terms of the public good, there’s also work that we’re doing with the Federal Emergency Management Agency and the National Oceanic and Atmospheric Administration on our community resilience estimates to create the same type of data visualisations that can show where the potential worrisome geographic spots are.</p>
</section>
<section id="on-the-opportunities-for-bringing-together-census-bureau-data-and-large-language-models" class="level3">
<h3 class="anchored" data-anchor-id="on-the-opportunities-for-bringing-together-census-bureau-data-and-large-language-models">On the opportunities for bringing together Census Bureau data and large language models</h3>
<p><strong>Sallie Ann Keller:</strong> We’re not going to be in the business of building generative AI models. But what we want is the statistics that we put out, the data that we put out, to be picked up by these large language models – to be kind of an input into generative AI. So, we are focused on that in terms of really looking at the structure of how we’re disseminating statistics, and how we’re disseminating things like data tables. How harvestable are they for AI? What are the guardrails we should put around that? We’re looking at and considering issues on data integrity, because when questions are posed, we would like our official statistics to be answering those questions, not our statistics translated through three other parties. Data integrity is really a huge issue, because we don’t want false data and infiltration happening that gets branded as our statistics. I don’t know where we’ll take it all, but I think we’d also like to be incredibly creative here. So, let’s suppose you ask a question and some statistic comes back. Well, why not have that be an experience, so that not just a statistic comes back but maybe a question or two comes back, to try to assess the context that you’re really asking about, so that we can not only have our data coming to you, but we can have the right data coming to you?</p>
<p><strong>Michael Hawes:</strong> Even with some of our more traditional statistical data products, informing users of the limitations and the the uncertainty baked into a lot of those estimates has historically been a challenge – even for some more sophisticated users. The number of people who ignore margins of error on data tables, even in our data products, is not insubstantial. And so, when we get into an AI-driven data dissemination kind of framework, how can we use the flexibility of those platforms to not just provide the answers to the questions people are asking, but also to educate and inform about what the limitations of those answers are?</p>
<div class="article-btn">
<p><a href="../../../../../../viewpoints/interviews/index.html">Find more Interviews</a></p>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-6">
<dl>
<dt>Copyright and licence</dt>
<dd>
© 2023 Royal Statistical Society
</dd>
</dl>
<p><a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> <img style="height:22px!important;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"></a> This article is licensed under a Creative Commons Attribution 4.0 (CC BY 4.0) <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> International licence</a>. Photo of Robert Santos is excluded from this licence; it is a US Government work.</p>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>How to cite</dt>
<dd>
Tarran, Brian. 2023. “‘We absolutely have to transform and modernise our operation’ – US Census Bureau director Robert Santos.” Real World Data Science, January 15, 2024. <a href="https://realworlddatascience.net/viewpoints/interviews/posts/2024/01/15/census-bureau.html">URL</a>
</dd>
</dl>
</div>
</div>
</div>


</section>

 ]]></description>
  <category>Data</category>
  <category>Data privacy</category>
  <category>Data literacy</category>
  <category>Education</category>
  <category>Public engagement</category>
  <category>AI</category>
  <guid>https://realworlddatascience.net/viewpoints/interviews/posts/2024/01/15/census-bureau.html</guid>
  <pubDate>Mon, 15 Jan 2024 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/viewpoints/interviews/posts/2024/01/15/images/robert-santos.png" medium="image" type="image/png" height="105" width="144"/>
</item>
<item>
  <title>Creating a web publication with Quarto: the Real World Data Science origin story</title>
  <dc:creator>Brian Tarran</dc:creator>
  <link>https://realworlddatascience.net/viewpoints/editors-blog/posts/2024/01/03/posit-conf-video.html</link>
  <description><![CDATA[ 





<p>When I attended posit::conf(2023) in Chicago last year, I gave a talk about creating Real World Data Science using Quarto, the open source publishing system developed by Posit. That talk is now online, along with all the other conference talks and keynotes.</p>
<p>My talk, “From Journalist to Coder: Creating a Web Publication with Quarto,” is embedded below. You can also find a selection of talks on <a href="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/09/19/positconf-blog.html">our posit::conf highlights blog</a>. The <a href="https://www.youtube.com/playlist?list=PL9HYL-VRX0oRFZslRGHwHuwea7SvAATHp">full conference playlist is on YouTube</a>.</p>
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/ncDEqHxMWnE?si=A1GmLphRPlmspJCj" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<div class="article-btn">
<p><a href="../../../../../../viewpoints/editors-blog/index.html">Back to Editors’ blog</a></p>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-6">
<dl>
<dt>Copyright and licence</dt>
<dd>
© 2024 Royal Statistical Society
</dd>
</dl>
<p><a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> <img style="height:22px!important;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"></a> This article is licensed under a Creative Commons Attribution 4.0 (CC BY 4.0) <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> International licence</a>.</p>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>How to cite</dt>
<dd>
Tarran, Brian. 2024. “Creating a web publication with Quarto: the Real World Data Science origin story.” Real World Data Science, January 03, 2024. <a href="https://realworlddatascience.net/viewpoints/editors-blog/posts/2024/01/03/posit-conf-video.html">URL</a>
</dd>
</dl>
</div>
</div>
</div>



 ]]></description>
  <category>Coding</category>
  <category>Communication</category>
  <category>Events</category>
  <category>Communities</category>
  <category>Open source</category>
  <guid>https://realworlddatascience.net/viewpoints/editors-blog/posts/2024/01/03/posit-conf-video.html</guid>
  <pubDate>Wed, 03 Jan 2024 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/viewpoints/editors-blog/posts/2024/01/03/images/video-grab.png" medium="image" type="image/png" height="105" width="144"/>
</item>
<item>
  <title>‘I was pretty clear in my mind that we were into a no-going-back situation’</title>
  <dc:creator>Brian Tarran</dc:creator>
  <link>https://realworlddatascience.net/viewpoints/interviews/posts/2023/12/15/ian-diamond.html</link>
  <description><![CDATA[ 





<p>For many people, six months into a new job is about the time you start to feel fully on top of things. You’ve figured out how the organisation works and your place in it. You’ve met all of your colleagues and got to know your way around the office. The job makes sense, everything’s under control. But then, a pandemic hits! What do you do? What is going through your head?</p>
<p>That’s a question we put to Professor Sir Ian Diamond, UK national statistician, who was only six months into the job when Covid-19 upended everything. He said: “My overall sense at all times was one of, ‘What needs to be done? What role can we play in helping to do it? And how do we make sure that we are doing things at pace?’”</p>
<p>There was no “flapping,” he said, but there was a real risk of exhaustion. “I could see pretty quickly that this was going to be a marathon, not a sprint, and while we had a lot to do,” he explained, “the last thing on earth we needed was for people to start burning out.”</p>
<p>Almost four years have passed since that time, but the effects of the pandemic continue to be felt – not least within the Office for National Statistics (ONS), the organisation Sir Ian leads. The Covid experience helped shape his thinking about how the ONS would operate post-pandemic, as he explains in this interview.</p>
<p>When we spoke with Sir Ian, he was six months into a second term as national statistician. By the end of that term, in 2028, what kind of organisation will the ONS be? Read on to find out.</p>
<div class="keyline">
<hr>
</div>
<p><strong>What was your experience of the Covid pandemic, being only six months into the role of national statistician at the time?</strong><br>
It was all-consuming and required an enormous amount of focus. At the beginning of the pandemic, huge amounts of data were flying in every different direction. I felt we were in a data deluge, and we needed to move to [delivering] insight, and really working hard early on to change the agenda towards a situation where we were asking questions – really serious and sensible questions – and working out if we had the data, or how we answered those questions.</p>
<p><strong>On the whole, ONS and the Government Statistical Service were praised for the way they responded to Covid. Did the pandemic experience inform your thinking about how the statistical system should operate once we moved out of that crisis situation?</strong><br>
Yes, in a number of areas. One was that we should not be completely dependent on data collected traditionally. For example, as we went into the pandemic, our ways of calculating inflation were pretty much dependent on people with clipboards going into supermarkets and shops and writing down the prices of things. We already had a project which was starting to think long term of using scanner data. But actually, being able to pivot very quickly to using web scraping to get data was incredibly important. We were also able to use web scraping early on to understand the availability of various goods in what we might call “adaptive purchasing,” or some would call “stockpiling.” And so, identifying that there were new ways of doing things and new data sources, I was pretty clear in my mind that we were into a no-going-back situation.</p>
<p>The second thing we demonstrated was that we could set things up very agilely and very quickly. And one final thing that I thought we absolutely have to continue with all the time is improved communication. You may recall that there were press conferences every day [during the early part of the pandemic], and I think during the start of those press conferences, the graphs and the slides were not always as brilliant as I would want them to be. We embedded a team into the Government Communication Service to work on the slides, and I thought that team did a great job. Improving the communication of statistics was incredibly important, because one of the things to come out of this dreadful pandemic was that people across the country became more data literate, and more demanding of data, and more able to interpret data. That was a good thing which I wanted to make sure we continued.</p>
<p><strong>In terms of embedding the lessons or the learnings of the pandemic into the ONS going forward, how much of it is culture change? How much is about rethinking the systems and the processes?</strong><br>
Was it culture? Was it improved processes? Was it better methods? All of the above. As an organisation, our main role in life is to measure the economy and society, and if you take that as your starting point, and then you ask the question, “In your lifetime, has the economy ever stood still? Has society ever stood still?” In my lifetime, I would argue, no. Therefore, we have to be an organisation which is constantly changing in order to reflect what is going on in the economy and in society. We have to change how we do things, and to ask questions about whether there are better ways of doing things, and that, I think, has been a really important reflection for us over the period both during and since the pandemic. We’ve learned a lot about the use of, for example, reproducible analytic pipelines to really improve the quality of our data at large, to improve the quality of our processes, and to enable us to do things more efficiently and effectively. We’ve learned a lot about new data sources, and we’ve really built on the opportunities and the skills so that you can now link data to be able to address questions that I could only have dreamt of 20 years ago.</p>
<p>And so, I do think we have changed the culture, changed our techniques, and changed our data. But does that mean that we’ve metaphorically thrown away the baby with the bathwater? Absolutely not. What we have now are appropriate methodologies to answer appropriate questions. Do we still use qualitative data? A hundred percent, when it is necessary to do so. Do we still use surveys? Yes, we’ve got some of the best surveys in the world. But equally, we also use digital data, administrative data, and we use very modern techniques of analysing those data. And we use data science in its broadest sense as often as we can.</p>
<p>So, I do think it’s been a major change in what we do, and that will continue. But underlying it all is a total commitment to quality, a total commitment to making sure that we have the best data to answer the question that we are trying to answer, and that all the time we are using the best approach to answer the questions.</p>
<div class="pullquote-container">
<div class="grid">
<div class="g-col-12 g-col-lg-4">
<div class="quarto-figure quarto-figure-left">
<figure class="figure">
<p><img src="https://realworlddatascience.net/viewpoints/interviews/posts/2023/12/15/images/ian-diamond-sq.png" class="img-fluid quarto-figure quarto-figure-left figure-img" alt="Photo of national statistician Professor Sir Ian Diamond, standing, with microphone, during a talk."></p>
<figcaption>Professor Sir Ian Diamond, UK national statistician. Image supplied, used with permission.</figcaption>
</figure>
</div>
</div>
<div class="g-col-12 g-col-lg-8 pullquote-grid pullquote">
<p><img src="https://realworlddatascience.net/images/pullquote-purple.png" class="img-fluid" width="50"></p>
<p>We have changed the culture, our techniques, and our data. What we have now are appropriate methodologies to answer appropriate questions. Do we still use qualitative data? A hundred percent, when it is necessary to do so. Do we still use surveys? Yes, we’ve got some of the best surveys in the world. But equally, we also use digital data, administrative data, and we use very modern techniques of analysing those data.</p>
</div>
</div>
</div>
<p><strong>As well as changing the culture and the processes within the ONS itself, has some of your work also been about trying to bring the user community with you? When I first started reporting on official statistics 20 years ago, there was a sense that users of the data valued consistency in methodology, because that meant they could go back and look at the time series. But now, with this emphasis on innovation and looking at different ways of producing insight from different sources of data, has there been a tension, if you like, between these two cultures?</strong><br>
That whole question of “we’ve always done it this way” against “we can now do it better” is a super important one. And the length of time series is also important. When we change the ways of doing things, we need to take our user community with us, and we do. At the same time, we also need a very strong narrative (a) about why what we are doing gives us better data, and (b) about what the changes in the time series mean. So, just this year, with regard to prices and inflation, we’ve been able to bring in much better data than we had previously on rail ticket prices by using electronic data. It’s really super exciting. But we didn’t just bring them in and say, “Hey, we’ve got this new way of doing train prices and we’re planning to do the same again next year with used car prices using electronic data!” What we do is we dual run, and we work with our prices advisory committee to ensure that we understand what the implications of this change are, and we understand how to communicate them. But, you’ve got to be measuring the economy in the very, very best way that you can. We should not shy away from improving what we do.</p>
<p><strong>To what extent can the changes in thinking, the changes of approach, be credited to the experimentation and innovation work that is coming out of the ONS Data Science Campus?</strong><br>
The Data Science Campus has been absolutely brilliant. But at the same time, innovation does not only take place in the Data Science Campus. What we’ve built is a culture of innovation right across the organisation. Is that culture of innovation driven by the Data Science Campus? Not so much driven, but certainly helped, and certainly in partnership, and the fact that it is there encourages that culture of innovation.</p>
<p>I do think it is important to recognise, as I say to my colleagues many times, that we are not a blue-sky research institute, we are a national statistics institute, and our job is to produce economic and social statistics. Therefore, we need to be in the business of not just research but research and development – and thinking through how the research on new data that we do will enable improved economic measurement is, for us, incredibly exciting.</p>
<p>I’ll give you an example. We’ve [recently] signed a contract to get telephony data – a few years historically, and then regular data going forward. Now, this is entirely anonymised, but it will enable us to understand much more about, for example, commuting. It means that we will now need to do research on how to use those mobility data, and we’ll be really pushing that forward very quickly. But, at the same time, it’s not just about what can we do that’s interesting in this area; we need to have a very clear vision of what success looks like and the measurements, the economic measurements, that we are going to improve.</p>
<p><strong>How do you see that innovation mindset rolling out across government as a whole?</strong><br>
It’s worth saying two things. Firstly, my job is not only national statistician, I also have an extra couple of hats: one is head of the Government Analysis Function, and one is head of the Government Digital Service. I take those roles very seriously because I do think we need to propagate good practice and innovation right across government departments. It’s no use if it just sits in ONS.</p>
<p>We try really, really hard to have innovation meetings and innovation months, and I try to speak at as many as I’m invited to. And I think it is incredibly important that we really see ourselves – right across the Government Statistical Service, right across the Government Analysis Function – as seeking to propagate good practice.</p>
<p><strong>You mentioned there about the Government Statistical Service and the Government Analysis Function. Is there scope one day for a Data Science Service within government?</strong><br>
The answer is yes. Under both the leadership of Laura Gilbert, who is head of 10 Downing Street’s data science, called 10DS, and Osama Rahman, who heads the Data Science Campus, we recently held a town hall for data scientists right across government to discuss, fundamentally, the question of what data scientists want from the analysis function, but equally [what they want] from a community of data scientists. Part of that is a question as to whether there should be, in government, a data science profession. I stress we haven’t come to the conclusion for that yet, but I would have to say it was a very successful town hall – many, many people attended, we had a really good discussion, and Laura and Osama will be taking forward that discussion over the next couple of months.</p>
<p><strong>You gave a keynote address at the RSS Conference in September, and one of the things you mentioned that I was particularly excited about was “Stat Chat.” I understand this is in the very early stages, and I have a very rudimentary understanding that it might well be a large language model trained on the ONS website and the data resources available, as a way to query the website. Can you tell me a bit more about the project?</strong><br>
We’re in private beta, and so there’s a whole set of agendas there. But we started it as a much better way to enable people to interrogate a pretty complex website with an enormous amount of data on, and to not only get to the datasets but to get to the existing metadata that are attached to them. What we wanted to do was to use open-source models, where the underlying data and the research behind them are made publicly available, so there’s nothing secret about this at the moment, and it’s very early stage. But we see the potential, as we move forward, as being able to really make it much easier for people to interrogate the data that we own and the data that we have published. If we can actually use large language models to enable people to be able to ask questions and then to get an authoritative answer from publicly available data, that seems to me to be a good place to be.</p>
<p><strong>I imagine, though, that when you’re dealing with something like national statistics, you need to be very alive to the danger of <a href="https://realworlddatascience.net/viewpoints/editors-blog/posts/2022/11/23/LLM-content-warning.html#qa">the hallucination problem in large language models</a>; that if you’re querying something, it doesn’t throw up an invented statistic?</strong><br>
I couldn’t agree more. And that’s why we’re in private beta, working very hard to make sure that (a) it is working properly, (b) that it’s got the right security around it, and (c) that it is actually really useful.</p>
<p><strong>The hallucination issue in LLMs leads us onto the topic of trust in information, and obviously the ONS is very keen to ensure that there is trust in official statistics and in the data that is produced. This is a wider problem than anything the ONS can hope to address by itself, but what are the kinds of conversations you’re having internally about distrust in official sources of information?</strong><br>
This is something I say to my colleagues a lot: We should not expect people to trust us. We have to demonstrate to people that we are trustworthy. That’s incredibly important. A lot of it is about transparency. A lot of it is about absolute openness, showing your working, explaining where your data came from, and explaining your motivation for doing something. People say to me, “You might write a really strong methodological piece, but not many people read it.” Yes, but it’s there. And I’m a huge believer in research integrity, and in open data, and enabling data to be available for secondary analysis. And I think the more you are transparent, the more you work with people, the better.</p>
<p>A critical part, also, of demonstrating that you are trustworthy is engaging with the public. And that’s not telling the public; it’s engaging with the public. We put a lot of time into working with the public to say, “Well, what if we did this? What if we did that?” and getting their input. I don’t have any kind of switch to make people feel that we are trustworthy. It’s a continuous process of transparency and openness, where people feel that they have everything they need [to know] about what we do and about our data.</p>
<p>We also are absolutely passionate about explaining uncertainty. Don’t tell me the answer is 62% – the answer has some uncertainty about it, and we need to really think about how we display that uncertainty. And I have to say, I think some of the techniques now to display uncertainty are just so beautiful – unbelievably beautiful – and we need to do that, not in a gimmicky way, but in a way that really explains the uncertainty in any data that we present.</p>
<p><strong>Final question: by the end of your second term as national statistician, where do you think ONS will be as an organisation?</strong><br>
I hope it will be an innovative, agile organisation which is using evermore diverse types of information, but doing so in a transparent and open and rigorous way to improve economic and social statistics which can impact positively on the lives of our fellow citizens.</p>
<div class="article-btn">
<p><a href="../../../../../../viewpoints/interviews/index.html">Find more Interviews</a></p>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-6">
<dl>
<dt>Copyright and licence</dt>
<dd>
© 2023 Royal Statistical Society
</dd>
</dl>
<p><a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> <img style="height:22px!important;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"></a> This article is licensed under a Creative Commons Attribution 4.0 (CC BY 4.0) <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> International licence</a>. Photo of Professor Sir Ian Diamond is not included in this licence.</p>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>How to cite</dt>
<dd>
Tarran, Brian. 2023. “‘I was pretty clear in my mind that we were into a no-going-back situation.’” Real World Data Science, December 15, 2023. <a href="https://realworlddatascience.net/viewpoints/interviews/posts/2023/12/15/ian-diamond.html">URL</a>
</dd>
</dl>
</div>
</div>
</div>



 ]]></description>
  <category>Data</category>
  <category>People</category>
  <category>Innovation</category>
  <category>Data literacy</category>
  <category>Public engagement</category>
  <guid>https://realworlddatascience.net/viewpoints/interviews/posts/2023/12/15/ian-diamond.html</guid>
  <pubDate>Fri, 15 Dec 2023 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/viewpoints/interviews/posts/2023/12/15/images/ian-diamond.png" medium="image" type="image/png" height="105" width="144"/>
</item>
<item>
  <title>Creating Christmas cards with R</title>
  <dc:creator>Nicola Rennie</dc:creator>
  <link>https://realworlddatascience.net/ideas/tutorials/posts/2023/12/12/xmas-cards.html</link>
  <description><![CDATA[ 





<p>When you think about data visualisation in R <span class="citation" data-cites="R-base">(R Core Team 2022)</span>, you’d be forgiven for not jumping straight to thinking about creating Christmas cards. However, the package and functions we often use to create bar charts and line graphs can be repurposed to create festive images. This tutorial provides a step-by-step guide to creating a Christmas card featuring a snowman – entirely in R. Though this seems like just a fun exercise, the functions and techniques you learn in this tutorial can also transfer into more traditional data visualisations created using {ggplot2} <span class="citation" data-cites="ggplot2">(Wickham 2016)</span> in R.</p>
<p>The code in this tutorial relies on the following packages:</p>
<div class="sourceCode" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">library</span>(ggplot2)</span>
<span id="cb1-2"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">library</span>(ggforce)</span>
<span id="cb1-3"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">library</span>(sf)</span></code></pre></div>
<blockquote class="blockquote">
<p>You may also have seen this tutorial presented at the <a href="https://github.com/nrennie/oxford-RUG-christmas-cards">Oxford R User Group November 2023 Meetup</a>.</p>
</blockquote>
<section id="lets-build-a-snowman" class="level2">
<h2 class="anchored" data-anchor-id="lets-build-a-snowman">Let’s build a snowman!</h2>
<p>Before we jump in to writing R code, let’s take a step back and think about what you actually need to build a snowman. If you were given some crayons and a piece of paper, what would you draw?</p>
<p>You might draw two or three circles to make up the head and body. Perhaps some smaller dots for buttons and eyes, and a (rudimentary) hat constructed from some rectangles. Some brown lines create sticks for arms and, of course, a triangle to represent a carrot for a nose. For the background elements of our Christmas card, we also need the night sky (or day if you prefer), a light dusting of snow covering the ground, and a few snowflakes falling from the sky.</p>
<p>Now lines, rectangles, circles, and triangles are all just simple geometric objects. Crucially, they’re all things that we can create with {ggplot2} in R.</p>
</section>
<section id="build-a-snowman-with-r" class="level2">
<h2 class="anchored" data-anchor-id="build-a-snowman-with-r">Build a snowman with R</h2>
<p>Let’s start with the background. The easiest way to start with a blank canvas in {ggplot2} is to create an empty plot using <code>ggplot()</code> with no arguments. We can also remove all theme elements (such as the grey background and grid lines) with <code>theme_void()</code>. To change the background colour to a dark blue for the night sky, we can edit the <code>plot.background</code> element of the theme using <code>element_rect()</code> (since the background is essentially just a big rectangle).</p>
<p>In {ggplot2} <code>fill</code> is the inner colour of shapes whilst <code>colour</code> is the outline colour. You can specify colours in different ways in R: either via the <code>rgb()</code> function, using a character string for a hex colour such as <code>"#000000"</code>, or using a named colour. If you run <code>colors()</code>, you’ll see all the valid named colours you can use. Here, we’ve picked <code>"midnightblue"</code>.</p>
<p>Let’s save this initial plot as an object <code>s1</code> that we’ll keep adding layers to. Saving plots in different stages of styling as objects can help to keep your code more modular.</p>
<div class="sourceCode" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb2-1">s1 <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">ggplot</span>() <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span></span>
<span id="cb2-2">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">theme_void</span>() <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span></span>
<span id="cb2-3">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">theme</span>(</span>
<span id="cb2-4">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">plot.background =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">element_rect</span>(</span>
<span id="cb2-5">      <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">fill =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"midnightblue"</span></span>
<span id="cb2-6">      )</span>
<span id="cb2-7">  )</span>
<span id="cb2-8">s1</span></code></pre></div>
<p>Next we’ll add some snow on the ground. We’ll do this by drawing a white rectangle along the bottom of the plot. There are two different functions that we could use to add a rectangle: <code>geom_rect()</code> or <code>annotate()</code>. The difference between the two is that <code>geom_rect()</code> maps columns of a <code>data.frame</code> to different elements of a plot whereas <code>annotate()</code> can take values passed in as vectors. Most of the {ggplot2} graphs you’ll see will use <code>geom_*()</code> functions. However, if you’re only adding one or two elements to a plot then <code>annotate()</code> might be quicker.</p>
<p>Since we’re only adding one rectangle for the snow, it’s easier to use <code>annotate()</code> with the <code>"rect"</code> geometry. This requires four arguments: the minimum and maximum x and y coordinates of the rectangle – essentially specifying where the corners are. We can also change the colour of the rectangle and its outline using the <code>fill</code> and <code>colour</code> arguments. Here, I’ve used a very light grey instead of white.</p>
<p>If we don’t set the axis limits using <code>xlim()</code> and <code>ylim()</code>, the plot area will resize to fit the area of the snow rectangle. The night sky background will disappear. You can choose any axis limits you wish here – but the unit square will make it easier to find the right coordinates when deciding where to position other elements. Finally, we add <code>coord_fixed()</code> to fix the 1:1 aspect ratio and make sure our grid is actually square with <code>expand = FALSE</code> to remove the additional padding at the sides of the plot.</p>
<div class="sourceCode" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb3-1">s2 <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> s1 <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span></span>
<span id="cb3-2">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">annotate</span>(</span>
<span id="cb3-3">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">geom =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"rect"</span>,</span>
<span id="cb3-4">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">xmin =</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">xmax =</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>,</span>
<span id="cb3-5">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">ymin =</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">ymax =</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.2</span>,</span>
<span id="cb3-6">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">fill =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"grey98"</span>,</span>
<span id="cb3-7">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">colour =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"grey98"</span></span>
<span id="cb3-8">  ) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span></span>
<span id="cb3-9">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">xlim</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span></span>
<span id="cb3-10">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">ylim</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span></span>
<span id="cb3-11">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">coord_fixed</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">expand =</span> <span class="cn" style="color: #8f5902;
background-color: null;
font-style: inherit;">FALSE</span>)</span>
<span id="cb3-12">s2</span></code></pre></div>
<div>

</div>
<div class="quarto-layout-panel" data-layout-ncol="2">
<div class="quarto-layout-row">
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: center;">
<p><img src="https://realworlddatascience.net/ideas/tutorials/posts/2023/12/12/images/s1.png" class="img-fluid" alt="Dark blue square."></p>
</div>
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: center;">
<p><img src="https://realworlddatascience.net/ideas/tutorials/posts/2023/12/12/images/s2.png" class="img-fluid" alt="Dark blue square with off-white rectangle at the bottom."></p>
</div>
</div>
</div>
<p>To finish off the background, we’ll add some falling snowflakes. We first need to decide where on the plot the snowflakes will appear. We’ll be plotting lots of snowflakes, so manually typing out the coordinates of where they’ll be would be very inefficient. Instead, we can use functions to generate the locations randomly. For this we’ll use the uniform distribution. The uniform distribution has two parameters – the lower and upper bounds where any values between the bounds are equally likely. You can generate samples from a uniform distribution in R using the <code>runif()</code> function.</p>
<p>When generating random numbers in R (or any other programming language), it’s important to set a seed. This means that if you give your code to someone else, they’ll get the same random numbers as you. Some people choose to use the date as the random seed and since we’re making Christmas cards, we’ll use Christmas day as the random seed – in <code>yyyymmdd</code> format, of course!</p>
<p>We create a variable <code>n</code> specifying how many snowflakes we’ll create. Creating a variable rather than hard coding the variables makes it easier to vary how many snowflakes we want. Since our plot grid goes between 0 and 1 in both the x and y directions, we generate random numbers between 0 and 1 for both the x and y coordinates and store the values in a <code>data.frame</code> called <code>snowflakes</code>.</p>
<div class="sourceCode" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb4-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">set.seed</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">20231225</span>)</span>
<span id="cb4-2">n <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">100</span></span>
<span id="cb4-3">snowflakes <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">data.frame</span>(</span>
<span id="cb4-4">  <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">x =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">runif</span>(n, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>),</span>
<span id="cb4-5">  <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">y =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">runif</span>(n, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb4-6">)</span></code></pre></div>
<p>Now we can plot the <code>snowflakes</code> data using <code>geom_point()</code> – the same function you’d use for a scatter plot. Since we’re using a <code>geom_*()</code> function, we need to tell {ggplot2} which columns go on the <code>x</code> and <code>y</code> axes inside the <code>aes()</code> function. To plot the snowflakes, we’re going to make using of R’s different point characters. The default when plotting with <code>geom_point()</code> is a small black dot, but we can choose to use a small star (close enough to a snowflake!) by setting <code>pch = 8</code> and changing the <code>colour</code> to <code>"white"</code>.</p>
<div class="sourceCode" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb5-1">s3 <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> s2 <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span></span>
<span id="cb5-2">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">geom_point</span>(</span>
<span id="cb5-3">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">data =</span> snowflakes,</span>
<span id="cb5-4">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">mapping =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">aes</span>(</span>
<span id="cb5-5">      <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">x =</span> x,</span>
<span id="cb5-6">      <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">y =</span> y</span>
<span id="cb5-7">    ),</span>
<span id="cb5-8">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">colour =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"white"</span>,</span>
<span id="cb5-9">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">pch =</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">8</span></span>
<span id="cb5-10">  )</span>
<span id="cb5-11">s3</span></code></pre></div>
<p>Now comes the part where we start rolling up some snowballs! Or, in the case of an R snowman, we draw some circles. Unfortunately, there isn’t a built-in <code>geom_*()</code> function in {ggplot2} for plotting circles. We could use <code>geom_point()</code> here and increase the size of the points but this approach can look a little bit <em>fuzzy</em> when the points are very large. Instead, we’ll turn to a {ggplot2} extension package for some additional <code>geom_*</code> functions - {ggforce} <span class="citation" data-cites="ggforce">(Pedersen 2022)</span>.</p>
<p>The <code>geom_circle()</code> function requires at least three elements mapped to the aesthetics inside <code>aes()</code>: the coordinates of the centre of the circle given by <code>x0</code> and <code>y0</code>, and the radii of each of the circles, <code>r</code>. Instead of creating a separate data frame and passing it into <code>geom_circle()</code>, we can alternatively create the data frame inside the function. The <code>fill</code> and <code>colour</code> arguments work as they do in {ggplot2} and we can set both to <code>"white"</code>.</p>
<div class="sourceCode" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb6-1">s4 <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> s3 <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span></span>
<span id="cb6-2">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">geom_circle</span>(</span>
<span id="cb6-3">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">data =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">data.frame</span>(</span>
<span id="cb6-4">      <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">x0 =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">c</span>(<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.6</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.6</span>),</span>
<span id="cb6-5">      <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">y0 =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">c</span>(<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.3</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span>),</span>
<span id="cb6-6">      <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">r =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">c</span>(<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.15</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.1</span>)</span>
<span id="cb6-7">    ),</span>
<span id="cb6-8">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">mapping =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">aes</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">x0 =</span> x0, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">y0 =</span> y0, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">r =</span> r),</span>
<span id="cb6-9">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">fill =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"white"</span>,</span>
<span id="cb6-10">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">colour =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"white"</span></span>
<span id="cb6-11">  )</span>
<span id="cb6-12">s4</span></code></pre></div>
<div>

</div>
<div class="quarto-layout-panel" data-layout-ncol="2">
<div class="quarto-layout-row">
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: center;">
<p><img src="https://realworlddatascience.net/ideas/tutorials/posts/2023/12/12/images/s3.png" class="img-fluid" alt="Dark blue square with off-white rectangle at the bottom and small random white stars."></p>
</div>
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: center;">
<p><img src="https://realworlddatascience.net/ideas/tutorials/posts/2023/12/12/images/s4.png" class="img-fluid" alt="Dark blue square with off-white rectangle at the bottom and small random white stars, and two white circles slightly off centre."></p>
</div>
</div>
</div>
<p>We can use <code>geom_point()</code> again to add some more points to represent the buttons and the eyes. Here, we’ll manually specify the coordinates of the points. For the buttons we add them in a vertical line in the middle of the snowman’s body circle, and for the eyes we add them in a horizontal line in the middle of the head circle.</p>
<p>Since no two rocks are exactly the same size, we can add some random variation to the size of the points using <code>runif()</code> again. We generate five different sizes between 2 and 4.5. For reference, the default point size is 1.5. Adding <code>scale_size_identity()</code> means that the sizes of the points are actually equally to the sizes we generated from <code>runif()</code> and removes the legend that is automatically added when we add <code>size</code> inside <code>aes()</code>.</p>
<div class="sourceCode" id="cb7" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb7-1">s5 <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> s4 <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span></span>
<span id="cb7-2">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">geom_point</span>(</span>
<span id="cb7-3">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">data =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">data.frame</span>(</span>
<span id="cb7-4">      <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">x =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">c</span>(<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.6</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.6</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.6</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.57</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.62</span>),</span>
<span id="cb7-5">      <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">y =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">c</span>(<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.25</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.3</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.35</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.52</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.52</span>),</span>
<span id="cb7-6">      <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">size =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">runif</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">4.5</span>)</span>
<span id="cb7-7">    ),</span>
<span id="cb7-8">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">mapping =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">aes</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">x =</span> x, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">y =</span> y, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">size =</span> size)</span>
<span id="cb7-9">  ) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span></span>
<span id="cb7-10">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">scale_size_identity</span>()</span>
<span id="cb7-11">s5</span></code></pre></div>
<p>To add sticks for arms, we can make use of <code>geom_segment()</code> to draw some lines. We could also use <code>geom_path()</code> but that is designed to connect points across multiple cases, whereas <code>geom_segment()</code> draws a single line per row of data – and we don’t want to join the snowman’s arms together!</p>
<p>To use <code>geom_segment()</code> we need to create a data frame containing the x and y coordinates for the start and end of each line, and then pass this into the aesthetic mapping with <code>aes()</code>. We can control the colour and width of the lines using the <code>colour</code> and <code>linewidth</code> arguments. Setting the <code>lineend</code> argument to <code>"round"</code> means that the ends of the lines will be rounded rather than the default straight edge.</p>
<div class="sourceCode" id="cb8" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb8-1">s6 <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> s5 <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> </span>
<span id="cb8-2">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">geom_segment</span>(</span>
<span id="cb8-3">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">data =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">data.frame</span>(</span>
<span id="cb8-4">      <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">x =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">c</span>(<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.46</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.7</span>),</span>
<span id="cb8-5">      <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">xend =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">c</span>(<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.33</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.85</span>),</span>
<span id="cb8-6">      <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">y =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">c</span>(<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.3</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.3</span>),</span>
<span id="cb8-7">      <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">yend =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">c</span>(<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.4</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.4</span>)</span>
<span id="cb8-8">    ),</span>
<span id="cb8-9">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">mapping =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">aes</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">x =</span> x, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">y =</span> y, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">xend =</span> xend, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">yend =</span> yend),</span>
<span id="cb8-10">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">colour =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"chocolate4"</span>,</span>
<span id="cb8-11">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">lineend =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"round"</span>,</span>
<span id="cb8-12">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">linewidth =</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span></span>
<span id="cb8-13">  )</span>
<span id="cb8-14">s6</span></code></pre></div>
<div>

</div>
<div class="quarto-layout-panel" data-layout-ncol="2">
<div class="quarto-layout-row">
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: center;">
<p><img src="https://realworlddatascience.net/ideas/tutorials/posts/2023/12/12/images/s5.png" class="img-fluid" alt="Dark blue square with off-white rectangle at the bottom and small random white stars, and two white circles slightly off centre. Five black dots denote two eyes and three buttons on a snowman."></p>
</div>
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: center;">
<p><img src="https://realworlddatascience.net/ideas/tutorials/posts/2023/12/12/images/s6.png" class="img-fluid" alt="Dark blue square with off-white rectangle at the bottom and small random white stars, and two white circles slightly off centre. Five black dots denote two eyes and three buttons on a snowman. Two brown lines look like arms."></p>
</div>
</div>
</div>
<p>We’ll now add a (very simple) hat to our snowman, fashioned out of two rectangles. We can add the rectangles as we did before using the <code>annotate()</code> function and specifying the locations of the corners of the rectangles. We start with a shorter wider rectangle for the brim of the hat, and then a taller, narrower rectangle for the crown of the hat. Since we’ll colour them both <code>"brown"</code>, it doesn’t matter if they overlap a little bit.</p>
<p>This <em>might</em> be one of the situations we should have used <code>geom_rect()</code> instead of <code>annotate()</code> but it might take a lot of trial and error to position the hat exactly where we want it, and this seemed a little easier with <code>annotate()</code>.</p>
<div class="sourceCode" id="cb9" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb9-1">s7 <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> s6 <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span></span>
<span id="cb9-2">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">annotate</span>(</span>
<span id="cb9-3">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">geom =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"rect"</span>,</span>
<span id="cb9-4">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">xmin =</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.46</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">xmax =</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.74</span>,</span>
<span id="cb9-5">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">ymin =</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.55</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">ymax =</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.60</span>,</span>
<span id="cb9-6">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">fill =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"brown"</span></span>
<span id="cb9-7">  ) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span></span>
<span id="cb9-8">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">annotate</span>(</span>
<span id="cb9-9">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">geom =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"rect"</span>,</span>
<span id="cb9-10">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">xmin =</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.50</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">xmax =</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.70</span>,</span>
<span id="cb9-11">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">ymin =</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.56</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">ymax =</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.73</span>,</span>
<span id="cb9-12">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">fill =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"brown"</span></span>
<span id="cb9-13">  )</span>
<span id="cb9-14">s7</span></code></pre></div>
<p>Now we can move on to the final component of building a snowman – the carrot for his nose! We’re going to use a triangle for the nose. Unfortunately, there are no built-in triangle geoms in {ggplot2} so we’ll have to make our own. There are different ways to do this, but here we’re going to make use of the {sf} package <span class="citation" data-cites="sf">(Pebesma 2018)</span>. The {sf} package (short for <em>simple features</em>) is designed for working with spatial data. Although we’re not working with maps, we can still use {sf} to make shapes – including polygons.</p>
<p>We start by constructing a matrix with two columns – one for x coordinates and one for y. The x coordinates start in the middle of the head and go slightly to the right for the triangle point. The y coordinates take a little bit more trial and error to get right. Note that although triangles only have three corners, we have four rows of points. The last row must be the same as the first to make the polygon <em>closed</em>. The matrix is then converted into a spatial object using the <code>st_polygon()</code> function, and we can check how it looks using <code>plot()</code>.</p>
<div class="sourceCode" id="cb10" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb10-1">nose_pts <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">matrix</span>(</span>
<span id="cb10-2">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">c</span>(</span>
<span id="cb10-3">    <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.6</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span>,</span>
<span id="cb10-4">    <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.65</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.48</span>,</span>
<span id="cb10-5">    <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.6</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.46</span>,</span>
<span id="cb10-6">    <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.6</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span></span>
<span id="cb10-7">  ),</span>
<span id="cb10-8">  <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">ncol =</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>,</span>
<span id="cb10-9">  <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">byrow =</span> <span class="cn" style="color: #8f5902;
background-color: null;
font-style: inherit;">TRUE</span></span>
<span id="cb10-10">)</span>
<span id="cb10-11">nose <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">st_polygon</span>(<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">list</span>(nose_pts))</span>
<span id="cb10-12"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">plot</span>(nose)</span></code></pre></div>
<div>

</div>
<div class="quarto-layout-panel" data-layout-ncol="2">
<div class="quarto-layout-row">
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: center;">
<p><img src="https://realworlddatascience.net/ideas/tutorials/posts/2023/12/12/images/s7.png" class="img-fluid" alt="Dark blue square with off-white rectangle at the bottom and small random white stars, and two white circles slightly off centre. Five black dots denote two eyes and three buttons on a snowman. Two brown lines look like arms. Two red rectangles form a hat."></p>
</div>
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: center;">
<p><img src="https://realworlddatascience.net/ideas/tutorials/posts/2023/12/12/images/nose.png" class="img-fluid" alt="Outline of a triangle pointing to the right against a white background."></p>
</div>
</div>
</div>
<p>We can plot <code>sf</code> objects with {ggplot2} using <code>geom_sf()</code>. <code>geom_sf()</code> is a slightly special <code>geom</code> since we don’t need to specify an aesthetic mapping for the <code>x</code> and <code>y</code> axes – they are determined automatically from the <code>sf</code> object along with which type of geometry to draw. If your <code>sf</code> object has points, points will be drawn. If it has country shapes, polygons will be drawn. Like other <code>geom_*()</code> functions, we can change the <code>colour</code> and <code>fill</code> arguments to a different colour – in this case <code>"orange"</code> to represent a carrot!</p>
<p>You should see a <code>Coordinate system already present. Adding new coordinate system, which will replace the existing one.</code> message when you run the following code. The is because <code>geom_sf</code> forces it’s own coordinate system on the plot overriding our previous code specifying <code>coord_fixed()</code>. If you run it without the <code>coord_sf(expand = FALSE)</code>, the extra space around the plot will reappear. We can remove it again with <code>expand = FALSE</code>.</p>
<div class="sourceCode" id="cb11" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb11-1">s8 <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> s7 <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span></span>
<span id="cb11-2">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">geom_sf</span>(</span>
<span id="cb11-3">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">data =</span> nose,</span>
<span id="cb11-4">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">fill =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"orange"</span>,</span>
<span id="cb11-5">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">colour =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"orange"</span></span>
<span id="cb11-6">  ) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span></span>
<span id="cb11-7">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">coord_sf</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">expand =</span> <span class="cn" style="color: #8f5902;
background-color: null;
font-style: inherit;">FALSE</span>)</span>
<span id="cb11-8">s8</span></code></pre></div>
<blockquote class="blockquote">
<p>You <em>could</em> skip the <code>sf</code> part of this completely and pass the coordinates directly into <code>geom_polygon()</code> instead. However, I’ve often found it quicker and easier to tinker with polygon shapes using <code>sf</code>.</p>
</blockquote>
<p>A key part of any Christmas card is the message wishing recipients a Merry Christmas! We can add text to our plot using the <code>annotate()</code> function and the <code>"text"</code> geometry (you could instead use <code>geom_text()</code> if you prefer). When adding text, we require at least three arguments: the <code>x</code> and <code>y</code> coordinates of where the text should be added, and the <code>label</code> denoting what text should appear. We can supply additional arguments to <code>annotate()</code> to style the text, such as: <code>colour</code> (which changes the colour of the text); <code>family</code> (to define which font to use); <code>fontface</code> (which determines if the font is bold or italic, for example); and <code>size</code> (which changes the size of the text). The <code>"mono"</code> option for <code>family</code> tells {ggplot2} to use the default system monospace font.</p>
<div class="sourceCode" id="cb12" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb12-1">s9 <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> s8 <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span></span>
<span id="cb12-2">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">annotate</span>(</span>
<span id="cb12-3">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">geom =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"text"</span>,</span>
<span id="cb12-4">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">x =</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">y =</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.07</span>,</span>
<span id="cb12-5">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">label =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Merry Christmas"</span>,</span>
<span id="cb12-6">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">colour =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"red3"</span>,</span>
<span id="cb12-7">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">family =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"mono"</span>,</span>
<span id="cb12-8">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">fontface =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"bold"</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">size =</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">7</span></span>
<span id="cb12-9">  )</span>
<span id="cb12-10">s9</span></code></pre></div>
<div>

</div>
<div class="quarto-layout-panel" data-layout-ncol="2">
<div class="quarto-layout-row">
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: center;">
<p><img src="https://realworlddatascience.net/ideas/tutorials/posts/2023/12/12/images/s8.png" class="img-fluid" alt="Dark blue square with off-white rectangle at the bottom and small random white stars, and two white circles slightly off centre. Five black dots denote two eyes and three buttons on a snowman. Two brown lines look like arms. Two red rectangles form a hat. Orange triangle as a nose."></p>
</div>
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: center;">
<p><img src="https://realworlddatascience.net/ideas/tutorials/posts/2023/12/12/images/s9.png" class="img-fluid" alt="Dark blue square with off-white rectangle at the bottom and small random white stars, and two white circles slightly off centre. Five black dots denote two eyes and three buttons on a snowman. Two brown lines look like arms. Two red rectangles form a hat. Orange triangle as a nose, with text reading Merry Christmas at the bottom."></p>
</div>
</div>
</div>
</section>
<section id="sending-christmas-cards-in-r" class="level2">
<h2 class="anchored" data-anchor-id="sending-christmas-cards-in-r">Sending Christmas cards in R</h2>
<p>Now that we’ve finished creating our Christmas card, we need to think about how to send it. You could save it as an image file using <code>ggsave()</code>, print it out, and send it in the post. Or you could also use R to send it!</p>
<p>There are many different R packages for sending emails from R. If you create a database of email addresses and names, you could personalise the message on the Christmas card and then send it automatically as an email from R. If you want to automate the process of sending physical cards from R, you might be interested in the <a href="https://github.com/jnolis">{ggirl} package</a> from Jacqueline Nolis <span class="citation" data-cites="ggirl">(Nolis 2023)</span>. {ggirl} allows you to send postcards with a <code>ggplot</code> object printed on the front. {ggirl} is also an incredible example of <a href="https://jnolis.com/blog/introducing_ggirl/">an eCommerce platform built with R</a>! Note that {ggirl} can currently only send physical items to addresses in the United States.</p>
</section>
<section id="other-christmas-r-packages" class="level2">
<h2 class="anchored" data-anchor-id="other-christmas-r-packages">Other Christmas R packages</h2>
<p>If you’re curious about making Christmas cards with R but you don’t have the time to make them from scratch, you’ll likely find the <code>christmas</code> R package <span class="citation" data-cites="christmas">(Barrera-Gomez 2022)</span> helpful. This package from Jose Barrera-Gomez can generate lots of different Christmas cards, many of them animated and available in different languages (English, Catalan and Spanish).</p>
<p>Emil Hvitfeldt has also created a <a href="https://quarto.org/">Quarto</a> <a href="https://github.com/EmilHvitfeldt/quarto-snow">extension that gives the effect of falling snowflakes</a> on HTML outputs – including revealjs slides which is perfect for festive presentations!</p>
<p>Have you made your own Christmas cards with R? We’d love to see your designs!</p>
<div class="callout callout-style-simple callout-note" style="margin-top: 2.25rem;">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-body-container">
<p>Inspired by Nicola’s tutorial, Real World Data Science has indeed made its own Christmas card design. <a href="../../../../../../viewpoints/editors-blog/posts/2023/12/12/rwds-xmas-card.html">Check out our attempt over at the Editors’ Blog</a>!</p>
</div>
</div>
</div>
<div class="article-btn">
<p><a href="../../../../../../ideas/tutorials/index.html">Explore more Tutorials</a></p>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-12">
<dl>
<dt>About the author</dt>
<dd>
<strong>Nicola Rennie</strong> is a lecturer in health data science in the Centre for Health Informatics, Computing, and Statistics (CHICAS) within Lancaster Medical School at Lancaster University. She’s an R enthusiast, data visualisation aficionado, and generative artist, among other things. Her personal website is hosted at <a href="https://nrennie.github.io/">nrennie.rbind.io</a>, and she is a co-author of the <a href="https://royal-statistical-society.github.io/datavisguide/">Royal Statistical Society’s Best Practices for Data Visualisation</a>.
</dd>
</dl>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>Copyright and licence</dt>
<dd>
© 2023 Nicola Rennie
</dd>
</dl>
<p><a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> <img style="height:22px!important;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"></a> This article is licensed under a Creative Commons Attribution 4.0 (CC BY 4.0) <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> International licence</a>.</p>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>How to cite</dt>
<dd>
Rennie, Nicola. 2023. “Creating Christmas cards with R.” Real World Data Science, December 12, 2023. <a href="https://doi.org/10.5281/zenodo.10530635"><img src="https://zenodo.org/badge/DOI/10.5281/zenodo.10530635.svg" class="img-fluid" style="vertical-align:text-bottom;" alt="DOI"></a>
</dd>
</dl>
</div>
</div>
</div>



</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0">
<div id="ref-christmas" class="csl-entry">
Barrera-Gomez, Jose. 2022. <em>Christmas: Generation of Different Animated Christmas Cards</em>. <a href="https://CRAN.R-project.org/package=christmas">https://CRAN.R-project.org/package=christmas</a>.
</div>
<div id="ref-ggirl" class="csl-entry">
Nolis, Jacqueline. 2023. <em>Ggirl: Ggplot2 Art in Real Life</em>. <a href="https://github.com/jnolis/ggirl">https://github.com/jnolis/ggirl</a>.
</div>
<div id="ref-sf" class="csl-entry">
Pebesma, Edzer. 2018. <span>“<span class="nocase">Simple Features for R: Standardized Support for Spatial Vector Data</span>.”</span> <em><span>The R Journal</span></em> 10 (1): 439–46. <a href="https://doi.org/10.32614/RJ-2018-009">https://doi.org/10.32614/RJ-2018-009</a>.
</div>
<div id="ref-ggforce" class="csl-entry">
Pedersen, Thomas Lin. 2022. <em>Ggforce: Accelerating ’Ggplot2’</em>. <a href="https://CRAN.R-project.org/package=ggforce">https://CRAN.R-project.org/package=ggforce</a>.
</div>
<div id="ref-R-base" class="csl-entry">
R Core Team. 2022. <em>R: A Language and Environment for Statistical Computing</em>. Vienna, Austria: R Foundation for Statistical Computing. <a href="https://www.R-project.org/">https://www.R-project.org/</a>.
</div>
<div id="ref-ggplot2" class="csl-entry">
Wickham, Hadley. 2016. <em>Ggplot2: Elegant Graphics for Data Analysis</em>. Springer-Verlag New York. <a href="https://ggplot2.tidyverse.org">https://ggplot2.tidyverse.org</a>.
</div>
</div></section></div> ]]></description>
  <category>R</category>
  <category>Data visualisation</category>
  <guid>https://realworlddatascience.net/ideas/tutorials/posts/2023/12/12/xmas-cards.html</guid>
  <pubDate>Tue, 12 Dec 2023 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/ideas/tutorials/posts/2023/12/12/images/xmas-card.png" medium="image" type="image/png" height="105" width="144"/>
</item>
<item>
  <title>A Christmas card in R for the Real World Data Science community</title>
  <dc:creator>Brian Tarran</dc:creator>
  <link>https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/12/12/rwds-xmas-card.html</link>
  <description><![CDATA[ 





<p>A few weeks back, I managed to catch Nicola Rennie’s presentation to the <a href="https://www.meetup.com/en-AU/oxford-r-user-group/events/297417319/">Oxford R User Group on how to create Christmas cards in R</a>. It was a fun session, and thanks to Nicola’s clear and concise explanations, I felt emboldened to attempt my own design, using her code as a base.</p>
<p>If you missed the Meetup session, Nicola has kindly written <a href="../../../../../../ideas/tutorials/posts/2023/12/12/xmas-cards.html">a tutorial for Real World Data Science</a> that walks through all the necessary steps to create a snowman against a snowy night’s sky. You’ll want to read that tutorial first before returning to this blog.</p>
<p>My design uses the same basic setting as Nicola’s but updates the scene to reflect the Real World Data Science (RWDS) brand colours, and I replace the snowman with a Christmas tree adorned with coloured baubles.</p>
<section id="snowy-sky" class="level2">
<h2 class="anchored" data-anchor-id="snowy-sky">Snowy sky</h2>
<p>We begin by loading in the following packages, adding a couple extra to the ones Nicola uses:</p>
<div class="sourceCode" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">library</span>(ggplot2)</span>
<span id="cb1-2"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">library</span>(ggforce)</span>
<span id="cb1-3"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">library</span>(sf)</span>
<span id="cb1-4"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">library</span>(png)</span>
<span id="cb1-5"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">library</span>(patchwork) </span></code></pre></div>
<p>Then we add the sky, now recoloured in RWDS purple using <code>fill</code> and <code>color</code>:</p>
<div class="sourceCode" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb2-1">s1 <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">ggplot</span>() <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span></span>
<span id="cb2-2">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">theme_void</span>() <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span></span>
<span id="cb2-3">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">theme</span>(</span>
<span id="cb2-4">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">plot.background =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">element_rect</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">fill =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"#939bc9"</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">color =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"#939bc9"</span>)</span>
<span id="cb2-5">  )</span>
<span id="cb2-6">s1</span></code></pre></div>
<p>We use the same code as Nicola to create the snowflakes, but we do this step first before adding snow on the ground, as we’re using the RWDS site background colour, hex code <code>#f0eeb</code>, to represent our settled snow:</p>
<div class="sourceCode" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb3-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># add snowflakes</span></span>
<span id="cb3-2"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">set.seed</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">20231225</span>)</span>
<span id="cb3-3">n <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">100</span></span>
<span id="cb3-4">snowflakes <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">data.frame</span>(</span>
<span id="cb3-5">  <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">x =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">runif</span>(n),</span>
<span id="cb3-6">  <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">y =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">runif</span>(n)</span>
<span id="cb3-7">)</span>
<span id="cb3-8">s2 <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> s1 <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span></span>
<span id="cb3-9">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">geom_point</span>(</span>
<span id="cb3-10">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">data =</span> snowflakes,</span>
<span id="cb3-11">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">mapping =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">aes</span>(</span>
<span id="cb3-12">      <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">x =</span> x,</span>
<span id="cb3-13">      <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">y =</span> y</span>
<span id="cb3-14">    ),</span>
<span id="cb3-15">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">colour =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"white"</span>,</span>
<span id="cb3-16">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">pch =</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">8</span></span>
<span id="cb3-17">  )</span>
<span id="cb3-18">s2</span>
<span id="cb3-19"></span>
<span id="cb3-20"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># snow on ground</span></span>
<span id="cb3-21">s3 <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> s2 <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span></span>
<span id="cb3-22">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">annotate</span>(</span>
<span id="cb3-23">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">geom =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"rect"</span>,</span>
<span id="cb3-24">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">xmin =</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">xmax =</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>,</span>
<span id="cb3-25">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">ymin =</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">ymax =</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.2</span>,</span>
<span id="cb3-26">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">fill =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"#f0eeeb"</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">colour =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"#f0eeeb"</span></span>
<span id="cb3-27">  ) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span></span>
<span id="cb3-28">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">xlim</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span></span>
<span id="cb3-29">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">ylim</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span></span>
<span id="cb3-30">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">coord_fixed</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">expand =</span> <span class="cn" style="color: #8f5902;
background-color: null;
font-style: inherit;">FALSE</span>)</span>
<span id="cb3-31">s3</span></code></pre></div>
<div>

</div>
<div class="quarto-layout-panel" data-layout-ncol="2">
<div class="quarto-layout-row">
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: center;">
<p><img src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/12/12/images/s2.png" class="img-fluid" alt="Purple square with white snowflakes."></p>
</div>
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: center;">
<p><img src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/12/12/images/s3.png" class="img-fluid" alt="Purple square with white snowflakes and off-white rectangle at the bottom."></p>
</div>
</div>
</div>
</section>
<section id="oh-christmas-tree" class="level2">
<h2 class="anchored" data-anchor-id="oh-christmas-tree">Oh, Christmas tree</h2>
<p>To build her snowman, Nicola created a series of circles that were stacked and overlaid. A simple Christmas tree, though, requires a series of triangles. So, taking Nicola’s snowman’s nose (also a triangle) as our starting point, we coded three sets of coordinates – <code>tree_pts1</code>, <code>tree_pts2</code>, and <code>tree_pts3</code> – for three triangles of decreasing size that would sit on top of one another.</p>
<div class="sourceCode" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb4-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># coordinates for tree base</span></span>
<span id="cb4-2">tree_pts1 <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">matrix</span>(</span>
<span id="cb4-3">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">c</span>(</span>
<span id="cb4-4">    <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.2</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.3</span>,</span>
<span id="cb4-5">    <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.6</span>,</span>
<span id="cb4-6">    <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.8</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.3</span>,</span>
<span id="cb4-7">    <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.2</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.3</span></span>
<span id="cb4-8">  ),</span>
<span id="cb4-9">  <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">ncol =</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>,</span>
<span id="cb4-10">  <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">byrow =</span> <span class="cn" style="color: #8f5902;
background-color: null;
font-style: inherit;">TRUE</span></span>
<span id="cb4-11">)</span>
<span id="cb4-12"></span>
<span id="cb4-13"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># coordinates for tree middle</span></span>
<span id="cb4-14">tree_pts2 <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">matrix</span>(</span>
<span id="cb4-15">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">c</span>(</span>
<span id="cb4-16">    <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.3</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span>,</span>
<span id="cb4-17">    <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.7</span>,</span>
<span id="cb4-18">    <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.7</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span>,</span>
<span id="cb4-19">    <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.3</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span></span>
<span id="cb4-20">  ),</span>
<span id="cb4-21">  <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">ncol =</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>,</span>
<span id="cb4-22">  <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">byrow =</span> <span class="cn" style="color: #8f5902;
background-color: null;
font-style: inherit;">TRUE</span></span>
<span id="cb4-23">)</span>
<span id="cb4-24"></span>
<span id="cb4-25"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># coordinates for tree top</span></span>
<span id="cb4-26">tree_pts3 <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">matrix</span>(</span>
<span id="cb4-27">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">c</span>(</span>
<span id="cb4-28">    <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.4</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.65</span>,</span>
<span id="cb4-29">    <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.75</span>,</span>
<span id="cb4-30">    <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.6</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.65</span>,</span>
<span id="cb4-31">    <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.4</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.65</span></span>
<span id="cb4-32">  ),</span>
<span id="cb4-33">  <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">ncol =</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>,</span>
<span id="cb4-34">  <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">byrow =</span> <span class="cn" style="color: #8f5902;
background-color: null;
font-style: inherit;">TRUE</span></span>
<span id="cb4-35">)</span>
<span id="cb4-36"></span>
<span id="cb4-37"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># put tree together</span></span>
<span id="cb4-38">tree <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">st_multipolygon</span>(<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">list</span>(<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">list</span>(tree_pts1),</span>
<span id="cb4-39">                             <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">list</span>(tree_pts2),</span>
<span id="cb4-40">                             <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">list</span>(tree_pts3)))</span>
<span id="cb4-41">s4 <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> s3 <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span></span>
<span id="cb4-42">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">geom_sf</span>(</span>
<span id="cb4-43">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">data =</span> tree,</span>
<span id="cb4-44">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">fill =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"chartreuse4"</span>,</span>
<span id="cb4-45">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">colour =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"chartreuse4"</span></span>
<span id="cb4-46">  ) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span></span>
<span id="cb4-47">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">coord_sf</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">expand =</span> <span class="cn" style="color: #8f5902;
background-color: null;
font-style: inherit;">FALSE</span>)</span>
<span id="cb4-48">s4</span></code></pre></div>
<p>A tree also requires a trunk, so we borrowed one of the rectangles from Nicola’s snowman’s hat for this purpose:</p>
<div class="sourceCode" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb5-1">s5 <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> s4<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span></span>
<span id="cb5-2">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">annotate</span>(</span>
<span id="cb5-3">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">geom =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"rect"</span>,</span>
<span id="cb5-4">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">xmin =</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.45</span>,</span>
<span id="cb5-5">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">xmax =</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.55</span>,</span>
<span id="cb5-6">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">ymin =</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.2</span>,</span>
<span id="cb5-7">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">ymax =</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.3</span>,</span>
<span id="cb5-8">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">fill =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"brown"</span></span>
<span id="cb5-9">  )</span>
<span id="cb5-10">s5</span></code></pre></div>
<p>And, of course, no Christmas tree is complete without decorations. The “rocks” that formed the buttons and eyes on Nicola’s snowman were updated to become gold and red baubles for our tree:</p>
<div class="sourceCode" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb6-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># add gold baubles</span></span>
<span id="cb6-2">s6 <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> s5 <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span></span>
<span id="cb6-3">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">geom_point</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">colour =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"gold"</span>,</span>
<span id="cb6-4">             <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">data =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">data.frame</span>(</span>
<span id="cb6-5">               <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">x =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">c</span>(<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.3</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.4</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.6</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.57</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.62</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.45</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span>),</span>
<span id="cb6-6">               <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">y =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">c</span>(<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.325</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.4</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.45</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.35</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.57</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.52</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.6</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.7</span>),</span>
<span id="cb6-7">               <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">size =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">runif</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">8</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">4.5</span>)</span>
<span id="cb6-8">             ),</span>
<span id="cb6-9">             <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">mapping =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">aes</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">x =</span> x, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">y =</span> y, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">size =</span> size)</span>
<span id="cb6-10">  ) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span></span>
<span id="cb6-11">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">scale_size_identity</span>()</span>
<span id="cb6-12">s6</span>
<span id="cb6-13"></span>
<span id="cb6-14"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># add red baubles</span></span>
<span id="cb6-15">s7 <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> s6 <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span></span>
<span id="cb6-16">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">geom_point</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">colour =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"red3"</span>,</span>
<span id="cb6-17">             <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">data =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">data.frame</span>(</span>
<span id="cb6-18">               <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">x =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">c</span>(<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.7</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.6</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.525</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.43</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.38</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.55</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span>),</span>
<span id="cb6-19">               <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">y =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">c</span>(<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.375</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.4</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.55</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.65</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.43</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.48</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.375</span>),</span>
<span id="cb6-20">               <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">size =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">runif</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">8</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">4.5</span>)</span>
<span id="cb6-21">             ),</span>
<span id="cb6-22">             <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">mapping =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">aes</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">x =</span> x, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">y =</span> y, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">size =</span> size)</span>
<span id="cb6-23">  ) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span></span>
<span id="cb6-24">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">scale_size_identity</span>()</span>
<span id="cb6-25">s7</span></code></pre></div>
<div>

</div>
<div class="quarto-layout-panel" data-layout-ncol="3">
<div class="quarto-layout-row">
<div class="quarto-layout-cell" style="flex-basis: 33.3%;justify-content: center;">
<p><img src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/12/12/images/s4.png" class="img-fluid" alt="Purple square with white snowflakes and green tree in foreground."></p>
</div>
<div class="quarto-layout-cell" style="flex-basis: 33.3%;justify-content: center;">
<p><img src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/12/12/images/s5.png" class="img-fluid" alt="Purple square with white snowflakes and green tree in foreground, now with brown trunk at foot of tree."></p>
</div>
<div class="quarto-layout-cell" style="flex-basis: 33.3%;justify-content: center;">
<p><img src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/12/12/images/s7.png" class="img-fluid" alt="Purple square with white snowflakes and green tree in foreground. Tree is decorated with red and gold baubles of various sizes."></p>
</div>
</div>
</div>
</section>
<section id="seasons-greetings" class="level2">
<h2 class="anchored" data-anchor-id="seasons-greetings">Season’s greetings</h2>
<p>The final step was to add text to the top of the image, wishing you all a Merry Christmas, and our logo to the bottom, so you know who the card is from:</p>
<div class="sourceCode" id="cb7" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb7-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># add text</span></span>
<span id="cb7-2">s8 <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> s7 <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span></span>
<span id="cb7-3">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">annotate</span>(</span>
<span id="cb7-4">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">geom =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"text"</span>,</span>
<span id="cb7-5">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">x =</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span>,</span>
<span id="cb7-6">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">y =</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.875</span>,</span>
<span id="cb7-7">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">label =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Merry Christmas"</span>,</span>
<span id="cb7-8">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">colour =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"red3"</span>,</span>
<span id="cb7-9">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">fontface =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"bold"</span>,</span>
<span id="cb7-10">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">size =</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">18</span></span>
<span id="cb7-11">  )</span>
<span id="cb7-12">s8</span>
<span id="cb7-13"></span>
<span id="cb7-14"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># add logo </span></span>
<span id="cb7-15">path <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"images/rwds-logo-150px.png"</span></span>
<span id="cb7-16">img <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">readPNG</span>(path, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">native =</span> <span class="cn" style="color: #8f5902;
background-color: null;
font-style: inherit;">TRUE</span>) </span>
<span id="cb7-17">s9 <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> s8 <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span>                   </span>
<span id="cb7-18">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">inset_element</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">p =</span> img, </span>
<span id="cb7-19">                <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">left =</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.3265</span>, </span>
<span id="cb7-20">                <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">bottom =</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.0</span>, </span>
<span id="cb7-21">                <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">right =</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.6735</span>, </span>
<span id="cb7-22">                <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">top =</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.2</span></span>
<span id="cb7-23">  ) </span>
<span id="cb7-24">s9</span></code></pre></div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/12/12/images/rwds-christmas-card.png" class="img-fluid quarto-figure quarto-figure-center figure-img" alt="Purple square with white snowflakes and green tree in foreground. Tree is decorated with red and gold baubles of various sizes. Text over tree reads Merry Christmas. Under tree is a logo for the Real World Data Science website."></p>
</figure>
</div>
<p>I hope you like the Christmas card! From all of us at Real World Data Science, thank you for your support throughout 2023. Merry Christmas, happy holidays, and best wishes for 2024!</p>
<div class="article-btn">
<p><a href="../../../../../../viewpoints/editors-blog/index.html">Back to Editors’ blog</a></p>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-6">
<dl>
<dt>Copyright and licence</dt>
<dd>
© 2023 Royal Statistical Society
</dd>
</dl>
<p><a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> <img style="height:22px!important;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"></a> This article is licensed under a Creative Commons Attribution 4.0 (CC BY 4.0) <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> International licence</a>.</p>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>How to cite</dt>
<dd>
Tarran, Brian. 2023. “A Christmas card in R for the Real World Data Science community.” Real World Data Science, December 12, 2023. <a href="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/12/12/rwds-xmas-card.html">URL</a>
</dd>
</dl>
</div>
</div>
</div>


</section>

 ]]></description>
  <category>R</category>
  <category>Data visualisation</category>
  <category>Updates</category>
  <guid>https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/12/12/rwds-xmas-card.html</guid>
  <pubDate>Tue, 12 Dec 2023 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/12/12/images/rwds-christmas-card-thumb.png" medium="image" type="image/png" height="105" width="144"/>
</item>
<item>
  <title>AI and digital ethics in 2023: a ‘remarkable, eventful year’</title>
  <dc:creator>Brian Tarran</dc:creator>
  <link>https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/12/08/digital-ethics-summit.html</link>
  <description><![CDATA[ 





<p>What a difference a year makes! That was the general tone of the conversation coming out of techUK’s <a href="https://www.techuk.org/digital-ethics-summit-2023-seizing-the-moment.html">Digital Ethics Summit</a> this week. At last year’s event, ChatGPT was but a few days old. An exciting, enticing prospect, sure – but not yet the phenomenon it would soon become. My notes from last year include only two mentions of the AI chatbot: Andrew Strait of the Ada Lovelace Institute expressing concern about the way ChatGPT had been released straight to the public, and Jack Stilgoe of UCL warning of the threat such technology poses to the social contract – public data trains it, while private firms profit.</p>
<p>A lot has happened since last December, as many of the speakers at Wednesday’s summit pointed out. UNESCO’s Gabriela Ramos commented on how <a href="https://www.gov.uk/government/publications/ai-safety-summit-programme">the UK’s AI Safety Summit</a>, <a href="https://www.whitehouse.gov/briefing-room/statements-releases/2023/10/30/fact-sheet-president-biden-issues-executive-order-on-safe-secure-and-trustworthy-artificial-intelligence/">US President Joe Biden’s executive order on AI</a>, and other international initiatives had brought about “a change in the conversation” on AI risk, safety, and assurance. Simon Staffell of Microsoft spoke of “a huge amount of progress” being made, building from principles into voluntary actions that companies and countries can take.</p>
<p>Luciano Floridi of Yale University described 2023 as a “remarkable, eventful year which we didn’t quite expect,” with various international efforts helping to build consensus on what needs to be done, and what needs to be regulated, to ensure the benefits of AI can be realised while harms are minimised. Camille Ford of the Centre for European Policy Studies noted that while attempts at global governance of AI make for a “crowded space” – with more than 200 documents in circulation – there are at least principles in common across the various initiatives, focusing on aspects such as transparency, reliability and trustworthiness, safety, privacy, and accountability and liability.</p>
<p>However, in some respects, we’ve not come as far as we could or should have over the past 12 months. Ford, for instance, called for more conversation on AI safety, and a frank discussion about on whose terms AI safety is defined. Not only are there the risks and harms of AI outputs to consider, but also environmental harms, exploitative labour practices, and more besides. <a href="https://realworlddatascience.net/viewpoints/posts/2023/12/06/ai-fringe.html">Echoing the Royal Statistical Society’s recent AI debate</a>, Ford said we need to focus on the risks we face now, rather than being consumed by discussions about the existential and catastrophic risks of AI – which, for many, are still firmly in the realm of science fiction.</p>
<p>There also remains “a big mismatch” between the AI knowledge and skills that reside within tech companies and that of other communities, said Zeynep Engin of Data for Policy. And many speakers were clear that the global south needs a more prominent voice in the AI debate.</p>
<section id="regulatory-approaches" class="level2">
<h2 class="anchored" data-anchor-id="regulatory-approaches">Regulatory approaches</h2>
<p>The UK government’s AI Safety Summit has been criticised for focusing too much on the hypothetical existential risks of AI. But, on regulation at least, there was broad agreement that the UK’s principles- and sector-based approach, outlined in <a href="https://www.gov.uk/government/publications/ai-regulation-a-pro-innovation-approach/white-paper">a March 2023 white paper</a>, is the right one. That’s not to say it’s perfect: discussions were had about whether regulatory bodies would be adequately funded to regulate the use of AI in their sectors, while Hetan Shah of the British Academy wondered “where was the golden thread” linking the AI white paper to the AI Safety Summit and its various pronouncements, including <a href="https://www.gov.uk/government/news/prime-minister-launches-new-ai-safety-institute">plans for an AI Safety Institute</a>. (On the Safety Institute in particular, Lord Tim Clement-Jones was sceptical of yet another body being drafted in to debate these issues – a point made by panellists at the RSS’s recent AI debate.)</p>
<p>Delegates also got to hear from the UK’s Information Commissioner directly. John Edwards delivered a keynote address in which he acknowledged the huge excitement surrounding the benefits AI promises to bring, while cautioning that deployment and use of AI must be done in accordance with existing rules on data protection and privacy. The technology may be new, he said, but the same old data rules apply: “Our legislation is founded on technology-neutral principles of general application. They are capable of adapting to numerous new technologies, as they have over the last 30 years and will continue to do.”</p>
<p>He warned that noncompliance with data protection rules and regulations “will not be profitable,” and that persistent misuse of AI and personal data for competitive advantage would be punished. Edwards concluded by saying that AI is built on the data of human individuals and should therefore be used to improve their lives, and not put them or their personal data at risk.</p>
</section>
<section id="elections-in-an-era-of-generative-ai" class="level2">
<h2 class="anchored" data-anchor-id="elections-in-an-era-of-generative-ai">Elections in an era of generative AI</h2>
<p>One major looming risk is the use of generative AI to create mis- and disinformation during election campaigns. Hans-Petter Dalen of IBM suggested that next year is perhaps the biggest year for elections in the history of mankind, with votes due in the UK, US, and India, to name but a few. Generative AI represents not a new threat, he said, but an “amplified” one – a point further developed by Henry Parker of Logically.ai. Parker spoke of the risk of large-scale breakdown in trust due to mis- or disinformation campaigns. Thanks to AI tools, he said, we are now seeing the “democratisation of disinformation.” What once might have cost millions of dollars and required a team of hundreds of people can now be done much more cheaply and with fewer human resources. As the Royal Society’s Areeq Chowdhury said, the challenge of disinformation has only become harder.</p>
<p>Asked how to counter this, Dalen said that if he were a politician, “I would certainly get my own blockchain and all my content would have been digitally watermarked from source – that’s what the blockchain does.” But digital watermarking is only part of the answer, added Parker. Identifying mis- and disinformation is both a question of provenance and of dissemination. Logically.ai is using AI as a tool to analyse behaviours around the circulation of mis- and disinformation, Parker said – positioning AI as but one solution to a problem it has helped exacerbate.</p>
<div class="article-btn">
<p><a href="../../../../../../viewpoints/editors-blog/index.html">Back to Editors’ blog</a></p>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-6">
<dl>
<dt>Copyright and licence</dt>
<dd>
© 2023 Royal Statistical Society
</dd>
</dl>
<p><a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> <img style="height:22px!important;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"></a> This article is licensed under a Creative Commons Attribution 4.0 (CC BY 4.0) <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> International licence</a>. Thumbnail photo by <a href="https://unsplash.com/@kajtek?utm_content=creditCopyText&amp;utm_medium=referral&amp;utm_source=unsplash">Kajetan Sumila</a> on <a href="https://unsplash.com/photos/a-screenshot-of-a-computer-bxaqUeVIGHU?utm_content=creditCopyText&amp;utm_medium=referral&amp;utm_source=unsplash">Unsplash</a>.</p>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>How to cite</dt>
<dd>
Tarran, Brian. 2023. “AI and digital ethics in 2023: a ‘remarkable, eventful year.’” Real World Data Science, December 8, 2023. <a href="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/12/08/digital-ethics-summit.html">URL</a>
</dd>
</dl>
</div>
</div>
</div>


</section>

 ]]></description>
  <category>AI</category>
  <category>Large language models</category>
  <category>Ethics</category>
  <category>Regulation</category>
  <category>Risk</category>
  <guid>https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/12/08/digital-ethics-summit.html</guid>
  <pubDate>Fri, 08 Dec 2023 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/12/08/images/kajetan-sumila-bxaqUeVIGHU-unsplash.png" medium="image" type="image/png" height="105" width="144"/>
</item>
<item>
  <title>Evaluating artificial intelligence: How data science and statistics can make sense of AI models</title>
  <dc:creator>Brian Tarran</dc:creator>
  <link>https://realworlddatascience.net/viewpoints/posts/2023/12/06/ai-fringe.html</link>
  <description><![CDATA[ 





<p>A little over a month ago, governments, technology firms, multilateral organisations, and academic and civil society groups came together at Bletchley Park – home of Britain’s World War II code breakers – to discuss the safety and risks of artificial intelligence.</p>
<p>One output from that event was <a href="https://www.gov.uk/government/publications/ai-safety-summit-2023-the-bletchley-declaration/the-bletchley-declaration-by-countries-attending-the-ai-safety-summit-1-2-november-2023">a declaration</a>, signed by countries in attendance, of their resolve to “work together in an inclusive manner to ensure human-centric, trustworthy and responsible AI that is safe, and supports the good of all.”</p>
<p>We also heard from UK prime minister Rishi Sunak of <a href="https://www.gov.uk/government/news/prime-minister-launches-new-ai-safety-institute">plans for an AI Safety Institute</a>, to be based in the UK, which will “carefully test new types of frontier AI before and after they are released to address the potentially harmful capabilities of AI models, including exploring all the risks, from social harms like bias and misinformation, to the most unlikely but extreme risk, such as humanity losing control of AI completely.”</p>
<p>But at a panel debate at the Royal Statistical Society (RSS) the day before the Bletchley Park gathering, data scientists, statisticians, and machine learning experts questioned whether such an institute would be sufficient to meet the challenges posed by AI; whether data inputs – compared to AI model outputs – are getting the attention they deserve; and whether the summit was overly focused on <a href="https://realworlddatascience.net/viewpoints/posts/2023/06/05/no-AI-probably-wont-kill-us.html">AI doomerism</a> and neglecting more immediate risks and harms. There were also calls for AI developers to be more driven to solve real-world problems, rather than just pursuing AI for AI’s sake.</p>
<p>The RSS event was chaired by Andrew Garrett, the Society’s president, and formed part of the national <a href="https://aifringe.org/">AI Fringe programme of activities</a>. The panel featured:</p>
<ul>
<li>Mihaela van der Schaar, John Humphrey Plummer professor of machine learning, artificial intelligence and medicine at the University of Cambridge and a fellow at The Alan Turing Institute.</li>
<li>Detlef Nauck, head of AI and data science research at BT, and a member of the <a href="https://realworlddatascience.net/viewpoints/editors-blog/posts/2022/10/18/meet-the-team.html">Real World Data Science editorial board</a>.</li>
<li>Mark Levene, principal scientist in the Department of Data Science at the National Physical Laboratory.</li>
<li>Martin Goodson, chief executive of Evolution AI, and former chair of the RSS Data Science and AI Section.</li>
</ul>
<p>What follows are some edited highlights and key takeaways from the discussion.</p>
<div class="keyline">
<hr>
</div>
<section id="ai-safety-and-ai-risks" class="level2">
<h2 class="anchored" data-anchor-id="ai-safety-and-ai-risks">AI safety, and AI risks</h2>
<p><strong>Andrew Garrett:</strong> For those who were listening to the commentary last week, the PM [prime minister] made a very interesting speech. Rishi Sunak announced the creation of the world’s first AI Safety Institute in the UK, to examine, evaluate and test new types of AI. He also stated that he pushed hard to agree the first ever international statement about the risks of AI because, in his view, there wasn’t a shared understanding of the risks that we face. He used the example of the IPCC, the Intergovernmental Panel on Climate Change, to establish a truly global panel to publish a “state of AI science” report. And he also announced an investment in raw computing power, so around a billion pounds in a supercomputer, and £2.5 billion in quantum computers, making them available for researchers and businesses as well as government.</p>
<p>The RSS provided two responses this year to prominent [AI policy] reviews. The first was in June <a href="https://rss.org.uk/RSS/media/File-library/Policy/2023/RSS-AI-white-paper-response-v2-2.pdf">on the AI white paper</a>, and the second was on <a href="https://rss.org.uk/RSS/media/File-library/Policy/RSS_Evidence_Communications_and_Digital_Lords_Select_Committee_Inquiry_Large_Language_Models_September_2023.pdf">the House of Lords Select Committee inquiry into large language models</a> back in September. How do they relate to what the PM said? There’s some good news here, and maybe not quite so good news.</p>
<p>First, the RSS had requested investments in AI evaluation and a risk-based approach. And you could argue, by stating that there will be a safety institute, that that certainly ticks one of the boxes. We also recommended investment in open source, in computing power, and in data access. In terms of computing power, that was certainly in the [PM’s] speech. We spoke about strengthening leadership, and in particular including practitioners in the [AI safety] debate. A lot of academics and maybe a lot of the big tech companies have been involved in the debate, but we want to get practitioners – those close to the coalface – involved in the debate. I’m not sure we’ve seen too much of that. We recommended that strategic direction was provided, because it’s such a fast-moving area, and the fact that the Bletchley Park Summit is happening tomorrow, I think, is good for that. And we also recommended that data science capability was built amongst the regulators. I don’t think there was any mention of that.</p>
<p>That’s the context [for the RSS event today]. What I’m going to do now is ask each of the panellists to give an introductory statement around the AI summit, focusing on the safety aspects. What do they see as the biggest risk? And how would they mitigate or manage this risk?</p>
<p><strong>Detlef Nauck:</strong> I work at BT and run the AI and data science research programme. We’ve been looking at the safety, reliability, and responsibility of AI for quite a number of years already. Five years ago, we put up a responsible AI framework in the company, and this is now very much tied into our data governance and risk management frameworks.</p>
<p>Looking at the AI summit, they’re focusing on what they call “frontier models,” and they’re missing a trick here because I don’t think we need to worry about all-powerful AI; we need to worry about inadequate AI that is being used in the wrong context. For me, AI is programming with data, and that means I need to know what sort of data has been used to build the model, and I need AI vendors to be upfront about it and to tell me: What is the data that they have used to build it, how have they built it, or if they’ve tested for bias? And there are no protocols around this. So, therefore, I’m very much in favour of AI evaluation. But I don’t want to wait for an institute for AI evaluation. I want the academic research that needs to be done around this, which hasn’t been done. I want everybody who builds AI systems to take this responsibility and document properly what they’re doing.</p>
<div class="pullquote-container">
<div class="grid">
<div class="g-col-12 g-col-lg-4">
<div class="quarto-figure quarto-figure-left">
<figure class="figure">
<p><img src="https://realworlddatascience.net/viewpoints/posts/2023/12/06/images/llm-3d-shapes-crop.png" class="img-fluid quarto-figure quarto-figure-left figure-img"></p>
</figure>
</div>
</div>
<div class="g-col-12 g-col-lg-8 pullquote-grid pullquote">
<p><img src="https://realworlddatascience.net/images/pullquote-purple.png" class="img-fluid" width="50"></p>
<p>I hear more and more a lot of companies talking about AI general intelligence, and how AI is going to take over the world, and I’m tremendously concerned about this. There is an opportunity to build AI that is human empowering, that keeps us strong, able, capable, intelligent, and can support us in all our human capabilities.</p>
</div>
</div>
</div>
<p><strong>Mihaela van der Schaar:</strong> I am an AI researcher building AI and machine learning technology. Before talking about the risks, I also would like to say that I see tremendous potential for good. Many of these machine learning AI models can transform for the better areas that I find extremely important – healthcare and education. That being said, there are substantial risks, and we need to be very careful about that. First, if not designed well, AI can be both unsafe as well as biased, and that could lead to tremendous impact, especially in medicine and education. I completely agree with all the points that the Royal Statistical Society has made not only about open source but also about data access. This AI technology cannot be built unless you have access to high quality data, and what I see a lot happening, especially in industry, is people have data sources that they’ll keep private, build second-rate or third-rate technology on them, and then turn that into commercialised products that are sold to us for a lot of money. If data is made widely available, the best as well as the safest AI can be produced, rather than monopolised.</p>
<p>Another area of risk that I’m especially worried about is human marginalisation. I hear more and more a lot of companies talking about AI general intelligence, and how AI is going to take over the world, and I’m tremendously concerned as an AI researcher about this. There is an opportunity to build AI that is human empowering, that keeps us strong, able, capable, intelligent, and can support us in all our human capabilities.</p>
<p><strong>Martin Goodson:</strong> The AI Safety Summit is starting tomorrow. But, unfortunately, I think the government are focusing on the wrong risks. There are lots of risks to do with AI, and if you look at the scoping document for the summit, it says that what they’re interested in is misuse risk and the risk of loss of control. Misuse risk is that bad actors will gain access to information that they shouldn’t have and build chemical weapons and things like that. And the loss of control risk is that we will have this super intelligence which is going to take over and we should see, as is actually mentioned, the risk of the extinction of the human race, which I think is a bit overblown.</p>
<p>Both of these risks – the misuse risk and the loss of control risk – are potential risks. But we don’t really know how likely they are. We don’t even know whether they’re possible. But there are lots of risks that we do know are possible, like loss of jobs, and reductions in salary, particularly of white-collar jobs – that seems inevitable. There’s another risk, which is really important, which is the risk of monopolistic control by the small number of very powerful AI companies. These are the risks which are not just likely but are actually happening now – people are losing their jobs right now because of AI – and in terms of monopolistic control, OpenAI is the only company that has anything like a large language model as powerful as GPT-4. Even the mighty Google can’t really compete. This is a huge risk, I think, because we have no control over pricing: they could raise the prices if they wanted to; they could constrain access; they could only give access to certain people that they want to give access to. We don’t have any control over these systems.</p>
<p><strong>Mark Levene:</strong> I work in NPL as a principal scientist in the data science department. I’m also emeritus professor in Birkbeck, University of London. I have a long-standing expertise in machine learning and focus in NPL on trustworthy AI and uncertainty quantification. I believe that measurement is a key component in locking-in AI safety. Trustworthy AI and safe AI both have similar goals but different emphases. We strive to demonstrate the trustworthiness of an AI system so that we can have confidence in the technology making what we perceive as responsible decisions. Safe AI puts the emphasis on the prevention of harmful consequences. The risk [of AI] is significant, and it could potentially be catastrophic if we think of nuclear power plants, or weapons, and so on. I think one of the problems here is, who is actually going to take responsibility? This is a big issue, and not necessarily an issue for the scientist to decide. Also, who is accountable? For instance, the developers of large language models: are they the ones that are accountable? Or is it the people who deploy the large language models and are fine-tuning them for their use cases?</p>
<p>The other thing I want to emphasise is the socio-technical characteristics [of the AI problem]. We need to get an interdisciplinary team of people to actually try and tackle these issues.</p>
</section>
<section id="do-we-need-an-ai-safety-institute" class="level2">
<h2 class="anchored" data-anchor-id="do-we-need-an-ai-safety-institute">Do we need an AI Safety Institute?</h2>
<p><strong>Andrew Garrett:</strong> Do we need to have an AI Safety Institute, as Rishi Sunak has said? And if we don’t need one, why not?</p>
<p><strong>Detlef Nauck:</strong> I’m more in favour of encouraging academic research in the field and funding the kind of research projects that can look into how to build AI safely, [and] how to evaluate what it does. One of the key features of this technology is it has not come out of academic research; it has been built by large tech companies. And so, I think we have to do a bit of catch up in scientific research and in understanding how are we building these models, what can they do, and how do we control them?</p>
<p><strong>Mihaela van der Schaar:</strong> This technology has a life of its own now, and we are using it for all sorts of things that maybe initially was not even intended. So, shall we create an AI [safety] institute? We can, but we need to realise first that testing AI and showing that it’s safe in all sorts of ways is complicated. I would dare say that doing that well is a big research challenge by itself. I don’t think just one institute will solve it. And I feel the industry needs to bear some of the responsibility. I was very impressed by Professor [Geoffrey] Hinton, who came to Cambridge and said, “I think that some of these companies should invest as much money in making safe AI as developing AI.” I resonated quite a lot with that.</p>
<p>Also, let’s not forget, many academic researchers have two hats nowadays: they are professors, and they are working for big tech [companies] for a lot of money. So, if we take this academic, we put them in this AI tech safety institute, we have potential for corruption. I’m not saying that this will happen. But one needs to be very aware, and there needs to be a very big separation between who develops [AI technology] and who tests it. And finally, we need to realise that we may require an enormous amount of computation to be able to validate and test correctly, and very few academic or governmental organisations may have [that].</p>
<div class="pullquote-container">
<div class="grid">
<div class="g-col-12 g-col-lg-8 pullquote-grid pullquote">
<p><img src="https://realworlddatascience.net/images/pullquote-purple.png" class="img-fluid" width="50"></p>
<p>I think it’s an insult to the UK’s scientific legacy that we’re reduced to testing software that has been made by US companies. We have huge talents in this country. Why aren’t we using that talent to actually build something instead of testing something that someone else has made?</p>
</div>
<div class="g-col-12 g-col-lg-4">
<div class="quarto-figure quarto-figure-right">
<figure class="figure">
<p><img src="https://realworlddatascience.net/viewpoints/posts/2023/12/06/images/llm-3d-shapes-crop.png" class="img-fluid quarto-figure quarto-figure-right figure-img"></p>
</figure>
</div>
</div>
</div>
</div>
<p><strong>Martin Goodson:</strong> Can I disagree with this idea of an evaluation institute? I think it’s a really, really bad idea, for two reasons. The first is an argument about fairness. If you look at drug regulation, who pays for clinical trials? It’s not the government. It’s the pharmaceutical companies. They spend billions on clinical trials. So, why do we want to do this testing for free for the big tech companies? We’re just doing product development for them. It’s insane! They should be paying to show that their products are safe.</p>
<p>The other reason is, I think it’s an insult to the UK’s scientific legacy that we’re reduced to testing software that has been made by US companies. I think it’s pathetic. We were one of the main leaders of the Human Genome Project, and we really pushed it – the Wellcome Trust and scientists in the UK pushed the Human Genome Project because we didn’t want companies to have monopolistic control over the human genome. People were idealistic, there was a moral purpose. But now, we’re so reduced that all we can do is test some APIs that have been produced by Silicon Valley companies. We have huge talents in this country. Why aren’t we using that talent to actually build something instead of testing something that someone else has made?</p>
<p><strong>Mark Levene:</strong> Personally, I don’t see any problem in having an AI institute for safety or any other AI institutes. I think what’s important in terms of taxpayers’ money is that whatever institute or forum is invested in, it’s inclusive. One thing that the government should do is, we should have a panel of experts, and this panel should be interdisciplinary. And what this panel can do is it can advise government of the state of play in AI, and advise the regulators. And this panel doesn’t have to be static, it doesn’t have to be the same people all the time.</p>
<p><strong>Andrew Garrett:</strong> To evaluate something, whichever way you chose to do it, you need to have an inventory of those systems. So, with the current proposal, how would this AI Safety Institute have an inventory of what anyone was doing? How would it even work in practice?</p>
<p><strong>Martin Goodson:</strong> Unless we voluntarily go to them and say, “Can you test out our stuff?” then they wouldn’t. That’s the third reason why it’s a terrible idea. You’d need a licencing regime, like for drugs. You’d need to licence AI systems. But teenagers in their bedrooms are creating AI systems, so that’s impossible.</p>
</section>
<section id="lets-do-reality-centric-ai" class="level2">
<h2 class="anchored" data-anchor-id="lets-do-reality-centric-ai">Let’s do reality-centric AI!</h2>
<p><strong>Andrew Garrett:</strong> What are your thoughts about Rishi Sunak wanting the UK to be an AI powerhouse?</p>
<p><strong>Martin Goodson:</strong> It’s not going to be a powerhouse. This stuff about us being world leading in AI, it’s just a fiction. It’s a fairy tale. There are no real supercomputers in the UK. There are moves to build something, like you mentioned in your introduction, Andrew. But what are they going do with it? If they’re just going to build a supercomputer and carry on doing the same kinds of stuff that they’ve been doing for years, they’re not going to get anywhere. There needs to be a big project with an aim. You can build as many computers as you want. But if you haven’t got a plan for what to do with them, what’s the point?</p>
<p><strong>Mihaela van der Schaar:</strong> I really would agree with that. What about solving some real problem: trying to solve cancer; trying to solve our crisis in healthcare, where we don’t have enough infrastructure and doctors to take care of us? What about solving the climate change problem, or even traffic control, or preventing the next financial crisis? I wrote a little bit about that, and I call it “let’s do reality-centric AI.” Let’s have some goal that’s human empowering, take a problem that we have – energy, climate, cancer, Alzheimer’s, better education for children, and more diverse education for children – and let us solve these big challenges, and in the process we will build AI that’s hopefully more human empowering, rather than just saying, “Oh, we are going to solve everything if we have general AI.” Right now, I hear too much about AI for the sake of AI. I’m not sure, despite all the technology we build, that we have advanced in solving some real-world problems that are important for humanity – and imminently important.</p>
<p><strong>Martin Goodson:</strong> So, healthcare– I tried to make an appointment with my GP last week, and they couldn’t get me an appointment for four weeks. In the US you have this United States Medical Licencing Examination, and in order to practice medicine you need to pass all three components, you need to pass them by about 60%. They are really hard tests. GPT-4 for gets over 80% in all three of those. So, it’s perfectly plausible, I think, that an AI could do at least some of the role of the GP. But, you’re right, there is no mission to do that, there is no ambition to do that.</p>
<p><strong>Mihaela van der Schaar:</strong> Forget about replacing the doctors with ChatGPT, which I’m less sure is such a good idea. But, building AI to do the planning of healthcare, to say, “[Patient A], based on what we have found out about you, you’re not as high risk, maybe you can come in four weeks. But [patient B], you need to come tomorrow, because something is worrisome.”</p>
<p><strong>Martin Goodson:</strong> We can get into the details, but I think we are agreeing that a big mission to solve real problems would be a step forward, rather than worrying about these risks of superintelligences taking over everything, which is what the government is doing right now.</p>
</section>
<section id="managing-misinformation" class="level2">
<h2 class="anchored" data-anchor-id="managing-misinformation">Managing misinformation</h2>
<p><strong>Andrew Garrett:</strong> We have some important elections coming up in 2024 and 2025. We haven’t talked much about misinformation, and then disinformation. So, I’m interested to get your views here. How much is that a problem?</p>
<p><strong>Detlef Nauck:</strong> There’s a problem in figuring out when it happens, and that’s something we need to get our heads around. One thing that we’re looking at is, how do we make communication safe from bad actors? How do you know that you’re talking to the person you see on the camera and it’s not a deep fake? Detection mechanisms don’t really work, and they can be circumvented. So, it seems like what we need is new standards for communication systems, like watermarks and encryption built into devices. A camera should be able to say, “I’ve produced this picture, and I have watermarked it and it’s encrypted to a certain level,” and if you don’t see that, you can’t trust that what you see comes from a genuine camera, and it’s not artificially created. It’s more difficult around text and language – you can’t really watermark text.</p>
<p><strong>Mark Levene:</strong> Misinformation is not just a derivative of AI. It’s a derivative of social networks and lots of other things.</p>
<p><strong>Mihaela van der Schaar:</strong> I would agree that this is not only a problem with AI. We need to emphasise the role of education, and lifelong education. This is key to being able to comprehend, to judge for ourselves, to be trained to judge for ourselves. And maybe we need to teach different methods – from young kids to adults that are already working – to really exercise our own judgement. And that brings me to this AI for human empowerment. Can we build AI that is training us to become smarter, to become more able, more capable, more thoughtful, in addition to providing sources of information that are reliable and trustworthy?</p>
<p><strong>Andrew Garrett:</strong> So, empower people to be able to evaluate AI themselves?</p>
<p><strong>Mihaela van der Schaar:</strong> Yes, but not only AI – all information that is given to us.</p>
<p><strong>Martin Goodson:</strong> On misinformation, I think this is really an important topic, because large language models are extremely persuasive. I asked ChatGPT a puzzle question, and it calculated all of this stuff and gave me paragraphs of explanations, and the answer was [wrong]. But it was so convincing I was almost convinced that it was right. The problem is, these things have been trained on the internet and the internet is full of marketing – it’s trillions of words of extremely persuasive writing. So, these things are really persuasive, and when you put that into a political debate or an election campaign, that’s when it becomes really, really dangerous. And that is extremely worrying and needs to be regulated.</p>
<div class="pullquote-container">
<div class="grid">
<div class="g-col-12 g-col-lg-4">
<div class="quarto-figure quarto-figure-left">
<figure class="figure">
<p><img src="https://realworlddatascience.net/viewpoints/posts/2023/12/06/images/llm-3d-shapes-crop.png" class="img-fluid quarto-figure quarto-figure-left figure-img"></p>
</figure>
</div>
</div>
<div class="g-col-12 g-col-lg-8 pullquote-grid pullquote">
<p><img src="https://realworlddatascience.net/images/pullquote-purple.png" class="img-fluid" width="50"></p>
<p>At the moment, if you type something into ChatGPT and you ask for references, half of them will be made up. We know that, and also OpenAI knows that. But it could be that, if there’s regulation that things are traceable, you should be able to ask, ‘How did this information come about? Where did it come from?’</p>
</div>
</div>
</div>
<p><strong>Mark Levene:</strong> You need ways to detect it. Even that is a big challenge. I don’t know if it’s impossible, because, if there’s regulation, for example, there should be traceability of data. So, at the moment, if you type something into ChatGPT and you ask for references, half of them will be made up. We know that, and also OpenAI knows that. But it could be that, if there’s regulation that things are traceable, you should be able to ask, “How did this information come about? Where did it come from?” But I agree that if you just look at an image or some text, and you don’t know where it came from, it’s easy to believe. Humans are easily fooled, because we’re just the product of what we know and what we’re used to, and if we see something that we recognise, we don’t question it.</p>
</section>
<section id="audience-qa" class="level2">
<h2 class="anchored" data-anchor-id="audience-qa">Audience Q&amp;A</h2>
<section id="how-can-we-help-organisations-to-deploy-ai-in-a-responsible-way" class="level3">
<h3 class="anchored" data-anchor-id="how-can-we-help-organisations-to-deploy-ai-in-a-responsible-way">How can we help organisations to deploy AI in a responsible way?</h3>
<p><strong>Detlef Nauck:</strong> Help for the industry to deploy AI reliably and responsibly is something that’s missing, and for that, trust in AI is one of the things that needs to be built up. And you can only build up trust in AI if you know what these things are doing and they’re properly documented and tested. So that’s the kind of infrastructure, if you like, that’s missing. It’s not all big foundation models. It’s about, how do you actually use this stuff in practice? And 90% of that will be small, purpose-built AI models. That’s an area where the government can help. How do you empower smaller companies that don’t have the background of how AI works and how it can be used, how can they be supported in knowing what they can buy and what they can use and how they can use it?</p>
<p><strong>Mark Levene:</strong> One example from healthcare which comes to mind: when you do a test, let’s say, a blood test, you don’t just get one number, you should get an interval, because there’s uncertainty. What current [AI] models do is they give you one answer, right? In fact, there’s a lot of uncertainty in the answer. One thing that can build trust is to make transparent the uncertainty that the AI outputs.</p>
</section>
<section id="how-can-data-scientists-and-statisticians-help-us-understand-how-to-use-ai-properly" class="level3">
<h3 class="anchored" data-anchor-id="how-can-data-scientists-and-statisticians-help-us-understand-how-to-use-ai-properly">How can data scientists and statisticians help us understand how to use AI properly?</h3>
<p><strong>Martin Goodson:</strong> One big thing, I think, is in culture. In machine learning – academic research and in industry – there isn’t a very scientific culture. There isn’t really an emphasis on observation and experimentation. We hire loads of people coming out of an MSc or a PhD in machine learning, and they don’t know anything, really, about doing an experiment or selection bias or how data can trip you up. All they think about is, you get a benchmark set of data and you measure the accuracy of your algorithm on that. And so there isn’t this culture of scientific experimentation and observation, which is what statistics is all about, really.</p>
<p><strong>Mihaela van der Schaar:</strong> I agree with you, this is where we are now. But we are trying to change it. As a matter of fact, at the next big AI conference, NeurIPS, we plan to do a tutorial to teach people exactly this and bring some of these problems to the forefront, because trying really to understand errors in data, biases, confounders, misrepresentation – this is the biggest problem AI has today. We shouldn’t just build yet another, let’s say, classifier. We should spend time to improve the ability of these machine learning models to deal with all sorts of data.</p>
</section>
<section id="do-we-honestly-believe-yet-another-institute-and-yet-more-regulation-is-the-answer-to-what-were-grappling-with-here" class="level3">
<h3 class="anchored" data-anchor-id="do-we-honestly-believe-yet-another-institute-and-yet-more-regulation-is-the-answer-to-what-were-grappling-with-here">Do we honestly believe yet another institute, and yet more regulation, is the answer to what we’re grappling with here?</h3>
<p><strong>Detlef Nauck:</strong> I think we all agree, another institute is not going to cut it. One of the main problems is regulators are not trained on AI, so it’s the wrong people looking into it. This is where some serious upskilling is required.</p>
</section>
<section id="are-we-wrong-to-downplay-the-existential-or-catastrophic-risks-of-ai" class="level3">
<h3 class="anchored" data-anchor-id="are-we-wrong-to-downplay-the-existential-or-catastrophic-risks-of-ai">Are we wrong to downplay the existential or catastrophic risks of AI?</h3>
<p><strong>Martin Goodson:</strong> If I was an AI, a superintelligent AI, the easiest path for me to cause the extinction of the human race would be to spread misinformation about climate change, right? So, let’s focus on misinformation, because that’s an immediate danger to our way of life. Why are we focusing on science fiction? Let’s focus on reality.</p>
</section>
<section id="ai-tech-has-advanced-but-evaluation-metrics-havent-moved-forward.-why" class="level3">
<h3 class="anchored" data-anchor-id="ai-tech-has-advanced-but-evaluation-metrics-havent-moved-forward.-why">AI tech has advanced, but evaluation metrics haven’t moved forward. Why?</h3>
<p><strong>Mihaela van der Schaar:</strong> First, the AI community that I’m part of innovates at a very fast pace, and they don’t reward metrics. I am a big fan of metrics, and I can tell you, I can publish much faster a method in these top conferences then I can publish a metric. Number two, we often have in AI very stupid benchmarks, where we test everything on one dataset, and these datasets may be very wrong. On a more positive note, this is an enormous opportunity for machine learners and statisticians to work together and advance this very important field of metrics, of test sets, of data generating processes.</p>
<p><strong>Martin Goodson:</strong> The big problem with metrics right now is contamination, because most of the academic metrics and benchmark sets that we’re talking about, they’re published on the internet, and these systems are trained on the internet. I’ve already said that I don’t think this [evaluation] institute should exist. But if it did exist, there’s one thing that they could do, which is important, and that would be to create benchmark datasets that they do not publish. But obviously, you may decide, also, that the traditional idea of having a training set and a test set just doesn’t make any sense anymore. And there are loads of issues with data contamination, and data leakage between the training sets and the test sets.</p>
</section>
</section>
<section id="closing-thoughts-what-would-you-say-to-the-ai-safety-summit" class="level2">
<h2 class="anchored" data-anchor-id="closing-thoughts-what-would-you-say-to-the-ai-safety-summit">Closing thoughts: What would you say to the AI Safety Summit?</h2>
<p><strong>Andrew Garrett:</strong> If you were at the AI Safety Summit and you could make one point very succinctly, what would it be?</p>
<p><strong>Martin Goodson:</strong> You’re focusing on the wrong things.</p>
<p><strong>Mark Levene:</strong> What’s important is to have an interdisciplinary team that will advise the government, rather than to build these institutes, and that this team should be independent and a team which will change over time, and it needs to be inclusive.</p>
<p><strong>Mihaela van der Schaar:</strong> AI safety is complex, and we need to realise that people need to have the right expertise to be able to really understand the risks. And there is risk, as I mentioned before, of potential collusion, where people are both building the AI and saying it’s safe, and we need to separate these two worlds.</p>
<p><strong>Detlef Nauck:</strong> Focus on the data, not the models. That’s what’s important to build AI.</p>
<div class="article-btn">
<p><a href="../../../../../viewpoints/index.html">Discover more Viewpoints</a></p>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-6">
<dl>
<dt>Copyright and licence</dt>
<dd>
© 2023 Royal Statistical Society
</dd>
</dl>
<p>Images by <a href="https://cream3d.com/">Wes Cockx</a> &amp; <a href="https://deepmind.google/discover/visualising-ai/">Google DeepMind</a> / <a href="https://www.betterimagesofai.org">Better Images of AI</a> / AI large language models / <a href="https://creativecommons.org/licenses/by/4.0/">Licenced by CC-BY 4.0</a>.</p>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>How to cite</dt>
<dd>
Tarran, Brian. 2023. “Evaluating artificial intelligence: How data science and statistics can make sense of AI models.” Real World Data Science, December 6, 2023. <a href="https://realworlddatascience.net/viewpoints/posts/2023/12/06/ai-fringe.html">URL</a>
</dd>
</dl>
</div>
</div>
</div>


</section>

 ]]></description>
  <category>AI</category>
  <category>Large language models</category>
  <category>Accountability</category>
  <category>Regulation</category>
  <category>Metrics</category>
  <category>Events</category>
  <guid>https://realworlddatascience.net/viewpoints/posts/2023/12/06/ai-fringe.html</guid>
  <pubDate>Wed, 06 Dec 2023 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/viewpoints/posts/2023/12/06/images/llm-3d-shapes.png" medium="image" type="image/png" height="105" width="144"/>
</item>
<item>
  <title>‘I would like modellers to be less ambitious in developing monster models that are impossible to inspect’</title>
  <dc:creator>Brian Tarran</dc:creator>
  <link>https://realworlddatascience.net/viewpoints/interviews/posts/2023/11/24/politics-of-modelling.html</link>
  <description><![CDATA[ 





<p>It was during the first wave of the Covid-19 pandemic, when citizens in many countries around the world were confined to their homes, that Andrea Saltelli and colleagues were inspired to write “a manifesto for responsible modelling.” The television news was, Saltelli recalls, dominated by models of Covid infections, hospitalisations, and deaths. Politicians pointed to charts showing those model projections and spoke of “flattening the curve” – driving down case numbers – so as not to overwhelm healthcare systems.</p>
<p>While all this was going on, Saltelli came into contact “with a fantastic group of people,” he says, “all of whom were, in a sense, concerned by the sudden eruption of mathematical modelling into everyday life.”</p>
<p>“We were concerned that this [modelling] was not being done properly, that too much importance was given to those numbers, too much certainty was attached to them, and nobody seemed to realise that the selection of certain numbers rather than others would eventually and dramatically bias the message that was given.”</p>
<p>In June 2020, Saltelli – along with Monica Di Fiore, Deborah Mayo, Theodore Porter, Philip Stark and others – published in <em>Nature</em> their manifesto setting out “<a href="https://www.nature.com/articles/d41586-020-01812-9">Five ways to ensure that models serve society</a>.” The ideas proposed in that three-page comment piece have now been given a book-length treatment, so we sat down with Saltelli to discuss <a href="https://global.oup.com/academic/product/the-politics-of-modelling-9780198872412?cc=gb&amp;lang=en&amp;"><em>The Politics of Modelling: Numbers Between Science and Policy</em></a>.</p>
<div class="keyline">
<hr>
</div>
<p><strong>Can you tell our readers a little about yourself?</strong><br>
I am a chemist. I got my degree in chemistry, but for most of my life I have worked as a mathematical modeller and applied statistician. More recently, let’s say in the last 10 years or so, I have also moved into issues of epistemology – meaning, how do we decide that we know what we know, and how do we do that when the source of the knowledge is represented by a mathematical model?</p>
<p><strong>I’d like to dig into the title of your new book. What should people understand about <em>The Politics of Modelling</em>?</strong><br>
It starts from a broader discussion of a state of exception enjoyed by mathematical modelling. One point we try to make in the book is that models are exceptional because they have an incredible palette of methodologies – even more than statistics. They are not a discipline, because everyone does modelling in their own craft in a different way. Modelling even escapes the gaze of sociologists most of the time because sociologists are more interested in algorithms and statistics. And, as a consequence of this state of exception, models enjoy many privileges, including a better defence of the pretence of neutrality, and they maintain, in a certain sense, a lapse of symmetry between developers and users. They also have a very strong grip on policy, whereby models can enjoy a high epistemic authority, and this epistemic authority seems to be proportional to the dimension of the model or the base of data on which the model has been calibrated. All of this creates a situation which leads to a problem – a problem for society, on the one hand, because models are used to suggest policies which are not optimal, and on the other hand, trust is consumed, trust is lost, and this may have been happening as a result of the Covid-19 epidemic and the way mathematical modelling was used in the context of the epidemic.</p>
<p><strong>The book emerged out of the “manifesto for responsible modelling” that you published in <em>Nature</em> a few years back. Could you describe that manifesto?</strong><br>
The manifesto was something which came out of the pandemic, in fact, because we were all locked up at home and we could spend some time reflecting and writing. We tried to produce a set of recommendations for both society and the modellers: for society to be a bit more circumspect in accepting results from mathematical modelling, and for modellers to be more cautious in formulating their predictions. But, beyond the issue of apparent precision of mathematical models, there was also the issue that models are built on a series of assumptions, each of which may have a great bearing on the result. And not only that but also, at the point where you formulate a mathematical model, you assume that you have already decided what is the problem, what is the direction of progress. So, there are really many normative assumptions which are embedded into that. Then there is the issue that mathematical models are not done by everyone; they are done by specific groups of people who belong to, normally, a certain identified class, some kind of elite – not a financial elite, but an elite in terms of competencies and knowledge. And this also creates bias, because – to put it brutally – if you can work at home with your laptop, the epidemic doesn’t affect you so much. But if you work in a plant and the plant is closed, and you are not paid, this destroys your life, or the life of your family. This asymmetry – or inequality, let’s say, or implicit bias – in those who are producing the analysis, this was, for many of us, an issue which needed to be brought to the attention of the public.</p>
<div class="pullquote-container">
<div class="grid">
<div class="g-col-12 g-col-lg-4">
<div class="quarto-figure quarto-figure-left">
<figure class="figure">
<p><img src="https://realworlddatascience.net/viewpoints/interviews/posts/2023/11/24/images/andrea-saltelli-sq.png" class="img-fluid quarto-figure quarto-figure-left figure-img" alt="Andrea Saltelli, co-editor of 'The Politics of Modelling'"></p>
<figcaption>Andrea Saltelli, co-editor of ‘The Politics of Modelling.’</figcaption>
</figure>
</div>
</div>
<div class="g-col-12 g-col-lg-8 pullquote-grid pullquote">
<p><img src="https://realworlddatascience.net/images/pullquote-purple.png" class="img-fluid" width="50"></p>
<p>The manifesto was something which came out of the pandemic… We tried to produce a set of recommendations for both society and the modellers: for society to be a bit more circumspect in accepting results from mathematical modelling, and for modellers to be more cautious in formulating their predictions.</p>
</div>
</div>
</div>
<p><strong>Surely the urgency of the Covid situation prevented people from taking a step back and thinking more deeply about how models are constructed. Is it not forgivable in a situation like that? Or, is your argument that we should be doing this at all times, regardless of the urgency, regardless of the time pressures?</strong><br>
I am tempted to say both yes and no. Yes, because surely the situation was urgent, and many things which were done in a way which one would consider suboptimal were later justified on the grounds of urgency. We noted incredible differences in the measures adopted in several countries, so for us it was obvious that even though everyone was claiming to “follow the science,” they seemed to be following different sciences, or perhaps they were following “the science” which was more instrumental or more convenient to justify what was simply politically expedient.</p>
<p>Beyond that, I would say: it’s always urgent, no? We are very often in these kinds of situations. One might say that even the regulation of artificial intelligence today is urgent. Regulation of pesticides is urgent. Not to mention geopolitics… Everything seems to be urgent, and this seems to be a constant in our relationship with technology in particular: we don’t want to kill innovation, but if we wait to see what a new piece of technology does before we regulate it, then maybe it’s too late to change it. This is exploited by many people, not least [Mark] Zuckerberg [CEO of Facebook owner Meta]. He says, “Move fast and break things,” but once things are broken, they’re broken.</p>
<p>And talking about things being broken, what we discuss in the book is also this issue of broken trust. People are losing faith in expertise – not in all countries in the same way; there are national differences that are important. But, in general, if you measure trust in science – which is still very high – it’s taken quite a dent during the pandemic, and we argue that this was in part due to abuse of mathematical models.</p>
<p><strong>The book, which you’ve edited with Monica Di Fiore, breaks down the manifesto for responsible modelling into extended essays from different contributors, looking at different aspects of modelling – the framing of models, the assumptions, the consequences. For these essays, you draw on experts from different fields: sociology, philosophy, statistics, civil engineering, geography, law, environmental sciences, and others. Why was it important to get such diverse perspectives on these various aspects of modelling?</strong><br>
There is a major divide between social science – humanities – on the one hand and natural sciences on the other hand, with lots of suspicion between the two fields and sometimes open hostility. Mathematical modelling is particularly impenetrable, as we argue, to the gaze coming from a social scientist – at least, more impenetrable than statistics or algorithms, which have been very much studied in recent years. And so, it was important to allow the two fields, the two big communities, to communicate and to speak to one another in a critical way.</p>
<p><strong>You write in your introduction to the book that the field of statistics has spent more time thinking more deeply about questions of data ethics, model assumptions, and so on. Can you give an example?</strong><br>
There is a book by a group of French statisticians, <em>Statactivisme</em>, which is rich with examples of how a statistician could make a difference by simply producing better numbers. They don’t say, “Throw away the model, throw away the numbers,” but simply be careful of what numbers you use. And I think models and modellers need something like this, some kind of systematic debate – a societal debate – with other disciplines on what they’re doing.</p>
<p><strong>One of the quotes that jumped out at me from the book was, “Models are underexplained but overinterpreted.” How do we reset that balance?</strong><br>
This is more easily said than done. The remedies to this are, maybe we should spend some time thinking about reproducibility, even in mathematical modelling. This is not done. We talk about the reproducibility of data but very few people talk about the reproducibility of a mathematical model. Another thing which I think would be useful is to think more about how to interpret models and less about how to make them bigger. And then, of course, there is the practice of “assumption hunting.” If you use a model, go and hunt for the assumptions contributing to its construction.</p>
<p>To the modellers we say, engage yourself in something that might be called “modelling of the model process,” which means, try to imagine what would happen if you took a different branch in the construction of the model. In this we make an analogy to the “garden of the forking paths,” something that statisticians discuss, because they understand that when they build a statistical construction, they can take one way or another way, and when they measure the impact of taking a different path – as, for instance, when they give the same data to different teams – they find an amazing diversity of results that are totally unexpected. We are learning now that not only in statistics and mathematical modelling but in the laboratory, too – conducting physical experiments, not numerical ones – you can have a diverging set of outcomes depending on who is doing the analysis.</p>
<p>All this should call for a science that is more humble – one that accepts this kind of possibility and works actively to make these issues evident but also solves them in order to produce knowledge that is useful.</p>
<p><strong>Earlier, you spoke about modellers coming from a specific group or class of people – an elite. We interviewed, earlier this year, <a href="https://realworlddatascience.net/viewpoints/interviews/posts/2023/01/25/erica-thompson.html">Erica Thompson</a>, author of the book <em>Escape from Model Land</em>, and one of the points Erica discussed was how to bring more diversity of thought and of voices into the modelling process. How do we engage broader communities in the construction of models – maybe not building the model itself, but thinking about what is important, what needs to be measured, what are we looking to understand?</strong><br>
This could be achieved if models were used in a context of what we, the authors, call an “extended peer community.” In other words, this is the idea that when you are discussing an issue, you should talk to the people directly affected by the issue because they have some knowledge about it. For this to take place, the model must be one instrument, which the community can get together to discuss, and so the model must not be too complex.</p>
<p><strong>Now that your book is out, what do you hope will be its impact?</strong><br>
Looking from the point of view of the modellers, I would like them to be more humble and less ambitious in developing monster models that are impossible to inspect and explore. From society I would like to see a more circumspect attitude, as I said before. Society has been trained to be sceptical of statistical information, but we should also be circumspect about the output of mathematical modelling. Ask more questions; ask, for instance, for the uncertainty range for a given number, or whether the number tells the entire story.</p>
<div class="article-btn">
<p><a href="../../../../../../viewpoints/interviews/index.html">Find more Interviews</a></p>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-6">
<dl>
<dt>Copyright and licence</dt>
<dd>
© 2023 Royal Statistical Society
</dd>
</dl>
<p><a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> <img style="height:22px!important;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"></a> This article is licensed under a Creative Commons Attribution 4.0 (CC BY 4.0) <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> International licence</a>.</p>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>How to cite</dt>
<dd>
Tarran, Brian. 2023. “‘I would like modellers to be less ambitious in developing monster models that are impossible to inspect.’” Real World Data Science, November 24, 2023. <a href="https://realworlddatascience.net/viewpoints/interviews/posts/2023/11/24/politics-of-modelling.html">URL</a>
</dd>
</dl>
</div>
</div>
</div>



 ]]></description>
  <category>Modelling</category>
  <category>Public policy</category>
  <guid>https://realworlddatascience.net/viewpoints/interviews/posts/2023/11/24/politics-of-modelling.html</guid>
  <pubDate>Fri, 24 Nov 2023 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/viewpoints/interviews/posts/2023/11/24/images/andrea-saltelli.png" medium="image" type="image/png" height="105" width="144"/>
</item>
<item>
  <title>Deduplicating and linking large datasets using Splink</title>
  <dc:creator>Robin Linacre</dc:creator>
  <link>https://realworlddatascience.net/case-studies/posts/2023/11/22/splink.html</link>
  <description><![CDATA[ 





<p>In 2019, the data linking team at the Ministry of Justice was challenged to develop a new data linking methodology to produce new, higher quality linked datasets from the justice system.</p>
<p>The ultimate goal was to share new linked datasets with academic researchers, as part of the ADR UK-funded <a href="https://www.gov.uk/guidance/ministry-of-justice-data-first">Data First programme</a>. These datasets – which include data from prisons, probation, and the criminal and family courts – are now available, and researchers can <a href="https://www.gov.uk/government/publications/moj-data-first-application-form-for-secure-access-to-data">apply for secure access</a>.</p>
<p>The linking methodology is widely applicable and has been published as a free and open source software package called <a href="https://github.com/moj-analytical-services/splink">Splink</a>. The software applies statistical best practice to accurately and quickly link and deduplicate large datasets. The software has now been downloaded over 7 million times, and has been used widely in government, academia and the private sector.</p>
<section id="the-problem" class="level2">
<h2 class="anchored" data-anchor-id="the-problem">The problem</h2>
<p>Data duplication is a ubiquitous problem affecting data quality. Organisations often have multiple records that refer to the same entity but no unique identifier that ties these entities together. Data entry errors and other issues mean that variations usually exist, so the records belonging to a single entity aren’t necessarily identical.</p>
<p>For example, in a company, customer data may have been entered multiple times in multiple different databases, with different spellings of names, different addresses, and other typos. The inability to identify which records belong to each customer presents a data quality problem at all stages of data analysis – from basic questions such as counting the number of unique customers, through to advanced statistical analysis.</p>
<p>With the growing size of datasets held by many organisations, any solution must be able to work on very large datasets of tens of millions of records or more.</p>
</section>
<section id="approach" class="level2">
<h2 class="anchored" data-anchor-id="approach">Approach</h2>
<p>In collaboration with academic experts, the team started with desk research into data linking theory and practice, and a review of existing open source software implementations.</p>
<p>One of the most common theoretical approaches described in the literature is the Fellegi-Sunter model. This statistical model has a long history of application for high profile, important record linking tasks such as in the US Census Bureau and the UK Office for National Statistics (ONS).</p>
<p>The model takes pairwise comparisons of records as an input, and outputs a match score between 0 and 1, which (loosely) can be interpreted as the probability of the two records being a match. Since the record comparison can be either two records from the same dataset, or records from different datasets, this is applicable to both deduplication and linkage problems.</p>
<p>An important benefit of the model is explainability. The model uses a number of parameters, each of which <a href="https://www.robinlinacre.com/partial_match_weights/">has an intuitive explanation</a> that can be understood by a non-technical audience. The relative simplicity of the model also means it is easier to understand and explain how biases in linkage may occur, such as varying levels of accuracy for different ethnic groups.</p>
<section id="example" class="level3">
<h3 class="anchored" data-anchor-id="example">Example</h3>
<p>Consider the following simple record comparison. Are these records a match?</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://realworlddatascience.net/case-studies/posts/2023/11/22/images/record_comparison.png" class="img-fluid figure-img"></p>
<figcaption><strong>Figure 1</strong>: Colour coded comparison of two records.</figcaption>
</figure>
</div>
<p>The parameters of the model are known as partial match weights, which capture the strength of the evidence in favour or against these records being a match.</p>
<p>They can be represented in a chart as follows, in which the highlighted bars correspond to the above example record comparison:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://realworlddatascience.net/case-studies/posts/2023/11/22/images/partial_match_weights.png" class="img-fluid figure-img"></p>
<figcaption><strong>Figure 2</strong>: Chart showing partial match weights of model.</figcaption>
</figure>
</div>
<p>We can see, for example, that the first name (Robin vs Robyn) is not an exact match, but they have a Jaro-Winkler similarity of above 0.9. As a result, the model ‘activates’ the corresponding partial match weight (in orange). This lends some evidence in favour of a match, but the partial match weight is not as strong as it would have been for an exact match.</p>
<p>Similarly we can see that the non-match on gender leads to the activation (in purple) of a strong negative partial match weight.</p>
<p>The activated partial match weight can then be represented in a waterfall chart as follows, which shows how the final match score is calculated:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://realworlddatascience.net/case-studies/posts/2023/11/22/images/waterfall.png" class="img-fluid figure-img"></p>
<figcaption><strong>Figure 3</strong>: Waterfall chart showing how partial match weights combine to calculate the final prediction.</figcaption>
</figure>
</div>
<p>The parameter estimates in these charts all have intuitive explanations:</p>
<ul>
<li>The partial match weight on first name is positive, but relatively weak. This makes sense, because the first names are a fuzzy match, not an exact match, so this provides only moderate evidence in favour of the record being a match.</li>
<li>The match weight for the exact match on postcode is stronger than the equivalent weight for surname. This is because the cardinality of the postcode field in the underlying data is higher than the cardinality for surname, so matches on postcode are less likely to occur by chance than matches on surname.</li>
<li>The negative match weight for the mismatch on gender is relatively strong. This reflects the fact that, in this dataset, it’s uncommon for the ‘gender’ field to match amongst truly matching records.</li>
</ul>
<p>The final result is that the model predicts these records are a match, but with only 94% probability: it’s not sure. Most examples would be less ambiguous than this one, and would have a match probability very close to either 0 or 1.</p>
<p>For further details of the theory behind the Fellegi-Sunter model, and a deep dive into the intuitive explanations of the model, I have have developed a <a href="https://www.robinlinacre.com/intro_to_probabilistic_linkage/">series of interactive tutorials</a>.</p>
</section>
</section>
<section id="implementation" class="level2">
<h2 class="anchored" data-anchor-id="implementation">Implementation</h2>
<p>Through our desk research and open source software review, an existing software package called <a href="https://github.com/kosukeimai/fastLink">fastLink</a> was identified which implements the Fellegi-Sunter model, but unfortunately the software is not able to handle very large datasets of more than a few hundred thousand records.</p>
<p>Inspired by the popularity of fastLink, the team quickly realised that the methodology it was developing was generally applicable and could be valuable to a wide range of users if published as a software package.</p>
<p>As we spoke to colleagues across government and beyond, we found record linkage and deduplication problems are pervasive, and crop up in many different guises, meaning that any software needed to be very general and flexible.</p>
<p>The result is Splink – which is a Python package that implements the Fellegi-Sunter model, and enables parameters to be estimated using the Expectation Maximisation algorithm.</p>
<p>The package is free to use, <a href="https://github.com/moj-analytical-services/splink">and open source</a>. It is accompanied by <a href="https://moj-analytical-services.github.io/splink/index.html">detailed documentation</a>, including a <a href="https://moj-analytical-services.github.io/splink/demos/tutorials/00_Tutorial_Introduction.html">tutorial</a> and a set of <a href="https://moj-analytical-services.github.io/splink/demos/examples/examples_index.html">examples</a>.</p>
<p>Splink makes no assumptions about the type of entity being linked, so it is very flexible. We are aware of its use to match data on a variety of entity types including persons, companies, financial transactions and court cases.</p>
<p>The package closely follows the statistical approach described in fastLink. In particular it implements the same mathematical model and likelihood functions described in the <a href="http://imai.fas.harvard.edu/research/files/linkage.pdf">fastLink paper</a> (see pages 354 to 357), with a comprehensive suite of tests to ensure correctness of the implementation.</p>
<p>In addition, Splink introduces a number of innovations:</p>
<ul>
<li>Able to work at massive scale – with proven examples of its use on over 100 million records.</li>
<li>Extremely fast – capable of linking 1 million records on a laptop in around a minute.</li>
<li><a href="https://moj-analytical-services.github.io/splink/charts/index.html">Comprehensive graphical output</a> showing parameter estimates and iteration history make it easier to understand the model and diagnose statistical issues.</li>
<li><a href="https://moj-analytical-services.github.io/splink/charts/waterfall_chart.html">A waterfall chart</a> which can be generated for any record pair, which explains how the estimated match probability is derived.</li>
<li>Support for deduplication, linking, and a combination of both, including support for deduplicating and linking multiple datasets.</li>
<li>Greater customisability of record comparisons, including the ability <a href="https://moj-analytical-services.github.io/splink/topic_guides/comparisons/customising_comparisons.html">to specify custom, user defined comparison functions.</a></li>
<li>Term frequency adjustments on any number of columns.</li>
<li>It’s possible to save a model once it’s been estimated – enabling a model to be estimated, quality assured, and then reused as new data becomes available.</li>
<li>A <a href="https://moj-analytical-services.github.io/splink/">companion website</a> provides a complete description of the various configuration options, and examples of how to achieve different linking objectives.</li>
</ul>
</section>
<section id="using-splink" class="level2">
<h2 class="anchored" data-anchor-id="using-splink">Using Splink</h2>
<p><a href="https://moj-analytical-services.github.io/splink/">Full documentation</a> and <a href="https://moj-analytical-services.github.io/splink/demos/tutorials/00_Tutorial_Introduction.html">a tutorial</a> are available for Splink, but the following snippet gives a simple example of Splink in action:</p>
<div class="sourceCode" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> splink.datasets <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> splink_datasets</span>
<span id="cb1-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> splink.duckdb.blocking_rule_library <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> block_on</span>
<span id="cb1-3"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> splink.duckdb.comparison_library <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> (</span>
<span id="cb1-4">    exact_match,</span>
<span id="cb1-5">    jaro_winkler_at_thresholds,</span>
<span id="cb1-6">    levenshtein_at_thresholds,</span>
<span id="cb1-7">)</span>
<span id="cb1-8"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> splink.duckdb.linker <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> DuckDBLinker</span>
<span id="cb1-9"></span>
<span id="cb1-10">df <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> splink_datasets.fake_1000</span>
<span id="cb1-11"></span>
<span id="cb1-12"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Specify a data linkage model</span></span>
<span id="cb1-13">settings <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> {</span>
<span id="cb1-14">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"link_type"</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"dedupe_only"</span>,</span>
<span id="cb1-15">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"blocking_rules_to_generate_predictions"</span>: [</span>
<span id="cb1-16">      block_on(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"first_name"</span>),</span>
<span id="cb1-17">      block_on(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"surname"</span>),</span>
<span id="cb1-18">    ],</span>
<span id="cb1-19">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"comparisons"</span>: [</span>
<span id="cb1-20">        jaro_winkler_at_thresholds(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"first_name"</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>),</span>
<span id="cb1-21">        jaro_winkler_at_thresholds(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"surname"</span>),</span>
<span id="cb1-22">        levenshtein_at_thresholds(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"dob"</span>),</span>
<span id="cb1-23">        exact_match(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"city"</span>, term_frequency_adjustments<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>),</span>
<span id="cb1-24">        exact_match(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"email"</span>),</span>
<span id="cb1-25">    ],</span>
<span id="cb1-26">}</span>
<span id="cb1-27"></span>
<span id="cb1-28">linker <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> DuckDBLinker(df, settings)</span>
<span id="cb1-29"></span>
<span id="cb1-30"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Estimate model parameters</span></span>
<span id="cb1-31"></span>
<span id="cb1-32"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Direct estimation using random sampling can be used for the u probabilities</span></span>
<span id="cb1-33">linker.estimate_u_using_random_sampling(target_rows<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1e6</span>)</span>
<span id="cb1-34"></span>
<span id="cb1-35"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Expectation maximisation is used to train the m values</span></span>
<span id="cb1-36">br_training <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> block_on([<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"first_name"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"surname"</span>])</span>
<span id="cb1-37">linker.estimate_parameters_using_expectation_maximisation(br_training)</span>
<span id="cb1-38"></span>
<span id="cb1-39">br_training <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> block_on(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"dob"</span>)</span>
<span id="cb1-40">linker.estimate_parameters_using_expectation_maximisation(br_training)</span>
<span id="cb1-41"></span>
<span id="cb1-42"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Use the model to compute pairwise match scores</span></span>
<span id="cb1-43">pairwise_predictions <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> linker.predict()</span>
<span id="cb1-44"></span>
<span id="cb1-45"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Cluster the match scores into groups to produce a synthetic unique person id</span></span>
<span id="cb1-46">clusters <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> linker.cluster_pairwise_predictions_at_threshold(</span>
<span id="cb1-47">  pairwise_predictions, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.95</span></span>
<span id="cb1-48">)</span>
<span id="cb1-49">clusters.as_pandas_dataframe(limit<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>)</span></code></pre></div>
<p>The example shows the flexibility of Splink, and how various types of configuration can be used:</p>
<ul>
<li><strong>How should different data fields be compared?</strong> In this example, the Jaro-Winkler distance is used for names, whereas Levenshtein is used for date of birth since Jaro-Winkler is not appropriate for numeric data.</li>
<li><strong>What blocking rules should be used?</strong> Blocking rules are the primary determinants of how fast Splink will run, but there is a trade off between speed and accuracy. In this case, the input data is small, so the blocking rules are loose.</li>
<li><strong>How should the model parameters be estimated?</strong> In this case, the user has no labels for supervised training, and so uses the unsupervised Expectation Maximisation approach.</li>
<li><strong>Is clustering needed?</strong> In this case, each person may potentially have many duplicates, so clustering is used. This creates an estimated (synthetic) unique identifier for each entity (person) in the input dataset.</li>
</ul>
</section>
<section id="outcomes" class="level2">
<h2 class="anchored" data-anchor-id="outcomes">Outcomes</h2>
<p>Splink has been used to link some of the largest datasets held by the Ministry of Justice as part of the <a href="https://www.gov.uk/guidance/ministry-of-justice-data-first">Data First programme</a>, and researchers are now <a href="https://www.gov.uk/government/publications/moj-data-first-application-form-for-secure-access-to-data">able to apply for secure access to these datasets</a>. Research using this data <a href="https://www.ons.gov.uk/aboutus/whatwedo/statistics/requestingstatistics/onsresearchexcellenceaward">won the ONS Linked Administrative Data Award at the 2022 Research Excellence Awards</a>.</p>
<p>More widely, the demand for Splink has been higher than we expected – with over 7 million downloads. It has been used in other government departments including the Office for National Statistics and internationally, the private sector, and published academic research from top international universities.</p>
<p>Splink has also had external contributions from over 30 people, including staff at the Australian Bureau of Statistics, DataBricks, other government departments, academics, and various private sector consultancies.</p>
<div class="callout callout-style-simple callout-note" style="margin-top: 2.25rem;">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-body-container">
<p><strong>Editor’s note</strong>: For more on data linkage, <a href="https://realworlddatascience.net/viewpoints/interviews/posts/2023/10/16/data-sharing-in-gov.html">check out our interview with Helen Miller-Bakewell of the UK Office for Statistics Regulation</a>, discussing the OSR report, <a href="https://osr.statisticsauthority.gov.uk/publication/data-sharing-and-linkage-for-the-public-good/">Data Sharing and Linkage for the Public Good</a>.</p>
</div>
</div>
</div>
<div class="article-btn">
<p><a href="../../../../../case-studies/index.html">Find more case studies</a></p>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-12">
<dl>
<dt>About the author</dt>
<dd>
<strong>Robin Linacre</strong> is an economist, data scientist and data engineer based at the UK Ministry of Justice. He is the lead author of Splink.
</dd>
</dl>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>Copyright and licence</dt>
<dd>
© 2023 Robin Linacre
</dd>
</dl>
<p><a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> <img style="height:22px!important;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"></a> This article is licensed under a Creative Commons Attribution 4.0 (CC BY 4.0) <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> International licence</a>. Thumbnail photo by <a href="https://unsplash.com/@possessedphotography?utm_content=creditCopyText&amp;utm_medium=referral&amp;utm_source=unsplash">Possessed Photography</a> on <a href="https://unsplash.com/photos/yellow-metal-chain-NwpSBZMhc-M?utm_content=creditCopyText&amp;utm_medium=referral&amp;utm_source=unsplash">Unsplash</a>.</p>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>How to cite</dt>
<dd>
Linacre, Robin. 2023. “Deduplicating and linking large datasets using Splink.” Real World Data Science, November 22, 2023. <a href="https://realworlddatascience.net/case-studies/posts/2023/11/22/splink.html">URL</a>
</dd>
</dl>
</div>
</div>
</div>


</section>

 ]]></description>
  <category>Crime and justice</category>
  <category>Data quality</category>
  <category>Data linkage</category>
  <guid>https://realworlddatascience.net/case-studies/posts/2023/11/22/splink.html</guid>
  <pubDate>Wed, 22 Nov 2023 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/case-studies/posts/2023/11/22/images/possessed-photography-NwpSBZMhc-M-unsplash.png" medium="image" type="image/png" height="105" width="144"/>
</item>
<item>
  <title>Learning from failure: ‘Red flags’ in body-worn camera data</title>
  <dc:creator>Noah Wright</dc:creator>
  <link>https://realworlddatascience.net/case-studies/posts/2023/11/16/learning-from-failure.html</link>
  <description><![CDATA[ 





<p>Incarcerated youth are an exceptionally vulnerable population, and body-worn cameras are an important tool of accountability both for those incarcerated and the staff who supervise them. In 2018 the Texas Juvenile Justice Department (TJJD) deployed body-worn cameras for the first time, and this is a case study of how the agency developed a methodology for measuring the success of the camera rollout. This is also a case study of analysis failure, as it became clear that real-world implementation problems were corrupting the data and rendering the methodology unusable. However, the process of working through the causes of this failure helped the agency identify previously unrecognized problems and ultimately proved to be of great benefit. The purpose of this case study is to demonstrate how negative findings can still be incredibly useful in real-world settings.</p>
<div class="callout callout-style-simple callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-1-contents" aria-controls="callout-1" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Why body-worn cameras?
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-1" class="callout-1-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>Body-worn cameras became a standard tool of policing in the US in the mid-2010s. By recording officer interactions with the public, law enforcement agencies could achieve a greater degree of accountability. Not only could credible claims of police abuse against civilians be easily verified, the argument went, but false accusations would decline as well, saving law enforcement agencies time and resources that would otherwise be wasted on spurious allegations. Initial studies seemed to support this argument.</p>
<p>TJJD faced similar issues to law enforcement agencies, and body-worn cameras seemed like they could be a useful tool. Secure youth residential facilities in Texas all had overhead cameras, but these were very old (they still ran on tape) and captured no audio. This presented a number of problems when it came to deciphering contested incidents, not to mention that these cameras had clearly not prevented any of the agency’s prior scandals from taking place. TJJD received special funding from the legislature to roll out body-worn cameras system-wide, and all juvenile correctional officers were required to wear one.</p>
</div>
</div>
</div>
<section id="background" class="level2">
<h2 class="anchored" data-anchor-id="background">Background</h2>
<p>From the outset of the rollout of body-worn cameras, TJJD faced a major issue with implementation: in 2019, body worn cameras were an established tool for law enforcement, but there was very little literature or best practice to draw from for their use in a correctional environment. Unlike police officers, juvenile correctional officers (JCOs) deal directly with their charges for virtually their entire shift. In an eight-hour shift, a police officer might record a few calls and traffic stops. A juvenile correctional officer, on the other hand, would record for almost eight consecutive hours. And, because TJJD recorded round-the-clock for hundreds of employees at a time, this added up very quickly to <em>a lot</em> of footage.</p>
<p>For example, a typical dorm in a correctional center might have four JCOs assigned to it. Across a single week, these four JCOs would be expected to record at least 160 hours of footage.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://realworlddatascience.net/case-studies/posts/2023/11/16/images/jcos-recording-totals.png" class="img-fluid quarto-figure quarto-figure-center figure-img" alt="A table illustrating working hours over the course of a week for four juvenile correctional officers"></p>
</figure>
</div>
<div class="figure-caption" style="text-align: center;">
<p><strong>Figure 1:</strong> Four JCOs x 40 hours per week = 160 hours of footage.</p>
</div>
<p>This was replicated across every dorm. Three dorms, for example, would produce nearly 500 hours of footage, as seen below.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://realworlddatascience.net/case-studies/posts/2023/11/16/images/jcos-recording-totals-across-dorms.png" class="img-fluid quarto-figure quarto-figure-center figure-img" alt="A table illustrating working hours over the course of a week for four juvenile correctional officers in each of three dorms in one juvenile correctional facility"></p>
</figure>
</div>
<div class="figure-caption" style="text-align: center;">
<p><strong>Figure 2:</strong> Three dorms x four JCOs x 40 hours per week = 480 hours of footage.</p>
</div>
<p>Finally, we had more than one facility. Four facilities with three dorms each would produce nearly 2,000 hours of footage every week.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://realworlddatascience.net/case-studies/posts/2023/11/16/images/jcos-recording-totals-across-facilities.png" class="img-fluid quarto-figure quarto-figure-center figure-img" alt="A table illustrating working hours over the course of a week for four juvenile correctional officers in each of three dorms in four separate juvenile correctional facilities"></p>
</figure>
</div>
<div class="figure-caption" style="text-align: center;">
<p><strong>Figure 3:</strong> Four facilities x three dorms x four JCOs x 40 hours per week = 1,960 hours of footage.</p>
</div>
<p>In actuality, we had a total of five facilities each with over a dozen dorms producing an anticipated <strong>17,000 hours</strong> of footage every week – an impossible amount to monitor manually.</p>
<p>As a result, footage review had to be done in a limited, reactive manner. If our monitoring team received an incident report, they could easily zero in on the cameras of the officers involved and review the incident accordingly. But our executive team had hoped to be able to use the footage proactively, looking for “red flags” in order to <em>prevent</em> potential abuses instead of only responding to allegations.</p>
<p>Because the agency had no way of automating the monitoring of footage, any proactive analysis had to be metadata-based. But what to look for in the metadata? Once again, the lack of best-practice literature left us in the lurch. So, we brainstormed ideas for “red flags” and came up with the following that could be screened for using camera metadata:</p>
<ol type="1">
<li><p><strong>Minimal quantity of footage</strong> – our camera policy required correctional officers to have their cameras on at all times in the presence of youth. No footage meant they weren’t using their cameras.</p></li>
<li><p><strong>Frequently turning the camera on and off</strong> – a correctional officer working a dorm should have their cameras always on when around youth and not be turning them on and off repeatedly.</p></li>
<li><p><strong>Large gaps between clips</strong> – it defeats the purpose of having cameras if they’re not turned on.</p></li>
</ol>
<p>In addition, we came up with a fourth red flag, which could be screened for by comparing camera metadata with shift-tracking metadata:</p>
<ol start="4" type="1">
<li><strong>Mismatch between clips recorded and shifts worked</strong> – the agency had very recently rolled out a new shift tracking software. We should expect to see the hours logged by the body cameras roughly match the shift hours worked.</li>
</ol>
</section>
<section id="analysis-part-1-quality-control-and-footage-analysis" class="level2">
<h2 class="anchored" data-anchor-id="analysis-part-1-quality-control-and-footage-analysis">Analysis, part 1: Quality control and footage analysis</h2>
<p>For this analysis, I gathered the most recent three weeks of body-worn camera data – which, at the time, covered April 1–21, 2019. I also pulled data from Shifthound (our shift management software) covering the same time period. Finally, I gathered HR data from CAPPS, the system that most of the State of Texas used at the time for personnel management and finance.<sup>1</sup> I then performed some quality control work, summarized in the dropdown box below.</p>
<div class="callout callout-style-simple callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-2-contents" aria-controls="callout-2" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Initial quality control steps
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-2" class="callout-2-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p><code>SkimR</code> is a helpful <code>R</code> package for exploratory analysis that gives summary statistics for every variable in a data frame, including missing values. After using the <code>skim</code> function on clip data, shift data, and HR data, I noticed that the clip data had some missing values for employee ID. This was an error which pointed to data entry mistakes – body-worn cameras do not record footage on their own, after all, so employee IDs should be assigned to each clip.</p>
<p>From here I compared the employee ID field in the clip data to the employee ID field in the HR data. Somewhat surprisingly, IDs existed in the clip data that did not correspond to any entries in the HR data, indicating yet more data entry mistakes – the HR data is the ground truth for all employee IDs. I checked the shift data for the same error – employee IDs that did not exist in the HR data – and found the same problem.</p>
<p>As well as employee IDs that did not exist in the HR data, I also looked for employee IDs in the footage and shift data which related to staff who were not actually employed between April 1–21, 2019. I found some examples of this, which indicated yet more errors: staff cannot use a body-worn camera or log a shift if they have yet to begin working or if they have been terminated (system permissions are revoked upon leaving employment).</p>
<p>I made a list of every erroneous ID to pass off to HR and monitoring staff before excluding them from the subsequent analysis. In total, 10.6% of clips representing 11.3% of total footage had to be excluded due to these initial data quality issues, foreshadowing the subsequent data quality issues the analysis would uncover.</p>
<p>The full analysis script <a href="https://t.ly/BUNRZ">can be found on GitHub</a>.</p>
</div>
</div>
</div>
<p>In order to operationalize the “red flags” from our brainstorming session, I needed to see what exactly the cameras captured in their metadata. The variables most relevant to our purposes were:</p>
<ul>
<li>Clip start</li>
<li>Clip end</li>
<li>Camera used</li>
<li>Who was assigned to the camera at the time</li>
<li>The role of the person assigned to the camera</li>
</ul>
<p>Using these fields, I first created the following <strong>aggregations per employee ID</strong>:</p>
<div>

</div>
<div class="quarto-layout-panel" data-layout-nrow="2">
<div class="quarto-layout-row">
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-left">
<figure class="figure">
<p><img src="https://realworlddatascience.net/case-studies/posts/2023/11/16/images/film.png" class="img-fluid quarto-figure quarto-figure-left figure-img" alt="graphical icon representing a strip of film"></p>
<figcaption><strong>Number of clips</strong> = Number of clips recorded.</figcaption>
</figure>
</div>
</div>
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-left">
<figure class="figure">
<p><img src="https://realworlddatascience.net/case-studies/posts/2023/11/16/images/calendar.png" class="img-fluid quarto-figure quarto-figure-left figure-img" alt="graphical icon representing a calendar"></p>
<figcaption><strong>Days with footage</strong> = Number of discrete dates that appear in these clips.</figcaption>
</figure>
</div>
</div>
</div>
<div class="quarto-layout-row">
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-left">
<figure class="figure">
<p><img src="https://realworlddatascience.net/case-studies/posts/2023/11/16/images/clock.png" class="img-fluid quarto-figure quarto-figure-left figure-img" alt="graphical icon representing a stopwatch"></p>
<figcaption><strong>Footage hours</strong> = Total duration of all shot footage.</figcaption>
</figure>
</div>
</div>
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-left">
<figure class="figure">
<p><img src="https://realworlddatascience.net/case-studies/posts/2023/11/16/images/caution.png" class="img-fluid quarto-figure quarto-figure-left figure-img" alt="graphical icon of an exclamation mark inside a circle"></p>
<figcaption><strong>Significant gaps</strong> = Number of clips where the previous clip’s end date was either greater than 15 minutes or less than eight hours before current clip’s start date.</figcaption>
</figure>
</div>
</div>
</div>
</div>
<p>I used these aggregations to devise the following <strong>staff metrics</strong>:</p>
<div>

</div>
<div class="quarto-layout-panel" data-layout-nrow="2">
<div class="quarto-layout-row">
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-left">
<figure class="figure">
<p><img src="https://realworlddatascience.net/case-studies/posts/2023/11/16/images/clip-per-day.png" class="img-fluid quarto-figure quarto-figure-left figure-img" alt="graphical icons representing a strip of film and a calendar"></p>
<figcaption><strong>Clips per day</strong> = Number of clips / Days with footage.</figcaption>
</figure>
</div>
</div>
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-left">
<figure class="figure">
<p><img src="https://realworlddatascience.net/case-studies/posts/2023/11/16/images/footage-per-day.png" class="img-fluid quarto-figure quarto-figure-left figure-img" alt="graphical icons representing a stopwatch and a calendar"></p>
<figcaption><strong>Footage per day</strong> = Footage hours / Days with footage.</figcaption>
</figure>
</div>
</div>
</div>
<div class="quarto-layout-row">
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-left">
<figure class="figure">
<p><img src="https://realworlddatascience.net/case-studies/posts/2023/11/16/images/avg-clip-length.png" class="img-fluid quarto-figure quarto-figure-left figure-img" alt="graphical icons representing a stopwatch and a strip of film"></p>
<figcaption><strong>Average clip length</strong> = Footage hours / Number of clips.</figcaption>
</figure>
</div>
</div>
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-left">
<figure class="figure">
<p><img src="https://realworlddatascience.net/case-studies/posts/2023/11/16/images/gaps-per-day.png" class="img-fluid quarto-figure quarto-figure-left figure-img" alt="graphical icons of an exclamation mark inside a circle and a calendar"></p>
<figcaption><strong>Gaps per day</strong> = Gaps / Days with footage.</figcaption>
</figure>
</div>
</div>
</div>
</div>
<p>Once I established these metrics for each employee I looked at their respective distributions. Standard staff shift lengths at the time were eight hours. If staff were using their cameras appropriately, we would expect to see distributions centered around clip lengths of about an hour, eight or fewer clips per day, and 8-12 footage hours per day. We would also expect to see 0 large gaps.</p>
<details>
<summary>
Show the code
</summary>
<div class="sourceCode" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb1-1"><span class="in" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">```{r}</span></span>
<span id="cb1-2"><span class="in" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">library(tidyverse)</span></span>
<span id="cb1-3"></span>
<span id="cb1-4"><span class="in" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">Footage_Metrics_by_Employee &lt;- read_csv("Output/Footage Metrics by Employee.csv")</span></span>
<span id="cb1-5"></span>
<span id="cb1-6"><span class="in" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">Footage_Metrics_by_Employee %&gt;% </span></span>
<span id="cb1-7"><span class="in" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">  select(-Clips, -Days_With_Footage, -Footage_Hours, -Gaps) %&gt;% </span></span>
<span id="cb1-8"><span class="in" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">  pivot_longer(-Employee_ID, names_to = "Metric", values_to = "Value") %&gt;% </span></span>
<span id="cb1-9"><span class="in" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">  ggplot(aes(x = Value)) +</span></span>
<span id="cb1-10"><span class="in" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">  geom_histogram() +</span></span>
<span id="cb1-11"><span class="in" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">  facet_wrap(~Metric, scales = "free")</span></span>
<span id="cb1-12"><span class="in" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">```</span></span></code></pre></div>
</details>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://realworlddatascience.net/case-studies/posts/2023/11/16/images/fig-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" alt="Four histograms of key metrics - average clip length, average number of clips per day, average footage hours per day, and average gaps per day."></p>
</figure>
</div>
<p>By eyeballing the distributions I could tell most staff were recording fewer than 10 clips per day, shooting about 0.5–2 hours for each clip, for a total of 2–10 hours of daily footage, with the majority of employees having less than one significant gap per day. Superficially, this appeared to provide evidence of widespread attempts at complying with the body-worn camera policy and no systemic rejection or resistance. If this were indeed the case, then we could turn our attention to individual outliers.</p>
<p>First, though, we thought we would attempt to validate this initial impression by testing another assumption. If each employee works on average 40 hours per week – a substantial underestimate given how common overtime was – we should expect, over a three-week period, to see about 120 hours of footage per employee in the dataset. This is <em>not</em> what we found.</p>
<p>Average footage per employee was 70.2 hours over the three-week period, meaning that the average employee was recording less than 60% of shift hours worked. With so many hours going unrecorded for unknown reasons, we needed to investigate further.</p>
<p>Surely the shift data would clarify this…</p>
</section>
<section id="analysis-part-2-footage-and-shift-comparison" class="level2">
<h2 class="anchored" data-anchor-id="analysis-part-2-footage-and-shift-comparison">Analysis, part 2: Footage and shift comparison</h2>
<p>With the data on shifts worked from our timekeeping system, I could theoretically compare actual shifts worked to the amount of footage recorded. If there were patterns in where the gaps in footage fell, that comparison might help to explain why.</p>
<p>In order to join the shift data to the camera data, I needed a common unit of analysis beyond “Employee ID.” Using only this value would produce a nonsensical table that joined up every clip of footage to every shift worked.</p>
<p>For example, let’s take employee #9001005 at Facility Epsilon between April 1–3. This employee has the following clips recorded during that time period:</p>
<div class="table-responsive">
<table class="table">
<thead>
<tr class="header">
<th style="text-align: left;">Employee_ID</th>
<th style="text-align: left;">Clip_ID</th>
<th style="text-align: left;">Clip_Start</th>
<th style="text-align: left;">Clip_End</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">9001005</td>
<td style="text-align: left;">156421</td>
<td style="text-align: left;">2019-04-01 05:54:34</td>
<td style="text-align: left;">2019-04-01 08:34:34</td>
</tr>
<tr class="even">
<td style="text-align: left;">9001005</td>
<td style="text-align: left;">155093</td>
<td style="text-align: left;">2019-04-01 08:40:59</td>
<td style="text-align: left;">2019-04-01 08:54:51</td>
</tr>
<tr class="odd">
<td style="text-align: left;">9001005</td>
<td style="text-align: left;">151419</td>
<td style="text-align: left;">2019-04-01 09:03:16</td>
<td style="text-align: left;">2019-04-01 11:00:30</td>
</tr>
<tr class="even">
<td style="text-align: left;">9001005</td>
<td style="text-align: left;">153133</td>
<td style="text-align: left;">2019-04-01 11:10:09</td>
<td style="text-align: left;">2019-04-01 12:39:51</td>
</tr>
<tr class="odd">
<td style="text-align: left;">9001005</td>
<td style="text-align: left;">151088</td>
<td style="text-align: left;">2019-04-01 12:57:51</td>
<td style="text-align: left;">2019-04-01 14:06:44</td>
</tr>
<tr class="even">
<td style="text-align: left;">9001005</td>
<td style="text-align: left;">150947</td>
<td style="text-align: left;">2019-04-02 05:56:34</td>
<td style="text-align: left;">2019-04-02 09:48:50</td>
</tr>
<tr class="odd">
<td style="text-align: left;">9001005</td>
<td style="text-align: left;">151699</td>
<td style="text-align: left;">2019-04-02 09:54:23</td>
<td style="text-align: left;">2019-04-02 12:17:15</td>
</tr>
</tbody>
</table>
</div>
<p>We can join this to a similar table of shifts logged. This particular employee had the following shifts scheduled from April 1–3:</p>
<div class="table-responsive">
<table class="table">
<thead>
<tr class="header">
<th style="text-align: left;">Employee_ID</th>
<th style="text-align: left;">Shift_ID</th>
<th style="text-align: left;">Shift_Start</th>
<th style="text-align: left;">Shift_End</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">9001005</td>
<td style="text-align: left;">E050603</td>
<td style="text-align: left;">2019-04-01 06:00:00</td>
<td style="text-align: left;">2019-04-01 14:00:00</td>
</tr>
<tr class="even">
<td style="text-align: left;">9001005</td>
<td style="text-align: left;">E051303</td>
<td style="text-align: left;">2019-04-02 06:00:00</td>
<td style="text-align: left;">2019-04-02 14:00:00</td>
</tr>
</tbody>
</table>
</div>
<p>The table shows two eight-hour morning shifts from 6:00 am to 2:00 pm. We can join the two tables together by ID on a messy many-to-many join, but that tells us nothing about how much they overlap (or fail to overlap) without extensive additional work. For example, we have a unique identifier for employee clip (Clip_ID) and employee shift (Shift_ID), but what we need is a unique identifier that can be used to join the two. Fortunately, for this particular data we can <em>create</em> a unique identifier since both clips and shifts are fundamentally measures of <em>time</em>. While Employee_ID is not in itself unique (i.e., one employee can have multiple clips attached to that ID), Employee_ID combined with time of day is unique. A person can only be in one place at a time, after all!</p>
<p>To reshape the data for joining, I created a function that takes any data frame with a start and end column and unfolds it into discrete units of time. Using the code below to create the “Interval_Convert” function, the shift data above for employee 9001005 converts into one entry per hour of the day per shift. As a result, two eight-hour shifts get turned into 16 employee hours (a sample of which is shown below).</p>
<details>
<summary>
Show the code
</summary>
<div class="sourceCode" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb2-1"><span class="in" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">```{r}</span></span>
<span id="cb2-2"><span class="in" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">library(sqldf)</span></span>
<span id="cb2-3"><span class="in" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">library(lubridate)</span></span>
<span id="cb2-4"></span>
<span id="cb2-5"><span class="in" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">Interval_Convert &lt;- function(DF, Start_Col, End_Col, Int_Unit, Int_Length = 1) {</span></span>
<span id="cb2-6"><span class="in" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">browser()</span></span>
<span id="cb2-7"><span class="in" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">  Start_Col2 &lt;- enquo(Start_Col)</span></span>
<span id="cb2-8"><span class="in" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">  End_Col2 &lt;- enquo(End_Col)</span></span>
<span id="cb2-9"><span class="in" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">  </span></span>
<span id="cb2-10"><span class="in" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">  Start_End &lt;- DF %&gt;%</span></span>
<span id="cb2-11"><span class="in" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    ungroup() %&gt;%</span></span>
<span id="cb2-12"><span class="in" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    summarize(Min_Start = min(!!Start_Col2),</span></span>
<span id="cb2-13"><span class="in" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">              Max_End = max(!!End_Col2)) %&gt;%</span></span>
<span id="cb2-14"><span class="in" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    mutate(Start = floor_date(Min_Start, Int_Unit),</span></span>
<span id="cb2-15"><span class="in" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">           End = ceiling_date(Max_End, Int_Unit))</span></span>
<span id="cb2-16"><span class="in" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">  </span></span>
<span id="cb2-17"><span class="in" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">  DF &lt;- DF %&gt;%</span></span>
<span id="cb2-18"><span class="in" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    mutate(Single = !!Start_Col2 == !!End_Col2)</span></span>
<span id="cb2-19"><span class="in" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">  </span></span>
<span id="cb2-20"><span class="in" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">  Interval_Table &lt;- data.frame(Interval_Start = seq.POSIXt(Start_End$Start[1], Start_End$End[1], by = str_c(Int_Length, " ", Int_Unit))) %&gt;%</span></span>
<span id="cb2-21"><span class="in" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    mutate(Interval_End = lead(Interval_Start)) %&gt;%</span></span>
<span id="cb2-22"><span class="in" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    filter(!is.na(Interval_End))</span></span>
<span id="cb2-23"><span class="in" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">  </span></span>
<span id="cb2-24"><span class="in" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">  by &lt;- join_by(Interval_Start &lt;= !!End_Col2, Interval_End &gt;= !!Start_Col2)  </span></span>
<span id="cb2-25"><span class="in" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">  </span></span>
<span id="cb2-26"><span class="in" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">  Interval_Data_Table &lt;- Interval_Table %&gt;% </span></span>
<span id="cb2-27"><span class="in" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    left_join(DF, by) %&gt;% </span></span>
<span id="cb2-28"><span class="in" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    mutate(Seconds_Duration_Within_Interval = if_else(!!End_Col2 &gt; Interval_End, Interval_End, !!End_Col2) -</span></span>
<span id="cb2-29"><span class="in" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">             if_else(!!Start_Col2 &lt; Interval_Start, Interval_Start, !!Start_Col2)) %&gt;%</span></span>
<span id="cb2-30"><span class="in" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    filter(!(Single &amp; Interval_End == !!Start_Col2),</span></span>
<span id="cb2-31"><span class="in" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">           as.numeric(Seconds_Duration_Within_Interval) &gt; 0)</span></span>
<span id="cb2-32"><span class="in" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">  </span></span>
<span id="cb2-33"><span class="in" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">  return(Interval_Data_Table)</span></span>
<span id="cb2-34"><span class="in" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span></span>
<span id="cb2-35"><span class="in" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">```</span></span></code></pre></div>
</details>
<div class="table-responsive">
<table class="table">
<colgroup>
<col style="width: 13%">
<col style="width: 12%">
<col style="width: 13%">
<col style="width: 9%">
<col style="width: 11%">
<col style="width: 10%">
<col style="width: 29%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">Interval_Start</th>
<th style="text-align: left;">Interval_End</th>
<th style="text-align: left;">Employee_ID</th>
<th style="text-align: left;">Shift_ID</th>
<th style="text-align: left;">Shift_Start</th>
<th style="text-align: left;">Shift_End</th>
<th style="text-align: left;">Seconds_Duration_Within_Interval</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">2019-04-01 06:00:00</td>
<td style="text-align: left;">2019-04-01 07:00:00</td>
<td style="text-align: left;">9001005</td>
<td style="text-align: left;">E050603</td>
<td style="text-align: left;">2019-04-01 06:00:00</td>
<td style="text-align: left;">2019-04-01 14:00:00</td>
<td style="text-align: left;">3600 secs</td>
</tr>
<tr class="even">
<td style="text-align: left;">2019-04-01 07:00:00</td>
<td style="text-align: left;">2019-04-01 08:00:00</td>
<td style="text-align: left;">9001005</td>
<td style="text-align: left;">E050603</td>
<td style="text-align: left;">2019-04-01 06:00:00</td>
<td style="text-align: left;">2019-04-01 14:00:00</td>
<td style="text-align: left;">3600 secs</td>
</tr>
<tr class="odd">
<td style="text-align: left;">2019-04-01 08:00:00</td>
<td style="text-align: left;">2019-04-01 09:00:00</td>
<td style="text-align: left;">9001005</td>
<td style="text-align: left;">E050603</td>
<td style="text-align: left;">2019-04-01 06:00:00</td>
<td style="text-align: left;">2019-04-01 14:00:00</td>
<td style="text-align: left;">3600 secs</td>
</tr>
<tr class="even">
<td style="text-align: left;">2019-04-01 09:00:00</td>
<td style="text-align: left;">2019-04-01 10:00:00</td>
<td style="text-align: left;">9001005</td>
<td style="text-align: left;">E050603</td>
<td style="text-align: left;">2019-04-01 06:00:00</td>
<td style="text-align: left;">2019-04-01 14:00:00</td>
<td style="text-align: left;">3600 secs</td>
</tr>
<tr class="odd">
<td style="text-align: left;">…</td>
<td style="text-align: left;">…</td>
<td style="text-align: left;">…</td>
<td style="text-align: left;">…</td>
<td style="text-align: left;">…</td>
<td style="text-align: left;">…</td>
<td style="text-align: left;">…</td>
</tr>
</tbody>
</table>
</div>
<p>The footage could be converted in a similar manner, and in this way I could break down both the shift data and the clip data into an hour-by-hour view and compare them to one another. Using this new format, I joined together the full tables of footage and shifts to determine how much footage was recorded with no corresponding shift in the timekeeping system.</p>
<div class="table-responsive">
<table class="table">
<colgroup>
<col style="width: 18%">
<col style="width: 34%">
<col style="width: 47%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">HR_Location</th>
<th style="text-align: left;">Footage_Hours_No_Shift</th>
<th style="text-align: left;">Employee_IDs_With_Missing_Shift</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">Alpha</td>
<td style="text-align: left;">1805</td>
<td style="text-align: left;">122</td>
</tr>
<tr class="even">
<td style="text-align: left;">Beta</td>
<td style="text-align: left;">3749</td>
<td style="text-align: left;">114</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Delta</td>
<td style="text-align: left;">1208</td>
<td style="text-align: left;">133</td>
</tr>
<tr class="even">
<td style="text-align: left;">Epsilon</td>
<td style="text-align: left;">2899</td>
<td style="text-align: left;">157</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Gamma</td>
<td style="text-align: left;">4153</td>
<td style="text-align: left;">170</td>
</tr>
</tbody>
</table>
</div>
<p>To summarize what the table is telling us: Almost every employee has footage hours that do not match with logged shifts, totaling nearly 14,000 hours when you add up the Footage_Hours_No_Shift column. But what about the opposite case? How many shift hours were logged with no corresponding footage?</p>
<div class="table-responsive">
<table class="table">
<colgroup>
<col style="width: 18%">
<col style="width: 33%">
<col style="width: 48%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">HR_Location</th>
<th style="text-align: left;">Shift_Hours_No_Footage</th>
<th style="text-align: left;">Employee_IDs_With_Missing_Footage</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">Alpha</td>
<td style="text-align: left;">7338</td>
<td style="text-align: left;">127</td>
</tr>
<tr class="even">
<td style="text-align: left;">Beta</td>
<td style="text-align: left;">6014</td>
<td style="text-align: left;">118</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Delta</td>
<td style="text-align: left;">12830</td>
<td style="text-align: left;">141</td>
</tr>
<tr class="even">
<td style="text-align: left;">Epsilon</td>
<td style="text-align: left;">9000</td>
<td style="text-align: left;">168</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Gamma</td>
<td style="text-align: left;">11960</td>
<td style="text-align: left;">183</td>
</tr>
</tbody>
</table>
</div>
<p>Oh dear. Again, almost every employee has logged shift hours with no footage: 47,000 hours in total. To put it another way, that’s an entire work week per employee not showing up in camera footage.</p>
<p>At this point, we could probably rule out deliberate noncompliance. The clip data already implied that most employees were following the policy, and our facility leadership would surely have noticed a mass refusal large enough to show up this clearly in the data.</p>
<p>One way to check for deliberate noncompliance would be to first exclude shifts that contain zero footage whatsoever. This would rule out total mismatches, where – for whatever reason – the logged shifts had totally failed to overlap with recorded clips. For the remaining shifts that <em>do</em> contain footage, we could look at the proportion of the shift covered by footage. So, if an eight-hour shift had four hours of recorded footage associated with it, then we could say that 50% of the shift had been recorded. The following histogram is a distribution of the number of employees organized by the percent of their shift-hours they recorded (but only shifts that had a nonzero amount of footage).</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://realworlddatascience.net/case-studies/posts/2023/11/16/images/fig-2.png" class="img-fluid quarto-figure quarto-figure-center figure-img" alt="A histogram of average percent of shifts recorded, excluding shifts with no recorded footage."></p>
</figure>
</div>
<p>As it turned out, most employees recorded the majority of their matching shifts, a finding that roughly aligns with the initial clip analysis. So, what explains the 14,000 hours of footage with no shifts, and the 47,000 hours of shifts with no footage?</p>
</section>
<section id="causes-of-failure" class="level2">
<h2 class="anchored" data-anchor-id="causes-of-failure">Causes of failure</h2>
<p>Here, I believed, we had reached the end of what I could do with data alone, and so I presented these findings (or lack thereof) to executive leadership. The failure to gather reliable data from linking the clip data to the shift data prompted follow-ups into what exactly was going wrong. As it turned out, <em>many</em> things were going wrong.</p>
<p>First, a number of technical problems plagued the early rollout of the cameras:</p>
<ul>
<li><p>All of our facilities suffered from high turnover, and camera ownership was not consistently updated. Employees who no longer worked at the agency could therefore appear in the clip data – somebody else had taken over their camera but had not put their name and ID on it.</p></li>
<li><p>We had no way of telling if a camera was not recording due to being docked and recharging or not recording due to being switched off.</p></li>
<li><p>In the early days of the rollout, footage got assigned to an employee based on the owner of the <em>dock</em>, not the camera. In other words, if Employee A had recorded their shift with their camera but uploaded the footage using a dock assigned to Employee B then the footage would show up in the system as belonging to Employee B.</p></li>
</ul>
<p>The shift data was, unsurprisingly, even worse, and it was here we came across our most important finding. While the evidence showed that there wasn’t any widespread non-compliance with the use of the cameras, there <em>was</em> widespread non-compliance with the use of our shift management software. Details are included in the dropdown box below.</p>
<div class="callout callout-style-simple callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-3-contents" aria-controls="callout-3" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Quality issues in shift tracking data
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-3" class="callout-3-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>Our HR system, CAPPS, had a feature that tracked hours worked in order to calculate leave and overtime pay. However, CAPPS was a statewide application designed for 9–5 office workers, and could not capture the irregular working hours of our staff (much less aid in planning future shifts). We had obtained separate shift management software to fill these gaps, but not realized how inconsistently it was being used. All facilities were required to have their employees log their shifts, but some followed through on this better than others. And even for those that did make a good-faith effort at follow-through, quality control was nonexistent.</p>
<p>In CAPPS, time entry determined pay, so strong incentives existed to ensure accurate entry. But for our shift management software, no incentives existed at all for making sure that entries were correct. For example, a correctional officer could have a 40-hour work week scheduled in the shift software but miss the entire week due to an injury, and the software would still show them as having worked 40 hours that week. Nobody bothered to go back and correct these types of errors because there was no reason to.</p>
<p>The software was intended to be used proactively for planning purposes, not after-the-fact for logging and tracking purposes. Thus, it produced data that was totally inconsistent with actual hours worked, which became apparent when compared to data (like body-worn camera footage) that tracked actual hours on the floor.</p>
<p>In the end, we had to rethink a number of aspects of the shift software’s implementation. In the process of these fixes, leadership also came to make explicit that the software’s primary purpose was to help facilities schedule future shifts, not audit hours worked after the fact (which CAPPS already did, just on a day-by-day basis as opposed to an hour-by-hour basis). This analysis was the only time we attempted to use the shift data in this manner.</p>
</div>
</div>
</div>
</section>
<section id="what-we-learned-from-failure" class="level2">
<h2 class="anchored" data-anchor-id="what-we-learned-from-failure">What we learned from failure</h2>
<p>Whatever means we used to monitor compliance with the camera policy, we learned that it couldn’t be fully automated. The agency followed up this analysis with a random sampling approach, in which monitors would randomly select times of day they knew a given staff member would have to have their cameras turned on and actually watch the associated clips. This review process confirmed the first impressions from the statistical review above: most employees <em>were</em> making good faith attempts at complying with the policy despite technical glitches, short-staffing, and administrative confusion. It also confirmed that proactive monitoring of correctional officers was a human process which had to come from supervisors and staff.</p>
<p>The one piece of the analysis we did use going forward was the clip analysis (converted into a Power BI dashboard and included in the <a href="https://github.com/enndubbs/Body-Worn-Camera-Monitoring">GitHub repository</a> for this article), but only as a supplement for already-launched investigations, not a prompt for one. Body-worn camera footage remained immensely useful for investigations after-the-fact, but inconsistencies in clip data were not, in and of themselves, particularly noteworthy “red flags.” At the end of the day, analytics can contextualize and enhance human judgment, but it cannot replace it.</p>
<p>In academia, the bias in favor of positive findings is well-documented. The failure to find something, or a lack of statistical significance, does not lend itself to publication in the same way that a novel discovery does. But, in an applied setting, where results matter more than publication criteria, negative findings can be highly insightful. They can falsify erroneous assumptions, bring unknown problems to light, and prompt the creation of new processes and tools. In this context, a failure is only truly a failure if nothing is learned from it.</p>
<div class="article-btn">
<p><a href="../../../../../case-studies/index.html">Find more case studies</a></p>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-12">
<dl>
<dt>About the author</dt>
<dd>
<strong>Noah Wright</strong> is a data scientist with the Texas Juvenile Justice Department. He is interested in the applications of data science to public policy in the context of real-world constraints, and the ethics thereof (ethics being highly relevant in his line of work). He can be reached on <a href="https://www.linkedin.com/in/noahdwright/">LinkedIn</a>.
</dd>
</dl>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>Copyright and licence</dt>
<dd>
© 2023 Noah Wright
</dd>
</dl>
<p><a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> <img style="height:22px!important;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"></a> This article is licensed under a Creative Commons Attribution 4.0 (CC BY 4.0) <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> International licence</a>.</p>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>How to cite</dt>
<dd>
Wright, Noah. 2023. “Learning from failure: ‘Red flags’ in body-worn camera data.” Real World Data Science, November 16, 2023. <a href="https://realworlddatascience.net/case-studies/posts/2023/11/16/learning-from-failure.html">URL</a>
</dd>
</dl>
</div>
</div>
</div>


</section>


<div id="quarto-appendix" class="default"><section id="footnotes" class="footnotes footnotes-end-of-document"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p>The underlying data for the analysis as presented in this article was requested through the Texas Public Information Act and went through TJJD’s approval process for ensuring anonymity of records. It is available on <a href="https://github.com/enndubbs/Body-Worn-Camera-Monitoring">GitHub</a> along with the rest of the code used to write this article.↩︎</p></li>
</ol>
</section></div> ]]></description>
  <category>Crime and justice</category>
  <category>Public policy</category>
  <category>Data quality</category>
  <category>Data analysis</category>
  <category>Monitoring</category>
  <guid>https://realworlddatascience.net/case-studies/posts/2023/11/16/learning-from-failure.html</guid>
  <pubDate>Thu, 16 Nov 2023 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/case-studies/posts/2023/11/16/images/bodycam-monitor.png" medium="image" type="image/png" height="105" width="144"/>
</item>
<item>
  <title>How to ‘open science’: A brief guide to principles and practices</title>
  <dc:creator>Isabel Sassoon</dc:creator>
  <link>https://realworlddatascience.net/ideas/posts/2023/11/06/how-to-open-science.html</link>
  <description><![CDATA[ 





<p><a href="https://www.fosteropenscience.eu/learning/what-is-open-science/#/id/5ab8ea32dd1827131b90e3ac">Open science</a> is about making your research freely accessible to others. This includes your data, your code and any outputs (such as reports or articles).</p>
<p>Many people in research, or working or studying in higher education, will be familiar with open science as a concept. As a lecturer, I was aware of it and frequently made use of open data for teaching and research, but it was not until it became a requirement from my funder that I took the opportunity to run my own research as open science by design.</p>
<p>Most tools that I was already familiar with could be used to support open science, but I soon realised that there were some steps and planning that I first needed to learn. As I discovered more about the processes and principles of open science, I came to see that making my research open would not require much additional time and effort. However, I felt that a succinct guide to open science would certainly help me – and others – to make the transition more easily. So, I set out to write such a guide.</p>
<p>This is the result! It is not meant to be an exhaustive document. Rather, I will explain the route I took to open science and what options are out there for others looking to follow suit.</p>
<section id="what-is-open-science" class="level2">
<h2 class="anchored" data-anchor-id="what-is-open-science">What is open science?</h2>
<p>“Open science refers to the process of making the content and process of producing evidence and claims transparent and accessible to others” <span class="citation" data-cites="munafo2017manifesto">(Munafò et al. 2017)</span>. The open science principles are:</p>
<dl>
<dt>Open source</dt>
<dd>
Any data, code or output is accessible and usable in software that is freely available and with an open license. What this means in practice is that, for example, when sharing data, the .csv format is used rather than .xlsx, as the latter requires closed source software (Microsoft Excel) to run.
</dd>
<dt>Open data</dt>
<dd>
Research data should be freely accessible. One approach to open data is to adhere to the FAIR Data Principles <span class="citation" data-cites="wilkinson2016fair">(Wilkinson et al. 2016)</span>. FAIR stands for Findable, Accessible, Interoperable, and Reusable, and these principles can be implemented as a step to help make your work open science. However, they are not the only way, nor are they a guarantee that your work will automatically meet the definition of “open science” if you implement them.
</dd>
<dt>Open access</dt>
<dd>
Access to published papers and/or outputs is freely available to all. This can be achieved, for example, by sharing published papers in a pre-print server.
</dd>
</dl>
<div class="callout callout-style-simple callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-1-contents" aria-controls="callout-1" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
What is a pre-print server?
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-1" class="callout-1-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>Pre-print servers are online repositories that enable you to share versions of your manuscript before or while your manuscript is under review. Examples of such repositories include <a href="https://arxiv.org/">ArXiv</a> and <a href="https://www.medrxiv.org/">MedRxiv</a>.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://realworlddatascience.net/ideas/posts/2023/11/06/images/pre-print.png" class="img-fluid quarto-figure quarto-figure-center figure-img" alt="Screengrab of the MedRxiv page for a paper titled 'Why one size fits all is not enough when designing COVID-19 immunity certificates for domestic use: a UK wide cross-sectional online survey.'"></p>
</figure>
</div>
<div class="figure-caption" style="text-align: center;">
<p>Pre-print server example from MedRxiv.</p>
</div>
</div>
</div>
</div>
<p>One additional benefit of open science is that it supports <a href="https://realworlddatascience.net/case-studies/posts/2023/06/15/road-to-reproducible-research.html">reproducible research</a>. This means that others can download your data and code, re-run the analysis, and see if they obtain the same results. To get the full benefit of open science and promote reproducibility, code needs to be written with enough explanations or comments to help others understand the logic of the various stages of an analysis.</p>
</section>
<section id="steps-to-open-science" class="level2">
<h2 class="anchored" data-anchor-id="steps-to-open-science">Steps to open science</h2>
<p>In this section, I will outline steps you can take to easily make your research open science. There will be situations where it is not possible to make all aspects of research open – for example, due to privacy and consent issues related to data. It is still possible to share some elements of such projects, but potentially this involves additional work – to create suitable demo data, say, or generate synthetic data in order to provide data that has comparable trends but preserves privacy. It may also be possible to share the data when it is requested on a case-by-case basis. I am not going to cover this here, but it is worth considering whether open science is possible in each case.</p>
<section id="before-you-begin" class="level3">
<h3 class="anchored" data-anchor-id="before-you-begin">Before you begin…</h3>
<p>Pre-registering an analysis plan for your research helps establish that your research is confirmatory (hypothesis testing) rather than exploratory (hypothesis generating). If you have some hypotheses or research questions that are the foundation of your research, it is worth pre-registering. If your research is exploratory, pre-registration is not necessarily applicable. Although pre-registration in itself is not a requirement for open science, the process of pre-registration can all be completed within repositories such as the Open Science Framework (OSF). Pre-registering your analysis plan will add value and rigour to you research.</p>
<p>If your research doesn’t require pre-registration, jump straight to Step 1.</p>
<div class="callout callout-style-simple callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-2-contents" aria-controls="callout-2" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
What is pre-registration?
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-2" class="callout-2-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>Pre-registration involves completing a form before you start your analysis to explain the primary research questions, the covariates of interest, and the methods you plan to use and why. <span class="citation" data-cites="haroz_2022">Haroz (2022)</span> provides more detail on how apps like OSF, Zenodo and Figshare support pre-registration. <a href="https://www.youtube.com/watch?v=_505Oek-wHM">This video</a> also gives more details.</p>
<p>Below is an example of a pre-registration.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://realworlddatascience.net/ideas/posts/2023/11/06/images/pre-registration.png" class="img-fluid quarto-figure quarto-figure-center figure-img" alt="Screengrab of a pre-registration document, detailing a research project's hypothesis, study type, and study design."></p>
</figure>
</div>
</div>
</div>
</div>
</section>
<section id="step-1" class="level3">
<h3 class="anchored" data-anchor-id="step-1">Step 1</h3>
<p>Does your research plan require you to write a lot of code for analysis purposes, perhaps in collaboration with others? If the answer is <strong>No</strong>, skip to Step 2. If <strong>Yes</strong>:</p>
<ul>
<li>Consider setting up a GitHub repository (or repo), especially if this is a collaborative project and it is likely that more than one person will be working on the code. Don’t forget to invite your collaborators to join the repo!</li>
<li>GitHub repos can be set to private and then made public at the appropriate time, so development work can take place behind closed doors and then released to the wider world when ready.</li>
<li>Ensure that your code is commented properly so that it is reusable and, eventually, your results are reproducible.</li>
</ul>
</section>
<section id="step-2" class="level3">
<h3 class="anchored" data-anchor-id="step-2">Step 2</h3>
<p>GitHub is a great tool for developing code collaboratively, but it may not be right for you – or indeed the only tool to use – if you have a lot of other material to work with and release as part of your research project. If that’s the case:</p>
<ul>
<li><p>Set up an area for your project on an open science repository such as OSF, Zenodo or Figshare. (If you use OSF then setting up an OSF repository is quick and easy – head to <a href="https://osf.io/">osf.io</a>. OSF allows many integrations, including to GitHub, through the use of add-ons.)</p></li>
<li><p>You can start by setting your repository as private and then make it public at the appropriate time.</p></li>
<li><p>Upload all project files, and don’t forget to invite your collaborators.</p></li>
<li><p>Add ORCIDs for every team member.</p></li>
</ul>
<div class="callout callout-style-simple callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-3-contents" aria-controls="callout-3" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
What is an ORCID?
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-3" class="callout-3-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>An ORCID is a persistent digital identifier that you own and control. It allows you to connect your ID with your professional information – affiliations, grants, publications, peer reviews, and more. You can set one up at <a href="https://orcid.org/register">orcid.org</a>.</p>
</div>
</div>
</div>
</section>
<section id="step-3" class="level3">
<h3 class="anchored" data-anchor-id="step-3">Step 3</h3>
<p>If you are ready to submit your research to a journal or conference, consider the following steps before you submit:</p>
<ul>
<li>Check that there is enough information in GitHub (if using) and OSF (if using) about the project. This should include instructions for someone to be able to access your files, use the data and run the code.</li>
<li>Make the GitHub and/or OSF repositories publicly visible.</li>
<li>If submitting to a journal that requires anonymous links, generate them and copy them into the manuscript. (In OSF, for example, it is possible to create anonymous links to your repository in case of double-blind submission requirements.)</li>
<li>Share a copy of your manuscript on a pre-print server – but don’t forget to check the journal or conference policy on pre-prints before you do!</li>
</ul>
<div class="callout callout-style-simple callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-4-contents" aria-controls="callout-4" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Apps and websites to support open science
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-4" class="callout-4-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>This is by no means a complete list but instead features the apps and websites that are commonly used when research projects include data and code.</p>
<section id="open-science-framework-osf" class="level5">
<h5 class="anchored" data-anchor-id="open-science-framework-osf">Open Science Framework (OSF)</h5>
<p>OSF is a free web app that supports researchers with sharing, archiving, registration and collaboration. The <a href="https://help.osf.io">Open Science Framework website</a> is worth checking out and includes a guide to help users get started. Once a project is public in the OSF it will have a DOI and a permanent link, so it can be cited. OSF can also support the tracking of versions of your file. One drawback can be that there is a limit on the maximum size of file that can be uploaded.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://realworlddatascience.net/ideas/posts/2023/11/06/images/osf.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:80.0%" alt="Screengrab of an Open Science Framework repository for a project titled 'Why one size fits all is not enough when designing COVID-19 immunity certificates for domestic use.'"></p>
</figure>
</div>
<div class="figure-caption" style="text-align: center;">
<p>Sample OSF repository.</p>
</div>
</section>
<section id="figshare" class="level5">
<h5 class="anchored" data-anchor-id="figshare">Figshare</h5>
<p>This web app supports storing and sharing research outputs (papers, FAIR data, and non-traditional research outputs). Like OSF, <a href="https://figshare.com">Figshare</a> provides a DOI for your files and is similarly limited in the maximum size of file that can be upload.</p>
</section>
<section id="zenodo" class="level5">
<h5 class="anchored" data-anchor-id="zenodo">Zenodo</h5>
<p>Another general purpose open repository. As with Figshare, <a href="https://zenodo.org">Zenodo</a> also provides a DOI.</p>
</section>
<section id="github" class="level5">
<h5 class="anchored" data-anchor-id="github">GitHub</h5>
<p>GitHub is a web app that offers distributed version control. It is very commonly used for software development, especially when there are multiple developers. Although you can share code and many file types through GitHub, accessing and collaborating on projects can be a daunting experience for those who are not familiar with the way GitHub works. Also, GitHub is not always required as it is possible to share your code through OSF, for example. If you want to know more about using GitHub in support of open science and reproducibility, read <a href="https://realworlddatascience.net/case-studies/posts/2023/06/15/road-to-reproducible-research.html">“The road to reproducible research”</a>.</p>
</section>
</div>
</div>
</div>
</section>
</section>
<section id="example-my-own-route-to-open-science" class="level2">
<h2 class="anchored" data-anchor-id="example-my-own-route-to-open-science">Example: my own route to open science</h2>
<p>In my case, my project did not involve a heavy amount of coding or a large number of researchers, so I opted to use <a href="https://osf.io/jubv6/">OSF</a> to store the ethics approval documents, the survey questions (which drove the data collection), the data in .csv format, and the outputs. I also then linked this to <a href="https://brunel.figshare.com/articles/dataset/Why_one_size_fits_all_is_not_enough_when_designing_COVID-19_immunity_certificates_for_domestic_use_a_UK_wide_cross-sectional_online_survey/16962895">Figshare</a> from my institution and published the article on <a href="https://www.medrxiv.org/content/10.1101/2021.10.12.21264898v2">MedRxiv</a> at the same time as I submitted it to a journal for review. The paper was eventually published in <a href="https://bmjopen.bmj.com/content/12/4/e058317">BMJ Open</a>. The steps I took in this case were sufficient for the work to be recognised as embracing open science principles.</p>
</section>
<section id="plot-your-own-route-to-open-science" class="level2">
<h2 class="anchored" data-anchor-id="plot-your-own-route-to-open-science">Plot your own route to open science</h2>
<div class="cell" data-layout-align="default">
<div class="cell-output-display">
<div>
<p></p><figure class="figure"><p></p>
<div>
<pre class="mermaid mermaid-js">flowchart TD
  D("- Set up GitHub repo
  - Set repo as private
  - Add collaborators")
  F("- Set up an OSF repository
  - Set project as private
  - Add collaborators and their ORCIDs")
  A(Pre-register statistical analysis plan?) -- Yes --&gt; B(Complete pre-registration through, e.g., Open Science Framework) --&gt; C(Does your research involve writing lots of code?) -- Yes --&gt; D --&gt; E(Do you plan to share data and other research material?) -- Yes --&gt; F --&gt; G(Research project is finished and ready to submit to journal or conference)
  A -- No --&gt; C -- No --&gt; E -- No --&gt; G
  G --&gt; H(Have you used repos?) -- Yes --&gt; I(Change repo settings - GitHub and/or OSF - to public) --&gt; J(Does publication permit sharing manuscripts to pre-print servers?) -- Yes --&gt; K(Submit to pre-print server) --&gt; L(Does publication require anonymous link to OSF repo for double-blind review?) -- Yes --&gt; M(Generate anonymous link and add to submission) --&gt; N(Submit your work)
  H -- No --&gt; J -- No --&gt; L -- No --&gt; N
</pre>
</div>
<p></p></figure><p></p>
</div>
</div>
</div>
</section>
<section id="in-summary" class="level2">
<h2 class="anchored" data-anchor-id="in-summary">In summary…</h2>
<p>To make your research open science, you need to:</p>
<ul>
<li>Make any data you collect or generate available to download and reuse.</li>
<li>Pre-register your statistical analysis plan.*</li>
<li>Make your code available for download, and document it clearly so others can reuse it.</li>
<li>Make any supporting material and outputs available for download in formats that are open source.</li>
<li>If publishing to a journal or conference, share manuscripts in a pre-print server.*</li>
</ul>
<div class="figure-caption">
<p>* May not be relevant or applicable, depending on the nature of your work.</p>
</div>
<div class="article-btn">
<p><a href="../../../../../ideas/index.html">Explore more data science ideas</a></p>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-12">
<dl>
<dt>About the author</dt>
<dd>
<p><strong>Isabel Sassoon</strong> is a senior lecturer in computer science and data science at Brunel University London and a member of the <a href="https://realworlddatascience.net/viewpoints/editors-blog/posts/2022/10/18/meet-the-team.html">Real World Data Science editorial board</a>.</p>
</dd>
</dl>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>Copyright and licence</dt>
<dd>
<p>© 2023 Isabel Sassoon</p>
</dd>
</dl>
<p><a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> <img src="https://mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1" style="height:22px!important;vertical-align:text-bottom;"><img src="https://mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1" style="height:22px!important;margin-left:3px;vertical-align:text-bottom;"></a> This article is licensed under a Creative Commons Attribution 4.0 (CC BY 4.0) <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> International licence</a> Thumbnail photo by <a href="https://unsplash.com/@the_photoman?utm_content=creditCopyText&amp;utm_medium=referral&amp;utm_source=unsplash">Basil James</a> on <a href="https://unsplash.com/photos/gray-stainless-steel-padlock-iC4BsZQaREg?utm_content=creditCopyText&amp;utm_medium=referral&amp;utm_source=unsplash">Unsplash</a>.</p>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>How to cite</dt>
<dd>
<p>Sassoon, Isabel. 2023. “How to ‘open science’: A brief guide to principles and practices.” Real World Data Science, November 6, 2023. <a href="https://realworlddatascience.net/ideas/posts/2023/11/06/how-to-open-science.html">URL</a></p>
</dd>
</dl>
</div>
</div>
</div>



</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0">
<div id="ref-haroz_2022" class="csl-entry">
Haroz, Steve. 2022. <span>“Comparison of Preregistration Platforms.”</span> MetaArXiv. <a href="https://doi.org/10.31222/osf.io/zry2u">https://doi.org/10.31222/osf.io/zry2u</a>.
</div>
<div id="ref-munafo2017manifesto" class="csl-entry">
Munafò, Marcus R., Brian A. Nosek, Dorothy V. M. Bishop, Katherine S. Button, Christopher D. Chambers, Nathalie Percie du Sert, Uri Simonsohn, Eric-Jan Wagenmakers, Jennifer J. Ware, and John Ioannidis. 2017. <span>“A Manifesto for Reproducible Science.”</span> <em>Nature Human Behaviour</em> 1 (1): 1–9.
</div>
<div id="ref-wilkinson2016fair" class="csl-entry">
Wilkinson, Mark D., Michel Dumontier, IJsbrand Jan Aalbersberg, Gabrielle Appleton, Myles Axton, Arie Baak, Niklas Blomberg, et al. 2016. <span>“The FAIR Guiding Principles for Scientific Data Management and Stewardship.”</span> <em>Scientific Data</em> 3 (1): 1–9.
</div>
</div></section></div> ]]></description>
  <category>Open science</category>
  <category>Open source</category>
  <category>Open data</category>
  <category>Reproducible research</category>
  <guid>https://realworlddatascience.net/ideas/posts/2023/11/06/how-to-open-science.html</guid>
  <pubDate>Mon, 06 Nov 2023 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/ideas/posts/2023/11/06/images/basil-james-iC4BsZQaREg-unsplash.png" medium="image" type="image/png" height="105" width="144"/>
</item>
<item>
  <title>How data science and statistics can shape the UK’s AI strategy</title>
  <dc:creator>Brian Tarran</dc:creator>
  <link>https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/10/30/ai-conf-panel.html</link>
  <description><![CDATA[ 





<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/7aZrkQIComM?si=7efQPy5m3ZCxe4sg" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<section id="about-the-panelists" class="level2">
<h2 class="anchored" data-anchor-id="about-the-panelists">About the panelists</h2>
<p><strong>Andrew Garrett</strong> (chair) is president of the Royal Statistical Society. He is executive vice president of scientific operations at the clinical research organisation ICON plc, where he is responsible for the strategic direction and operational delivery of a range of clinical trial services. Having worked extensively in the area of rare diseases, he has held various biostatistics managerial positions in the pharmaceutical industry, including vice president of biostatistics, medical writing and regulatory affairs at Quintiles (now IQVIA).</p>
<p><strong>Peter Wells</strong> is a technologist, who accidentally started a second career in public policy. He has both worked on AI policy and helped design AI-enabled services. After 20 years in the telecoms industry, he found himself spending 2014 developing digital government policy for the Labour Party. Since then he has worked with multiple governments and organisations including the Open Data Institute, Projects by IF, Google, Meta and the Government Digital Service.</p>
<p><strong>Maxine Setiawan</strong> is a data scientist specialising in AI and data risk and trusted AI in EY UK&amp;I. She works to help clients from various industries assess and manage risks from analytics and AI systems, and implement AI governance to ensure AI systems are implemented with fair, accountable, and trustworthy principles. She combines her socio-technical background with an MSc in Social Data Science from the University of Oxford, and her experience working in data science within consulting firms.</p>
<p><strong>Sophie Carr</strong> is chair of the <a href="https://realworlddatascience.net/viewpoints/editors-blog/posts/2022/10/18/meet-the-team.html">Real World Data Science editorial board</a> and is the founder and owner of Bays Consulting, a data science company. Having trained as an aeronautical engineer, Sophie completed her PhD in Bayesian analysis part time whilst she worked and, following redundancy, founded her own company. She is the VP for education and statistical literacy at the RSS and sits on the executive committees of the Academy for Mathematical Sciences and the International Centre for Mathematical Sciences. She is also currently <a href="https://ima.org.uk/12382/worlds-most-interesting-mathematician-2019-dr-sophie-carr/">the world’s most interesting mathematician</a>.</p>
<p><strong>Chris Nemeth</strong> is a professor of statistics at Lancaster University. His primary research area is in probabilistic machine learning and computational statistics. He holds an EPSRC-funded Turing AI fellowship on Probabilistic Algorithms for Scalable and Computable Approaches to Learning (PASCAL), and through his fellowship he works closely with partners including Shell, Tesco, Elsevier, Microsoft Research and The Alan Turing Institute. He is chair of the <a href="https://rss.org.uk/membership/rss-groups-and-committees/sections/statistical-computing/">Royal Statistical Society Section on Computational Statistics and Machine Learning</a>.</p>
<p><strong>Karen Tingay</strong> is a principal statistical methodologist at the Office for National Statistics where she specialises in natural language processing and in managing complex survey imputation. She established and heads up the Text Data Subcommunity, a large network of public sector analysts to build capability and best practice guidance in managing and analysing unstructured text data, on behalf of the Government Data Science Community. She sits on several cross-government and international working groups on responsible use of generative AI.</p>
<div class="article-btn">
<p><a href="../../../../../../viewpoints/editors-blog/index.html">Back to Editors’ blog</a></p>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-6">
<dl>
<dt>Copyright and licence</dt>
<dd>
© 2023 Royal Statistical Society
</dd>
</dl>
<p><a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> <img style="height:22px!important;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"></a> This article is licensed under a Creative Commons Attribution 4.0 (CC BY 4.0) <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> International licence</a>.</p>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>How to cite</dt>
<dd>
Tarran, Brian. 2023. “How data science and statistics can shape the UK’s AI strategy.” Real World Data Science, October 30, 2023. <a href="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/10/30/ai-conf-panel.html">URL</a>
</dd>
</dl>
</div>
</div>
</div>


</section>

 ]]></description>
  <category>AI</category>
  <category>Large language models</category>
  <category>Events</category>
  <guid>https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/10/30/ai-conf-panel.html</guid>
  <pubDate>Mon, 30 Oct 2023 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/10/30/images/panel.png" medium="image" type="image/png" height="105" width="144"/>
</item>
<item>
  <title>‘Statistics and data science are at the heart of the AI movement – we want to be a strong voice in the debate’</title>
  <dc:creator>Brian Tarran</dc:creator>
  <link>https://realworlddatascience.net/viewpoints/interviews/posts/2023/10/25/evaluating-ai.html</link>
  <description><![CDATA[ 





<p>Next week, the Royal Statistical Society (RSS) is hosting a panel debate on <a href="https://rss.org.uk/training-events/events/events-2023/rss-events/evaluating-artificial-intelligence-how-data-scienc/#fulleventinfo">“Evaluating artificial intelligence: How data science and statistics can make sense of AI models.”</a> The event forms part of the <a href="https://aifringe.org/">AI Fringe programme of activities</a> and is timed to precede the <a href="https://www.gov.uk/government/publications/ai-safety-summit-introduction">UK government’s AI Safety Summit at Bletchley Park</a>.</p>
<p>RSS president Andrew Garrett is chairing this free, in-person event on 31 October, and he’ll be joined by five panellists to discuss big questions around AI model development, evaluation, risk and benefits:</p>
<ul>
<li>Mihaela van der Schaar, John Humphrey Plummer professor of machine learning, artificial intelligence and medicine at the University of Cambridge and a fellow at The Alan Turing Institute</li>
<li><a href="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/01/27/talking-chatgpt.html">Detlef Nauck</a>, head of AI and data science research, BT</li>
<li><a href="https://realworlddatascience.net/viewpoints/interviews/posts/2023/04/28/stephanie-hare.html">Stephanie Hare</a>, researcher, broadcaster, and author of <em>Technology is Not Neutral</em></li>
<li>Mark Levene, principal scientist, department of data science, National Physical Laboratory</li>
<li><a href="https://realworlddatascience.net/viewpoints/posts/2023/10/20/ai-for-humanity.html">Martin Goodson</a>, chief executive, Evolution AI, and former chair of the RSS Data Science and AI Section</li>
</ul>
<p>We sat down with Andy for a quick-fire Q&amp;A to hear more of what’s in store for next week’s event.</p>
<div class="keyline">
<hr>
</div>
<p><strong>The RSS event takes place one day before the UK government’s AI Safety Summit. Why is it so important for statisticians and data scientists to be involved in the debate over AI safety?</strong><br>
Statistics and data science are at the heart of the AI movement – it’s really a question of taking data and information, and using statistical algorithms to create outputs. That’s at the core of what we do as statisticians and data scientists. Although it’s called AI, it uses mathematical and statistical methods.</p>
<p><strong>The AI Safety Summit focuses on risks posed by certain types of AI systems. Where do you see the biggest risk?</strong><br>
Risk depends upon the purpose and the impact of the AI. It’s very different whether something is being used to inform or recommend or persuade or decide. If it’s a decision-making system, say, there is a bigger risk associated with it if the decision to be made will have an important impact on your life – so, that might be a medical decision or a decision on whether you’re to receive benefits or housing, or how you’re treated in the judicial system. It’s important to understand what the AI is being used for and how much control you have over it, and also how much oversight there is. Will the decision be made solely by an algorithm, or is there human oversight?</p>
<p>There is a particular concern moving forward around misinformation and disinformation. That is a genuine concern, particularly with big elections coming up in the UK and beyond. People are sharing things that they don’t realise are disinformation, so it is really important to understand where the information is coming from, its provenance; that’s incredibly important. We’ve seen with hallucinogenic AI that sometimes there are references given for outputs that don’t actually exist. So we need to constantly scrutinise where information sources are coming from and, if sources are quoted, do they really exist?</p>
<p><strong>The <a href="https://rss.org.uk/RSS/media/File-library/Policy/2023/RSS-AI-white-paper-response-v2-2.pdf">RSS policy response</a> to the UK government’s <a href="https://www.gov.uk/government/publications/ai-regulation-a-pro-innovation-approach/white-paper">AI regulation whitepaper</a> urges investment in a Centre for AI Evaluation Methodology. What informed this recommendation?</strong><br>
The white paper uses the word “proportionate” many, many times. When you talk about safety, inevitably you move into the area of risk, and if you want safety measures to be proportionate, and you want those measures to be based upon risk, then – effectively – you have to understand how you evaluate risk, how you evaluate the probability of something happening, and what the impact might be if it does happen. That naturally lends itself to needing to evaluate both the potential harm but also the potential benefit of using AI. I think the summit is focused more around harm, and the concerns around potential harms, rather than the trade off between harm and benefit. But that was certainly the reason we got into talking about the importance of evaluation, and evaluation is used in other industries where there is high risk. Drug development is an example, as is healthcare, where treatments and new methods are evaluated so that people are informed about both the potential harms and the potential benefits.</p>
<div class="pullquote-container">
<div class="grid">
<div class="g-col-12 g-col-lg-4">
<div class="quarto-figure quarto-figure-left">
<figure class="figure">
<p><img src="https://realworlddatascience.net/viewpoints/interviews/posts/2023/10/25/images/andy-garrett-crop.png" class="img-fluid quarto-figure quarto-figure-left figure-img" alt="Portrait photo of Andrew Garrett"></p>
<figcaption>Andrew Garrett, president, Royal Statistical Society</figcaption>
</figure>
</div>
</div>
<div class="g-col-12 g-col-lg-8 pullquote-grid pullquote">
<p><img src="https://realworlddatascience.net/images/pullquote-purple.png" class="img-fluid" width="50"></p>
<p>We have a really important role to play in focusing attention not only on AI outputs but on inputs. That is an area that hasn’t received enough attention but it is one that statisticians understand incredibly well.</p>
</div>
</div>
</div>
<p><strong>A lot of the focus of the AI debate is on outputs. Should we be talking more about inputs – the data the models are trained on, where the data is coming from, and issues of quality and bias, etc.?</strong><br>
There should be more discussion of this, yes. Statisticians and data scientists, but statisticians in particular, are trained very much around the data generating process, so we naturally think about how data is gathered, the potential biases in a dataset, and the representation that you need for a study. We understand that the data going in is as important as the outputs produced. And I think it’s becoming more and more necessary to understand where exactly the data is coming from, whether it’s diverse, whether it’s representative of the populations you want to study, and so on. This is an incredibly important area, and provenance of data – like provenance of information – will become ever more important. So, with a large language model, for example, what information is it trained on? Did the developers have permission to use that information? How representative is that information? These sorts of questions need to be addressed, because your outputs will only ever be as good as your inputs.</p>
<p><strong>AI systems are having wide-reaching effects across society. What impact are AI tools having on the work of statisticians and data scientists, and how would you evaluate the impacts so far: good, bad, or neutral?</strong><br>
You have to be a cynic and an evangelist at the same time. There is some very good work being done but also some very naive work. AI is not magic. It requires the same thoroughness and lifecycle management as anything else. Certainly in terms of pattern recognition, image recognition, it’s been very useful. On MRI images, for example, can you reduce the amount of time humans need to spend looking at the data because you have an AI tool helping with the assessment? Of course, the challenge is then, when you have an AI assessment, what do you compare it to? You could compare it to what an expert would assess, but is that a suitable reference point for saying something is a good system, knowing that humans themselves are not perfect? AI systems are able to handle large datasets, large images, very quickly. And so the speed of being able to do that has a potential advantage, although it depends on the level of human oversight. Where we’re seeing these tools being advantageous, I think, is where you have some human oversight but some of the heavy lifting is being done by the AI systems.</p>
<p><strong>What do you hope will emerge from the panel debate at the RSS next week? Reaching consensus on such a big, broad topic is unlikely, perhaps, but what are the kinds of things that you’re hoping to learn and take away from the discussion?</strong><br>
We’ve got some very good practitioners on the panel, and I’m hoping that we’ll generate some really good discussion from the panel and some really good questions from the audience. When it comes to the AI conversation generally, there’s a danger that it has focused too much so far on either the academic view of things or the large tech company perspective, so we’re probably missing out a whole tranche of people who are working at the coalface on these things, working in smaller companies. So, I’d like to understand a little bit more about what is happening in that part of industry. I know there’s a big focus on things like building out capability in the UK, and that’s not simply a question of having people with expertise – it’s about having access to things like the right sort of computing environments. So, I think there’s going to be some interesting discussion around what’s holding back industry. Overall, though, what I’d like to see come out of this meeting is a more proportionate response, from people who are working on this on a day-to-day basis. Statisticians are good at that – at coming up with a measured response, an informed response. Do we have the same concerns about the existential threat of AI that have been discussed by some of the larger companies, for example?</p>
<p><strong>Aside from coming along and contributing to this panel discussion, how else can statisticians and data scientists engage with the AI debate and help shape a collective response to this major issue?</strong><br>
I’d certainly encourage them to join the RSS and be a part of our work on this. We want to be a strong voice in the debate on AI because it is underpinned by statistical and mathematical techniques, as I mentioned at the start. We have a really important role to play in focusing attention not only on AI outputs but on inputs. That is an area that hasn’t received enough attention but it is one that statisticians understand incredibly well – and it’s one that brings into discussion issues such as ethics, consent, copyright, etc., and that’s very much where we should be engaging as well.</p>
<div class="callout callout-style-simple callout-note">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-body-container">
<p>Register now for <a href="https://rss.org.uk/training-events/events/events-2023/rss-events/evaluating-artificial-intelligence-how-data-scienc/#fulleventinfo">“Evaluating artificial intelligence: How data science and statistics can make sense of AI models,”</a> a free, in-person debate at the RSS offices in London, 4 pm – 6 pm, Tuesday, October 31.</p>
</div>
</div>
</div>
<div class="article-btn">
<p><a href="../../../../../../viewpoints/interviews/index.html">Find more Interviews</a></p>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-6">
<dl>
<dt>Copyright and licence</dt>
<dd>
© 2023 Royal Statistical Society
</dd>
</dl>
<p><a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> <img style="height:22px!important;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"></a> This article is licensed under a Creative Commons Attribution 4.0 (CC BY 4.0) <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> International licence</a>.</p>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>How to cite</dt>
<dd>
Tarran, Brian. 2023. “‘Statistics and data science are at the heart of the AI movement – we want to be a strong voice in the debate.’” Real World Data Science, October 25, 2023. <a href="https://realworlddatascience.net/viewpoints/interviews/posts/2023/10/25/evaluating-ai.html">URL</a>
</dd>
</dl>
</div>
</div>
</div>



 ]]></description>
  <category>AI</category>
  <category>Events</category>
  <category>Algorithms</category>
  <category>Risk</category>
  <guid>https://realworlddatascience.net/viewpoints/interviews/posts/2023/10/25/evaluating-ai.html</guid>
  <pubDate>Wed, 25 Oct 2023 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/viewpoints/interviews/posts/2023/10/25/images/andy-garrett.png" medium="image" type="image/png" height="105" width="144"/>
</item>
<item>
  <title>An AI for humanity</title>
  <dc:creator>Martin Goodson</dc:creator>
  <link>https://realworlddatascience.net/viewpoints/posts/2023/10/20/ai-for-humanity.html</link>
  <description><![CDATA[ 





<div class="callout callout-style-simple callout-note" style="margin-top: 0;">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-body-container">
<p>This is the text of a talk Martin Goodson gave to the European Commission in Brussels on October 10, 2023. It is republished with permission from the <a href="https://rssdsaisection.substack.com/p/an-ai-for-humanity">Royal Statistical Society Data Science and AI Section Newsletter Substack</a>. The views expressed are the author’s own and do not necessarily represent those of the RSS.</p>
</div>
</div>
</div>
<p>For years academics have published studies about the limits of automation by AI, suggesting that jobs requiring creativity were the least susceptible to automation. That <a href="https://www.businessinsider.com/lost-job-chatgpt-made-me-obsolete-copywriter-2023-7?r=US&amp;IR=T">turned</a>. <a href="https://www.washingtonpost.com/technology/2023/06/02/ai-taking-jobs/">out</a>. <a href="https://www.theguardian.com/film/2023/aug/21/ai-jobs-hollywood-writers-actors-strike">well</a>.</p>
<p>Actually, that’s not completely true: some said that jobs that need a long period of education, like teaching and healthcare, were going to be the hardest of all to automate. <a href="https://www.khanacademy.org/khan-labs">Oh</a>. <a href="https://www.microsoft.com/en-us/research/uploads/prod/2023/03/GPT-4_medical_benchmarks.pdf">dear</a>.</p>
<p>Let’s face it, all predictions about the limits of AI have been hopelessly wrong. Maybe we need to accept that there aren’t going to be any limits. How is this going to affect our society?</p>
<p>Studies came out from <a href="https://www.nber.org/papers/w31161">Stanford</a> and <a href="https://www.science.org/doi/10.1126/science.adh2586">MIT</a> this year, looking at the potential of AI assistants to improve the productivity of office workers. Both came to the same conclusion – that the workers with the lowest ability and least experience were the ones who gained the most in productivity.</p>
<p>In other words, AI has made human knowledge and experience less valuable.</p>
<p>Researchers at Microsoft and Open AI <a href="https://arxiv.org/abs/2303.13375">wrote</a> something important on this phenomenon that I’d like to quote in full:</p>
<blockquote class="blockquote">
<p>Large swaths of modern society are predicated on a “grand bargain” in which professional classes invest years or even decades in technical education and training and are [afforded] the exclusive right to practice in their field, social prestige, and above-average compensation.</p>
<p>Technical disruption of this social contract can have implications not only for the medical field but for numerous other knowledge-intensive professions including law, banking, engineering, accounting, and others.</p>
</blockquote>
<p>Let’s talk about the fairness of this. Because the AI models didn’t invent medicine, accountancy or engineering. They didn’t learn anything directly from the world – human experts taught AI models how to do these things. And they [the human experts] did it without giving their permission, or even knowing that it was happening.</p>
<p>The large tech companies have sucked up all of human knowledge and culture and now provide access to it for the price of an API call. This is a huge transfer of power and value from humanity to the tech companies.</p>
<p>Biologists in the 1990s found themselves in a very similar position. Celera Genomics was trying to achieve commercial control over the human genome. To stop this happening, the publicly funded Human Genome Project (HGP) resolved to sequence the human genome and release the data for free on a daily basis, before Celera could patent any of it.</p>
<p>The HGP was criticised because of ethical concerns (including concerns about eugenics), and because it was thought to be a huge waste of money. The media attacked it, claiming that a publicly funded initiative could not possibly compete with the commercial sector. Fortunately for humanity, a group of scientists with a vision worked together to make it a success.</p>
<p>And it was a huge success: in purely economic terms it produced nearly $1 trillion in economic impacts for investment of about $4 billion. Apart from the economics, the Human Genome Project accelerated development of the genomic technologies that underlie things like mRNA vaccine technology.</p>
<p>The parallels to our current situation with AI are striking. With OpenAI, just like Celera, we have a commercial enterprise that launched with an open approach to data sharing but eventually changed to a more closed model.</p>
<p>We have commentators suggesting that a publicly funded project to create an open-source AI would be ethically dubious, a waste of money and beyond the competency of the public sector. Where the analogy breaks down is that unlike in the 1990s, we do not have any strong voices arguing on the other side, for openness and the creation of shared AI models for all humanity.</p>
<p>Public funding is needed for an “AI for humanity” project, modelled on the Human Genome Project. How else can we ensure the benefits of AI are spread widely across the global population and not concentrated in the hands of one or two all-powerful technology companies?</p>
<p>We’ll never know what the world would have looked like if we’d let Celera gain control over the human genome. Do we want to know a world where we let technology companies gain total control over artificial intelligence?</p>
<section id="faq" class="level2">
<h2 class="anchored" data-anchor-id="faq">FAQ</h2>
<section id="how-about-all-the-ethical-considerations-around-ai-shouldnt-we-consider-this-before-releasing-any-open-source-models" class="level5">
<h5 class="anchored" data-anchor-id="how-about-all-the-ethical-considerations-around-ai-shouldnt-we-consider-this-before-releasing-any-open-source-models">How about all the ethical considerations around AI – shouldn’t we consider this before releasing any open-source models?</h5>
<p>Of course. Obviously, there are ethical implications that need to be considered carefully, just as there were for the genome project. At the start of that project, the ethical, legal, and social issues (or ELSI) program was set up. The National Institutes of Health (NIH) devoted about 5% of their total Human Genome Project budgets to the ELSI program and it is now the largest bioethics program in the world. All important ethical issues were considered carefully and resolved without drama.</p>
</section>
<section id="arent-there-enough-community-efforts-to-build-open-source-ai-models-already" class="level5">
<h5 class="anchored" data-anchor-id="arent-there-enough-community-efforts-to-build-open-source-ai-models-already">Aren’t there enough community efforts to build open-source AI models already?</h5>
<p>There are good projects producing open-source large language models, like Llama 2 from Meta and Falcon from the TII in the United Arab Emirates. These are not quite as powerful as [Open AI’s] GPT-4 but they prove the concept that open-source models can approach the capabilities of the front-running commercial models; even when produced by a single well-funded lab (and a state-funded lab in the case of the TII). A coordinated international publicly funded project will be needed to surpass commercial models in performance.</p>
<p>In any case, do we want to be dependent on the whims of the famously civic-minded Mark Zuckerberg [CEO of Meta] for access to open-source AI models? We shouldn’t forget that the original Llama model was released with a restrictive licence that was eventually changed to something more open after a community outcry. We are lucky they made this decision. But the future of our societies needs to rely on more than luck.</p>
</section>
<section id="how-about-the-uk-government-ai-safety-summit-and-ai-safety-institute-wont-they-be-doing-similar-work" class="level5">
<h5 class="anchored" data-anchor-id="how-about-the-uk-government-ai-safety-summit-and-ai-safety-institute-wont-they-be-doing-similar-work">How about the UK Government AI Safety Summit and AI Safety Institute – won’t they be doing similar work?</h5>
<p>Absolutely not! The limit of the UK Government’s ambition seems to be to set the UK up as a sort of <a href="https://www.politico.eu/article/uk-pitch-ai-safety-institute-rishi-sunak/">evaluation and testing</a> station for AI models made in Silicon Valley. This is as far from the spirit of the Human Genome Project as it’s possible to be.</p>
<p>Sir John Sulston, the leader of the HGP in the UK, was a Nobel Prize-winning scientific hero who wanted to stop Celera Genomics from gaining monopolistic control over the human genome at all costs. The current UK ambition would be like reducing the Human Genome Project to merely testing Celera Genomics’ data for errors.</p>
</section>
<section id="how-will-an-international-ai-for-humanity-project-avoid-the-devaluation-of-human-knowledge-and-experience-and-consequent-job-losses" class="level5">
<h5 class="anchored" data-anchor-id="how-will-an-international-ai-for-humanity-project-avoid-the-devaluation-of-human-knowledge-and-experience-and-consequent-job-losses">How will an international ‘AI for humanity’ project avoid the devaluation of human knowledge and experience, and consequent job losses?</h5>
<p>It may not be possible to avoid this. But governments will at least be able to mitigate societal disruption if they can redistribute some of the wealth gained via AI (e.g., via universal basic income). They will not be able to do this if all of the wealth accrues to only one or two technology companies based in Silicon Valley.</p>
</section>
<section id="how-about-existential-risk" class="level5">
<h5 class="anchored" data-anchor-id="how-about-existential-risk">How about existential risk?</h5>
<p>‘Existential risk’ is a science fiction smokescreen generated by large tech companies to distract from the real issues. I cannot think of a better response than the words of Prof <a href="https://www.independent.co.uk/tech/rishi-sunak-university-of-oxford-san-francisco-government-people-b2349105.html">Sandra Wachter</a> at the University of Oxford: “Let’s focus on people’s jobs being replaced. These things are being completely sidelined by the Terminator scenario.”</p>
<div class="callout callout-style-simple callout-note">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-body-container">
<p>Martin Goodson will be speaking live at the Royal Statistical Society on October 31, 2023, as part of a panel discussion on “Evaluating artificial intelligence: How data science and statistics can make sense of AI models.” <a href="https://rss.org.uk/training-events/events/events-2023/rss-events/evaluating-artificial-intelligence-how-data-scienc/#fulleventinfo">Register now</a> for this free in-person debate. The event forms part of the <a href="https://aifringe.org/">AI Fringe</a> programme of activities, which runs alongside the UK Government’s <a href="https://www.gov.uk/government/topical-events/ai-safety-summit-2023">AI Safety Summit</a> (1–2 November).</p>
</div>
</div>
</div>
<div class="article-btn">
<p><a href="../../../../../viewpoints/index.html">Discover more Viewpoints</a></p>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-12">
<dl>
<dt>About the author</dt>
<dd>
<strong>Martin Goodson</strong> is the former chair of the <a href="https://rss.org.uk/membership/rss-groups-and-committees/sections/data-science-section/">RSS Data Science and AI Section</a> (2019–2022). He is the organiser of the <a href="https://www.meetup.com/london-machine-learning-meetup/">London Machine Learning Meetup</a>, the largest network of AI practitioners in Europe, with over 11,000 members. He is also the CEO of AI startup, <a href="https://www.evolution.ai/">Evolution AI</a>.
</dd>
</dl>
</div>
<div class="g-col-12 g-col-md-12">
<dl>
<dt>Copyright and licence</dt>
<dd>
© 2023 Martin Goodson
</dd>
</dl>
<p>Thumbnail image by <a href="https://unsplash.com/@etiennegirardet?utm_content=creditCopyText&amp;utm_medium=referral&amp;utm_source=unsplash">Etienne Girardet</a> on <a href="https://unsplash.com/photos/a-red-wall-with-a-white-sticker-on-it-_HO6LmpGDl8?utm_content=creditCopyText&amp;utm_medium=referral&amp;utm_source=unsplash">Unsplash</a>.</p>
</div>
</div>
</div>


</section>
</section>

 ]]></description>
  <category>AI</category>
  <category>Open source</category>
  <guid>https://realworlddatascience.net/viewpoints/posts/2023/10/20/ai-for-humanity.html</guid>
  <pubDate>Fri, 20 Oct 2023 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/viewpoints/posts/2023/10/20/images/etienne-girardet-_HO6LmpGDl8-unsplash.png" medium="image" type="image/png" height="105" width="144"/>
</item>
<item>
  <title>‘Feelings about sharing data can be context and time dependent – you can’t just do one survey or focus group’</title>
  <dc:creator>Brian Tarran</dc:creator>
  <link>https://realworlddatascience.net/viewpoints/interviews/posts/2023/10/16/data-sharing-in-gov.html</link>
  <description><![CDATA[ 





<p>This summer, the UK Office for Statistics Regulation (OSR) published its report on <a href="https://osr.statisticsauthority.gov.uk/publication/data-sharing-and-linkage-for-the-public-good/">Data Sharing and Linkage for the Public Good</a>. In the report, the OSR notes that the value of sharing and linking data has become widely recognised within government, though there remain areas of challenge and uncertainties about “the public’s attitude to, and confidence in, data sharing.”</p>
<p>The report also warns that “unless significant changes are implemented… progress that has been made could be lost and the potential for data sharing and linkage to deliver public good will not be achieved.”</p>
<p>To find out more about the report and its recommendations for change, we sat down with Helen Miller-Bakewell, OSR’s head of development and impact. Listen to the full interview below or on YouTube.</p>
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/72eqvS34n7c?si=tzoiivVk-m4su1aT" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<section id="transcript" class="level2">
<h2 class="anchored" data-anchor-id="transcript">Transcript</h2>
<div class="callout callout-style-simple callout-warning" style="margin-top: 0.75rem;">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-body-container">
<p>This transcript has been produced using <a href="https://otter.ai/">speech-to-text transcription software</a>. It has been only lightly edited to correct mistranscriptions and remove some repetitions.</p>
</div>
</div>
</div>
<p><strong>Brian Tarran</strong><br>
Hello, I’m Brian Tarran, editor of realworlddatascience.net. And welcome to another Real World Data Science interview. Today I’m speaking with Helen Miller-Bakewell of the Office for Statistics Regulation. And we’re talking about the Office’s July 2023 report, Data Sharing and Linkage for the Public Good. In this report, the OSR reviews progress that has been made towards sharing and linking data for the public good. It says that the value of sharing and linking data has become widely recognised within government, though there remain areas of challenge and uncertainties about, quote, the public’s attitude to and confidence in data sharing. The report warns that quote, unless significant changes are implemented, the OSR is concerned that progress that has been made could be lost and the potential for data sharing and linkage to deliver public good will not be achieved. In my interview with Helen, we talk about some of the key highlights and findings of the report some of its main recommendations, some examples of data sharing and linkage that are going on now within government. So let’s hand over now to Helen, who will begin by introducing herself, her role within OSR and some of the background to the report.</p>
<p><strong>Helen Miller-Bakewell</strong><br>
So I’m Helen, Helen Miller-Bakewell, I have an official title of head of development and impact within OSR. OSR as a whole, our kind of formal job is to regulate statistics produced by government, we are the regulatory arm of the UK Statistics Authority. And our aim is to work towards statistics that serves the public good, and a government that produces and uses statistics analysis in a way that means the public can feel confident in them, and the analysis that that’s done and how they’re used. Within OSR, I used to be a regulator of statistics, I was out there looking at official statistics on crime and security, holding them up against our code of practice for statistics, which sets the standards that we would like to see government statistics meet. In my role now I actually oversee a few of our cross organisation functions, that all are designed to try and improve the way that OSR as a whole works, and to do work that can support the statistical system as a whole. And the most relevant one for today is the data and methods function. And a key piece of work that that function has been working on for the last year is looking at how data sharing and linkage is done across government, and that supports one of OSR’s wider interests and ambitions. One of our ambitions for the current five years is to make greater data available in a secure way for research and evaluation. That’s what this report that we’re going to be talking about has contributed to.</p>
<p><strong>Brian Tarran</strong><br>
Before we get stuck into the report, maybe it’s worth setting out what does OSR mean when it’s talking about data sharing and linkage? What’s the driver for this being a kind of a priority, something that OSR wants to encourage and to see happen? What are the public benefits that you hope to accrue from it?</p>
<p><strong>Helen Miller-Bakewell</strong><br>
The general premise that’s underpinned the report, and the reason that we have been a champion and advocate for date sharing and linkage for a while, is that we think data can be more powerful when it’s linked, and when it’s made accessible, in a secure way, to a wider audience for analysis. And it can offer more insights and better fulfil its potential to serve the public goods. And again, I keep saying serve the public goods. Within OSR, we very much think that statistics analysis, it shouldn’t just be for government, for decision makers in government, it should be available to the public, to all stakeholders, really, who wants to use it to make decisions hold government to account.</p>
<p><strong>Brian Tarran</strong><br>
So for people reading this or listening to this, who haven’t yet had a chance to dig into the report – and it’s very interesting report – what are the key messages that you want to share with people? What is the, I guess, what’s the assessment of the current state of data sharing and linkage?</p>
<p><strong>Helen Miller-Bakewell</strong><br>
I think some of the key messages do echo what other reports have said in this space, which is that there really has been some excellent progress in terms of data sharing and data linkage. We last reported on data sharing and linkage back in 2018 and 2019, when the DA was kind of coming into force and things were starting to move slowly.</p>
<p><strong>Brian Tarran</strong><br>
Sorry to interrupt you. But what is the DEA did you say?</p>
<p><strong>Helen Miller-Bakewell</strong><br>
It’s the Digital Economy Act. So there was some amendments to the DEA, it created new, new powers to enable greater sharing of data for research and statistics, and it put the Office for National Statistics at the centre of those powers. It kind of gave ONS greater powers to ask other departments across the government to share data with them for research and statistical purposes. And the UK Statistics Authority as well have powers to accredit researcher and accredit processing environments so that people can have access to more data as well across governments.</p>
<p><strong>Brian Tarran</strong><br>
So your last report was in 2018, 2019 time. There’s been good progress, you say, since then. I wanted to ask you about some good examples of data linkage that you’ve seen in that time. Maybe the obvious one is Covid, I’m guessing. The pandemic, that offered a lot of opportunities for linking different datasets together. But are there– is that it? Or are there others that you want to highlight?</p>
<p><strong>Helen Miller-Bakewell</strong><br>
I think the pandemic definitely provided a really strong impetus to share data, to link data. And I think, you know, we saw things done which hadn’t been possible previously, it broke down barriers, and was a kind of an excellent enabler, which is fantastic, because it was a crisis situation. And actually, yes, one of the examples that I would highlight, and I know others in OSR would highlight that was doing Covid, was Office for National Statistics estimates of Covid-19 mortality rates among different ethnic groups, and that drew on census data, it drew on death registration data at your on hospital episode statistics, it drew on data from lots of different places to create some really, really important analysis. It’s exciting to be able to say now that there are good examples of data sharing and linkage across different topic areas and different organisations. And I think if you spoke to regulators in OSR working in different domains, they will each have like their favourite examples of, of data sharing and linkage. Having worked in crime and security regulation myself, the one that comes straight to mind is Data First, which is data linkage project led by Ministry of Justice, working with ADR UK – another one, I don’t have to say full often, Administrative Data Research UK – and that’s done a fantastic job of kind of opening up access again, in a secure way, a real focus on security, to a wealth of data from across MOJ systems, sometimes horrible, clunky legacy systems – I hope none won’t be offended if I say that – but making it valuable because people can, you know, to a greater extent now link it and link it to data from other departments as well.</p>
<p>I did ask a couple of colleagues if they wanted to throw me any other examples of data sharing and linkage that they particularly think highly of, and another one that came up was the Registration and Population Interaction Database, RAPID database, which has been created by DWP [Department for Work and Pensions]. And that provides that brings together data, information from DWP, HMRC [His Majesty’s Revenue &amp; Customs] and local authorities to try and give a view of citizens’ interactions across the breadth of DWP services. What the report does say is, although we have these good examples, there are still barriers and challenges to doing data sharing and linkage. And that, that can, can be true across the whole process, right from getting support for the idea, through the practical steps of finding out what data is available, where, who owns it, how you can get to it, and then actually doing the linkage bit technically at the end. So we’ve been in a situation where things definitely have improved. But it’s, in many cases, it is not easy or efficient yet to share or link data. Our report talks about different barriers we heard about during the course of interviews with stakeholders, that we’ve encountered through our regulatory work as well. And we make 16 – to be precise – recommendations for how we could, or how government could, could start to chip away at those to, to improve the situation going forward.</p>
<p><strong>Brian Tarran</strong><br>
Yeah, and I would like to talk about some of those recommendations, I guess the more technical side of the recommendations, a bit, a bit later. One thing I wanted to ask you now about was about a word that sort of jumped out at me in, in the report was this idea of needing there to be a social licence for data sharing. And in the report, social licence has, has been defined as the, like, the level of acceptance or approval in local communities for data linkage projects. Now, I guess for something like the pandemic, right, you can argue that there is a kind of an implicit social licence, it was an emergency situation, there was, you know, people at risk. So that sort of use case was kind of justified, but I was curious about how social licences for these things can best be established and, and maintained, because that’s about kind of interaction with the public, right? You know, you could put a load of government statisticians and data scientists into a room and say, what could you do with this, all this data and how you could, could you link it all together? And they’d get very excited about it? But actually, then, how do you then take that to the public and convince them that it’s a good idea, or are there other ways of making sure this social licence has been obtained?</p>
<p><strong>Helen Miller-Bakewell</strong><br>
So, social licence and public engagement were one of the topics that was good, most consistently mentioned across the interview– interviews we held. And yeah, there just seemed to be a consensus which we would support that those working on data sharing and linkage should be prioritising public engagement around their work, both to kind of gauge the amount of social licence that there might be, or any sticking points, and potentially start to build social licence as well. And I think, you know, it’s really great to see people thinking like that, and I would actually say as well, it seems to be a recurring theme. And it’s really nice to see that having prominence. Another finding from the interviews was, you know, the flip side of this, yes, people think it’s important, but often people can not quite know how to approach public engagement, building social licence. And there are actually a few examples we highlight in the report where we, where we think public engagement has been done, done well, hopefully, to kind of inspire people. I would say, you know, I have a few kind of overarching thoughts on what can be important. And I think it, it comes so much to trust and trustworthiness. And I think the way, some ways that you can support trust with the public are transparency, saying what you’re going to do and why, and how, and actually the outcomes as well, when possible, let’s sit closing the circle. Thinking about this interview, I remembered OSR ran a public dialogue last year with ADR UK. And we were trying to talk to members of the public about what they understand by the public good of statistics and data. And one of the messages that came up there was people want to feel the impact their data and feel that outcome. And they don’t always feel they get that knowledge back. Like, what, what was, so what was the outcome of you having my data and doing these things that you kind of said you would do? So yeah, transparency, and then kind of linked to that, I guess, like continuous engagement, and considered engagement. And the public is not a homogenous group, there will be different groups that are important to engage for different data sharing, different data linkage projects, and you kind of need to consider who are the people you need to really engage with for your specific initiatives. And then it’s, I’m afraid you can’t just do one survey or one focus group, there needs to be some kind of mechanism for getting more continuous engagement to keep an eye on actually, how are people feeling now, because we know that social licence and people’s feelings about sharing data, it can be context dependent, it can be time dependent. And actually the first couple of recommendations in the report, so right there at one and two, number one is about the value of trackers like CDEI’s [Centre for Data Ethics and Innovation] Public Attitudes Survey, which, you know, are run on a semi-regular basis to try and track how the public are feeling at a high level about questions around data. And then our second recommendation is about having an organisation that can do more to produce guidance and support people doing research to do public engagement well.</p>
<p><strong>Brian Tarran</strong><br>
Does the mission statement of statistics for the public good, does that kind of help guide the approach, right? So any data linkage, data sharing project, you need to understand, you need to think about okay, what’s the public good that we’re trying to achieve here? And then that becomes your, almost the point, the focal point of the discussion with the public about why we want to do this and why we think there’ll be a benefit.</p>
<p><strong>Helen Miller-Bakewell</strong><br>
Absolutely. This focus on the public good is what we always come back to in, in OSR. And again, it is something that can sometimes slightly differentiate us from other organisations in this space where there may be a very internal government focus. Yeah, absolutely. What’s the outcome that’s seeking to be achieved? And will we achieve it? Did we achieve it?</p>
<p><strong>Brian Tarran</strong><br>
One of the parts of the report that I was quite interested in was the four future scenarios. The task you set yourself was to look five years from, from now at where we might be, and I guess give a range of, like, scenarios in which data linkage is great, and everyone’s doing it and it’s fully supported, down to it’s, you know, it’s happening on a piecemeal basis or not at all. So what I wanted to understand was, how those scena– whether any of those scenarios are more likely than others to emerge, and whether the kind of likelihood of those scenarios emerging are dependent on certain of your recommendations.</p>
<p><strong>Helen Miller-Bakewell</strong><br>
The scenarios just allowed us to explore in a theoretical way, like, yeah, where, where could we end up? We hope the 16 recommendations we’ve made, taken together, if they could all be fully delivered, could lead us towards that ultimate scenario of data sharing and linkage for the public good. And you can put quite neatly different recommendations against different bits of that scenario to help get, get us there. I think if, if I reflect on the scenarios like right now, the one that feels like most familiar to me is data sharing and linkage in silos. We’ve kind of spoken a little bit earlier already about how there are some areas of government and some topic areas and some organisations that are doing some really brilliant work. And I could see quite a realistic scenario where that kind of becomes more entrenched over, over the next five years. But, you know, maybe that’s actually just realistic, right? Maybe it’s unrealistic to expect that every organisation [in] government with different, different sizes, different funding, different priorities, could, could end up in exactly the same place on date sharing and linkage, all at the kind of, the top level. But I do, I do think if we can chip away at the recommendations we’ve made, then every organisation could improve on their starting point and move towards that, that scenario.</p>
<p><strong>Brian Tarran</strong><br>
Okay, so let’s talk about some of the recommendations of how we get there. And there were a couple of areas I particularly wanted to focus on. One was talking about career frameworks, and having those kind of reflect, and I guess, reward the skills of those who are working on data and data linkage projects. So I was kind of wondering, you know, are there, are these skills that are kind of currently either underserved or under recognised within the existing career frameworks? And if so, how do we change that? Or was that is that beyond the scope of your report to recommend that?</p>
<p><strong>Helen Miller-Bakewell</strong><br>
I think the situation across government is perhaps relatively complicated here. And I think what we, what we’d really like to see, essentially, is a situation where people in roles, in data roles, basically feel valued, and they can see a clear career pathway for them within government. And I think what we have at the moment is a variety of career frameworks that support people working in in roles with data and a decentralised pay model. Which means pay scales across, across roles can, can – and frameworks – can vary. You can see intuitively, how that has the potential to kind of create confusion for individuals – like well, which career framework should I look at – and, and then on the pay side, the potential to create kind of skills sink, where people want to go and work particular areas simply because they can be paid more, and in some cases it’s a considerable amount more, actually. And the reason I say it’s complicated is because, I mean, to some extent, this, what we have, is appropriate. People who work on data and sharing and linkage projects can come from lots of different analytical backgrounds – like, you could have a statistician or a social researcher or a data scientist or data architect, they could all be working on a, on a data sharing project, shall we say. And actually, it kind of makes sense that people in those kind of different roles might have different career frameworks and paths. And similarly, as I say, pay is decentralised, I don’t think OSR has much power to change too much there. But, you can see there are arguments for departments being able to have their own say on what skills they need to kind of pay more for in different circumstances at different times to, to bolster things. However, what we have said in the report, what we call for, and what we will try and speak to people who own frameworks to try and facilitate, is just a bit more awareness between people who own different frameworks about what else is out there, and a bit more consistency, therefore, about how different data skills perhaps are reflected and where they’re reflected in different frameworks. So we’re not asking for one single framework, I don’t think that would be practical, or particularly serve people working in data very well. But yeah, like more awareness, better joined up working, more consistent use of frameworks in, in job adverts, for example, just to help people see more clarity about their careers and where they can take them.</p>
<p><strong>Brian Tarran</strong><br>
I was at an event recently where, you know, people working in, in data science or data, data kind of roles in government, were talking about how, like, the sort of career pathways and that there’s a feeling that technical skills, or growing technical skills aren’t always as well rewarded as greater sort of managerial responsibilities, so that if you become a, someone who’s excellent at being able to solve the, the knotty problems of data linkage and sharing, right, you might not be as well compensated for that as you might be if you were, say, running a team of 20, 30 people and sort of not actually applying those technical skills on a day-to-day basis. So it’s, I guess that was where my question was coming from was, is it that sort of thing that we kind of need to, need to address in some way? But, again, that might be beyond the scope of, you know, what you were looking at it on this particular matter?</p>
<p><strong>Helen Miller-Bakewell</strong><br>
Well, I think it’s something for us to think more about, if I’m honest. We have committed ourselves to a follow on report for this. And we want to kind of take a look at the recommendations next year and see, you know, how far everything’s got. So, you know, any, any additional bits that we haven’t covered in this first report are good for us to think about. I think the situation you’ve just outlined sounds very familiar, to be honest, and not just across data science, across a whole load of roles where, yeah, actually your technical skills, they take you really well to middle management, but then there often comes a point where, if you want to go higher and have greater remuneration, you might have to move more to those softer skills, those managerial skills. That’s something we can think a bit more about, actually. And when we do have conversations with those who we kind of pointed to for the frameworks recommendation, maybe have a look into it a bit more.</p>
<p><strong>Brian Tarran</strong><br>
This is, I guess, some somewhat related to the previous point. But the other aspect of the recommendations that jumped out to me were the discussion around quality metadata and documentation, standardisation and things like that as being priorities for effective data linkage, these are the things that need to be in place. But again, when you chat to researchers, not just in government but all over the place, these less glamorous aspects of data management are kind of underappreciated. And often teams are, the way that, the way teams work, the way projects work is you finish one, you move on to the next, you don’t really want to think too much about the one that you just worked on, because you’ve got a new priority or a new round of funding or whatever it is. So how do we convince senior leaders that, that there are sufficient resources for this sort of work that needs to be done? It might not sort of deliver necessarily immediate value and benefits, but it’s about kind of accruing the kind of infrastructure, I guess, to, to make sure that data sharing and linkage, you can achieve your, you know, your most optimistic vision of data sharing and linkage being widespread in government.</p>
<p><strong>Helen Miller-Bakewell</strong><br>
Yeah, I think it’s a really important question. And yeah, having worked as a statistician as well, before I came into this world of regulation, yep, I recognise what you just described. And, you know, I think it’s always going to be a challenge in these kind of fast-paced multiple priority environments, where often people are resource stretched in terms of people, time, money, all those things together. Though, I think there’s a couple of tacks. One, I think, is maybe improving the data literacy of senior leaders, and trying to give them a greater understanding of, of data, how it’s used, and around these issues of kind of standardisation, and why they’re why they’re so important. And, actually, a couple of the recommendations earlier on in the report, in the people section, are around improving the– or strengthening the statistical literacy and the data literacy of senior leaders and recommending they go on, for example, the Data Science Campus in ONS run a master class for senior leaders across the service. So I think there was a kind of a bit of a, an education thing. And yeah, I guess, you know, part of that is setting out, like, what are the benefits? And what are the risks of not doing this? I think that, you know, here comes a role for people like OSR in setting expectations, especially in the world of official statistics, it is completely within our power to set the expectation for what government statistics should be doing with regards to metadata, or kind of following, following best practice and things like that. Our code of practice for statistics does do that to some extent already. And us as well, there’s a role for us in demonstrating the benefits and saying why we’re asking people to do these things and, and what’s good when it, when it goes well. I was thinking about this, and it drew to mind the EAST Framework. I don’t know if you’ve come across that. It’s a framework that was introduced to me by the Behavioural Insights Team for bringing about change and what you– what interventions need to be if they’re going to be successful, and it’s Easy, Attractive, Social and Timely. And I think when we and when other organisations who are kind of working on metadata standardisation, like the Central Digital Data Office, like Department for Science, Innovation and Technology, there’s, you know, there’s a few players here. We need to be keeping these, the EAST in mind as we design to try and help people kind of come on board with things more easily. And yeah, recommendation 16 in the report, the final one, is about standardisation and about, there are lots of players in this space and can we, can we bring them together a bit to be even more effective? So that’s, that’s definitely something we’ll be looking at in the coming months.</p>
<p><strong>Brian Tarran</strong><br>
And you said that there’ll be a follow up report soon. When is that? When are you targeting?</p>
<p><strong>Helen Miller-Bakewell</strong><br>
We’re planning next summer. So last time when we did our first report on Joined-up Data in 2018. And then we did a follow on one year on in 2019. We found that was quite an effective way to, for us and others, to kind of build and maintain momentum. And yeah, again, you know, feels a bit unfair almost to just put out a load of recommendations, and then then leave, leave the world to it. We’d like to see if we can help facilitate and then tell people how we’ve been getting on.</p>
<p><strong>Brian Tarran</strong><br>
And I’m guessing it’s not, you’re not looking for all recommend– 16 recommendations to be implemented by next year. But it’s, are we making steps towards some of them? Are we are we heading in the right direction?</p>
<p><strong>Helen Miller-Bakewell</strong><br>
You know, let’s practice what we preach. A bit of transparency. Yeah, are we heading in the right direction? And if we’re not, you know, is there a plan? I’d love to be optimistic. That optimistic. I wouldn’t expect that we can just put ticks against all 16 recommendations next year. But hopefully, yeah, we can, we could do some progress bars.</p>
<p><strong>Brian Tarran</strong><br>
Excellent. Well, we should probably schedule a follow up interview for a year’s time then. But Helen, thank you very much for your time today.</p>
<p><strong>Helen Miller-Bakewell</strong><br>
Oh, you’re very welcome. And if anyone, any of your listeners interested in, in the report, please do get in touch with OSR. We’d be very happy to talk about the report that we’ve just written or about, you know what we’re doing. Following on from that? Yeah, thank you.</p>
<p><strong>Brian Tarran</strong><br>
So we’ll definitely put a link to the report in the show notes. So once again, Helen, thank you very much for joining us.</p>
<p><strong>Helen Miller-Bakewell</strong><br>
Oh, you’re welcome. Thank you.</p>
<div class="article-btn">
<p><a href="../../../../../../viewpoints/interviews/index.html">Find more Interviews</a></p>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-6">
<dl>
<dt>Copyright and licence</dt>
<dd>
© 2023 Royal Statistical Society
</dd>
</dl>
<p><a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> <img src="https://mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1" style="height:22px!important;vertical-align:text-bottom;"><img src="https://mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1" style="height:22px!important;margin-left:3px;vertical-align:text-bottom;"></a> This interview is licensed under a Creative Commons Attribution 4.0 (CC BY 4.0) <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> International licence</a>.</p>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>How to cite</dt>
<dd>
Tarran, Brian. 2023. “‘Feelings about sharing data can be context and time dependent – you can’t just do one survey or focus group.’” Real World Data Science, October 16, 2023. <a href="https://realworlddatascience.net/viewpoints/interviews/posts/2023/10/16/data-sharing-in-gov.html">URL</a>
</dd>
</dl>
</div>
</div>
</div>


</section>

 ]]></description>
  <category>Data sharing</category>
  <category>Data linkage</category>
  <category>Public engagement</category>
  <guid>https://realworlddatascience.net/viewpoints/interviews/posts/2023/10/16/data-sharing-in-gov.html</guid>
  <pubDate>Mon, 16 Oct 2023 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/viewpoints/interviews/posts/2023/10/16/images/helen-miller-bakewell.png" medium="image" type="image/png" height="105" width="144"/>
</item>
<item>
  <title>Join Real World Data Science at three events this October!</title>
  <dc:creator>Brian Tarran</dc:creator>
  <link>https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/10/10/october-events.html</link>
  <description><![CDATA[ 





<p>Summer 2023 for us was a blur of excellent data science and statistics events. There was the <a href="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/08/06/jsm-blog.html">Joint Statistical Meetings in Toronto</a>, the <a href="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/08/24/rss-conference.html">Royal Statistical Society Conference in Harrogate</a>, and <a href="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/09/19/positconf-blog.html">posit::conf(2023) in Chicago</a>. But if that wasn’t enough, autumn promises more good stuff, and more opportunities to meet with Real World Data Science in person and online.</p>
<section id="an-introduction-to-real-world-data-science" class="level3">
<h3 class="anchored" data-anchor-id="an-introduction-to-real-world-data-science">An introduction to Real World Data Science</h3>
<p><strong>Date:</strong> Monday, October 16, 2023 <strong>Time:</strong> 12 pm – 1 pm <strong>Location:</strong> Online</p>
<p>Next week is Members’ Week at the Royal Statistical Society (RSS), and the RSS calendar is full of events targeted at members – prospective members, new members, and established members. Kicking things off on Monday lunchtime is <a href="https://rss.org.uk/training-events/events/events-2023/rss-events/the-real-world-data-science/">an online event to introduce Real World Data Science</a>. We’ll discuss the aims of this project, our guiding ethos and content plans, and we’ll explain the various ways in which people can contribute to the site.</p>
<p>Chances are, if you’re reading this blog, you won’t need much of an introduction to Real World Data Science. But do please help spread the word to potential new readers, and encourage them to <a href="https://rss.org.uk/training-events/events/events-2023/rss-events/the-real-world-data-science/">register for this free event</a>.</p>
</section>
<section id="nhs-r-community-annual-conference" class="level3">
<h3 class="anchored" data-anchor-id="nhs-r-community-annual-conference">NHS-R Community Annual Conference</h3>
<p><strong>Date:</strong> Tuesday, October 17, 2023 <strong>Time:</strong> 9:30 am – 10:00 am <strong>Location:</strong> Edgbaston Stadium, Birmingham (in person) and online</p>
<p>It’s a real honour for us to be invited to give a keynote talk at <a href="https://nhsrcommunity.com/events/nhs-r-community-conference-2023-ticket-for-in-person-attendance-on-tuesday-17th-october-2023/">this annual gathering of the NHS-R Community</a>, a group dedicated to promoting the use of R in the National Health Service. Our talk is titled, “Forging community links: NHS-R, the Royal Statistical Society and Real World Data Science,” and we’ll explain how the Real World Data Science project came about, how we embraced open-source tools and the idea of collaborative content development, and why there’s so much to be gained from sharing data science case studies across domains.</p>
</section>
<section id="evaluating-artificial-intelligence-how-data-science-and-statistics-can-make-sense-of-ai-models" class="level3">
<h3 class="anchored" data-anchor-id="evaluating-artificial-intelligence-how-data-science-and-statistics-can-make-sense-of-ai-models">Evaluating artificial intelligence: How data science and statistics can make sense of AI models</h3>
<p><strong>Date:</strong> Tuesday, October 31, 2023 <strong>Time:</strong> 4 pm – 6 pm <strong>Location:</strong> RSS, London (in person only)</p>
<p>Real World Data Science has partnered with colleagues and volunteers across the RSS to organise another <a href="https://rss.org.uk/training-events/events/events-2023/rss-events/evaluating-artificial-intelligence-how-data-scienc/#fulleventinfo">AI panel debate</a>, following up on the AI discussion at the <a href="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/08/24/rss-conference.html">RSS Annual Conference</a>.</p>
<p>This event forms part of the <a href="https://aifringe.org/">AI Fringe programme of events</a>, which coincides with <a href="https://www.gov.uk/government/publications/ai-safety-summit-introduction">the UK government’s AI Safety Summit on 1–2 November</a>.</p>
<p>Our free event focuses on big questions around AI model evaluation, which will also be a key topic of discussion at the summit. One of the government’s stated objectives is for the summit to identify “areas for potential collaboration on AI safety research, including evaluating model capabilities and the development of new standards to support governance,” and so we’ll be asking:</p>
<ul>
<li>What should AI evaluation look like?</li>
<li>How will it work in practice?</li>
<li>What metrics are most important?</li>
<li>Who gets to decide all of this?</li>
</ul>
<p><a href="https://rss.org.uk/training-events/events/events-2023/rss-events/evaluating-artificial-intelligence-how-data-scienc/#fulleventinfo">Register via the RSS website</a> to attend this free in-person event, chaired by RSS president Andy Garrett. Panellists will be announced soon, so stay tuned!</p>
<div class="article-btn">
<p><a href="../../../../../../viewpoints/editors-blog/index.html">Back to Editors’ blog</a></p>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-6">
<dl>
<dt>Copyright and licence</dt>
<dd>
© 2023 Royal Statistical Society
</dd>
</dl>
<p><a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> <img style="height:22px!important;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"></a> This article is licensed under a Creative Commons Attribution 4.0 (CC BY 4.0) <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> International licence</a>.</p>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>How to cite</dt>
<dd>
Tarran, Brian. 2023. “Join Real World Data Science at three events this October!” Real World Data Science, October 10, 2023. <a href="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/10/10/october-events.html">URL</a>
</dd>
</dl>
</div>
</div>
</div>


</section>

 ]]></description>
  <category>AI</category>
  <category>Large language models</category>
  <category>Communities</category>
  <category>Events</category>
  <category>Updates</category>
  <guid>https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/10/10/october-events.html</guid>
  <pubDate>Tue, 10 Oct 2023 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/10/10/images/oct-events.png" medium="image" type="image/png" height="105" width="144"/>
</item>
<item>
  <title>‘I fell in love with math, really, and fell into data science because of that’</title>
  <dc:creator>Brian Tarran</dc:creator>
  <link>https://realworlddatascience.net/careers/career-profiles/posts/2023/10/04/niclas-thomas.html</link>
  <description><![CDATA[ 





<p>A passion for maths and solving mathematical problems led Niclas Thomas to a PhD in machine learning with a focus on medical research. But then a conversation with a recruiter steered his career towards data science in the retail sphere. After stints at Tesco, Sainsbury’s, and Gousto, Thomas is now head of data science for Next, the clothing retailer.</p>
<p>In this interview with Real World Data Science, Thomas reflects on his career journey so far, from hands-on coding work to team leadership and management. He also argues for the importance of communication and storytelling as part of the data science skill set.</p>
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/0y6yye1A9vU?si=oea60bsc8r83icom" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<section id="transcript" class="level2">
<h2 class="anchored" data-anchor-id="transcript">Transcript</h2>
<div class="callout callout-style-simple callout-warning" style="margin-top: 0.75rem;">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-body-container">
<p>This transcript has been produced using <a href="https://otter.ai/">speech-to-text transcription software</a>. It has been only lightly edited to correct mistranscriptions and remove some repetitions.</p>
</div>
</div>
</div>
<p><strong>Brian Tarran</strong><br>
Niclas Thomas, thank you for joining us today. I hope you’re well.</p>
<p><strong>Niclas Thomas</strong><br>
I am indeed thanks. Thank you for having me.</p>
<p><strong>Brian Tarran</strong><br>
Today we’re meeting because we want to find out a little bit about your career in data science, how you got into it, what you’re doing now, where you see both your career and data science as a profession going next. So do you mind– can we start by giving us a brief introduction to who Niclas Thomas is?</p>
<p><strong>Niclas Thomas</strong><br>
Yeah, of course. Yeah. So I’m currently working as head of data science at Next. My background is academia originally, a maths degree. I did my PhD in machine learning, and more in medical research, so more of an applied machine learning position where the idea was to try and predict, ultimately, predict disease from a given sample of data from blood – can you actually predict future disease? – which I think is a really interesting area; I love medical research. And then [I] switched over to more commercial role and worked in several retail data science roles: so, Tesco, Sainsbury’s, Gousto, and then now, as I said, currently head of data science at Next, where I run a team, and I imagine most listeners will be familiar with what Next do: a retail, a clothing brand on the whole, where the idea is, obviously to sell some great stuff, great products and put the right product in front of the right customer.</p>
<p><strong>Brian Tarran</strong><br>
Can you tell us, what does your job involve? What are your sort of main tasks and responsibilities in that role?</p>
<p><strong>Niclas Thomas</strong><br>
Yeah, so I suppose I’m lucky enough to have been head of data science at several different companies: Sainsbury’s, Gousto, and Next. So it’s always interesting to compare the role of the head of data science in each of those three. At the moment, I think there’s a core focus on, well, ultimately making sure the teams are efficient as possible. And that really means just making sure our tech stack – what tools, what programming languages, what software we use on a day to day basis – is set up for success and make sure the team have what they need to be able to do the job as efficiently as possible, whether that’s using Python or R, whether that’s how we develop code, and how we work with other people as well, being a big part of that, then. So how do we work with other software engineers? How do we work with web developers, then, to make sure that the work we do actually gets in the hands of the business and ultimately in the hands of the customer. So that’s one aspect: it’s just making sure the team is set up for success, both in terms of the ways they work and what tools they have to work as well, then. I guess the other side of that coin is what we actually work on. So understanding the value of potential work we could do, and helping the team understand what that value is, and, and ultimately giving direction of what things we want to work on next. Obviously, that’s not my decision in isolation, but understanding on the one hand, what other stakeholders want to do, what my superiors wants to do, as well. And trying to put that all into the mix to understand these are the next best projects to work on given a finite amount of people to work on these problems. And then ultimately, then, the last part, then, is ultimately helping the team deliver those projects, those products as well then, which usually means calling on my experience of having solved these problems myself, either directly when I was earlier in my career or indirectly through leading others then or, you know, being the head of a team and working with some other great people and to learn from their experiences as well.</p>
<p><strong>Brian Tarran</strong><br>
What does data science mean to you, personally? I’m not asking you to define it for everybody. But for you, what is what is data science?</p>
<p><strong>Niclas Thomas</strong><br>
Yeah, I wish I’d come up over the years with a great definition of this. But yeah, I mean, really, it just, I mean, at the very highest level, it just means using data to drive business value, I suppose, as I guess in my– which probably reflects the fact that it’s more of a business role that I have. But I think that in its broadest sense, I think that’s true: using data to drive insights and make decisions for the business. There are more, I guess, detailed definitions of that. So, for example, the way I’ve always differentiated between data analytics and data science is that if you want to make repeated decisions on a daily or weekly basis, then that’s when it becomes more about a data science question versus a data analytics question, because data analytics is generally about answering large one off ad hoc questions, rather than making the same decision over and over again and using methods appropriate for that. But, ultimately, that’s what data science means to me, I think: making repeated decisions using data and the scientific method to use data for good.</p>
<p><strong>Brian Tarran</strong><br>
And so what do you think is your most important skill as a data scientist given that definition that you have of data science?</p>
<p><strong>Niclas Thomas</strong><br>
In my role, I suppose communication ultimately becomes the most important thing. I’d say definitely earlier in my career, and I think if you’re the person actually delivering and implementing the algorithm, I think that the technical skill set obviously is really important then. But ultimately, I almost see my role as the head of data science as a hybrid– as a link between my team and the rest of the business, then. So it’s really about being able to, on the one hand, translate technical concepts into non technical descriptions of what we’re actually doing, making sure the rest of the business can understand and vice versa, then making sure I understand the business process and business terminology well enough to be able to translate that for the team, as and when needed, into a vision for a project, a product, then, and develop a strategy for that. So I think that the communication both in the strictest sense of being able to talk that through with, with my team, with other team members, with stakeholders, as well, but also more in the looser sense, then, of being able to define that strategy, being able to define what the roadmap for a particular project or a product might look like.</p>
<p><strong>Brian Tarran</strong><br>
Can you talk us through your so your education and your training that led up to your kind of first data science job, your first data science role.</p>
<p><strong>Niclas Thomas</strong><br>
I suppose the first time, the first time I– actually, I’d never heard about it, I think, when a recruiter approached me. This is probably going back into 2014, when I was maybe eight months into my postdoc after my PhD. I think– obviously it did exist before that, although I suppose the terminology wasn’t quite as widespread going back almost 10 years now where the term is a lot more rife. So my original background, I did a master’s in maths originally, four years. And then I remember being– the last year of that, then, I was applying for a few jobs, and I applied for one at the Met Office, where the focus obviously was predicting weather, forecasting. And I wasn’t successful in that job. But I did notice that the, on the job spec at the time, it was PhD preferred was one of the specs on that role. It was probably the first time I thought about taking on a PhD as more of a career move rather than as the natural progression to an academic career, more of a business career move if you like, then of actually how it can help you in more business settings. So that was at least when I decided to do my PhD and thought it’s certainly not going to be– and this was back in 2008, so at the time of the financial issues at the time when getting jobs was harder anyway, so it felt like a win-win of doing something that would be– I was clear I wanted to work in a data role of some sort. And that combined with the fact that I thought it would be a good career move and the financial climate at the time wasn’t brilliant. So I took on a PhD then. And then in terms of actually getting into, into my first data science position was, as I said, just after I finished my PhD, I had been working about six months, eight months as a postdoc, and then a recruiter just described a role that was available at Tesco at the time. And it sounded a lot of what I was doing in my current postdoc role at the time – making predictions based on data and exactly the same techniques – sounded really interesting. And it must have been the way the recruiter sold it at the time as well then, because it’s something I was really keen to take on and then made my move off the back of that then. So yeah, kind of moved into it a little bit, I guess, semi deliberately from taking a PhD on first, but always with the view of moving over to a business role at some point after that.</p>
<p><strong>Brian Tarran</strong><br>
But it wasn’t like you started out your further education thinking, “I want to be a data scientist, what do I need to do to kind of get there? What are the subjects I need to focus on? What are the topics I need to research?</p>
<p><strong>Niclas Thomas</strong><br>
Yeah. Oh, absolutely. Yeah, it certainly wasn’t by design at the very start of my journey. I fell in love with math, really, and just fell into data science because of that, really, I loved numbers and loved solving maths problems. So that’s why I did a degree in it first of all, then and certainly, you know, even midway through my degree, then I wasn’t really sure what I wanted to do. It was more, as you say, just by chance, then, that there were a few opportune moments that came around then, that opportunities came around at the right time to fall into that career.</p>
<p><strong>Brian Tarran</strong><br>
Doing a PhD in machine learning as you did, that was quite a – in hindsight – a smart choice of PhD to pursue, I think, right?</p>
<p><strong>Niclas Thomas</strong><br>
I think so. Yeah, I suppose it was– still even at that stage it wasn’t necessarily, again, the terminology ‘data science’ wasn’t really around. Certainly, when I started my PhD in 2009 2010. It wasn’t really terminology, at least it may have been in usage a little bit in terms of being on, you know, if you look for jobs on LinkedIn or Indeed, but it certainly wasn’t terminology that that I would have been particularly familiar with.</p>
<p><strong>Brian Tarran</strong><br>
Your first job in data science was at Tesco. You mentioned that you were you were kind of recruited to that role there. How does it compare to your current role? So I guess, you know, what’s the difference between being a data scientist versus head of data science as you are now?</p>
<p><strong>Niclas Thomas</strong><br>
Yeah, I think there are probably more similarities than differences, I would say. We were quite lucky in the setup in Tesco that the recruitment strategy seemed to be more focused around people who already had some experience in, generally, either already had business experience or a PhD. So we were fairly independent in solving our own– the project that we were working on and working on that. Not necessarily with the head of data science guiding us, you know, day by day, in terms of the actual nitty gritty and the technical detail, which is great, then. So it did mean that we had responsibility and ownership for our product quite early on. So yeah, I really enjoyed that. I suppose I was writing a lot more code in those days than I do now. I rarely, if ever write code at the moment. So I think that’s probably true for the last maybe three or four years, I think, only occasionally getting my hands dirty. And even when it is, it’s not really to build an algorithm, it’s more to inquire about what data we have to solve the algorithm then. So even when I do get my hands dirty, it’s more in the very early stages of the whole algorithm development lifecycle. So I think that’s probably the biggest difference is just the actual ownership of development there – probably expected, I would say, but it’s– I think that’s one of the beauties of being in your first job or two in data science. I think the– I think in most places I’ve seen, I think you’ll get ownership of, of the work, the stuff that you work on, on a day to day basis, quite early on. And you’ll be expected to contribute code and ideas for that as well, which I think most people would love. I certainly loved it at the time.</p>
<p><strong>Brian Tarran</strong><br>
What was the most important thing you learned in your first year in that job?</p>
<p><strong>Niclas Thomas</strong><br>
I think, again, it’s probably a lot around the ways of working, I would say – of the various ways you can [work], which I never really thought about it before. Working in academia, it was quite isolated, I suppose. You work on your own project, you work on your own work and don’t really– or at least, I found I didn’t really work with anyone else that much. Maybe that was the nature of my work as well, we’d obviously be dependent on people working in a lab to get data. But I think the day to day work, I was working quite in isolation, whereas the team aspect of working, I think, was a steep learning curve then – so agile methodology, and everything around that, which was very, very new to me. And the various ways you can do that. I’m generally not someone for overly putting processes in place in a team, only where necessary. But I think there’s some great learnings from that as well. It certainly started to shape how I think I would want to run a team if and when I got to that position.</p>
<p><strong>Brian Tarran</strong><br>
So, Nick, what have been your career highlights so far?</p>
<p><strong>Niclas Thomas</strong><br>
I think in terms of– there was one product we built in Sainsbury’s in particular. So in terms of, on a product level of replenishment. So how do you most efficiently get products from the back of the store onto the shelves of an individual store? And what’s the most optimal strategy to do that, which I love for a variety of reasons. A, it was one of the first full data science products that we had deployed and worked on as a team in Sainsbury’s. So there was that kind of milestone about it. I think it also stood out as a really nice move away from classic machine learning – i.e., making a prediction, a classification model – to something that was a bit more operations research based and more based on optimization. So using graph theory, making a graph network of a store. And using that to solve the problem of taking a route through the store, for example, a bit like a Google Maps for a store basically, was how we always pitched it to our stakeholders, and how can you choose the best route and again, moving more into a bit more of a vehicle routing problem, then: if you’ve got two different trolleys, how do you decide what items to put on trolley one versus trolley two? So there’s loads of interesting stuff on the technical side of things and it was, again, I felt it was probably one of the highlights – as well as the end product, it was also the one I worked on at the very start. So actually, the understanding whether it would be possible to do that, what kind of technical approach. So I think certainly from a product perspective, that’s probably stuck in my mind. Aside from that, on a more personal level, I guess, I did decide to write a book off the back of my PhD. Just mainly on my experiences from my PhD and postdoc. I mean, it’s not like a confessional. But more on the– just working with non data scientists and making it more accessible was really what I really focused on there. So having worked with clinicians, immunologists and others as part of the medical research that I did, I felt that data can be accessible if you pitch it in a way and make it easy to use. And so that was the purpose of what was largely an educational textbook.</p>
<p><strong>Brian Tarran</strong><br>
Do you want to give a short plug for the book, what it’s called and where people can find it?</p>
<p><strong>Niclas Thomas</strong><br>
Yeah, so it’s, Data Science for Immunologists is the name of the book. It’s available on Amazon. I’m one of the two co-authors on that then. And we do have a website, <a href="https://datascienceforimmunologists.com/">datascienceforimmunologists.com</a>, as well then if you did want to visit and you can either buy the book, there’s a link on that website or just go straight to Amazon and it’s available there.</p>
<p><strong>Brian Tarran</strong><br>
This next question, we’ve gone from highlights to lowlights. Have there been any mistakes or regrets that you’ve had along the way in your data science career so far?</p>
<p><strong>Niclas Thomas</strong><br>
The main mistakes I think I’ve made before is not valuing, A, communication or soft skills, but B, the leadership and management as well then. And I think especially it’s something, when working at Gousto as well that was something that was a big focus of the team and something that I really took from my time there as well was the, I guess, the art of good management and good leadership, you know, what the difference is between the two. So I wouldn’t say there’s any one bang event that’s a mistake or regret, but it’s probably, as ever, it’s probably I would have put more emphasis on it sooner had I known that how important those skills would be.</p>
<p><strong>Brian Tarran</strong><br>
Yeah, but I think that’s understandable to a certain extent. If you’re coming from, I guess, a role that’s very hands on, doing things yourself, getting into the messy details of a project, it can sometimes be hard to kind of take a step back and adopt more of a kind of leadership, management position, can’t it?</p>
<p><strong>Niclas Thomas</strong><br>
Yeah, definitely. Yeah, definitely. I would agree with that. And I think it’s also, I’d probably say for a lot of people starting out, and certainly it was for me, that the technical– the technical aspect is probably why you get into a role in data science in the first place, that you just love solving problems, basically, whether that’s with code or with pen and paper. And so that’s, that’s what you want to do. And getting your mind focused elsewhere away from that is probably not viewed as the most fun thing to do, I probably wouldn’t have, when I was starting out in 2014, 2015, I probably wouldn’t have thought it was as fun or as interesting to do that as I do now, maybe. So I think that’s the other reason why it probably doesn’t get as much focus earlier on in my career anyway, at least, as it probably deserved.</p>
<p><strong>Brian Tarran</strong><br>
How do you think your– how do you see your role, I guess, evolving over the rest of your career in data science?</p>
<p><strong>Niclas Thomas</strong><br>
I suppose on a personal level, for me it’s, I’m always thinking of what, 10 years down the line, do I still want to be focused just on data science? Or do I want to be focused on a data role, more broadly? I suppose that’s always the main question to ask. And so by that I mean, looking at data engineering as well, data analytics, and being responsible for a wider group. I think the way the field is going anyway, I think a lot more companies seem to move to vertical management rather than horizontal. So by that, I mean having heads of data in different areas of the business. So rather than having a head of data and a head of analytics, you might have a head of data for certain aspects of the business and another head of data then that’s responsible for both in other areas of the business, then. So either way, I think that the broadening of responsibilities and not just being responsible for data science is probably one way I would see my career potentially moving. At the moment, I love just focusing just on the data science, I’m really happy doing that now. But I think that could be one way that my focus changes in the future.</p>
<p><strong>Brian Tarran</strong><br>
What personal or professional advice would you give for anyone wanting to be a data scientist?</p>
<p><strong>Niclas Thomas</strong><br>
Yeah, so first of all, the balance between the soft and hard skills. I think I’ve alluded to it before, but the– don’t put too much– I mean, still emphasise on the technical skills are really important, but don’t feel like it’s the be all end all. I think just understanding the softer side of how you communicate, how you tell a story, for example, and storytelling with data, I think is really important. So I’d say that’s probably one focus area. I think that the second would probably, and maybe it’s a harder one to act on, but being passionate, I think, because whenever I’m looking to recruit anyone new into my team, I think it’s as much about understanding what the potential of that person is as is what is their current performance or where their current capability is – how good they could be in the future is arguably more important. And I think a lot of that comes to ultimately someone’s– whether they have a fixed or growth mindset. So by that, I mean, ultimately, do they want to learn or not, and if they really want to learn, as a lot of data scientists do, but if they have a huge passion for or about data science, and wanting to learn about just how to get better – whether that’s a better coder, better at maths, anything around that – then if you have that attitude, I think then it’s, A, you can have a great impact on our team, but B, I think it’s a sign of someone who can be a great performer in the future.</p>
<p><strong>Brian Tarran</strong><br>
So what do you think will be the main challenges facing data science as a field over the next few years?</p>
<p><strong>Niclas Thomas</strong><br>
I think probably, certainly, currently maybe living up to the hype, I suppose. And matching I suppose the classic Gartner Hype Cycle of, it feels like we’re probably at the stage where there’s a lot of– the hype has been around for a few years of data science now and I think making sure we tackle the right problems, I suppose, is one of the – and by ‘we’ I mean, Next as a business or whatever business we’re working in at the time – I think it’s making sure we’re working on the right things. Because I think a lot of people will be keen to have data scientists as part of their work and the product they’re trying to build. What is the best place to spend our time, and what projects we should be working on most I think is– becomes important then because, as I say, there’s a huge demand for data scientists time, I think, in every company. And so choosing where we spend that time wisely, I think, becomes the key challenge and the important decisions for, especially for a head of data science like myself to make then, to make sure we’re best using the team’s capacity, then.</p>
<div class="article-btn">
<p><a href="../../../../../../careers/career-profiles/index.html">Discover more Career profiles</a></p>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-6">
<dl>
<dt>Copyright and licence</dt>
<dd>
© 2023 Royal Statistical Society
</dd>
</dl>
<p><a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> <img style="height:22px!important;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"></a> This interview is licensed under a Creative Commons Attribution 4.0 (CC BY 4.0) <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> International licence</a>.</p>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>How to cite</dt>
<dd>
Tarran, Brian. 2023. “‘I fell in love with math, really, and fell into data science because of that.’” Real World Data Science, October 4, 2023. <a href="https://realworlddatascience.net/careers/career-profiles/posts/2023/10/04/niclas-thomas.html">URL</a>
</dd>
</dl>
</div>
</div>
</div>


</section>

 ]]></description>
  <category>Leadership</category>
  <category>Management</category>
  <category>Communication</category>
  <guid>https://realworlddatascience.net/careers/career-profiles/posts/2023/10/04/niclas-thomas.html</guid>
  <pubDate>Wed, 04 Oct 2023 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/careers/career-profiles/posts/2023/10/04/images/niclas-thomas.png" medium="image" type="image/png" height="105" width="144"/>
</item>
</channel>
</rss>
