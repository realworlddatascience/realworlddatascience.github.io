<?xml version="1.0" encoding="UTF-8"?>
<rss  xmlns:atom="http://www.w3.org/2005/Atom" 
      xmlns:media="http://search.yahoo.com/mrss/" 
      xmlns:content="http://purl.org/rss/1.0/modules/content/" 
      xmlns:dc="http://purl.org/dc/elements/1.1/" 
      version="2.0">
<channel>
<title>Real World Data Science</title>
<link>https://realworlddatascience.net/latest-content.html</link>
<atom:link href="https://realworlddatascience.net/latest-content.xml" rel="self" type="application/rss+xml"/>
<description></description>
<image>
<url>https://realworlddatascience.net/images/rwds-logo-150px.png</url>
<title>Real World Data Science</title>
<link>https://realworlddatascience.net/latest-content.html</link>
<height>83</height>
<width>144</width>
</image>
<generator>quarto-1.7.32</generator>
<lastBuildDate>Mon, 07 Jul 2025 00:00:00 GMT</lastBuildDate>
<item>
  <title>We’re Back: Real World Data Science Relaunches</title>
  <dc:creator>Editorial Board</dc:creator>
  <link>https://realworlddatascience.net/the-pulse/editors-blog/posts/2025/07/07/editors-relaunch.html</link>
  <description><![CDATA[ 





<p>You may have noticed our brief hiatus. Since publishing our series on AI - which covered <a href="https://realworlddatascience.net/foundation-frontiers/posts/2024/04/29/gen-ai-human-intel.html">the quest for human-level intelligence</a>, <a href="https://realworlddatascience.net/foundation-frontiers/posts/2024/05/07/ai-series-3.html">data-set risks</a>, <a href="https://realworlddatascience.net/foundation-frontiers/posts/2024/05/14/ai-series-2.html">ethical considerations</a> and much more - the ongoing deluge of content and commentary on AI in the wider world has continued to accelerate. This year has seen a surge in developments that sit at the intersection of data science and AI: from the growing use of synthetic data to overcome privacy and bias challenges, to the rise of multi-modal models that demand increasingly sophisticated data engineering and integration techniques. The emergence of Agentic AI has sparked new conversations around data provenance, model interpretability, and the reproducibility crisis in machine learning. Meanwhile, the meteoric rise of open-source disruptor DeepSeek triggered stock-market ruptures and industry panic, before <a href="https://www.theguardian.com/technology/2025/jan/27/deepseek-cyberattack-ai">cyber-attacks</a>, <a href="https://www.wiz.io/blog/wiz-research-uncovers-exposed-deepseek-database-leak">data leaks</a> and a <a href="https://gizmodo.com/deepseek-gets-an-f-in-safety-from-researchers-2000558645?utm_source=pocket_shared">failed safety test</a> complicated its standing - a parable for the volatility of the space, where data governance failures and safety oversights can rapidly derail innovation. Meanwhile, governments worldwide are <a href="https://www.aa.com.tr/en/europe/macron-announces-112b-in-ai-investment-over-coming-years/3477218?utm_source=pocket_saves">investing heavily</a> in <a href="https://assets.publishing.service.gov.uk/media/67851771f0528401055d2329/ai_opportunities_action_plan.pdf?utm_source=substack&amp;utm_medium=email">national data infrastructure</a> and advanced analytics capabilities, while grappling with how best to regulate a field that is evolving faster than policy can keep up.</p>
<p>The world of data science has been a dizzying place over the last few months, so we took a moment to pause and take stock. In the face of rapid change and constant noise, it felt important to reflect with intention on the role Real World Data Science can and should play in this evolving landscape. Now we’re back - ready to rejoin the conversation with renewed clarity and purpose.</p>
<p>As a project from the <a href="https://rss.org.uk/">Royal Statistical Society</a>, in partnership with the <a href="https://www.amstat.org/">American Statistical Association</a>, we are backed by organisations with nearly two centuries of history in championing sound evidence, rigorous methodology and ethical data use. These values form the foundation of our next phase - distilled into the essential pillars: data, evidence and decision. With an esteemed editorial board representing the cutting-edge of industry and academia, and an international network of practitioners working at the coalface of modern data science, we are uniquely placed to navigate the pace and complexity of today’s data-driven world. Real World Data Science will meet that world in real time with the RSS’s trademark steadying presence, bridging the gap between rigorous analysis and real-time relevance.</p>
<p>We are now returning with a slightly refreshed site, encompassing four editorial sections:<br>
<a href="https://realworlddatascience.net/the-pulse/">The Pulse</a> - covering news, updates and real-time commentary<br>
<a href="https://realworlddatascience.net/applied-insights/">Applied Insights</a> - exploring how data science is used to solve real-world problems in business, public policy and beyond<br>
<a href="https://realworlddatascience.net/foundation-frontiers/">Foundations &amp; Frontiers</a> - unpicking the ideas behind the impact: the concepts, tools and methods that make data science possible<br>
<a href="https://realworlddatascience.net/people-paths/">People &amp; Paths</a> - offering strategic reflections on careers, leadership and professional evolution in data science.</p>
<p>You can find the full details of these sections, plus guidance around submitting to them, in our new <a href="https://realworlddatascience.net/the-pulse/editors-blog/posts/2025/07/07/relaunch-CFS.html">Call for Submissions</a>.</p>
<p>Despite these updates, we remain committed to providing content that is useful and relevant for practicing data scientists seeking to learn good practices in the field and new potential applications.</p>
<p>The choices we make now will shape how data and AI serve society for years to come. If you’re working on the front lines of these changes, whether through research, practice, or critical reflection, we invite you to share your insights and help us build a future for data science that is thoughtful, transparent and grounded in real world understanding.</p>
<p><a href="https://realworlddatascience.net/the-pulse/editors-blog/posts/2022/10/18/meet-the-team.html">Meet the Team</a></p>
<div class="article-btn">
<p><a href="../../../../../../the-pulse/editors-blog/index.html">Back to Editors’ blog</a></p>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-6">
<dl>
<dt>Copyright and licence</dt>
<dd>
© 2025 Royal Statistical Society
</dd>
</dl>
<p><a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> <img style="height:22px!important;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"></a> This article is licensed under a Creative Commons Attribution 4.0 (CC BY 4.0) <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> International licence</a>.</p>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>How to cite</dt>
<dd>
Real World Data Science Editorial Board. 2025. “We’re Back: Real World Data Science Relaunches” Real World Data Science, July 7, 2025. <a href="https://realworlddatascience.net/the-pulse/editors-blog/posts/2025/07/07/editors-relaunch.html">URL</a>
</dd>
</dl>
</div>
</div>
</div>



 ]]></description>
  <category>Call for contributions</category>
  <category>Updates</category>
  <guid>https://realworlddatascience.net/the-pulse/editors-blog/posts/2025/07/07/editors-relaunch.html</guid>
  <pubDate>Mon, 07 Jul 2025 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/the-pulse/editors-blog/posts/2025/07/07/images/team.png" medium="image" type="image/png" height="77" width="144"/>
</item>
<item>
  <title>Call for Submissions</title>
  <dc:creator>Editorial Board</dc:creator>
  <link>https://realworlddatascience.net/the-pulse/editors-blog/posts/2025/07/08/relaunch-CFS.html</link>
  <description><![CDATA[ 





<p>Get ready to engage with Real World Data Science as we unveil an exciting editorial refresh! We’re thrilled to announce that submissions are now open across our four dynamic sections: The Pulse, Applied Insights, Foundations &amp; Frontiers, and People &amp; Pathways. Join us as we redefine the conversation in data science with fresh perspectives and insights. Real World Data Science is relaunching to meet the pace and complexity of today’s data-driven world in real time, with the RSS’s trademark steadying presence. We will be publishing high-quality case-studies, tutorials and think-pieces that bridge the gap between rigorous analysis and real-time relevance, and that speak directly to latest events and emerging trends. All submissions will be peer-reviewed by members of the Real World Data Science <a href="https://realworlddatascience.net/the-pulse/editors-blog/posts/2022/10/18/meet-the-team.html">Editorial Board</a>.</p>
<section id="our-audience" class="level2">
<h2 class="anchored" data-anchor-id="our-audience">Our Audience:</h2>
<p>People working in data science looking for practical insights, methodological rigour and thought-leadership that informs their work and decision-making.</p>
</section>
<section id="our-voice" class="level2">
<h2 class="anchored" data-anchor-id="our-voice">Our Voice:</h2>
<p>Authoritative, Trustworthy, Cutting Edge</p>
</section>
<section id="our-editorial-sections" class="level2">
<h2 class="anchored" data-anchor-id="our-editorial-sections">Our Editorial Sections:</h2>
<p>Real World Data Science has four editorial sections. Please read through and consider where your piece would fit best. Each piece we publish needs to be tailored towards the focus of one of these sections.</p>
<p><a href="https://realworlddatascience.net/the-pulse/">THE PULSE</a><br>
News, updates and real time commentary. Purpose: To respond to current events, trends and debates in the data science world with rigour, insight and relevance.<br>
Content Types: Articles that speak directly to current events/trends/launches<br>
Example Call To Action: Invite readers to share your commentary with their networks as a trusted voice in the space. Invite engagement, discussion and debate over the topics.</p>
<p><a href="https://realworlddatascience.net/applied-insights/">APPLIED INSIGHTS</a><br>
How data science is used to solve real-world problems in business, public policy and beyond<br>
Purpose: To showcase real-world applications of data science, including hands-on tutorials, project walk-throughs, and case studies from industry, academia, or public service.<br>
Content Types:<br>
<em>High-quality step-by-step tutorials with code<br>
</em>Case studies detailing a problem, approach, and outcome<br>
*Lessons learned from real-world deployments Example Call To Action: Readers should walk away with something to try.</p>
<p><a href="https://realworlddatascience.net/foundation-frontiers/">FOUNDATIONS &amp; FRONTIERS</a><br>
The ideas behind the impact: the concepts, tools and methods that make data science possible<br>
Purpose: To deepen understanding of the theoretical and ethical foundations of data science, and to spotlight thought leadership and emerging ideas.<br>
Content Types: <em>Think-piece style articles with an engaging angle on methodology, ethics and standards<br>
</em>Interviews with thought-leaders<br>
*Summaries/explainers of academic papers (Data Science Bites) Example Call To Action: Invite discussion and engagement – pose questions and challenges to the reader.</p>
<p><a href="https://realworlddatascience.net/people-paths/">PEOPLE &amp; PATHS</a><br>
Strategic reflections on careers, leadership and professional evolution in data science.<br>
Purpose: To explore the evolving nature of data science careers through the lens of experience, leadership, and long-term impact. This section highlights how professionals shape and are shaped by the field—through roles, decisions, and philosophies.<br>
Content Types: <em>Profiles of/interviews with senior professionals reflecting on career philosophy and leadership<br>
</em>Roundtables with experts on hiring, mentoring, or organisational design *Commentary on career-defining trends, such as the rise of AI governance or the shift toward interdisciplinary teams<br>
Example Call To Action: Encourage readers to share our strategic insights with their community.</p>
</section>
<section id="use-of-ai-in-submissions" class="level2">
<h2 class="anchored" data-anchor-id="use-of-ai-in-submissions">Use of AI in Submissions</h2>
<p>We recognise that LLMs and other generative AI tools are increasingly part of the data science workflow, from code generation and data cleaning to drafting documentation and shaping analysis. We welcome a transparent approach in submissions that have made use of these tools, and ask that authors include a declaration outlining where and how AI was used in the development of their submission. This helps us maintain transparency, uphold standards of reproducibility, and better understand the evolving role of AI in real-world data science practice.</p>
<div class="article-btn">
<p><a href="../../../../../../the-pulse/editors-blog/index.html">Back to Editors’ blog</a></p>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-6">
<dl>
<dt>Copyright and licence</dt>
<dd>
© 2025 Royal Statistical Society
</dd>
</dl>
<p><a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> <img style="height:22px!important;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"></a> This article is licensed under a Creative Commons Attribution 4.0 (CC BY 4.0) <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> International licence</a>. Thumbnail photo by <a href="https://unsplash.com/@johnsonvr?utm_content=creditCopyText&amp;utm_medium=referral&amp;utm_source=unsplash">Virgina Johnson</a> on <a href="https://unsplash.com/photos/turned-on-red-open-neon-sigange-QmNnZj_Ok-M?utm_content=creditCopyText&amp;utm_medium=referral&amp;utm_source=unsplash">Unsplash</a>.</p>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>How to cite</dt>
<dd>
Real World Data Science Editorial Board. 2025. “Call for Submissions” Real World Data Science, July 7, 2025. <a href="https://realworlddatascience.net/the-pulse/editors-blog/posts/2025/07/07/relaunch-CFS.html">URL</a>
</dd>
</dl>
</div>
</div>
</div>


</section>

 ]]></description>
  <category>Call for contributions</category>
  <category>Updates</category>
  <guid>https://realworlddatascience.net/the-pulse/editors-blog/posts/2025/07/08/relaunch-CFS.html</guid>
  <pubDate>Mon, 07 Jul 2025 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/the-pulse/editors-blog/posts/2025/07/08/images/open.png" medium="image" type="image/png"/>
</item>
<item>
  <title>RSS: Data Science and Artificial Intelligence - showcase your research</title>
  <link>https://realworlddatascience.net/foundation-frontiers/datasciencebites/posts/2025/02/05/DSAI-journal.html</link>
  <description><![CDATA[ 





<p><img src="https://realworlddatascience.net/foundation-frontiers/datasciencebites/posts/2025/02/05/images/RSS-DSAI-Logo-blue.png" class="img-fluid" style="width:80.0%" alt="RSS Data Science and AI logo"><br>
</p>
<p><em>RSS: Data Science and Artificial Intelligence</em> provides a new forum for research of interest to a broad readership, spanning the data science fields. Created in recognition of the growing importance of data science and artificial intelligence in science and society, the new journal aims to fill the need for a venue that truly spans the relevant fields.</p>
<div class="img-float">
<p><img src="https://realworlddatascience.net/foundation-frontiers/datasciencebites/posts/2025/02/05/images/RSS-DSAI-cover.jpg" class="img-fluid" style="float: left; margin-right: 25px;;width:25.0%"></p>
</div>
<p>This new open access journal joins the RSS family of world class statistics journals and is published by Oxford University Press.</p>
<section id="scope-and-type-of-papers" class="level2">
<h2 class="anchored" data-anchor-id="scope-and-type-of-papers">Scope and type of papers</h2>
<p><em>RSS: Data Science and Artificial Intelligence</em> is seeking high quality papers from across the breadth of these disciplines which encompass statistics, machine learning, deep learning, econometrics, bioinformatics, engineering, computational social sciences and beyond.</p>
<p>As well as three primary paper types - method papers, applications papers and behind-the-scenes papers - <em>RSS: Data Science and Artificial Intelligence</em> will publish editorials, op-eds, interviews, and reviews/perspectives in line with its goal to become a primary destination for data scientists</p>
</section>
<section id="why-publish" class="level2">
<h2 class="anchored" data-anchor-id="why-publish">Why Publish?</h2>
<p><em>RSS: Data Science and Artificial Intelligence</em> offers an exciting open access venue for your work with a broad reach and is peer reviewed by editors esteemed in their field. Discover more about <a href="https://academic.oup.com/rssdat/pages/why-publish" target="_blank">why the new journal is the ideal platform for showcasing your research</a></p>
</section>
<section id="submit-a-paper" class="level2">
<h2 class="anchored" data-anchor-id="submit-a-paper">Submit a paper</h2>
<p>Find out how to <a href="https://academic.oup.com/jrsssa/pages/general-instructions" target="_blank">prepare your manuscript</a> for submission and visit our submission site to <a href="https://mc.manuscriptcentral.com/rssdat" target="_blank">submit your paper</a></p>
<div class="keyline">
<hr>
</div>
</section>
<section id="editors" class="level2">
<h2 class="anchored" data-anchor-id="editors">Editors</h2>
<p>&nbsp;</p>
<div class="grid">
<div class="g-col-12 g-col-md-4">
<p><img src="https://realworlddatascience.net/foundation-frontiers/datasciencebites/posts/2025/02/05/images/Mukherjee_Sach.jpg" class="img-fluid" alt="Photo of Mukherjee, Director of Research in Machine Learning for Biomedicine at the MRC"></p>
<p><strong>Sach Mukherjee</strong> is Director of Research in Machine Learning for Biomedicine at the Medical Research Council (MRC) Biostatistics Unit, University of Cambridge, and Head of Statistics and Machine Learning at the German Center for Neurodegenerative Diseases.</p>
</div>
<div class="g-col-12 g-col-md-4">
<p><img src="https://realworlddatascience.net/foundation-frontiers/datasciencebites/posts/2025/02/05/images/silvia-chiappa.jpeg" class="img-fluid" alt="Silvia Chiappa, Research Scientist at Google DeepMind"></p>
<p><strong>Silvia Chiappa</strong> is a Research Scientist at <a href="https://deepmind.com/" target="_blank">Google DeepMind</a> London, where she leads the Causal Intelligence team, and Honorary Professor at the <a href="https://www.ucl.ac.uk/computer-science/" target="_blank">Computer Science Department</a> of University College London.</p>
</div>
<div class="g-col-12 g-col-md-4">
<p><img src="https://realworlddatascience.net/foundation-frontiers/datasciencebites/posts/2025/02/05/images/neil-lawrence.png" class="img-fluid" alt="Neil Lawrenece, DeepMind Professor of Machine Learning at the University of Cambridge"></p>
<p><strong>Neil Lawrenece</strong> is the inaugural DeepMind Professor of Machine Learning at the University of Cambridge. He has been working on machine learning models for over 20 years. He recently returned to academia after three years as Director of Machine Learning at Amazon.</p>
</div>
</div>
<p><br>
</p>
<p><strong>View the full editorial board here:</strong> <a href="https://academic.oup.com/rssdat/pages/editorial-board" target="_blank">Editorial Board | RSS Data Science | Oxford Academic (oup.com)</a></p>
</section>
<section id="open-access" class="level2">
<h2 class="anchored" data-anchor-id="open-access">Open Access</h2>
<p><em>RSS: Data Science and Artificial Intelligence</em> is fully open access (OA) and is published by Oxford University Press (OUP). Your research will be free to read and can be accessed globally. An OA license increases the visibility of your research and creates more opportunities for fellow researchers to read, share, cite, and build upon your findings.</p>
<p>The cost of publishing Open Access may be covered under a Read and Publish agreement between OUP and the corresponding author’s institution. <a href="https://academic.oup.com/pages/open-research/read-and-publish-agreements/participating-journals-and-institutions" target="_blank">Find out if your institution is participating</a>. Members of the Royal Statistical Society can submit papers at a reduced cost.</p>
<p>Explore the journal’s website now <a href="https://www.academic.oup.com/rssdat" target="_blank">www.academic.oup.com/rssdat</a></p>
<div class="article-btn">
<p><a href="../../../../../../foundation-frontiers/index.html">Explore more data science ideas</a></p>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-6">
<dl>
<dt>Copyright and licence</dt>
<dd>
© 2023 Royal Statistical Society
</dd>
</dl>
<p><a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> <img style="height:22px!important;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"></a> This article is licensed under a Creative Commons Attribution (CC BY 4.0) <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;">International licence</a>.</p>
</div>
<div class="g-col-12 g-col-md-6">

</div>
</div>
</div>


</section>

 ]]></description>
  <category>AI</category>
  <category>Data Science</category>
  <category>Machine learning</category>
  <category>Deep learning</category>
  <category>Econometrics</category>
  <guid>https://realworlddatascience.net/foundation-frontiers/datasciencebites/posts/2025/02/05/DSAI-journal.html</guid>
  <pubDate>Wed, 05 Feb 2025 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/foundation-frontiers/datasciencebites/posts/2025/02/05/images/RSS-DS-AI-cover.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>Defining Purposes and Uses to Support the Development of Statistical Products in a 21st Century Census Curated Data Enterprise Environment</title>
  <link>https://realworlddatascience.net/applied-insights/case-studies/posts/2024/11/22/development-plan-2.html</link>
  <description><![CDATA[ 





<center>
Acknowledgments: This research was sponsored by the: <br> Unites States Census Bureau Agreement No.&nbsp;01-21-MOU-06 and <br> Alfred P. Sloan Foundation Grant No.&nbsp;G-2022-19536
</center>
<p><br> <br> <em>The views expressed in this article are those of the authors and not the Census Bureau.</em></p>
<section id="summing-it-up" class="level2" data-number="1">
<h2 data-number="1" class="anchored" data-anchor-id="summing-it-up"><span class="header-section-number">1</span> Summing it up</h2>
<p>We end where we began in the first article of our series. Through this four-part series, we introduced a Curated Data Enterprise (CDE) Framework (see Figure&nbsp;1) that can guide the development and dissemination of statistics broadly applicable to addressing social and economic issues while ensuring replicability and reusability. The CDE provides the scaffold for scaling the statistical product development of interest to the US Census Bureau and broadly applies to official statistics agencies <span class="citation" data-cites="keller2022bold">(Keller et al. 2022)</span>. We illustrated this through a use case on climate resiliency of skilled nursing facilities, highlighting the replicability and reusability of the capabilities that would benefit inclusion in a CDE.</p>
<div id="fig-cde" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-cde-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="https://realworlddatascience.net/applied-insights/case-studies/posts/2024/11/22/images/figure-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-cde-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;1: The CDE Framework starts with the purposes &amp; uses of the statistical products. The outer rectangle identifies the guiding principles for ethical, transparent, reproducible statistical product development and dissemination. The inner rectangle identifies the statistical product development steps.
</figcaption>
</figure>
</div>
<p>As noted in the first three articles, the process begins with articulating purposes and uses through stakeholder engagement and continues by leveraging that engagement, including subject matter expertise, to inform statistical product development. Eliciting purposes and uses from stakeholders and data users is facilitated by asking questions such as: &nbsp;</p>
<ol type="1">
<li><p>What questions keep you awake at night because you don’t have data insights to address them? What are those purposes and uses that you need statistical products to support?</p></li>
<li><p>How do we collaborate and engage with you to better understand your needs and help you identify gaps in understanding regarding purpose and use?</p></li>
<li><p>How do we prioritize what statistical products to develop first?</p></li>
</ol>
<p>Examples of purposes and uses that drive new statistical products include accurately measuring gig employment <span class="citation" data-cites="salvo2022gig">(Salvo, Shipp, and Zhang 2022a)</span>, migration due to extreme climate events <span class="citation" data-cites="salvo2022migration">(Salvo, Shipp, and Zhang 2022b)</span>, the various dimensions of housing affordability <span class="citation" data-cites="wu2023housing">(Wu et al. 2023)</span>, and addressing the undercount of young children <span class="citation" data-cites="Salvo2023children">(Salvo, Lancaster, and Shipp 2023)</span>. Other topics that require multiple sources and types of data include creating a household living budget based on the minimum necessary to ensure an adequate standard of living <span class="citation" data-cites="lancaster2023HLB">(Lancaster et al. 2023)</span> and using this budget as a starting point for measuring insecurity across components such as food or housing <span class="citation" data-cites="montalvo2023">(Montalvo et al. 2023)</span>.</p>
</section>
<section id="developing-an-end-to-end-e2e-curation-system" class="level2" data-number="2">
<h2 data-number="2" class="anchored" data-anchor-id="developing-an-end-to-end-e2e-curation-system"><span class="header-section-number">2</span> Developing an end-to-end (E2E) curation system</h2>
<p>Purposes and uses defined in use cases are important to support the rapid development of statistical products. These use cases will capture the imagination of those working to address today’s critical issues and advance public understanding and trust in federal statistics.&nbsp;The above paragraph provides examples of purposes and uses for which we have developed use cases.</p>
<p>Use cases are a powerful mechanism to promote methodological research to develop and implement capabilities needed in a CDE. The objectives are to undertake research projects that have the potential to create statistical products with explicit purposes and uses that will exercise the end-to-end (E2E) curation components.</p>
<p>When implemented, these proposed use cases will demonstrate a sequence of capabilities needed to build the CDE, such as agile data discovery, reusing modules and data (including synthetic data), tracking the provenance of collected and generated data, reusing synthetic data and methods to integrate many types of data, conducting statistical analysis involving heterogeneous data integration, and reviewing data and statistical results with an equity and ethics lens. These steps will be captured in an end-to-end curation system.</p>
<ol type="1">
<li><strong>Criteria for developing and evaluating use cases that will uncover the capabilities and research necessary to develop the CDE</strong></li>
</ol>
<p>Criteria are needed to evaluate, and partner with researchers and stakeholders in developing and implementing the capabilities to capture in the CDE. The choice of use cases, when curated, needs to provide unique insight into CDE capabilities and statistical product development. The capabilities to be developed include addressing some purpose and use that no single source of information can resolve, generating practical diagnostics to improve existing methods, creating pilot software, and validating new and improved statistical products. These criteria, developed through listening sessions and discussions with experts, guide the prioritization and selection of use cases and their evaluation after curation (see Table 2) <span class="citation" data-cites="keller2022bold">(Keller et al. 2022)</span>.</p>
<table class="caption-top table">
<caption>Table 2. Criteria for Selecting and Prioritizing Use Cases to Identify CDE Capabilities</caption>
<colgroup>
<col style="width: 100%">
</colgroup>
<tbody>
<tr class="odd">
<td><strong>Value and feasibility of the CDE approach described in the existing research (potential use case)</strong> to address emerging or long-standing issues, ie, its purpose and use over and above existing approaches to address high-priority problems. | | <strong>Stakeholders’</strong> challenges and issues as the source of purposes and uses. | | <strong>Subject matter experts</strong> to advise on the approach and implementation. | | <strong>Partners to access data</strong> from local and state governments, non-profit organizations, and the private sector, and strategies to overcome legal and administrative barriers to such access that benefits to both the providers and recipients of the data. | <strong>Survey, administrative, opportunity, and procedural data</strong> from multiple sources (eg, local, state, federal, third-party) to address the purpose and use (issue) in an integrated way. There are well-defined data ingestion and governance requirements. | | <strong>Computation and measurement requirements for statistical products include</strong> the unit(s) of analysis and their characteristics, temporal sequence, geocoded location data, and methods for imputations, projections, and statistical analysis. | | <strong>Equity and ethical dimensions are considered</strong> at each step to ensure that the use case provides fair and accurate representation across groups and an assessment that the potential benefits outweigh the potential harm. | | <strong>Evidence of CDE capabilities</strong> to be built, including the code, data, and documentation to create the statistical products, which can be described in the curation step. | | <strong>Statistical products</strong> include integrated data sources, indicators, maps, visualizations, storytelling and analysis. | | Potential viability of proposed <strong>dissemination platforms</strong> for interactive access to data products at all levels of data acumen <span class="citation" data-cites="keller2021acumen">(Keller and Shipp 2021)</span> while adhering to confidentiality and privacy rules. |</td>
</tr>
</tbody>
</table>
<ol start="2" type="1">
<li><strong>An end-to-end curation process</strong></li>
</ol>
<p>Curation is an end-to-end process defined by the context of the purposes and uses that document the decisions and trade-offs at each step in the CDE Framework. The following curation definition will be used as it serves the CDE’s vision.</p>
<p><strong><em>Curation</em></strong> involves documenting, for each statistical product, the <strong>inputs</strong> from which the product is derived, the <strong>wrangling</strong> used to transform the information into product, and the <strong>statistical product</strong> itself. Purposes and uses provide the context for each statistic and statistical product.</p>
<p>This definition has evolved from numerous stakeholder discussions via listening sessions and discussions with Census Bureau staff. <span class="citation" data-cites="nusser2024curation faniel2019context nasem2022transparency">(Nusser et al. forthcoming; Faniel, Frank, and Yakel 2019; NASEM 2022)</span>.</p>
<p>As use cases are curated, the CDE capabilities will evolve to quickly develop statistical products. These curated use cases are integral to developing an E2E curation process for the CDE. &nbsp;</p>
<ol start="3" type="1">
<li><strong>Invitation to contribute purpose and use ideas for developing new statistical products</strong></li>
</ol>
<p>The CDE development aims to curate a significant number of use cases that address social and economic issues that have the potential to define capabilities to be built in the CDE. Initially, they are seeking ideas for purposes and uses to define these use cases and statistical products.</p>
<p>The skilled nursing facility use case included code, data, and documentation to calculate the probability of workers getting to work during a weather event, resilience indicators at the county or sub-county level, alternative skilled nursing home deficiency measures, and other capabilities.</p>
<p><strong>Incorporating capabilities in the CDE</strong></p>
<p>To accelerate the development of statistical products, the Census Bureau will develop use cases to articulate and create CDE capabilities. This requires identifying those valuable nuggets for learning and quickly translating and incorporating this information into the CDE. Examples of critical capabilities of interest are learning about the utility of synthetic data, the ability to aggregate data into custom geographies, and combining different units of analysis. The expected outcome is the creation of an innovative 21<sup>st</sup> Century Census Curated Data Enterprise focused on purposes and uses that overcome the limitations and challenges of today’s survey-alone model. &nbsp;</p>
<p>The 21<sup>st</sup> Century Census Curated Data Enterprise development presents an opportunity for researchers to help drive the development of the CDE as the foundation for creating new statistical products. The US Census Bureau is seeking ideas for purposes and uses that will define new statistical products. They are interested in research projects (use cases) that are guided by the CDE framework as potential new statistical products. They want to learn from and understand your experiences in using the CDE framework, for example, what worked well, what challenges you faced, how each step in the framework was curated, and what capabilities are replicable and reusable for developing and enhancing statistical products.</p>
<div class="nav-btn-container">
<div class="grid">
<div class="g-col-12 g-col-sm-6">
<div class="nav-btn">
<p><a href="../../../../../../applied-insights/case-studies/posts/2024/11/19/use-case-2.html">← Part 3: Climate resiliency of skilled nursing facilities</a></p>
</div>
</div>
</div>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-12">
<dl>
<dt>About the authors</dt>
<dd>
<strong>Stephanie Shipp</strong> leads the Curated Data Enterprise research portfolio and collaborates with the US Census. She is an economist with experience in data science, survey statistics, public policy, innovation, ethics, and evaluation.
</dd>
<dd>
<strong>Joseph Salvo</strong> is a demographer with experience in US Census Bureau statistics and data. He makes presentations on demographic subjects to a wide range of groups about managing major demographic projects involving the analysis of large data sets for local applications.
</dd>
<dd>
<strong>Vicki Lancaster</strong> is a statistician with expertise in experimental design, linear models, computation, visualizations, data analysis, and interpretation.
</dd>
</dl>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>Copyright and licence</dt>
<dd>
© 2024 Stephanie Shipp
</dd>
</dl>
<p><a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> <img style="height:22px!important;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"></a> This article is licensed under a Creative Commons Attribution 4.0 (CC BY 4.0) <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> International licence</a>. Thumbnail photo by <a href="https://unsplash.com/@goumbik">Lukas Blazek</a> on <a href="https://unsplash.com/photos/turned-on-black-and-grey-laptop-computer-mcSDtbWXUZU">Unsplash</a>.</p>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>How to cite</dt>
<dd>
Shipp S, Salvo J, Lancaster V (2024). “Statistical Products in a 21<sup>st</sup> Century Census Curated Data Enterprise Environment” Real World Data Science, November 22, 2024. <a href="https://realworlddatascience.net/applied-insights/case-studies/posts/2024/11/22/development-plan-2.html">URL</a>
</dd>
</dl>
</div>
</div>
</div>



</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0">
<div id="ref-faniel2019context" class="csl-entry">
Faniel, Ixchel M, Rebecca D Frank, and Elizabeth Yakel. 2019. <span>“Context from the Data Reuser’s Point of View.”</span> <em>Journal of Documentation</em> 75 (6): 1274–97. <a href="https://doi.org/10.1108/JD-08-2018-0133">https://doi.org/10.1108/JD-08-2018-0133</a>.
</div>
<div id="ref-keller2022bold" class="csl-entry">
Keller, Sallie, Kenneth Prewitt, John Thompson, Steve Jost, Christopher Barrett, Sarah Nusser, Joseph Salvo, and Stephanie Shipp. 2022. <span>“A 21st Century Census Curated Data Enterprise. A Bold New Approach to Create Official Statistics. Technical Report.”</span> <em>Proceedings of the Biocomplexity Institute</em> BI-2022-1115: 297–323. <a href="https://doi.org/10.18130/r174-yk24">https://doi.org/10.18130/r174-yk24</a>.
</div>
<div id="ref-keller2021acumen" class="csl-entry">
Keller, Sallie, and Stephanie Shipp. 2021. <span>“Data Acumen in Action.”</span> <em>Notices of the American Mathematical Society</em>. <a href="https://www.ams.org/journals/notices/202109/noti2353/noti2353.html?adat=October%202021&amp;trk=2353&amp;galt=feature&amp;cat=feature&amp;pdfissue=202109&amp;pdffile=rnoti-p1468.pdf
  ">https://www.ams.org/journals/notices/202109/noti2353/noti2353.html?adat=October%202021&amp;trk=2353&amp;galt=feature&amp;cat=feature&amp;pdfissue=202109&amp;pdffile=rnoti-p1468.pdf </a>.
</div>
<div id="ref-lancaster2023HLB" class="csl-entry">
Lancaster, V., M. Montalvo, J. Salvo, and S. Shipp. 2023. <span>“The Importance of Household Living Budget in the Context of Measuring Economic Vulnerability: A Census Curated Data Enterprise Use Case Demonstration.”</span> <em>Proceedings of the Biocomplexity Institute</em> Technical Report. TR# BI-2023-258. <a href="https://doi.org/10.18130/p43z-c742">https://doi.org/10.18130/p43z-c742</a>.
</div>
<div id="ref-montalvo2023" class="csl-entry">
Montalvo, Cesar, Vicki Lancaster, Joseph Salvo, and Stephanie Shipp. 2023. <span>“The Importance of Household Living Budget in the Context of Food Insecurity: A Census Curated Data Enterprise Use Case Demonstration.”</span> <em>Proceedings of the Biocomplexity Institute, Technical Report BI-2023-261</em>. <a href="https://doi.org/10.18130/2kgx-tv50">https://doi.org/10.18130/2kgx-tv50</a>.
</div>
<div id="ref-nasem2022transparency" class="csl-entry">
NASEM. 2022. <span>“Transparency in Statistical Information for the National Center for Science and Engineering Statistics and All Federal Statistical Agencies.”</span> <em>National Academies of Science, Engineering, and Medicine</em>. <a href="https://doi.org/10.1162/99608f92.17405bb6">https://doi.org/10.1162/99608f92.17405bb6</a>.
</div>
<div id="ref-nusser2024curation" class="csl-entry">
Nusser, S., S. Keller, S. Shipp, Z. Zhu, and E. Wu. forthcoming. <span>“Curation in the Context of the Census Curated Data Enterprise (CDE).”</span> <em>TBD</em>, forthcoming.
</div>
<div id="ref-Salvo2023children" class="csl-entry">
Salvo, J., V. Lancaster, and S. Shipp. 2023. <span>“The Net Undercount of Children Under 5 Years of Age in the Decennial Census: An Art of the Possible Use Case.”</span> <em>Proceedings of the Biocomplexity Institute</em> Technical Report. TR# BI-2023-000. <a href="https://doi.org/10.18130/nzyj-m621">https://doi.org/10.18130/nzyj-m621</a>.
</div>
<div id="ref-salvo2022migration" class="csl-entry">
Salvo, J., S. Shipp, and S. Zhang. 2022b. <span>“Building a Case Study of Domestic Migration and the Curated Data TR# 2022-027 - Essential Elements.”</span> <em>Proceedings of the Biocomplexity Institute</em> Technical Report BI 2022-027 (2022b). <a href="https://doi.org/10.18130/bcwa-gt69">https://doi.org/10.18130/bcwa-gt69</a>.
</div>
<div id="ref-salvo2022gig" class="csl-entry">
———. 2022a. <span>“Defining the Role of Gig Employment in the Post-Pandemic World of Work.”</span> <em>Proceedings of the Biocomplexity Institute</em> Technical Report BI 2022-026 (2022a).<a href=".&nbsp;https://doi.org/10.18130/wkx0-4y46">&nbsp;https://doi.org/10.18130/wkx0-4y46</a>.
</div>
<div id="ref-wu2023housing" class="csl-entry">
Wu, E., J. Salvo, V. Lancaster, and S. Shipp. 2023. <span>“Housing Affordability – an Art of the Possible Use Case to Develop the 21st Century Census Curated Data Enterprise.”</span> <em>Proceedings of the Biocomplexity Institute</em> Technical Report BI-2023-262. <a href="https://doi.org/10.18130/qgkd-va29">https://doi.org/10.18130/qgkd-va29</a>.
</div>
</div></section></div> ]]></description>
  <category>Public Policy</category>
  <category>Data Analysis</category>
  <category>Data Integration</category>
  <category>Curation</category>
  <category>Statistical Products</category>
  <guid>https://realworlddatascience.net/applied-insights/case-studies/posts/2024/11/22/development-plan-2.html</guid>
  <pubDate>Fri, 22 Nov 2024 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/applied-insights/case-studies/posts/2024/11/22/images/figure-1.png" medium="image" type="image/png" height="81" width="144"/>
</item>
<item>
  <title>Translating the Curated Data Model into Practice - Climate resiliency of skilled nursing facilities</title>
  <dc:creator>Vicki Lancaster, Stephanie Shipp, Sallie Keller, Henning Mortveit, Samarth Swarup, Aaron Schroeder, and Dawen Xie &lt;br /&gt; University of Virginia, Biocomplexity Institute</dc:creator>
  <link>https://realworlddatascience.net/applied-insights/case-studies/posts/2024/11/19/use-case-2.html</link>
  <description><![CDATA[ 





<center>
Acknowledgments: This research was sponsored by the: <br> Unites States Census Bureau Agreement No.&nbsp;01-21-MOU-06 and <br> Alfred P. Sloan Foundation Grant No.&nbsp;G-2022-19536
</center>
<p><br> <br></p>
<section id="introduction" class="level2" data-number="1">
<h2 data-number="1" class="anchored" data-anchor-id="introduction"><span class="header-section-number">1</span> Introduction</h2>
<p>Here, we demonstrate how the CDE Framework can be implemented for a research use case related to skilled nursing facilities. The framework provides the guiding principles for ethical, transparent, and reproducible research and dissemination and the research process for developing the statistical product.</p>
<p>Across the US, federally regulated skilled nursing facilities (SNFs) provide essential care, rehabilitation, and related health services to about 1.3 million people. An SNF is a facility that meets specific federal regulatory certification requirements that enable it to provide short-term inpatient care and services to patients who require medical, nursing, or rehabilitative services. Their patients can be among the most vulnerable members of our society, and yet, historically, SNFs have not been incorporated into existing emergency response systems. For example, during the 2004 Florida hurricane season, SNFs were given the same priority as day spas for restoring electricity, telephones, water, and other essential services <span class="citation" data-cites="hyer2006establishing">(Hyer et al. 2006)</span>. Even worse are the deaths of SNF residents in Louisiana following Hurricanes Katrina and Rita in 2005 <span class="citation" data-cites="dosa2008controversy">(Dosa et al. 2008)</span>. This was still an issue in 2021. In Louisiana, 15 SNF residents died when evacuated to a warehouse during Hurricane Ida (2021), and 12 died in Florida as a result of Hurricane Irma (2017). In both instances, the deaths were attributed to extreme heat and lack of electricity <span class="citation" data-cites="skarha2021association">(Skarha et al. 2021)</span>.</p>
<p>These events prompted the <span class="citation" data-cites="sheet2022protecting">(The White House 2022)</span> initiative, <em>Protecting Seniors by Improving Safety and Quality of Care in the Nation’s Nursing Homes</em>, stating, ‘All people deserve to be treated with dignity and respect and to have access to quality medical care.’</p>
<p>However, there are questions that need to be addressed to best protect SNFs and their residents. For example, how resilient are SNFs in extreme climate events? This use case demonstration shows how we built a new statistical product to address this question using the CDE Framework <span class="citation" data-cites="lancaster2023CDE">(Lancaster et al. 2023)</span>.</p>
</section>
<section id="purposes-and-uses" class="level2" data-number="2">
<h2 data-number="2" class="anchored" data-anchor-id="purposes-and-uses"><span class="header-section-number">2</span> Purposes and uses</h2>
<p>A skilled nursing facility (SNF) is a federally regulated nursing facility with the staff and equipment to provide skilled nursing care, skilled rehabilitation services, and other related health services <span class="citation" data-cites="cmsglossary">(Medicare &amp; Medicaid Services 2023)</span>. The context of this use case is to create a baseline picture of SNFs in Virginia and then integrate information on the risk of extreme flood events to assess facility and community preparedness – for example, how likely are the nursing staff<sup>1</sup> to make it to the facility in the event of a flood?</p>
<p>This use case has two parts. The first creates a baseline data picture of SNFs, bringing together data about the residents, nursing staff, and SNF characteristics. The second addresses two issues raised in the <span class="citation" data-cites="sheet2022protecting">(The White House 2022)</span> initiative: emergency preparedness and nurse staffing. We frame these issues into three purpose and use questions with the ultimate goal of creating statistical products that address these questions:</p>
<ol type="1">
<li><p>Can SNF workers get to work during an extreme flood event?</p></li>
<li><p>Are SNFs prepared for a flood emergency?</p></li>
<li><p>Can communities support SNFs during an emergency?</p></li>
</ol>
</section>
<section id="statistical-product-development-stages" class="level2" data-number="3">
<h2 data-number="3" class="anchored" data-anchor-id="statistical-product-development-stages"><span class="header-section-number">3</span> Statistical product development stages</h2>
<p><strong>Subject matter input and literature review</strong></p>
<p>The subject matter experts consulted included nursing facility administrators, SNF resident advocates, demographers, and researchers. Our discussions and literature review informed us of the many federal policies governing SNFs regarding inspections and data reporting requirements (procedural data). In addition, we were told about non-public data sources on residents and SNF staff that were aggregated to the SNF level and provided to the public under a grant from the National Institute on Aging. This information was important since we had yet to come across this source in our data discovery process. The dialogue with experts and our literature review helped us generate a ‘wish list’ of variables we used to inform our data discovery process that we visualized into a conceptual data map (see Figure&nbsp;1).</p>
<div id="fig-data" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-data-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="https://realworlddatascience.net/applied-insights/case-studies/posts/2024/11/19/images/figure-3.png" class="img-fluid quarto-figure quarto-figure-center figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-data-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;1: Conceptual Data Map Aligned to Purpose and Use: The conceptual data map displays the results of our data discovery. The team identifies the data needs informed by expert elicitation and literature review. For this use case the data discovery took three phases: (1) create a data picture of SNF owners, nursing staff, and residents, and the communities the facilities reside in; (2) identify the potential risks of a severe flood events, coastal and riverine; and (3) identify the potential weakness in the SNF’s and community’s ability to respond.
</figcaption>
</figure>
</div>
<p><strong>Data discovery</strong></p>
<p>Data discovery focused on identifying data sources to address the purpose and use questions and was informed by the conceptual data map.</p>
<p>For the first question – Can SNF workers get to work during an extreme flood event? – we discovered and used proprietary synthetic population, transportation routes, building data sources, and publicly available flood data. The <a href="https://developer.here.com/documentation">HERE Premium Streets</a> proprietary data includes information about roads, such as type of road, speed limits, number of lanes, etc. The proprietary synthetic population data, Building Knowledge Base (BKB), are used to identify where SNF workers live and work to map transportation routes from home to work <span class="citation" data-cites="mortveitNSSAC">(Mortveit, Xie, and Marathe 2023)</span>. Publicly available data from the Federal Emergency Management Administration (FEMA) provided flooding risk estimates along the routes from nursing staff homes to the SNF.</p>
<p>For the second question – Are SNFs prepared for a flood emergency? – we used Center for Medicare and Medicaid (CMS) SNF inspection and deficiency data as a proxy for preparedness. We also examined SNF residents’ physical and mental health to assess SNF emergency preparedness. For example, if most residents faced mobility challenges, the SNF would need more resources available during an emergency to move residents to a safer facility. We used data about residents from the Long Term Care Focus <span class="citation" data-cites="brown2022ltcfocus">(LTCFocus 2022)</span> Public Use Data sponsored by the National Institute on Aging (Brown University 2022).</p>
<p>We used data to measure community resilience, assets, and risks by geography at the county, city, and census tract levels to address the third question, Can communities support SNFs during an emergency? These data included:</p>
<ul>
<li>Health professional shortages area (HRSA 2022)</li>
<li>Shelter facilities and emergency service providers data <span class="citation" data-cites="dhs2022hifld">(Homeland Security: Geospatial Management Office 2022)</span></li>
<li>Community Resilience Indicator Analysis and National Risk Index for Natural Hazards <span class="citation" data-cites="FEMA2022a">(FEMA 2022)</span>.</li>
</ul>
<p>All data are provided in a <a href="https://github.com/uva-bi-sdad/census_cde_demo_2/tree/main/data">GitHub</a> repository along with their metadata, except for the three proprietary data sources. Articles about how the synthetic estimates are constructed are provided for two of these proprietary data sources. The third data source was obtained from a private-sector vendor whose data and documentation are proprietary; a link is provided to their website.</p>
<p><strong>Data ingest and governance</strong></p>
<p>All the public data, metadata, code, statistical products, data processes, and relevant literature on SNF policies and regulations are stored in a <a href="https://github.com/uva-bi-sdad/census_cde_demo_2/tree/main">GitHub</a> repository.</p>
<p>In our experience, data wrangling is the most time-consuming and challenging part of product development. This speaks directly to the benefit of the CDE; once a researcher has wrangled together multiple data sources, it can be made available to other researchers.</p>
<p>The two predominant issues with data wrangling for this Use Case included reconciling data sources that contain data on the same topic and creating linkages between data sources. For example, we reviewed three hospital data sources:</p>
<ol type="1">
<li><a href="https://hifld-geoplatform.opendata.arcgis.com/">Homeland Security Infrastructure Foundation-Level Data</a> (HIFLD) (DHS 2022)</li>
<li><a href="https://healthdata.gov/dataset/COVID-19-Reported-Patient-Impact-and-Hospital-Capa/6xf2-c3ie">HealthData.gov - COVID-19 Reported Patient Impact and Hospital Capacity by State</a> (HHS 2022)</li>
<li><a href="https://vhha.com/about-virginia-hospitals/">Map of VHHA Hospital and Health System Members</a> (Virginia Hospital &amp; Healthcare Association 2022)</li>
</ol>
<p>We observed inconsistences and omissions across the three data sources including:&nbsp;</p>
<ul>
<li>non-standard hospital names and hospital classification types</li>
<li>inconsistent availability of hospital IDs (such as Medicare Provider Number) &nbsp;</li>
<li>conflicting geographic information, including address, latitude, and longitude.</li>
</ul>
<p>We did not attempt to reconcile these inconsistencies for the demonstration but decided to use a single source for shelter facility and emergency service provider data. We used <a href="https://hifld-geoplatform.opendata.arcgis.com/">HIFLD</a> data since they provided the most current data (DHS 2022). The use of these data reinforces the purpose of the use case – to illuminate the challenges in creating statistical products and what the Census Bureau would need to consider.</p>
<p>Similar inconsistencies made it difficult to link data sources using geographic variables. For example, we used shelter facility and emergency service provider data sources from the HIFLD – including hospitals, Red Cross chapter facilities, National Shelter System Facilities, emergency medical service stations, fire stations, and urgent care facilities – to calculate a metric for potential community support. The goal was to place each facility in a Virginia county or independent city. Virginia is divided into 95 counties, and 38 independent cities considered county-equivalents for census purposes, and in some cases, there is a county and a city with the same name (eg, Richmond County and Richmond City, each in different locations in Virginia). It was necessary to <a href="https://en.wikipedia.org/wiki/Canonicalization">canonicalize</a> the county and city names (when available), which meant aligning upper and lower cases, removing unnecessary characters, and distinguishing between county and city.<sup>2</sup></p>
<p>The challenge with locating shelter facilities and emergency service providers within a county or independent city was using different variables to identify their location (latitude and longitude, address, ZIP code<sup>3</sup>, Federal Information and Processing Standard (FIPS) code, and county/city name). In cases where the data source only had a ZIP or FIPS code, a Department of Housing and Urban Development crosswalk was used to link the two codes; in other cases, a crosswalk that linked non-independent cities and towns to counties was used; and in others, a crosswalk that linked FIP codes to counties and independent cities. Researchers would benefit from exhaustive crosswalks between all variables on the same topic, such as location variables, facility names, and identification numbers, to reduce the time spent on data wrangling.</p>
<p>Regarding data products related to popular indices, such as climate disaster risks and community resilience, they are operationalized differently across the various departments and agencies within the federal and state governments and private and non-profit sectors. It is an enormous task to review the methodology and technology reports (if available) to understand their differences and decide which versions are most relevant (fitness-for-purpose) for a particular use case. Again, after reviewing the options for this use case, we determined that the National Risk Index for riverine and coastal floods from FEMA was the best option for climate risk estimates. The detailed technical report, <em>National Risk Index Technical Document</em> <span class="citation" data-cites="FEMA2021risk">(FEMA 2021)</span>, provides a clear assessment of the assumptions and limitations of the data and a description of how the risk estimates were derived. Researchers would benefit from guidance on the numerous constructions of indices on the same topic. A use case on a specific index topic could be used to highlight differences and similarities among indices, which would help with data wrangling and fitness-for-use. Ideally, the use case could benchmark the various constructions and provide a statistical assessment.</p>
<section id="question-1-can-snf-workers-get-to-work-during-an-extreme-flooding-event" class="level3" data-number="3.1">
<h3 data-number="3.1" class="anchored" data-anchor-id="question-1-can-snf-workers-get-to-work-during-an-extreme-flooding-event"><span class="header-section-number">3.1</span> <strong>Question 1: Can SNF workers get to work during an extreme flooding event?</strong></h3>
<p>Sufficient nursing staff is of significant concern to assure resident safety and quality of care.</p>
<p>Since proprietary synthetic population data and commercial sector digitized mapping data were used to construct the routes SNF nursing staff are likely to take from home to work, only an outline of the computational process used to identify the routes is provided. Publicly available data from FEMA were used to estimate flooding risk along a particular route. Below is a general description of the modeling steps and the proprietary data used to assess SNF vulnerability as a function of the nursing staff’s inability to report to work due to the transportation infrastructure <span class="citation" data-cites="choupani2016population">(Choupani and Mamdoohi 2016)</span>.</p>
<p><strong>Computational modules</strong></p>
<p>Here is the basic outline of the process that uses proprietary data that starts at network construction and ends with routes. For more details, see the GitHub repository: <a href="https://github.com/uva-bi-sdad/census_cde_demo_2/blob/main/documents/products/processes/commute_vulnerability/algorithm.md">Vulnerability of SNFs concerning Commuting</a>.</p>
<ol type="1">
<li>Extract network data from HERE (2021 Q1 in this use case).</li>
<li>Process the extracted data to form a network suitable for routing. This includes inference of speed limits for road links where such data is missing.</li>
<li>Prepare origin-destination pairs. In this case, the list of locations pairs a worker’s home and work locations. The person is constructed in the synthetic population pipeline, and residences and workplaces are derived through the data fusion process used to construct the NSSAC building database.</li>
<li>Construct routes using the Quest router.</li>
</ol>
<p>Once the routes to an SNF were established, the expected number of nursing staff at an SNF during a flood event could be calculated as the sum of the probabilities of each worker being able to commute to work during a flood event. A computational model was developed using the following data:</p>
<ul>
<li>SNF locations in Virginia from the Centers for Medicare &amp; Medicaid Services (CMS);</li>
<li>Home locations of workers at each SNF assigned from the synthetic population and Building Knowledge Base <span class="citation" data-cites="beckman1996creating mortveitNSSAC">(Beckman, Baggerly, and McKay 1996; Mortveit, Xie, and Marathe 2023)</span>;</li>
<li>Virginia road networks; and</li>
<li>FEMA census tract-level riverine and coastal flood risks.</li>
</ul>
<p>Using router software, the Virginia road network was used from the HERE map data to compute each nursing staff’s likely route to their SNF. Routers are commonly used within transportation and traffic simulators. The router software used for this demonstration is a highly parallelizable router previously developed in BI NSSAC, known as the Simba router <span class="citation" data-cites="barrett2013planning">(Barrett et al. 2013)</span>.</p>
<p>The FEMA risk data provide the riverine and coastal flood risks for each census tract in Virginia. Given the routes, the FEMA riverine and coastal flood risks were used to estimate the probability of the nursing staff making it to work. The FEMA technical document <em>National Risk Index Technical Document</em> <span class="citation" data-cites="FEMA2021risk">(FEMA 2021)</span> provides information on how natural hazard risks are calculated. We use these risk estimates ranging from 0 to 100 as a proxy for the probability a worker can reach the SNF by dividing by 100. For example, we assume a risk is zero if there is zero probability of being unable to reach the SNF due to an extreme flood event.</p>
<p>In contrast, a risk of 100 indicates the roads are underwater, and the probability of being unable to reach the SNF is one. The maximum risks along transportation routes leading to an SNF range from 0 to 47 for riverine flooding and 0 to 40 for coastal flooding. We assume the combined value of the maximum riverine and coastal flood risks along a worker’s transportation routes, divided by 100, is the worker’s probability of not getting to work during a flooding event.</p>
<p>Since we do not have data on the exact home locations of the nursing staff, we estimated how many could reach the facility by taking a random sample (whose size is the CMS average daily nursing staff<sup>4</sup> for an SNF) from the possible routes identified using the HERE Virginia road network. We calculated the average with a 95% nonparametric confidence interval. The 283 SNFs used in our research have an average daily nursing staff of 12,609. Using the above approach, we estimated that 10,005 (95% CI: 9,013, 10,700) or 79% can get work during an extreme flood event. The individual SNF nursing staff percentage who can make it to work ranges from 48% to 93%.</p>
<p>Figure&nbsp;2 visualizes this analysis for the 283 SNFs ordered by the observed average daily nursing staff numbers at the facility from smallest to largest, displayed using the orange line. The black line indicates the expected number in an extreme flood event and the 95% nonparametric confidence interval (grey band). The code for Figure&nbsp;2 is provided in the <a href="https://github.com/uva-bi-sdad/census_cde_demo_2/blob/main/source_code/analyses/VA_Probability_of_Getting_to_SNF.R">GitHub</a> repository.</p>
<div id="fig-ns" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-ns-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="https://realworlddatascience.net/applied-insights/case-studies/posts/2024/11/19/images/figure-4.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="2000">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-ns-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2: SNF Average Observed and Expected Average Daily Nursing Staff Numbers: The horizontal axis is ordered by the size of the nursing staff at the facility from smallest to largest. The orange line displays the observed average daily nursing staff numbers. The black line displays the estimated numbers in the event of an extreme coastal and/or riverine flood event. The grey band is the 95% nonparametric confidence interval.
</figcaption>
</figure>
</div>
<p>For example, in King George County, the SNF is Heritage Hall King George (Federal Provider Number 495300 in Figure&nbsp;3), located near the Potomac River, which opens to the Chesapeake Bay. According to CMS, the Heritage Hall King George facility has an average daily skilled nursing staff of 41. Using the HERE Virginia road network, we identified 101 routes the staff could use to reach the facility. The combined maximum coastal and riverine flood risks along these routes ranged from 5.6 to 66.7; a random sample of 41 from the 101 routes gives an average probability of reaching the facility of 0.74 with a 95% nonparametric confidence interval of [0.65, 0.80]. These were used to estimate the average number of nursing staff at the facility, 30, during a flood event, along with a 95% nonparametric confidence interval [14, 38]. Publicly available data from the Federal Emergency Management Administration (FEMA) provided flooding risk estimates along the routes from the nursing staff home to the SNF along with proprietary road and building information<strong>.</strong></p>
<div id="fig-map" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-map-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="https://realworlddatascience.net/applied-insights/case-studies/posts/2024/11/19/images/figure-5.png" class="img-fluid quarto-figure quarto-figure-center figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-map-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;3: An Example of Nursing Staff Routes to Heritage Hall King George SNF: Routes that workers can take to work at Heritage Hall  King George SNF FPN 495300 (identified with the black oval). The risk levels of each road are identified with colors, from low risk (blue), medium-low (yellow), orange (medium), red (medium-high), to high risk (dark red). The risk scores are used to calculate the probability of a worker getting to work during an extreme flood event using publicly available FEMA data and proprietary road and building data.
</figcaption>
</figure>
</div>
</section>
<section id="question-2.-are-snfs-prepared-for-emergencies" class="level3" data-number="3.2">
<h3 data-number="3.2" class="anchored" data-anchor-id="question-2.-are-snfs-prepared-for-emergencies"><span class="header-section-number">3.2</span> <strong>Question 2. Are SNFs prepared for emergencies?</strong></h3>
<p>To address this question, we examined how prepared SNFs are for emergencies using annual inspection and deficiency data as a proxy for preparedness. CMS issues deficiencies to SNFs that fail to meet federal Medicare and Medicaid preparedness standards. Every deficiency is classified into one of 12 categories based on the scope and severity of the deficiency. There are two broad types of non-health-related deficiencies:</p>
<ul>
<li><p>Emergency Preparedness Deficiencies – There are four elements of emergency preparedness. They cover an emergency plan, policies and procedures, a communication plan, and training and testing.</p></li>
<li><p>Fire Life Safety Code – The set of fire protection requirements are designed to provide a reasonable degree of safety from fire. They cover construction, protection, and operational features designed to provide safety from fire, smoke, and panic.</p></li>
</ul>
<p>We calculated separate Emergency Preparedness and Fire Life Safety Code deficiency indices to combine them to create a single index to measure SNF preparedness and distinguish between high and low performing SNFs. The computation of the indices has four steps.</p>
<ol type="1">
<li><p><em>Number of deficiencies</em>: For each SNF, the total number of deficiencies during the past four years, 2018-2022, was divided by the number of SNF inspections over the same period to estimate the average number of deficiencies per inspection.</p></li>
<li><p><em>Time to resolve deficiencies</em>: We next computed the average number of days it took to resolve each deficiency.</p></li>
<li><p><em>Scope and severity of deficiencies</em>: We then transformed the deficiency letter inspection rating for scope and severity to a numerical weight using the CMS technical guide, <em>Care Compare Nursing Home Five-Star Quality Rating System</em> <span class="citation" data-cites="CMS2022design">(Medicare &amp; Medicaid Services 2022)</span>,and averaged the ratings.</p></li>
<li><p>The estimates from these three steps were summed to compute separate Emergency Preparedness and Fire Life Safety Code deficiency indices (see Figure&nbsp;4) and are provided for reuse in a .csv file on <a href="https://github.com/uva-bi-sdad/census_cde_demo_2/blob/main/documents/products/processes/derived_variables/va_snf_deficiency_indices_k_e.csv">GitHub</a>.</p></li>
</ol>
<p>Figure&nbsp;4 displays the results of an exploratory data analysis for each index. These analyses assessed fitness-for-use; we wanted to construct an indicator with sufficient variability to discriminate between high and low-performing SNFs. It is evident we accomplished this in Figure&nbsp;4 there are SNFs with indices outside the main body of the data. We summed the Emergency Preparedness and Fire Life Safety Code indices and categorized them into high, medium, low, and no deficiencies.</p>
<div id="fig-def" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-def-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="https://realworlddatascience.net/applied-insights/case-studies/posts/2024/11/19/images/figure-6.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="900">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-def-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4: Exploratory Data Analysis Visualizations for the Emergency Preparedness and Fire Life Safety Code Deficiencies
</figcaption>
</figure>
</div>
</section>
<section id="question-3-can-communities-support-snfs-during-emergencies" class="level3" data-number="3.3">
<h3 data-number="3.3" class="anchored" data-anchor-id="question-3-can-communities-support-snfs-during-emergencies"><span class="header-section-number">3.3</span> <strong>Question 3: Can communities support SNFs during emergencies?</strong></h3>
<p>To answer this question, we computed a community resiliency index using the US Census American Community Survey and the guidance provided by the <em>Homeland Security document Community Resilience Indicator Analysis: County-Level Analysis of Commonly Used Indicators from Peer-Reviewed Research</em> <span class="citation" data-cites="edgemon2018community">(Edgemon et al. 2018)</span><em>.</em> The index was constructed by summing the county (census tract) level percentages for the following variables:</p>
<ul>
<li>fraction employed</li>
<li>fraction with no disability</li>
<li>fraction with a high school diploma or greater</li>
<li>fraction of households with at least one vehicle</li>
<li>reverse GINI Index – so all indicators are in a positive direction.</li>
</ul>
<p>Figure&nbsp;5 displays the combined deficiency indices, Emergency Preparedness + Fire Life Safety Code, for each SNF with the choropleth map for the community resilience index at the census tract level. We also examined the number of shelter facilities and emergency service providers and the availability of medical staff per 10,000 residents. We constructed isochrones to establish the distance from the SNF to these potential sources of support. Working on this component of the use case highlighted the need for cross-agency data, pointing to the utility of future strategic partnering between the US Census Bureau, CMS, and FEMA.</p>
<div id="fig-cri" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-cri-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="https://realworlddatascience.net/applied-insights/case-studies/posts/2024/11/19/images/figure-7.png" class="img-fluid quarto-figure quarto-figure-center figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-cri-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;5: 2020 Population Resilience Composite Index for Virginia Census Tracts: The light yellow tracts are the least resilient, and the dark green are the most resilient. The locations of the 283 SNFs are identified with filled circles, orange circles with the highest
</figcaption>
</figure>
</div>
<p>In addition to describing the population using a resilience index, we also developed a measure to present the number of shelter facilities and emergency service providers (data from Homeland Security / Homeland Infrastructure Foundation Level Data) and the availability of medical doctors (MDs) and Doctor of Osteopathic Medicine (ODs) who provide direct patient care (HRSA 2022) (Figure&nbsp;6).&nbsp;</p>
<p>The number of MDs and ODs is described as a primary care health professional shortage area. HRSA defines these contiguous areas where primary medical care professionals are overutilized, excessively distant, or inaccessible to the population of the area under consideration. Figure&nbsp;6 (bottom) shows that approximately one-third of the counties and independent cities have health professional shortage areas across their entire boundary, and another 40 percent have shortages within parts of their boundaries.</p>
<div id="fig-help" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-help-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="https://realworlddatascience.net/applied-insights/case-studies/posts/2024/11/19/images/figure-8.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="1000">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-help-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;6: Assessment of the number of shelter facilities and emergency service providers per 10,000 population (top) and medically underserved areas (bottom): On both maps, the lighter the color, the more in need is the population of shelter facilities and emergency services (top chart) or health professionals (bottom chart). The location of the 283 SNFs are identified with filled circles, orange circles are those with the highest deficiency index and grey circles are those with no deficiencies.
</figcaption>
</figure>
</div>
</section>
</section>
<section id="guiding-principles-for-ethical-transparent-reproducible-statistical-product-development-and-dissemination." class="level2" data-number="4">
<h2 data-number="4" class="anchored" data-anchor-id="guiding-principles-for-ethical-transparent-reproducible-statistical-product-development-and-dissemination."><span class="header-section-number">4</span> Guiding principles for ethical, transparent, reproducible statistical product development and dissemination.</h2>
<p><strong>Communication</strong></p>
<p>We communicated results throughout the Demonstration Use Case research with our Census CDE Working Group (composed of former Census Bureau Directors and Communication Director, and academic and industry census experts), with the Census Bureau, at conferences such as the annual Federal Statistical Committee on Methodology, and sharing drafts to seek input and ideas. The discussions and presentations helped to shape ideas and advance our thinking about how best to address the purpose and use questions.</p>
<p><strong>Stakeholder engagement</strong></p>
<p>We engaged stakeholders by sharing our research and results through conference presentations at the American Community Survey Data Users Conference and the Applied Public Data Users Conference.&nbsp;We also shared this demonstration project at Listening Sessions with stakeholders as an example of statistical product development. The Listening Sessions bring together 7 to 12 stakeholders by topic (e.g., children’s health) or function (e.g., state demographers) to seek their ideas for new statistical products.</p>
<p><strong>Equity and ethics</strong></p>
<p>As described in the Introduction, there are ethics and equity issues that drew us to develop this Use Case. Here we focus on equity and ethics vis-a-vis the data choices and analyses. With regard to ethical considerations with our data discovery process, fitness-for-purpose evaluation, and analyses, two questions arose:</p>
<ol type="1">
<li><p>What role does synthetic data have to play, and how do you benchmark it to evaluate fitness-for-purpose?</p></li>
<li><p>How do you construct and evaluate an index with the goal of identifying vulnerable populations?</p></li>
</ol>
<p>Realizing the importance of nursing staff levels, we discussed and questioned whether the synthetic data had biases and were not representative of SNF residents and employees. We benchmarked the synthetic SNF nursing staff numbers against those submitted quarterly to CMS and observed they were biased low, so we decided to use the CMS data. These data were used to estimate the average number of nursing staff that could reach the facility during an extreme flood event (Figure&nbsp;2).</p>
<p>In this use case, we were fortunate to have the “truth” to benchmark the synthetic data for the average daily nursing staff at each SNF. But this was not the case for the home locations of the nursing staff, therefore, the synthetic locations were not used since we had no way to benchmark them. Ideally, we would use the actual addresses of SNF employees. Instead, we used a simulation to estimate the average risks over routes leading to the SNF. This approach could be replaced with (or benchmarked against) the Census commuting data sets (eg, <a href="https://www.census.gov/topics/employment/commuting/guidance/flows.html">Commuting Flows</a> or the <a href="https://lehd.ces.census.gov/data/">LEHD Origin-Destination Employment Statistics</a>) and the home census tract used as the starting point for each worker. For the number of nursing staff and their home locations, it is impossible to identify potential biases that would result in the inequitable allocation of emergency rescue resources without a thorough understanding of how the synthetic data were generated.</p>
<p>How one evaluates the equity of an index is a more challenging task. Questions that need to be addressed include:</p>
<ol type="1">
<li><p>How do you select the variables used to construct an indicator to guide an equitable allocation of technical assistance?</p></li>
<li><p>What relationship between these variables is important?</p></li>
<li><p>What are the differences across the numerous publicly available resilience estimators? Do some lead to a more equitable allocation of technical assistance in the event of an extreme clime event?</p></li>
<li><p>How do you validate a resilience estimator?</p></li>
</ol>
<p>The technical document <em>Community Resilience Indicator Analysis: County-Level Analysis of Commonly Used Indicators from Peer-Reviewed Research</em> <span class="citation" data-cites="edgemon2018community">(Edgemon et al. 2018)</span> identified the 20 most commonly selected variables for constructing resilience estimators from peer-reviewed research. Future research will need to validate these indices against past extreme climate events.</p>
<p><strong>Privacy and confidentiality</strong></p>
<p>We did not do a full disclosure review. However, some data are proprietary, and we could not release those data. We discuss how we used these data.</p>
<p><strong>Dissemination</strong></p>
<p>We disseminated the final version of the use case in the University of Virginia Libra Open repository <span class="citation" data-cites="lancaster2023CDE">(Lancaster et al. 2023)</span>.</p>
<p><strong>Curation</strong></p>
<p>Curation involves documenting all steps of the process so that they can be repeated, validated, reused, or extended. The final report explains the process in words. Curation must also provide the data, metadata, source code, and products. This led us to construct a GitHub repository. A <a href="https://github.com/uva-bi-sdad/census_cde_demo_2/blob/main/README.pdf">README</a> file guides the reader through the material and provides instructions for replicating the research results. Note that the README file must be downloaded for the hyperlinks to work.</p>
</section>
<section id="using-the-snf-statistical-product" class="level2" data-number="5">
<h2 data-number="5" class="anchored" data-anchor-id="using-the-snf-statistical-product"><span class="header-section-number">5</span> Using the SNF statistical product</h2>
<p>This potential statistical product has many uses. Federal policymakers and administrators regulate SNFs; however, they only sometimes realize the impacts on costs and the need for increased resources to meet these regulations. For example, by reviewing the aggregate inspection deficiency metrics, policymakers can target resources where they are most needed. Providing additional funding to pay workers more, improve their facilities, and address inspection deficiencies would improve the quality of SNFs.&nbsp;</p>
<p>The media and advocacy groups play a role in highlighting good and bad cases of SNF care or where communities do not have adequate assets to support SNFs during an emergency event. For example, a <em>New Yorker</em> article <span class="citation" data-cites="rafiei2022private">(Rafiei 2022)</span> highlighted how nursing homes decline dramatically when bought by private equity owners. The GAO (September 22, 2023) recently identified the need for more information about private equity ownership in CMS data – a gap that CMS needs to address. And, of course, researchers and analysts are essential for conducting research that leads to creating and improving statistical products around SNFs. By releasing a regularly scheduled SNF statistical product, the changes in SNFs over time can be monitored.</p>
</section>
<section id="what-cde-capabilities-have-this-use-case-demonstrated" class="level2" data-number="6">
<h2 data-number="6" class="anchored" data-anchor-id="what-cde-capabilities-have-this-use-case-demonstrated"><span class="header-section-number">6</span> What CDE capabilities have this use case demonstrated?</h2>
<p>As demonstrated by this use case, the CDE Framework is a powerful process for guiding and curating the development of statistics to address complex purposes and uses. Additionally, use cases help illuminate technical capabilities that should be present in the data enterprise to facilitate and accelerate the reuse of data and methods in the development and dissemination of new statistical products.</p>
<p>This CDE demonstration is the first of many use cases needed to define and develop CDE capabilities. Underlying each use case is the curation process. Curation documents each step, including decisions that may involve trade-offs. Curation preserves and adds value to the data. This includes organizing to facilitate data discovery and easy access; providing metadata to enable the reuse in scientific and programmatic research; enhancing the value of the data enterprise through linkages between datasets; and mapping the network of interconnections between datasets, research outputs, researchers, and institutions. Over time, a searchable curation system will be needed as a foundation for creating statistical products in the CDE.</p>
<p>The types of products from a use case that can benefit the larger community are only limited by the creativity of the researchers and stakeholders carrying out the use case. The products from this use case are re-useable code; integrated data sets across diverse topics for each SNF; maps and other visualizations; statistical products such as SNF deficiency indices and various indices that measure community and SNF resilience; the probability of a worker reaching an SNF in the event of extreme flooding; and a GitHub repo that provides easy access to all these products plus relevant metadata, literature, and government documents and regulations.</p>
<p>Conducting this use case has been an eye-opening experience as to the amount and quality of publicly available data to address our research questions. The statistical capabilities and products flowing from diverse use cases can only be identified as the program progresses.</p>
<div class="nav-btn-container">
<div class="grid">
<div class="g-col-12 g-col-sm-6">
<div class="nav-btn">
<p><a href="../../../../../../applied-insights/case-studies/posts/2024/11/08/what-is-CDE-2.html">← Part 2: What is the CDE?</a></p>
</div>
</div>
<div class="g-col-12 g-col-sm-6">
<div class="nav-btn">
<p><a href="../../../../../../applied-insights/case-studies/posts/2024/11/22/development-plan-2.html">Part 4: Census Curated Data Enterprise Environment →</a></p>
</div>
</div>
</div>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-12">
<dl>
<dt>About the authors</dt>
<dd>
<strong>Vicki Lancaster</strong> is a statistician with expertise in experimental design, linear models, computation, visualizations, data analysis, and interpretation. She works with scientists at federal agencies on projects requiring statistical skills and creativity, eg, defining skilled technical workforce using novel data sources.
</dd>
<dd>
<strong>Stephanie Shipp</strong> leads the Curated Data Enterprise research portfolio and collaborates with the US Census. She is an economist with experience in data science, survey statistics, public policy, innovation, ethics, and evaluation.
</dd>
<dd>
<strong>Sallie Keller</strong> is the Chief Scientist and Associate Director of Research and Methodology at the US Census Bureau. She is a statistician with research interest in social and decision informatics, statistics underpinnings of data science, and data access and confidentiality. Sallie Keller was at the University of Virginia when this work was conducted.
</dd>
<dd>
<strong>Aaron Schroeder</strong> has experience in the technologies and related policies of information and data integration and systems analysis, including policy and program development and implementation.
</dd>
<dd>
<strong>Henning Mortveit</strong> develops massively interacting systems and the mathematics supporting rigorous analysis and understanding of their stability and resiliency.
</dd>
<dd>
<strong>Samarth Swarup</strong> conducts research in computational social science, resiliency and sustainability, and stimulation analytics.
</dd>
<dd>
<strong>Dawen Xie</strong> develops geographic information systems, visual analytics, information management systems, and databases, with a current focus on building dynamic web systems.
</dd>
</dl>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>Copyright and licence</dt>
<dd>
© 2024 Stephanie Shipp
</dd>
</dl>
<p><a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> <img style="height:22px!important;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"></a> This article is licensed under a Creative Commons Attribution 4.0 (CC BY 4.0) <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> International licence</a>. Thumbnail photo by <a href="https://www.shutterstock.com/g/Ground+Picture">Ground Picture</a> on <a href="https://www.shutterstock.com/image-photo/lovely-nurse-assisting-senior-man-get-2006404274">Shutterstock</a>.</p>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>How to cite</dt>
<dd>
Lancaster V, Shipp S, Keller S et al.&nbsp;(2024). “Translating the Curated Data Model into Practice - climate resiliency of skilled nursing facilities” Real World Data Science, November 19, 2024. <a href="https://realworlddatascience.net/applied-insights/case-studies/posts/2024/11/19/use-case-2.html">URL</a>
</dd>
</dl>
</div>
</div>
</div>



</section>


<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0">
<div id="ref-barrett2013planning" class="csl-entry">
Barrett, Christopher, Keith Bisset, Shridhar Chandan, Jiangzhuo Chen, Youngyun Chungbaek, Stephen Eubank, Yaman Evrenosoğlu, et al. 2013. <span>“Planning and Response in the Aftermath of a Large Crisis: An Agent-Based Informatics Framework.”</span> In <em>2013 Winter Simulations Conference (WSC)</em>, 1515–26. IEEE.
</div>
<div id="ref-beckman1996creating" class="csl-entry">
Beckman, Richard J, Keith A Baggerly, and Michael D McKay. 1996. <span>“Creating Synthetic Baseline Populations.”</span> <em>Transportation Research Part A: Policy and Practice</em> 30 (6): 415–29.
</div>
<div id="ref-choupani2016population" class="csl-entry">
Choupani, Abdoul-Ahad, and Amir Reza Mamdoohi. 2016. <span>“Population Synthesis Using Iterative Proportional Fitting (IPF): A Review and Future Research.”</span> <em>Transportation Research Procedia</em> 17: 223–33.
</div>
<div id="ref-dosa2008controversy" class="csl-entry">
Dosa, David M, Kathryn Hyer, Lisa M Brown, Andrew W Artenstein, LuMarie Polivka-West, and Vincent Mor. 2008. <span>“The Controversy Inherent in Managing Frail Nursing Home Residents During Complex Hurricane Emergencies.”</span> <em>Journal of the American Medical Directors Association</em> 9 (8): 599–604. <a href="https://pubmed.ncbi.nlm.nih.gov/19083295/">https://pubmed.ncbi.nlm.nih.gov/19083295/</a>.
</div>
<div id="ref-edgemon2018community" class="csl-entry">
Edgemon, Lesley, Carol Freeman, Carmella Burdi, Trail, and Kyle Pfeiffer. 2018. <span>“Community Resilience Indicator Analysis: County-Level Analysis of Commonly Used Indicators from Peer-Reviewed Research.”</span> <em>Argonne National Laboratory</em>. <a href="https://www.researchgate.net/publication/331232094_Community_Resilience_Indicator_Analysis_County-Level_Analysis_of_Commonly_Used_Indicators_From_Peer-Reviewed_Research">https://www.researchgate.net/publication/331232094_Community_Resilience_Indicator_Analysis_County-Level_Analysis_of_Commonly_Used_Indicators_From_Peer-Reviewed_Research</a>.
</div>
<div id="ref-FEMA2021risk" class="csl-entry">
FEMA. 2021. <span>“National Risk Index Technical Documentation.”</span> Federal Emergency Management Agency. 2021. <a href="https://www.fema.gov/sites/default/files/documents/fema_national-risk-index_technical-documentation.pdf
  ">https://www.fema.gov/sites/default/files/documents/fema_national-risk-index_technical-documentation.pdf </a>.
</div>
<div id="ref-FEMA2022a" class="csl-entry">
———. 2022. <span>“Community Resilience Indicator Analysis: Commonly Used Indicators from Peer-Reviewed Research: Updated for Research Published 2003-2021.”</span> Federal Emergency Management Agency. 2022. <a href="hhttps://www.fema.gov/sites/default/files/documents/fema_2022-community-resilience-indicator-analysis.pdf
  ">hhttps://www.fema.gov/sites/default/files/documents/fema_2022-community-resilience-indicator-analysis.pdf </a>.
</div>
<div id="ref-dhs2022hifld" class="csl-entry">
Homeland Security: Geospatial Management Office, Department of. 2022. <span>“Homeland Security Infrastructure Foundation-Level Data Open Data.”</span> 2022. <a href="https://hifld-geoplatform.opendata.arcgis.com/">https://hifld-geoplatform.opendata.arcgis.com/</a>.
</div>
<div id="ref-hyer2006establishing" class="csl-entry">
Hyer, Kathryn, Lisa M Brown, Amy Berman, and LuMarie Polivka-West. 2006. <span>“Establishing and Refining Hurricane Response Systems for Long-Term Care Facilities: The John a. Hartford Foundation Was the Lead Funder of a Hurricane Summit to Focus on the Neglected Needs of the Elderly.”</span> <em>Health Affairs</em> 25 (Suppl1): W407–11. <a href="https://www.healthaffairs.org/doi/full/10.1377/hlthaff.25.w407?casa_token=XbJ2j-CdtssAAAAA:USJMJsZq_jlYlQlASQt4O4OYJcq_AOKjpXOx5tTMUIZxoNVXZCzj1_ejtQyLHrnTg6B1BygFuuGZ">https://www.healthaffairs.org/doi/full/10.1377/hlthaff.25.w407?casa_token=XbJ2j-CdtssAAAAA:USJMJsZq_jlYlQlASQt4O4OYJcq_AOKjpXOx5tTMUIZxoNVXZCzj1_ejtQyLHrnTg6B1BygFuuGZ</a>.
</div>
<div id="ref-lancaster2023CDE" class="csl-entry">
Lancaster, V., S. Shipp, S. Keller, A. Schroeder, H. Mortveit, S. Swarup, and D. Xie. 2023. <span>“Census Curated Data Enterprise Use Case Demonstration: Climate Resiliency of Skilled Nursing Facilities”</span> TR 2023-53. <a href="https://doi.org/10.18130/ce97-sp05">https://doi.org/10.18130/ce97-sp05</a>.
</div>
<div id="ref-brown2022ltcfocus" class="csl-entry">
LTCFocus, Brown University. 2022. <span>“Who We Are.”</span> 2022. <a href="https://ltcfocus.org/about">https://ltcfocus.org/about</a>.
</div>
<div id="ref-CMS2022design" class="csl-entry">
Medicare &amp; Medicaid Services, Centers for. 2022. <span>“Design for Care Compare Nursing Home Five-Star Quality Rating System: Technical Users’ Guide.”</span> 2022. <a href="https://www.cms.gov/medicare/provider-enrollment-and-certification/certificationandcomplianc/downloads/usersguide.pdf">https://www.cms.gov/medicare/provider-enrollment-and-certification/certificationandcomplianc/downloads/usersguide.pdf</a>.
</div>
<div id="ref-cmsglossary" class="csl-entry">
———. 2023. <span>“CMS Glossary.”</span> 2023. <a href="https://www.cms.gov/glossary?term=skilled+nursing+facility&amp;items_per_page=10&amp;viewmode=grid ">https://www.cms.gov/glossary?term=skilled+nursing+facility&amp;items_per_page=10&amp;viewmode=grid </a>.
</div>
<div id="ref-mortveitNSSAC" class="csl-entry">
Mortveit, H., D. Xie, and M. Marathe. 2023. <span>“NSSAC Building Knowledge Base: Modeling and Implementation.”</span>
</div>
<div id="ref-rafiei2022private" class="csl-entry">
Rafiei, Y. 2022. <span>“When Private Equity Takes over a Nursing Home.”</span> <em>New Yorker</em> 2022: 333. <a href="https://www.newyorker.com/news/dispatch/when-private-equity-takes-over-a-nursing-home">https://www.newyorker.com/news/dispatch/when-private-equity-takes-over-a-nursing-home</a>.
</div>
<div id="ref-skarha2021association" class="csl-entry">
Skarha, Julianne, Lily Gordon, Nazmus Sakib, Joseph June, Dylan J Jester, Lindsay J Peterson, Ross Andel, and David M Dosa. 2021. <span>“Association of Power Outage with Mortality and Hospitalizations Among Florida Nursing Home Residents After Hurricane Irma.”</span> In <em>JAMA Health Forum</em>, 2:e213900–213900. 11. American Medical Association. <a href="https://jamanetwork.com/journals/jama-health-forum/fullarticle/2786665">https://jamanetwork.com/journals/jama-health-forum/fullarticle/2786665</a>.
</div>
<div id="ref-sheet2022protecting" class="csl-entry">
The White House. 2022. <span>“Protecting Seniors by Improving Safety and Quality of Care in the Nation’s Nursing Homes.”</span> 2022. <a href="https://www.whitehouse.gov/briefing-room/statements-releases/2022/02/28/fact-sheet-protecting-seniors-and-people-with-disabilities-by-improving-safety-and-quality-of-care-in-the-nations-nursing-homes/
  ">https://www.whitehouse.gov/briefing-room/statements-releases/2022/02/28/fact-sheet-protecting-seniors-and-people-with-disabilities-by-improving-safety-and-quality-of-care-in-the-nations-nursing-homes/ </a>.
</div>
</div></section><section id="footnotes" class="footnotes footnotes-end-of-document"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p>Nursing staff includes medical aides and technicians, certified nursing assistants, licensed practical nurses (LPNs), LPNs with administrative duties, registered nurses (RNs), RNs with administrative duties, and the RN director of nursing.↩︎</p></li>
<li id="fn2"><p>For example, distinguishing county from city when the name is the same could be done using State/County FIPS codes. Richmond County is 51159; Richmond City is 51760.↩︎</p></li>
<li id="fn3"><p><em>ZIP code is a system of postal codes used by the United States Postal Service. ZIP</em> was chosen to indicate mail travels more quickly when senders use the postal code.↩︎</p></li>
<li id="fn4"><p>Average Daily Nursing Staff is the daily number of Medical Aides and Technicians, CNAs, LPNs, LPNs with administrative duties, RNs, RNs with administrative duties, and RN Director of Nursing averaged over three months.↩︎</p></li>
</ol>
</section></div> ]]></description>
  <category>Public Policy</category>
  <category>Data Analysis</category>
  <category>Data Integration</category>
  <category>Curation</category>
  <category>Statistical Products</category>
  <guid>https://realworlddatascience.net/applied-insights/case-studies/posts/2024/11/19/use-case-2.html</guid>
  <pubDate>Tue, 19 Nov 2024 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/applied-insights/case-studies/posts/2024/11/19/images/nurse-thumbnail.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>Advancing Data Science in Official Statistics – What is the Curated Data Enterprise?</title>
  <dc:creator>Sallie Keller, Stephanie Shipp, Vicki Lancaster, and Joseph Salvo &lt;br /&gt; University of Virginia</dc:creator>
  <link>https://realworlddatascience.net/applied-insights/case-studies/posts/2024/11/08/what-is-CDE-2.html</link>
  <description><![CDATA[ 





<center>
Acknowledgments: This research was sponsored by the: <br> Unites States Census Bureau Agreement No.&nbsp;01-21-MOU-06 and <br> Alfred P. Sloan Foundation Grant No.&nbsp;G-2022-19536
</center>
<p><br> <br></p>
<p><em>The views expressed in this perspective are those of the authors and not the Census Bureau.</em></p>
<section id="introduction" class="level2">
<h2 class="anchored" data-anchor-id="introduction">Introduction</h2>
<p>Today, official statistics – tables, reports and microdata – are produced using data from a single survey. These surveys are foundational for researchers and policymakers. However, many issues cannot be answered by surveys alone. For example, creating a picture of how prepared skilled nursing facilities (SNFs) are for climate emergencies requires wrangling all types of data about the facilities and their communities.(<em>Note: A skilled nursing facility is a facility that meets specific federal regulatory certification requirements that enable it to provide short-term inpatient care and services to patients who require medical, nursing, or rehabilitative services.</em>) This includes SNF data on the number and dates of inspections, deficiencies, residents’ mental and physical health, the number of nursing staff and where they live, community assets data on the number of shelter facilities, health professionals and emergency service providers, and community risks data on the probability of an extreme climate event. How can we create new statistical products useful to policymakers, emergency responders, skilled nursing facility staff, and others to inform their decisions?</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Official statistics
</div>
</div>
<div class="callout-body-container callout-body">
<p>Official statistics are essential for a democratic society as they provide economic, demographic, social, and environmental data about the government, the economy, and the environment. Official statistical agencies should compile and make these statistics available impartially to honor the right to public information.</p>
<p>Objective, reliable, and accessible official statistics instill confidence in the integrity of government and public decision-making regarding a country’s economic, social, and environmental situation at national and international levels. They should be widely available and meet the needs of various users <span class="citation" data-cites="UnitedNations2024">(United Nations 2024)</span>.</p>
</div>
</div>
<p>With the explosion of available data, there is an opportunity to combine all types of information to create statistical products that address cross-cutting topics for a wide range of purposes and uses. The US Census Bureau is modernizing and transforming its enterprise system to accommodate a new way to produce statistical products that take advantage of all data types: designed surveys and censuses, public and private administrative data, opportunity data scraped from the internet, and procedural data <span class="citation" data-cites="keller2022bold">(Keller et al. 2022)</span>.</p>
<blockquote class="blockquote">
<p><em>‘We are moving towards a single enterprise, data-centric operation that enables us to funnel data from many sources in a single data lake using common collection and ingestion platforms… This is the essence of <strong>a curated data approach</strong> — assemble, assess, and fill in the gaps to create quality statistical data.’</em></p>
</blockquote>
<blockquote class="blockquote">
<p><strong>Robert Santos,</strong> Director, US Census Bureau</p>
</blockquote>
<p>This curated approach is embodied in the Curated Data Enterprise (CDE). The Curated Data Enterprise Framework in Figure&nbsp;1 provides a guide for creating statistical products that enable the full integration of data from many sources <span class="citation" data-cites="keller2020doing">(Keller et al. 2020)</span>. At the heart of the framework are the purposes and uses that provide the context and driving force for developing the statistical product. The outer rectangle in Figure&nbsp;1 identifies the guiding principles for ethical, transparent and reproducible product development and dissemination. The inner rectangle identifies the steps in the statistical product development, including integrating primary and secondary data sources. The arrows convey that this process may only sometimes be linear. Instead, the process is iterative, where new information may be discovered at any point, requiring reevaluating and updating prior steps. Our Social and Decision Analytics research group in the Biocomplexity Institute developed, tested, and refined the CDE (data science) Framework in our research since 2013 <span class="citation" data-cites="keller2017building keller2020doing">(Keller, Lancaster, and Shipp 2017; Keller et al. 2020)</span>. The proposed use of the CDE to develop statistical products at the US Census Bureau is in its early stages.</p>
<div id="fig-cde" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-cde-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="https://realworlddatascience.net/applied-insights/case-studies/posts/2024/11/08/images/figure-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-cde-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;1: The CDE Framework starts with the purposes &amp; uses of the statistical products. The outer rectangle identifies the guiding principles for ethical, transparent, reproducible statistical product development and dissemination. The inner rectangle identifies the statistical product development steps.
</figcaption>
</figure>
</div>
<p>The next article in this series will put the CDE Framework into practice by demonstrating the use case on skilled nursing facilities’ preparedness for emergencies during extreme climate events. As a prelude to that article, we have created a visual for the statistical product development component of how that process works in action in Figure&nbsp;2.</p>
<div id="fig-ex" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-ex-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="https://realworlddatascience.net/applied-insights/case-studies/posts/2024/11/08/images/figure-2.png" class="img-fluid quarto-figure quarto-figure-center figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-ex-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2: Example: Steps in the statistical product development for the skilled nursing facility use case. The diagram describes the steps applied to a use case on the resilience of skilled nursing facilities. Section 3 of this series describes the steps in detail.
</figcaption>
</figure>
</div>
<p>The CDE Framework’s guiding principles and research steps are described below. To find out more click on a cross reference.</p>
<p><strong>Guiding principles</strong>:</p>
<ul>
<li>Purposes and uses</li>
<li>Stakeholders</li>
<li>Curation</li>
<li>Equity and ethics</li>
<li>Privacy and confidentiality</li>
<li>Communications and dissemination</li>
</ul>
<p><strong>Research steps</strong>:</p>
<ul>
<li>Subject matter input</li>
<li>Data discovery</li>
<li>Data ingestion &amp; Governance</li>
<li>Data wrangling</li>
<li>Fitness-for-purpose</li>
<li>Statistics development</li>
</ul>
</section>
<section id="guiding-principles" class="level2">
<h2 class="anchored" data-anchor-id="guiding-principles">Guiding principles</h2>
<section id="sec-gp1" class="level3">
<h3 class="anchored" data-anchor-id="sec-gp1">Purposes and uses</h3>
<p>The CDE is centered on developing statistical products to meet specific purposes and uses. Researchers and stakeholders propose the purposes and uses, defining the ‘why’ for developing statistics and statistical products. They include questions or issues that the statistics should be designed to support and are clarified by documented best practices, literature reviews and conversations with subject matter experts.</p>
</section>
<section id="sec-gp2" class="level3">
<h3 class="anchored" data-anchor-id="sec-gp2">Stakeholders</h3>
<p>Stakeholders include individuals, groups, and organizations that have the potential to affect or be affected by the outcome of the research. Engaging stakeholders is crucial for fostering the connection and trust that can lead to better decision making. <span class="citation" data-cites="kujala2022stakeholder">Kujala et al. (2022)</span> best described the principle of stakeholder engagement: ‘Stakeholder engagement refers to the aims, activities, and impacts of stakeholder relations in a moral, strategic, and pragmatic manner.’ When placed within the CDE context and represented in the Framework, collaborative engagement with stakeholders occurs at all stages of product development to better understand what the final product needs to look like. Further, product development is not a linear process but occurs through successive waves of iteration with users.</p>
<p>Forming partnerships with stakeholders is instrumental in identifying requirements and implementing statistical products. This requires listening to community voices in an active engagement strategy.<sup>1</sup> Of necessity, these partnerships entail collaboration, such as creative and collaborative problem-solving workshops and the development of innovative digital tools vetted by networks of users.<sup>2</sup></p>
</section>
<section id="sec-gp3" class="level3">
<h3 class="anchored" data-anchor-id="sec-gp3">Curation</h3>
<p>The broad meaning of curation is the act of organizing, documenting and maintaining a collection of artifacts. The artifacts of the development and dissemination of statistics or statistical products include all the components in Figure&nbsp;1, from meeting with stakeholders to formulating the purposes and uses to creating and disseminating the statistical products. Maintaining the artifacts is the essence of the CDE. <em>Every step in the process should be documented and easily accessible in a repository, for example, GitHub, for the work to be transparent and reproducible</em>. Curation in the context of the CDE is an end-to-end activity. It involves documenting the purpose and use, providing the context for acquiring, wrangling, and archiving data from many sources to support the development of statistical products. It will include metadata <span class="citation" data-cites="cannon2013">(Cannon 2013)</span>, the code used to read and write the data, and the code that ingested the data from the source and prepared it for analysis.</p>
<p><em>Curation steps</em></p>
<ul>
<li>Document the development of the research questions, why this research is important, and how it supports the purposes and uses and resulting statistical product.</li>
<li>Document the context for the purposes and uses, ie, a policy directive, stakeholder request, policy evaluation, etc.</li>
<li>What stakeholder engagement and transparency are built into the process?</li>
</ul>
</section>
<section id="sec-gp4" class="level3">
<h3 class="anchored" data-anchor-id="sec-gp4">Equity and ethics</h3>
<p>An ethics review ensures dialogue on this topic throughout the statistical product development and dissemination life cycle. This involves teams of researchers and stakeholders across many areas of expertise, each with its own research integrity norms and practices. This requires that ethics be woven into every aspect of the CDE. An <em>equity</em> review ensures that underserved groups are represented and biases inherent in various data sources are acknowledged.</p>
<p><em>Curation questions</em></p>
<ul>
<li>What are the project’s expected benefits to the ‘public good’? Do they outweigh potential risks to specific sub-populations, eg, individuals, firms and their locations by different levels of geography?</li>
<li>Are there implicit assumptions and biases regarding the studied communities in framing the project and associated data sources? If yes, how will they be addressed?</li>
<li>What type of institutional approval process and contracts are needed? What statistical quality standards and confidentiality standards will be needed? For an explanation of the Institution Review Board see Note&nbsp;1.</li>
</ul>
<p>An ethics checklist can help with this process. Links to ethics checklists are provided below.</p>
<ul>
<li>University of Virginia, Biocomplexity Institute, <a href="https://biocomplexity.virginia.edu/sites/default/files/sda/UVA%20SDAD%20EthicsChecklist%2018May2022.pdf">Social and Decision Analytics Division Data Science Project Ethics Tool</a></li>
<li>United Kingdom Government, <a href="https://www.gov.uk/government/publications/data-ethics-framework#full-publication-update-history">Data Ethics Framework</a></li>
</ul>
</section>
<section id="sec-gp5" class="level3">
<h3 class="anchored" data-anchor-id="sec-gp5">Privacy and confidentiality</h3>
<p>Privacy is about the individual, whereas confidentiality is about the individual’s information. Privacy refers to an individual’s desire to control their information. Confidentiality refers to the researcher’s agreement with the individual, which could be an agency like the Census Bureau, regarding how their information will be handled, managed, and disseminated <span class="citation" data-cites="keller2016does">(Keller, Shipp, and Schroeder 2016)</span>. This is a guiding principle because it needs to be considered and embraced at the earliest possible stages of statistical product development and will impact dissemination choices.</p>
<p><em>Curation questions</em></p>
<ul>
<li>What steps are taken to ensure the privacy and confidentiality of the data?</li>
<li>What statistical methods (if any) are used to ensure the privacy and confidentiality of the data?</li>
<li>How do the methods chosen to protect confidentiality affect the purposes and uses of the data?</li>
<li>What stakeholder engagement and transparency are built into the process?</li>
<li>Does the context surrounding the purposes, uses, and anticipated data sources require an Institutional Review Board (IRB) review and approval? If yes, is it archived?</li>
</ul>
<div id="nte-irb" class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note&nbsp;1: Institutional Review Board
</div>
</div>
<div class="callout-body-container callout-body">
<p>In the United States, institutional review boards (IRBs) assess the ethics and safety of research studies involving human subjects, such as behavioral studies or clinical trials for new drugs or medical devices. Today, the definition of human subjects has evolved to include secondary data, such as administrative data collected for other purposes, eg, local property data collected for tax purposes.</p>
<p>The Belmont Commission was convened in the late 1970s after the ethical failures of many research projects that involved vulnerable populations surfaced. The Belmont Commission issued three principles for the conduct of ethical research:</p>
<ul>
<li><p><strong>Respect for people</strong> — treating people as autonomous and honoring their wishes</p></li>
<li><p><strong>Beneficence</strong> — understanding the risks and benefits of the study and weighing the balance between (1) doing no harm and (2) maximizing possible benefits and minimizing possible harms</p></li>
<li><p><strong>Justice</strong> — deciding if the risks and benefits of research are distributed fairly.</p></li>
</ul>
<p>These principles were translated to a set of regulations called the Common Rule that govern federally-funded research. The Belmont Commission provided the foundation for IRB principles and focused on research involving human subjects in experiments and studies. IRB approval is required to be eligible for federal grants and contracts. Many universities also require IRB review for research conducted by faculty, students, and researchers <span class="citation" data-cites="shipp2023making">(Shipp, LaLonde, and Martinez 2023)</span>.</p>
</div>
</div>
</section>
<section id="sec-gp6" class="level3">
<h3 class="anchored" data-anchor-id="sec-gp6">Communication and dissemination</h3>
<p>Communication involves sharing data, statistical method choices, well-documented code, working papers, and <em>dissemination</em> through research team meetings, stakeholder engagements, conference presentations, publications, webinars, websites, and social media. As a principle, communication and dissemination are critical to ensure that statistical product development processes and findings are transparent and reproducible <span class="citation" data-cites="berman2016realizing">(Berman et al. 2016)</span>. An essential facet of this step is to tell the story of the analysis by conveying the context, purpose, and implications of the research and findings <span class="citation" data-cites="berinato2019data wing2019data nasem2022transparency">(Berinato 2019; Wing 2019; NASEM 2022)</span>.</p>
<p><em>Curation questions</em></p>
<ul>
<li>Are the meeting notes, statistical products, code, reports, and presentations archived in a repository?</li>
<li>Briefly describe what did not work in this process, eg, data wrangling challenges where data sources could not be integrated, data source changes after a fitness-for-purpose assessment, analyses that were changed because assumptions were not met, etc.</li>
<li>Have project methods and outputs been made as transparent as possible?</li>
<li>Are the potential limitations of the research clearly presented?</li>
<li>Why or why not should the research be used as the basis for an institutional or policy action?</li>
<li>Have the predicted benefits and social costs to all potentially affected communities been considered?</li>
</ul>
</section>
</section>
<section id="research-steps" class="level2">
<h2 class="anchored" data-anchor-id="research-steps">Research steps</h2>
<section id="sec-rs1" class="level3">
<h3 class="anchored" data-anchor-id="sec-rs1">Subject matter input</h3>
<p>Subject matter (domain) expertise plays a role in translating the information acquired into understanding the underlying phenomena in the data <span class="citation" data-cites="box1978statistics">(Box et al. 1978)</span>. Domain knowledge provides the context to define, evaluate and interpret the findings at each research stage <span class="citation" data-cites="leonelli2019data snee2014follow">(Leonelli 2019; Snee, DeVeaux, and Hoerl 2014)</span>. Subject matter input can be obtained through a review of the literature, talking to experts, or learning about their work at conferences or other convenings. Subject matter experts are different than stakeholders. Both provide important input to identifying and clarifying purposes and uses.</p>
<p><em>Curation steps</em></p>
<ul>
<li>Document the meetings with subject matter experts and stakeholders.</li>
<li>Document the literature search methods and the results of the literature review.</li>
<li>Document choices are made during the development of the products.</li>
<li>Were subject matter experts and stakeholders recruited from underrepresented groups?</li>
</ul>
</section>
<section id="sec-rs2" class="level3">
<h3 class="anchored" data-anchor-id="sec-rs2">Data discovery</h3>
<p>Data discovery identifies potential sources that address the research goals defined by purposes and uses. Data sources include the following types <span class="citation" data-cites="keller2020doing">(Keller et al. 2020)</span>.</p>
<ol type="1">
<li><p>Designed data are collected using statistically designed methods, such as surveys, censuses, and data generated from an experimental or quasi-experimental design, such as a clinical trial or agricultural field study.</p></li>
<li><p>Administrative data are collected for the administration of an organization or program by entities such as government agencies.</p></li>
<li><p>Opportunity data are derived from internet-based information, such as websites, wearable and other sensor devices, and social media, and captured through application programming interfaces (APIs) and web scraping, eg, geocoded place-based data, transportation routes, and other data sources.</p></li>
<li><p>Procedural data are processes and policies, such as a change in health care coverage, a data repository policy outlining procedures and the metadata required to store data, or a responsible AI policy.</p></li>
</ol>
<p>The goal of the data discovery process is to think broadly and imaginatively about all data types and to capture the variety of data sources that could be useful for the problem. There are three steps in the data discovery process <span class="citation" data-cites="keller2016does">(Keller, Shipp, and Schroeder 2016)</span>.</p>
<ol type="1">
<li><p>Identify potential data sources and make an inventory.</p></li>
<li><p>Create a set of questions to screen the data sources to ensure the data meet the criteria for use.</p></li>
<li><p>Select and acquire the data sources that meet the screening criteria.</p></li>
</ol>
<p><em>Curation steps</em></p>
<ul>
<li>Describe your data discovery process and reasoning behind the selected data sources.
<ul>
<li>Do underrepresented groups have adequate geographic coverage? If not, are there methods, such as synthetic data, you can use to provide adequate coverage?</li>
<li>Have checks and balances been established to identify and address implicit biases in the data and interpretation of the data? Has the team engaged in discussion and provided insights across their diverse perspectives?</li>
</ul></li>
<li>Describe the assumptions that need to be made to use these data sources.</li>
<li>Identify and document the paradata and metadata that describe each data source. Paradata describe how the data were collected, while metadata are ‘data about data’. It includes information about the data’s content, data dictionaries and technical documents that will help the user assess its fitness for purpose <span class="citation" data-cites="cannon2013 nasem2022transparency">(Cannon 2013; NASEM 2022)</span>.</li>
<li>Discuss data sources you would have used if they were available.</li>
</ul>
</section>
<section id="sec-rs3" class="level3">
<h3 class="anchored" data-anchor-id="sec-rs3">Data ingest and governance</h3>
<p>Data ingestion is the process of bringing data into the data management platform(s) for use. Data governance establishes and adheres to rules and procedures regarding data access, dissemination and destruction.</p>
<p><em>Curation steps</em></p>
<ul>
<li>Document policies and institutional agreements for data use.
<ul>
<li>Have team members reviewed data use agreements, standard operating procedures (SOPs), and data management plans? Are they fair?</li>
<li>Do additional procedures need to be defined for this project?</li>
</ul></li>
<li>Document the code and processes used to ingest the data sources and manage governance.</li>
</ul>
</section>
<section id="sec-rs4" class="level3">
<h3 class="anchored" data-anchor-id="sec-rs4">Data wrangling</h3>
<p>Data wrangling includes the activities of data profiling, preparing, linking and exploring used to assess the data’s quality and representativeness and what analyses the data can support.</p>
<table class="caption-top table">
<caption>Table 1. Activities of data wrangling</caption>
<colgroup>
<col style="width: 31%">
<col style="width: 14%">
<col style="width: 30%">
<col style="width: 21%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: center;">Profiling</th>
<th style="text-align: center;">Preparing</th>
<th style="text-align: center;">Linking</th>
<th style="text-align: center;">Exploring</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;"><ul>
<li>data quality</li>
<li>data structure</li>
<li>meta data, paradata, and provenance</li>
</ul></td>
<td style="text-align: center;"><ul>
<li>cleaning</li>
<li>transforming</li>
<li>structuring</li>
</ul></td>
<td style="text-align: center;"><ul>
<li>ontology selection &amp; alignment</li>
<li>entity resolution / harmonization</li>
</ul></td>
<td style="text-align: center;"><ul>
<li>visualizations</li>
<li>descriptive statistics</li>
<li>characterizations</li>
</ul></td>
</tr>
</tbody>
</table>
<p><em>Curation steps</em></p>
<ul>
<li>Describe any data quality issues within the stated purpose and use context and how they were resolved. This can include statistical solutions like imputing missing data, identifying outliers or constructing synthetic populations.
<ul>
<li>How representative are the data?</li>
<li>What populations are and are not covered?</li>
</ul></li>
<li>Describe any issues with the wrangling process and how they were resolved.</li>
<li>Document the code used to wrangle the data and describe how it was validated.</li>
<li>Document assumptions made regarding the transformation and use of the data.</li>
</ul>
</section>
<section id="sec-rs5" class="level3">
<h3 class="anchored" data-anchor-id="sec-rs5">Fitness-for-purpose</h3>
<p>Fitness-for-purpose starts with assessing the constraints imposed on the data by the particular statistical methods used and the population to which the inferences extend. It is a function of the modeling, data quality needs of the models, and data coverage (representativeness) needs of the models. The statistical product’s ‘fitness-for-purpose’ involves those on the receiving end of the data helping identify issues germane to the data application, such as identifying biases affecting equity. For example, given known differences in their availability, does using administrative records lead to better modeling outcomes for some groups more than others? What can be done to compensate for such bias?</p>
<p><em>Curation steps</em></p>
<ul>
<li>Document the constraints and limitations of the data.&nbsp;
<ul>
<li>What are the limitations of the results? Are the results useful, given the purpose of the study?</li>
</ul></li>
<li>Discuss the populations to which any inferences will generalize.
<ul>
<li>Do the statistical results support the potential benefits of the study previously stated?</li>
<li>Do any data require revisiting the question of potential biases being introduced through the choice of data sets and variables?</li>
</ul></li>
</ul>
</section>
<section id="sec-rs6" class="level3">
<h3 class="anchored" data-anchor-id="sec-rs6">Statistics development</h3>
<p>The development of statistics and statistical products for dissemination is a function of the research questions, the data’s limitations and the assumptions of the statistical method(s) used.</p>
<p><em>Curation steps</em></p>
<ul>
<li>Describe the statistical methods planned and used and how the method assumptions were evaluated.</li>
<li>Discuss the conclusions of the statistical analyses and any inferences that can be made from the disseminated statistical products.</li>
<li>Discuss how the statistics support the purposes and uses driving the development of the products.</li>
</ul>
<p>Here, we have defined the CDE and provided a conceptual walk through of the framework from Figure&nbsp;1. In the next article, we will put the CDE Framework into practice through a demonstration use case on the resilience of skilled nursing facilities.</p>
<div class="nav-btn-container">
<div class="grid">
<div class="g-col-12 g-col-sm-6">
<div class="nav-btn">
<p><a href="../../../../../../applied-insights/case-studies/posts/2024/11/01/policy-problem.html">← Part 1: The policy problem</a></p>
</div>
</div>
<div class="g-col-12 g-col-sm-6">
<div class="nav-btn">
<p><a href="../../../../../../applied-insights/case-studies/posts/2024/11/19/use-case-2.html">Part 3: Climate resiliency of skilled nursing facilities →</a></p>
</div>
</div>
</div>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-12">
<dl>
<dt>About the authors</dt>
<dd>
<p><strong>Sallie Keller</strong> is the Chief Scientist and Associate Director of Research and Methodology at the US Census Bureau. She is a statistician with research interest in social and decision informatics, statistics underpinnings of data science, and data access and confidentiality. Sallie Keller was at the University of Virginia when this work was conducted.</p>
</dd>
<dd>
<p><strong>Stephanie Shipp</strong> leads the Curated Data Enterprise research portfolio and collaborates with the US Census. She is an economist with experience in data science, survey statistics, public policy, innovation, ethics, and evaluation.</p>
</dd>
<dd>
<p><strong>Vicki Lancaster</strong> is a statistician with expertise in experimental design, linear models, computation, visualizations, data analysis, and interpretation. She works with scientists at federal agencies on projects requiring statistical skills and creativity, eg, defining skilled technical workforce using novel data sources.</p>
</dd>
<dd>
<p><strong>Joseph Salvo</strong> is a demographer with experience in US Census Bureau statistics and data. He makes presentations on demographic subjects to a wide range of groups about managing major demographic projects involving the analysis of large data sets for local applications.</p>
</dd>
</dl>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>Copyright and licence</dt>
<dd>
<p>© 2024 Stephanie Shipp</p>
</dd>
</dl>
<p><a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> <img src="https://mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1" style="height:22px!important;vertical-align:text-bottom;"><img src="https://mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1" style="height:22px!important;margin-left:3px;vertical-align:text-bottom;"></a> This article is licensed under a Creative Commons Attribution 4.0 (CC BY 4.0) <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> International licence</a>. Thumbnail photo by <a href="https://www.shutterstock.com/g/Chaay_Tee">Chay_Tee</a> on <a href="https://www.shutterstock.com/image-photo/back-rear-view-young-asian-woman-2170748613">Shutterstock</a>.</p>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>How to cite</dt>
<dd>
<p>Keller S, Shipp S, Lancaster V, Salvo J (2024). “Advancing Data Science in Official Statistics – What is the Curated Data Enterprise?” Real World Data Science, November 8, 2024. <a href="https://realworlddatascience.net/applied-insights/case-studies/posts/2024/11/08/what-is-CDE-2.html">URL</a></p>
</dd>
</dl>
</div>
</div>
</div>



</section>
</section>


<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0">
<div id="ref-berinato2019data" class="csl-entry">
Berinato, Scott. 2019. <span>“Data Science and the Art of Persuasion: Organizations Struggle to Communicate the Insights in All the Information They’ve Amassed. Here’s Why, and How to Fix It.”</span> <em>Harvard Business Review</em> 97 (1). <a href="https://hbr.org/2019/01/data-science-and-the-art-of-persuasion">https://hbr.org/2019/01/data-science-and-the-art-of-persuasion</a>.
</div>
<div id="ref-berman2016realizing" class="csl-entry">
Berman, Francine, Rob Rutenbar, Henrik Christensen, Susan Davidson, Deborah Estrin, Michael Franklin, Brent Hailpern, et al. 2016. <span>“Realizing the Potential of Data Science: Final Report from the National Science Foundation Computer and Information Science and Engineering Advisory Committee Data Science Working Group.”</span> <em>National Science Foundation Computer and Information Science and Engineering Advisory Committee Report</em>.
</div>
<div id="ref-box1978statistics" class="csl-entry">
Box, George EP, William H Hunter, Stuart Hunter, et al. 1978. <em>Statistics for Experimenters</em>. Vol. 664. John Wiley; sons New York.
</div>
<div id="ref-cannon2013" class="csl-entry">
Cannon, Sandra. 2013. <span>“Defining <span>‘Core’</span> Metadata: What Is Needed to Make Data Discoverable. Paper Presented at the Federal CASIC Workshops (Survey Uses of Metadata).”</span> <a href="https://www.census.gov/fedcasic/fc2013/">https://www.census.gov/fedcasic/fc2013/</a>.
</div>
<div id="ref-keller2017building" class="csl-entry">
Keller, Sallie, Vicki Lancaster, and Stephanie Shipp. 2017. <span>“Building Capacity for Data-Driven Governance: Creating a New Foundation for Democracy.”</span> <em>Statistics and Public Policy</em> 4 (1): 1–11.
</div>
<div id="ref-keller2022bold" class="csl-entry">
Keller, Sallie, Kenneth Prewitt, John Thompson, Steve Jost, Christopher Barrett, Sarah Nusser, Joseph Salvo, and Stephanie Shipp. 2022. <span>“A 21st Century Census Curated Data Enterprise. A Bold New Approach to Create Official Statistics. Technical Report.”</span> <em>Proceedings of the Biocomplexity Institute</em> BI-2022-1115: 297–323. <a href="https://doi.org/10.18130/r174-yk24">https://doi.org/10.18130/r174-yk24</a>.
</div>
<div id="ref-keller2020doing" class="csl-entry">
Keller, Sallie, Stephanie S Shipp, Aaron D Schroeder, and Gizem Korkmaz. 2020. <span>“Doing Data Science: A Framework and Case Study.”</span> <em>Harvard Data Science Review</em> 2 (1). <a href="https://doi.org/10.1162/99608f92.2d83f7f5">https://doi.org/10.1162/99608f92.2d83f7f5</a>.
</div>
<div id="ref-keller2016does" class="csl-entry">
Keller, Sallie, Stephanie Shipp, and Aaron Schroeder. 2016. <span>“Does Big Data Change the Privacy Landscape? A Review of the Issues.”</span> <em>Annual Review of Statistics and Its Application</em> 3: 161–80. <a href="https://www.annualreviews.org/content/journals/10.1146/annurev-statistics-041715-033453
  ">https://www.annualreviews.org/content/journals/10.1146/annurev-statistics-041715-033453 </a>.
</div>
<div id="ref-kujala2022stakeholder" class="csl-entry">
Kujala, Johanna, Sybille Sachs, Heta Leinonen, Anna Heikkinen, and Daniel Laude. 2022. <span>“Stakeholder Engagement: Past, Present, and Future.”</span> <em>Business &amp; Society</em> 61 (5): 1136–96. <a href="https://doi.org/10.1177/00076503211066595">https://doi.org/10.1177/00076503211066595</a>.
</div>
<div id="ref-leonelli2019data" class="csl-entry">
Leonelli, Sabina. 2019. <span>“Data Governance Is Key to Interpretation: Reconceptualizing Data in Data Science.”</span> <a href="https://doi.org/10.1162/99608f92.17405bb6">https://doi.org/10.1162/99608f92.17405bb6</a>.
</div>
<div id="ref-nasem2022transparency" class="csl-entry">
NASEM. 2022. <span>“Transparency in Statistical Information for the National Center for Science and Engineering Statistics and All Federal Statistical Agencies.”</span> <em>National Academies of Science, Engineering, and Medicine</em>. <a href="https://doi.org/10.1162/99608f92.17405bb6">https://doi.org/10.1162/99608f92.17405bb6</a>.
</div>
<div id="ref-shipp2023making" class="csl-entry">
Shipp, Stephanie, Donna LaLonde, and Wendy Martinez. 2023. <span>“Making Ethical Decisions Is Hard!”</span> <em>CHANCE</em> 36 (4): 42–50. <a href="https://www.tandfonline.com/eprint/D5KR3XFRUG2QV4FVCKQI/full?target=10.1080/09332480.2023.2290955">https://www.tandfonline.com/eprint/D5KR3XFRUG2QV4FVCKQI/full?target=10.1080/09332480.2023.2290955</a>.
</div>
<div id="ref-snee2014follow" class="csl-entry">
Snee, Ronald D, Richard D DeVeaux, and Roger W Hoerl. 2014. <span>“Follow the Fundamentals.”</span> <em>Quality Progress</em> 47 (1): 24–28. <a href="https://search-proquest-com.proxy01.its.virginia.edu/docview/1491963574?accountid=14678">https://search-proquest-com.proxy01.its.virginia.edu/docview/1491963574?accountid=14678</a>.
</div>
<div id="ref-UnitedNations2024" class="csl-entry">
United Nations. 2024. <span>“Development of a National Statistical System, Principle 1 - Relevance, Impartiality and Equal Access.”</span> <a href="https://unstats.un.org/unsd/goodprac/bpaboutpr.asp?RecId=1">https://unstats.un.org/unsd/goodprac/bpaboutpr.asp?RecId=1</a>.
</div>
<div id="ref-wing2019data" class="csl-entry">
Wing, Jeannette M. 2019. <span>“The Data Life Cycle.”</span> <em>Harvard Data Science Review</em> 1 (1): 6. <a href="https://doi.org/10.1162/99608f92.e26845b4">https://doi.org/10.1162/99608f92.e26845b4</a>.
</div>
</div></section><section id="footnotes" class="footnotes footnotes-end-of-document"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p><a href="https://www.census.gov/newsroom/blogs/director/2023/01/a-look-ahead-2023.html" class="uri">https://www.census.gov/newsroom/blogs/director/2023/01/a-look-ahead-2023.html</a>&nbsp;↩︎</p></li>
<li id="fn2"><p><a href="https://www.census.gov/partners/act.html" class="uri">https://www.census.gov/partners/act.html</a>↩︎</p></li>
</ol>
</section></div> ]]></description>
  <category>Public Policy</category>
  <category>Data Analysis</category>
  <category>Data Integration</category>
  <category>Curation</category>
  <category>Statistical Products</category>
  <guid>https://realworlddatascience.net/applied-insights/case-studies/posts/2024/11/08/what-is-CDE-2.html</guid>
  <pubDate>Fri, 08 Nov 2024 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/applied-insights/case-studies/posts/2024/11/08/images/screen.thumbnail.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>Advancing Data Science in Official Statistics – The Policy Problem</title>
  <dc:creator>Sallie Keller, Stephanie Shipp, Vicki Lancaster and Joseph Salvo &lt;br /&gt; University of Virginia</dc:creator>
  <link>https://realworlddatascience.net/applied-insights/case-studies/posts/2024/11/01/policy-problem.html</link>
  <description><![CDATA[ 





<center>
Acknowledgments: This research was sponsored by the: <br> United States Census Bureau Agreement No.&nbsp;01-21-MOU-06 and <br> Alfred P. Sloan Foundation Grant No.&nbsp;G-2022-19536
</center>
<p><br> <br> <em>The views expressed in this artice are those of the authors and not the Census Bureau.</em></p>
<section id="introduction" class="level2">
<h2 class="anchored" data-anchor-id="introduction">Introduction</h2>
<p>Two centuries ago, when the Framers of the US Constitution laid the cornerstone for the federal statistical system, they could not have imagined the complexity of questions future generations would want to ask or the variety of data sources available to address them. Back in 1787, counting the population and apportioning state seats in the House of Representatives were the most urgent tasks before the young nation, and so a requirement for a decennial census was written into the Constitution. Now, 233 years later, the census continues to serve its original purpose – but purposes and uses for census data have exploded.</p>
<p>Questions we now seek to answer go beyond what the census (or surveys) alone can hope to address. Even with the multitude of other surveys commissioned by today’s US Census Bureau, researchers and policymakers find themselves looking to novel sources of data – from structured numeric data in traditional databases to unstructured text documents scraped from the internet – to explore issues such as understanding how prepared nursing homes and communities are for extreme climate events,eg, hurricanes, wildfires, or floods. Wrangling these sources with traditionally designed data, such as censuses and surveys, can fill data gaps, improve the quality and usefulness of statistical products, speed up their dissemination, and inspire the creation of new types of statistical products.</p>
<p>That is the impetus for developing the Curated Data Enterprise (CDE), an innovation in data science aimed at creating statistical products from all data types and building the infrastructure to support them. The Curated Data Enterprise, as the name implies, includes an end-to-end curation model to capture the complete statistical product development process. The CDE is designed to enable data discovery and retrieval, data quality assessment across multiple and diverse sources of information, and the reuse of data and models over time to accelerate statistical product development. The US Census Bureau has partnered with the University of Virginia, a working group of former Census Bureau Directors, a Communication Director, and university, non-profit and industry experts to develop this approach.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
The US <a href="https://www.census.gov/">Census Bureau</a>
</div>
</div>
<div class="callout-body-container callout-body">
<p>The US Census Bureau provides the latest official statistics, facts, and figures about America’s people, places, and economy. It collects data for 130 surveys annually and the decennial census that gives the Bureau its name. The US Census Bureau collects data from households, businesses, governments and non-profit organizations. For each survey, tabulations and margins of error are published in news releases and reports. Public-use microdata subject to disclosure rules are provided for household and demographic surveys. Microdata for economic and household surveys, without disclosure rules applied, are accessible to researchers through the <a href="https://www.census.gov/about/adrm/fsrdc.html">Federal Statistical Research Data Centers</a>.</p>
<p>Statistical agencies in other countries are also modernizing their surveys and statistical product development. See a summary of selected countries <span class="citation" data-cites="Lanman2023">(Lanman, Davis, and Shipp 2023)</span>.</p>
</div>
</div>
</section>
<section id="a-new-approach" class="level2">
<h2 class="anchored" data-anchor-id="a-new-approach">A new approach</h2>
<p>To realize the CDE vision, the development of statistical products will address stakeholder questions using all data types – designed surveys and censuses, public and private administrative data, opportunity data scraped from the internet and procedural data <span class="citation" data-cites="keller2022bold">(Keller et al. 2022)</span>. This new approach aligns with the US Census Bureau’s modernization and transformation <span class="citation" data-cites="thieme2022technology">(Thieme 2022)</span> while maintaining the fundamental responsibilities of statistical agencies <span class="citation" data-cites="management2023fundamentals">(OMB 2023)</span>. It is also consistent with a conclusion by the NASEM <em>Panel on the Implications of Using Multiple Data Sources for Major Survey Programs</em>: ‘The quality of statistics produced from multiple data sources depends on properties of the individual sources as well as the methods used to combine them. A new framework of quality standards and guidelines is needed to evaluate such data sources’ fitness for use’ <span class="citation" data-cites="NASEM2023">(NASEM 2023, 192)</span>.</p>
<p>The CDE approach provides such a framework to address many of the challenges that official statistics face today, as well as demonstrate that they are poised to adopt a new approach to producing official statistics. For example:</p>
<ul>
<li><p>The timeliness and frequency of our official statistics are insufficient when there are shocks to the economy, such as the Covid-19 pandemic, when retrospective survey data were of limited usefulness. Federal agencies responded during the pandemic with relevance and agility by creating and launching fast-response Household Pulse Surveys that met immediate needs for data, trading off timeliness for quality <span class="citation" data-cites="Groshen2021Future">(Groshen 2021)</span>. Public engagement and support for these new relevant and timely data products at a time of crisis were essential to the success of this new statistical product.</p></li>
<li><p>The policy environment has responded to technological, social, and survey changes by encouraging efficient use of existing data, reuse, sharing and furthering open data principles. Researchers are now creating innovative statistical products using multiple data sources to better address the US’s needs and interests. The Commission on Evidence-Based Policymaking <span class="citation" data-cites="abraham2018promise">(Abraham et al. 2018)</span> and the Federal Data Strategy <span class="citation" data-cites="FedDataStrat">(<span>“Federal Data Strategy, Leveraging Data as a Strategic Asset”</span> 2021)</span> recommendations encourage agencies to permit access to data to undertake evaluation and research studies.</p></li>
<li><p>Techniques such as rapid scanning, text recognition, user-friendly uploads, and new devices, sensors, and systems can now record and transcribe data in real time. Using these techniques, governments and corporations now routinely and instantaneously collect and store data on behaviors and states as varied as purchase transactions, climate and road conditions, healthcare plan utilization, and land use and zoning. Extensive digitization and recording, better system connectedness and interactivity, and increased human-computer interaction can result in faster data accumulation, enhancing the usability of private and public administrative data while maintaining privacy and confidentiality <span class="citation" data-cites="brady2019challenge jarmin2019evolving">(Brady 2019; Jarmin 2019)</span>. &nbsp;</p></li>
<li><p>New techniques and data sources can transform statistical agencies ‘from the 20th-century survey-centric model to a 21st-century model that blends structured survey data with administrative and unstructured alternative digital data sources’, leading to better measures of the gig economy, retail sales, healthcare, workforce, and tools and methods to integrate multiple data sources while maintaining privacy and confidentiality <span class="citation" data-cites="jarmin2019evolving">(Jarmin 2019)</span>.</p></li>
</ul>
<p>The next three articles in this series will:</p>
<ul>
<li><p>provide an overview of the CDE and its corresponding framework</p></li>
<li><p>put the CDE Framework into practice through a demonstration use case on the resilience of skilled nursing facilities</p></li>
<li><p>describe our next steps for developing the CDE through a use case research program.</p></li>
</ul>
<div class="nav-btn-container">
<div class="grid">
<div class="g-col-12 g-col-sm-6">
<div class="nav-btn">
<p><a href="../../../../../../applied-insights/case-studies/posts/2024/11/08/what-is-CDE-2.html">Part 2: What is the Curated Data Enterprise? →</a></p>
</div>
</div>
</div>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-12">
<dl>
<dt>About the authors</dt>
<dd>
<p><strong>Sallie Keller</strong> is the Chief Scientist and Associate Director of Research and Methodology at the US Census Bureau. She is a statistician with research interest in social and decision informatics, statistics underpinnings of data science, and data access and confidentiality. Sallie Keller was at the University of Virginia when this work was conducted.</p>
</dd>
<dd>
<p><strong>Stephanie Shipp</strong> leads the Curated Data Enterprise research portfolio and collaborates with the US Census. She is an economist with experience in data science, survey statistics, public policy, innovation, ethics, and evaluation.</p>
</dd>
<dd>
<p><strong>Vicki Lancaster</strong> is a statistician with expertise in experimental design, linear models, computation, visualizations, data analysis, and interpretation. She works with scientists at federal agencies on projects requiring statistical skills and creativity, eg, defining skilled technical workforce using novel data sources.</p>
</dd>
<dd>
<p><strong>Joseph Salvo</strong> is a demographer with experience in US Census Bureau statistics and data. He makes presentations on demographic subjects to a wide range of groups about managing major demographic projects involving the analysis of large data sets for local applications.</p>
</dd>
</dl>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>Copyright and licence</dt>
<dd>
<p>© 2024 Stephanie Shipp</p>
</dd>
</dl>
<p><a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> <img src="https://mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1" style="height:22px!important;vertical-align:text-bottom;"><img src="https://mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1" style="height:22px!important;margin-left:3px;vertical-align:text-bottom;"></a> This article is licensed under a Creative Commons Attribution 4.0 (CC BY 4.0) <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> International licence</a>. Thumbnail photo by <a href="https://unsplash.com/@goumbik">Lukas Blazek</a> on <a href="https://unsplash.com/photos/turned-on-black-and-grey-laptop-computer-mcSDtbWXUZU">Unsplash</a>.</p>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>How to cite</dt>
<dd>
<p>Keller S, Shipp S, Lancaster V, Salvo J (2024). “Advancing Data Science in Official Statistics: The Policy Problem.” Real World Data Science, November 01, 2024. <a href="https://realworlddatascience.net/applied-insights/case-studies/posts/2024/11/01/policy-problem.html">URL</a></p>
</dd>
</dl>
</div>
</div>
</div>



</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0">
<div id="ref-abraham2018promise" class="csl-entry">
Abraham, Katherine G, Ron Haskins, Sherry Glied, Robert M Groves, Robert Hahn, Hilary Hoynes, and KR Wallin. 2018. <span>“The Promise of Evidence-Based Policymaking: Report of the Commission on Evidence-Based Policymaking.”</span> <em>Washington, DC: Commission on Evidence-Based Policymaking</em>. <a href="https://www.cep.gov/ content/dam/cep/report/cep-final-report.pdf">https://www.cep.gov/ content/dam/cep/report/cep-final-report.pdf</a>.
</div>
<div id="ref-brady2019challenge" class="csl-entry">
Brady, Henry E. 2019. <span>“The Challenge of Big Data and Data Science.”</span> <em>Annual Review of Political Science</em> 22: 297–323. <a href="https://www.annualreviews.org/doi/abs/10.1146/annurev-polisci-090216-023229">https://www.annualreviews.org/doi/abs/10.1146/annurev-polisci-090216-023229</a>.
</div>
<div id="ref-FedDataStrat" class="csl-entry">
<span>“Federal Data Strategy, Leveraging Data as a Strategic Asset.”</span> 2021. 2021. <a href="https://strategy.data.gov/">https://strategy.data.gov/</a>.
</div>
<div id="ref-Groshen2021Future" class="csl-entry">
Groshen, Erica L. 2021. <span>“The <span>Future</span> of <span>Official</span> <span>Statistics</span>.”</span> <em>Harvard Data Science Review</em> 3 (4).<a href=" https://doi.org/10.1162/99608f92.591917c6"> https://doi.org/10.1162/99608f92.591917c6</a>.
</div>
<div id="ref-jarmin2019evolving" class="csl-entry">
Jarmin, Ron S. 2019. <span>“Evolving Measurement for an Evolving Economy: Thoughts on 21st Century US Economic Statistics.”</span> <em>Journal of Economic Perspectives</em> 33 (1): 165–84.
</div>
<div id="ref-keller2022bold" class="csl-entry">
Keller, Sallie, Kenneth Prewitt, John Thompson, Steve Jost, Christopher Barrett, Sarah Nusser, Joseph Salvo, and Stephanie Shipp. 2022. <span>“A 21st Century Census Curated Data Enterprise. A Bold New Approach to Create Official Statistics. Technical Report.”</span> <em>Proceedings of the Biocomplexity Institute</em> BI-2022-1115: 297–323. <a href="https://doi.org/10.18130/r174-yk24">https://doi.org/10.18130/r174-yk24</a>.
</div>
<div id="ref-Lanman2023" class="csl-entry">
Lanman, Kathryn, Olivia Davis, and Stephanie Shipp. 2023. <span>“What Can We Learn from Other Countries about How They Are Using Administrative Data to Supplement, Enhance, or Create New Data Products?”</span> <em>Proceedings of the Biocomplexity Institute</em>. <a href="https://doi.org/10.18130/2n54-sc22">https://doi.org/10.18130/2n54-sc22</a>.
</div>
<div id="ref-NASEM2023" class="csl-entry">
NASEM. 2023. <span>“Toward a 21st Century National Data Infrastructure: Enhancing Survey Programs by Using Multiple Data Sources.”</span> <em>National Academies of Science, Engineering, and Medicine</em>. <a href="https://doi.org/10.17226/26804">https://doi.org/10.17226/26804</a>.
</div>
<div id="ref-management2023fundamentals" class="csl-entry">
OMB. 2023. <span>“Fundamental Responsibilities of Recognized Statistical Agencies and Units.”</span> <em>Federal Register: The Daily Journal of the US Government</em>, 56708–44. <a href="https://www.federalregister.gov/documents/2023/08/18/2023-17664/fundamental-responsibilities-of-recognized-statistical-agencies-and-units
  ">https://www.federalregister.gov/documents/2023/08/18/2023-17664/fundamental-responsibilities-of-recognized-statistical-agencies-and-units </a>.
</div>
<div id="ref-thieme2022technology" class="csl-entry">
Thieme, Michael. 2022. <span>“Technology Transformations at the Census Bureau: Building a Modern, Data-Centric Ecosystem.”</span> <a href="hhttps://www.census.gov/newsroom/blogs/research-matters/2022/10/technology-transformation.html
  ">hhttps://www.census.gov/newsroom/blogs/research-matters/2022/10/technology-transformation.html </a>.
</div>
</div></section></div> ]]></description>
  <category>Public Policy</category>
  <category>Data Analysis</category>
  <category>Data Integration</category>
  <category>Curation</category>
  <category>Statistical Products</category>
  <guid>https://realworlddatascience.net/applied-insights/case-studies/posts/2024/11/01/policy-problem.html</guid>
  <pubDate>Fri, 01 Nov 2024 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/applied-insights/case-studies/posts/2024/11/01/images/laptop-thumbnail.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>The machine learning victories at the 2024 Nobel Prize Awards and how to explain them</title>
  <dc:creator>Anna Demming</dc:creator>
  <link>https://realworlddatascience.net/foundation-frontiers/posts/2024/10/31/machine-learning-nobel-prizes.html</link>
  <description><![CDATA[ 





<p>Few saw it coming when on 8th October 2024 the Nobel Committee awarded the <a href="https://www.nobelprize.org/prizes/physics/2024/prize-announcement/">2024 Nobel Prize for Physics</a> to John Hopfield for his Hopfield networks and Geoffrey Hinton for his Boltzmann machines as seminal developments towards machine learning that have statistical physics at the heart of them. The next day machine learning albeit using a different architecture bagged half of the <a href="https://www.nobelprize.org/prizes/chemistry/2024/prize-announcement/">Nobel Prize for Chemistry</a> as well, with the award going to Demis Hassabis and John Jumper for the development of an algorithm that predicts protein folding conformations. The other half of the Chemistry Nobel was awarded to David Baker for successfully building new proteins.</p>
<div id="fig-1" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center" alt="Close-up of a copy of the Nobel Prize Medal. Photographed on the floor of the Nobel Museum in Old Town, Stockholm. Machine learning came up a winner in both the Physics and Chemistry Nobel Prizes for 2024. Credit: Shutterstock">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="https://realworlddatascience.net/foundation-frontiers/posts/2024/10/31/images/Nobelpic-shutterstock-991.png" class="img-fluid quarto-figure quarto-figure-center figure-img" alt="Close-up of a copy of the Nobel Prize Medal. Photographed on the floor of the Nobel Museum in Old Town, Stockholm. Machine learning came up a winner in both the Physics and Chemistry Nobel Prizes for 2024. Credit: Shutterstock">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;1: Close-up of a copy of the Nobel Prize Medal. Photographed on the floor of the Nobel Museum in Old Town, Stockholm. Machine learning came up a winner in both the Physics and Chemistry Nobel Prizes for 2024. Credit: Shutterstock
</figcaption>
</figure>
</div>
<p>While the AI takeover at this year’s Nobel announcements for Physics and Chemistry came as surprise to most, there has been some keen interest on how these apparently different approaches to machine learning might actually reduce to the same thing, revealing new ways of extracting some fundamental explainability from the generative AI algorithms that have so far been considered effectively “black boxes”. The “transformer architectures” behind the likes of ChatGPT and AlphaFold are incredibly powerful but offer little explanation as to how they reach their solutions so that people have resorted to querying the algorithms and adding to them in order to extract information that might offer some insights. “This is a much more conceptual understanding of what’s going on,” says Dmitry Krotov, now a researcher at IBM Research in Cambridge Massachusetts, who working alongside John Hopfield made some of the first steps that helps bring the two types of machine learning algorithm together.</p>
<section id="collective-phenomena" class="level2">
<h2 class="anchored" data-anchor-id="collective-phenomena">Collective phenomena</h2>
<p>Hopfield networks brought some of the mathematical toolbox long applied to extract “collective phenomena” from vast numbers of essentially identical parts such as atoms in a gas or atomic spins in magnetic materials. Although there maybe too many particles to track each individually, properties like temperature and magnetic field can be extracted using statistical physics. Hopfield showed that similarly a useful phenomenon he described as “associative memory” could be constructed from large numbers of artificial neurons by defining a “minimum energy”, which describes the network of neurons. The energy is determined by connections between neurons, which store information about patterns. Thus the network can retrieve the memorized patterns by minimizing that energy, just as stable conformations of atomic spins might be found in a magnetic material<sup>1</sup>. As the energy of the network is then subsequently minimised the pattern gets closer to the one that was memorised, just as when recalling a word or someone’s name we might first run through similar sounding words or names.</p>
<p>These Hopfield networks proved a seminal step in progressing AI algorithms, enabling a kind of pattern recognition from multiple stored patterns. However, it turned out that the number of patterns that could be stored was fundamentally limited due to what are known as “local” minima. You can imagine a ball rolling down a hill – it will reach the bottom of the hill fine so long as there are no dips for it to get stuck in en route. Algorithms based on Hopfield networks were prone to getting stuck in such dips or undesirable local minima, until Hopfield and Krotov put their heads together to find a way around it. Krotov describes himself as “incredibly lucky” that his research interests aligned so well with Hopfield. “He’s just such a smart and genuine person, and he has been in the field for many years,” he tells Real World Data Science. “He just knows things that no one else in the world knows.” Together they worked out they could address the problem of local minima by toggling the “activation function”.</p>
<div id="fig-2" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center" alt="Energy Landscape of a Hopfield Network, highlighting the current state of the network (up the hill), an attractor state to which it will eventually converge, a minimum energy level and a basin of attraction shaded in green. Note how the update of the Hopfield Network is always going down in Energy. Credit: Mrazvan22/wikimedia">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="https://realworlddatascience.net/foundation-frontiers/posts/2024/10/31/images/Energy_landscape.png" class="img-fluid quarto-figure quarto-figure-center figure-img" alt="Energy Landscape of a Hopfield Network, highlighting the current state of the network (up the hill), an attractor state to which it will eventually converge, a minimum energy level and a basin of attraction shaded in green. Note how the update of the Hopfield Network is always going down in Energy. Credit: Mrazvan22/wikimedia">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2: Energy Landscape of a Hopfield Network, highlighting the current state of the network (up the hill), an attractor state to which it will eventually converge, a minimum energy level and a basin of attraction shaded in green. Note how the update of the Hopfield Network is always going down in Energy. Credit: Mrazvan22/wikimedia
</figcaption>
</figure>
</div>
<p>In a Hopfield network all the neurons are connected to all the other neurons, however originally the algorithm only considered interactions between two neurons at each point, i.e.&nbsp;the interaction between neuron 1 and neuron 2, neuron 1 and neuron 3 and neuron 2 and neuron 3, but not the interactions among all three altogether. By including such “higher order” interactions between more than two neurons, Krotov and Hopfield found they made the basins of attraction for the true minimum energy states deeper. You can think of it a little like the ball rolling down a steeper hill so that it picks up more momentum along the slope of the main hill and is less prone to falling in little dips en route. This way Krotov and Hopfield increased the memory of Hopfield networks in what they called the Dense Associative Memory, which they described in 2016<sup>2</sup>. Long before then, however, Geoffrey Hinton had found a different tack to follow to increase the power of this kind of neural network.</p>
</section>
<section id="generative-ai" class="level2">
<h2 class="anchored" data-anchor-id="generative-ai">Generative AI</h2>
<p>Geoffrey Hinton showed that by defining some neurons as a hidden layer and some as a visible layer (a Boltzmann machine<sup>3</sup>) and limiting the connections so that neurons are only connected with neurons in other layers (a restricted Boltzmann machine<sup>4</sup>), finding the most likely network would generate networks with meaningful similarities – a type of generative AI. This and many other contributions by Geoffrey Hinton also proved incredibly useful in the progress of machine learning. However, the generative AI algorithms grabbing headlines today have actually been devised using a “transformer” architecture, which differs from Hopfield networks and Boltzmann machines, or so it seemed initially.</p>
<p>Transformer algorithms first emerged as a type of language model and were defined by a characteristic termed “attention”. “They say that each word represents a token, and essentially the task of attention is to learn long-range correlations between those tokens,” Krotov explains using the word “bank” as an example. Whether the word means the edge of a river or a financial institution can only be ascertained from the context in which it appears. “You learn these long-range correlations, and that allows you to contextualize and understand the meaning of every word.” The approach was first reported in 2017 in a paper titled “Attention is all you need”<sup>5</sup> by researchers at Google Brain and Google Research.</p>
<p>It was not long before people figured out that the approach would enable powerful algorithms for tasks beyond language manipulation, including Demis Hassabis and John Jumper at Deep Mind as they worked to figure out an algorithm that could predict the folding conformations of proteins. The algorithm they landed on in 2020 – AlphaFold2 – was capable of protein conformation prediction with a 90% accuracy, way ahead of any other algorithm at the time, including Deep Mind’s previous attempt AlphaFold, which although streaks ahead of the field at the time it was developed in 2018, still only achieved an accuracy of 60%. It was for the extraordinary predictive powers for protein conformations achieved by AlphaFold2 that Hassabis and Jumper were awarded half the 2024 Nobel Prize for Chemistry.</p>
</section>
<section id="connecting-the-dots" class="level2">
<h2 class="anchored" data-anchor-id="connecting-the-dots">Connecting the dots</h2>
<p>Transformer architectures are undoubtedly hugely powerful but how they operate can seem something of a dark art as although computer scientists know how they are programmed, even they cannot tell how they reach their conclusions in operation. Instead they query the algorithm and add to it to try and get some pointers as to what the trail of logic might have been. Here Hopfield networks have an advantage because people can hope to get a grasp on what energy minima they are converging to, and that way get a handle on their working out. However, in their paper “Hopfield networks is all you need”<sup>6</sup>, researchers in Austria and Norway showed that the activation function, which Hopfield and Krotov had toggled to make Hopfield networks store more memories, can also link them to transformer architectures – essentially if the function is exponential they can reduce to the same thing.</p>
<p>“We think about attention as learning long-range correlations, and this dense associative memory interpretation of attention tells you that each word creates a basin of attraction,” Krotov explains. “Essentially, the contextualization of the unknown word happens through the attraction to these different memories,” he adds. “That kind of lens of thinking about transformers through the prism of energy landscapes – it’s opened up this whole new world where you can think about what transformers are doing computationally, and how they perform that computation.”</p>
<p>“I think it’s great that the power of these tools is being recognised for the impact that they can have in accelerating innovation in new ways,” says Janet Bastiman, RSS Data Science and AI Section Chair and Chief Data Scientist at financial crimes compliance solutions company Napier AI, as she comments on the Nobel Prize awards. Bastiman’s most recent work has been on adding explanation to networks. She notes how the report Hopfield networks is all you need highlights “the difference that layers can have on the final outcomes for specific tasks and a clear need for understanding some of the principles of the layers of networks in order to validate results and be aware of potential difficulties and”best” scenarios for different use cases.”</p>
<p>Krotov also points out that since Hopfield networks are rooted in neurobiological interpretations, it helps to find “neurobiological ways of interpreting their computation” for transformer algorithms too. As such the vein Hopfield and Hinton tapped into with their seminal advances is proving ever richer in what Krotov describes as “the emerging field of the physics of neural computation”.</p>
<div class="article-btn">
<p><a href="../../../../../foundation-frontiers/index.html">Explore more data science ideas</a></p>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-12">
<dl>
<dt>About the author</dt>
<dd>
<strong>Anna Demming</strong> is a freelance science writer and editor based in Bristol, UK. She has a PhD from King’s College London in physics, specifically nanophotonics and how light interacts with the very small, and has been an editor for Nature Publishing Group (now Springer Nature), IOP Publishing and New Scientist. Other publications she contributes to include The Observer, New Scientist, Scientific American, Physics World and Chemistry World..
</dd>
</dl>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>Copyright and licence</dt>
<dd>
© 2024 Anna Demming
</dd>
</dl>
<p><a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> <img style="height:22px!important;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"></a> Text, code, and figures are licensed under a Creative Commons Attribution 4.0 (CC BY 4.0) <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;">International licence</a>, except where otherwise noted. Thumbnail image by <a href="https://www.shutterstock.com/image-photo/mute-key-on-neat-white-keyboard-1832448097">Shutterstock/Park Kang Hun</a> <a href="https://creativecommons.org/licenses/by/4.0/">Licenced by CC-BY 4.0</a>.</p>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>How to cite</dt>
<dd>
Demming, Anna. 2024. “The machine learning victories at the 2024 Nobel Prize awards and how to explain them” Real World Data Science, October 31, 2024. <a href="https://realworlddatascience.net/foundation-frontiers/posts/2024/10/31/machine-learning-nobel-prizes.html">URL</a>
</dd>
</dl>
</div>
</div>
</div>


</section>


<div id="quarto-appendix" class="default"><section id="footnotes" class="footnotes footnotes-end-of-document"><h2 class="anchored quarto-appendix-heading">References</h2>

<ol>
<li id="fn1"><p>Hopfield J J Neural networks and physical systems with emergent collective computational abilities <em>PNAS</em> <strong>79</strong> 2554-2558 (1982) <a href="https://www.pnas.org/doi/pdf/10.1073/pnas.79.8.2554">https://www.pnas.org/doi/pdf/10.1073/pnas.79.8.2554</a>↩︎</p></li>
<li id="fn2"><p>Krotov D and Hopfield J J Dense Associative Memory for Pattern Recognition <em>NIPS</em> (2016)<a href="https://papers.nips.cc/paper_files/paper/2016/hash/eaae339c4d89fc102edd9dbdb6a28915-Abstract.html">https://papers.nips.cc/paper_files/paper/2016/hash/eaae339c4d89fc102edd9dbdb6a28915-Abstract.html</a>↩︎</p></li>
<li id="fn3"><p>Ackley D H, Hinton G E and Sejnowski T E A learning algorithm for boltzmann machines <em>Cognitive Science</em> <strong>9</strong> 147-169 (1985) <a href="https://www.sciencedirect.com/science/article/pii/S0364021385800124">https://www.sciencedirect.com/science/article/pii/S0364021385800124</a>↩︎</p></li>
<li id="fn4"><p>Salakhutdinov R, Mnih A and Hinton G Restricted Boltzmann machines for collaborative filtering <em>ICML ’07: Proceedings of the 24th international conference on Machine learning</em> 791-798 (2007) <a href="https://dl.acm.org/doi/10.1145/1273496.1273596">https://dl.acm.org/doi/10.1145/1273496.1273596</a>↩︎</p></li>
<li id="fn5"><p>Vaswani A, Shazeer N, Parmar N, Uszkoreit J, Jones L, Gomez A N, Kaiser Ł, Polosukhin I Attention is all you need <em>NIPS</em> (2017)<a href="https://papers.nips.cc/paper_files/paper/2017/hash/3f5ee243547dee91fbd053c1c4a845aa-Abstract.html">https://papers.nips.cc/paper_files/paper/2017/hash/3f5ee243547dee91fbd053c1c4a845aa-Abstract.html</a>↩︎</p></li>
<li id="fn6"><p>Ramsauer H, Schäfl B, Lehner J, Seidl P, Widrich M, Adler T, Gruber L, Holzleitner M, Pavlović M, Kjetil Sandve G, Greiff V, Kreil D, Kopp M, Klambauer G, Brandstetter J and Hochreiter S <em>arXiv</em> (2020) <a href="https://arxiv.org/abs/2008.02217">https://arxiv.org/abs/2008.02217</a>↩︎</p></li>
</ol>
</section></div> ]]></description>
  <category>AI</category>
  <category>Algorithms</category>
  <category>Machine Learning</category>
  <guid>https://realworlddatascience.net/foundation-frontiers/posts/2024/10/31/machine-learning-nobel-prizes.html</guid>
  <pubDate>Thu, 31 Oct 2024 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/foundation-frontiers/posts/2024/10/31/images/Nobelpic-shutterstock-991.png" medium="image" type="image/png" height="96" width="144"/>
</item>
<item>
  <title>Are we at risk of muting the female voice in the digital world?</title>
  <dc:creator>Anna Demming</dc:creator>
  <link>https://realworlddatascience.net/foundation-frontiers/posts/2024/09/17/digital-gender-gap.html</link>
  <description><![CDATA[ 





<p>Knowledge is power and today a lot of that knowledge – not just what you know but who you know – is online. In 2015 the UN General Assembly laid out 17 Sustainable Development Goals (SDGs) that aim to end poverty and other deprivations while improving the welfare of both people and the planet. One of the <a href="https://sdgs.un.org/goals/goal5#targets_and_indicators">SDGs deals with gender equality</a> and emphasises the importance of digital technology for empowering women. Online, a woman can engage in commercial, social, business or networking transactions without the need to be absent from care responsibilities at home or maintain traditional 9-5 working hours or, in some instances, even expose the fact that she is a woman at all – all potentially transformative features of online engagement<sup>1</sup>. Yet the reality for digital technology to empower women is by no means clear cut.</p>
<p>‘For me, whether digital technologies are able to empower women was fundamentally an empirical question,’’ says professor of demography and computational data science at Oxford University <a href="https://www.sociology.ox.ac.uk/people/ridhi-kashyap">Ridhi Kashyap</a>. She adds that in order to ask these questions of impact, you first need to be able to measure inequalities in digital access. However, the pace of technological change has been a lot faster than the rate at which national censuses – or other kinds of surveys useful to social scientists – update their questions, so they shed little light on the demographics around digital technologies.</p>
<p>Since then, progress in accruing data on digital access has revealed some stark gender inequalities. However, access is not the only fly in the ointment when it comes to the potential for digital technology to help towards gender equality. ‘The most harmful illegal online content disproportionately affects women and girls,’ says the <a href="https://www.gov.uk/government/publications/online-safety-act-explainer/online-safety-act-explainer#how-the-act-protects-women-and-girls">explainer for the UK’s 2023 Online Safety Act</a>. A <a href="https://www.turing.ac.uk/news/publications/understanding-gender-differences-experiences-and-concerns-surrounding-online">study by the Turing Institute</a> published earlier this year has revealed nuances on this picture, but confirmed that many women feel particularly vulnerable online, suggesting women may be losing a seat at the table as debate and discourse increasingly moves online.</p>
<div id="fig-1" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center" alt="Muted. In the absence of proactive intervention, the shift of debate and discourse online risks muting women and girls as multiple factors exclude them from engaging there as productively as male counterparts. Copyright: Park Kang Hun/Shutterstock.">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="https://realworlddatascience.net/foundation-frontiers/posts/2024/09/17/images/Minoan-Illustration.jpg" class="img-fluid quarto-figure quarto-figure-center figure-img" alt="Muted. In the absence of proactive intervention, the shift of debate and discourse online risks muting women and girls as multiple factors exclude them from engaging there as productively as male counterparts. Copyright: Park Kang Hun/Shutterstock.">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;1: Muted. In the absence of proactive intervention, the shift of debate and discourse online risks muting women and girls as multiple factors exclude them from engaging there as productively as male counterparts. Copyright: Park Kang Hun/Shutterstock.
</figcaption>
</figure>
</div>
<p>The digital gender gap has a cost estimated at $126 billion USD for the 32 low- and low-to-middle-income countries analysed by the Alliance for Affordable Internet (A4AI)<sup>2</sup>. This is due to the ‘untold wealth of cultural, social, and scientific knowledge lost because of the exclusion of women’s and girls’ voices from the online world.’ Focus on this issue has brought a little more clarity to the size of the problem. However, while the UK’s Online Safety Act marks some progress, questions remain as to what can be done, and whether the hope of digital technologies helping towards gender equality is still justified.</p>
<section id="gender-disparities-in-internet-access" class="level2">
<h2 class="anchored" data-anchor-id="gender-disparities-in-internet-access">Gender disparities in internet access</h2>
<p>A turning point in the conversation around digital technology and gender equality came in 2018 with work by Kashyap and collaborators in the US and Qatar at the time. They found that where traditional survey-based data on internet and mobile gender gaps was available, it correlated well with the gender gap on Facebook, using data extracted for Facebook’s ad platform: When Facebook’s aggregate user counts did not show women, it provided a good signal that women were not online altogether in those countries. As such, the work revealed a potentially useful proxy to gauge the digital gender gap in countries where little traditional survey data was available<sup>3</sup>. <a href="https://www.digitalgendergaps.org/">The results</a> revealed an unexpectedly large gender gap, particularly in parts of South Asia and certain countries in Africa where men were up to twice as likely to have access to the Internet compared with women.</p>
<p>‘In some sense it was perhaps not surprising,’’ says Kashyap highlighting that having a mobile phone or similar device that grants access to the internet amounts to a kind of asset ownership, and studies for other assets indicate women are less likely to own them. ‘This is broadly reflective of economic gender inequality,’ she adds. Perhaps more surprising is that the gaps have changed very little in the five years since <a href="https://www.digitalgendergaps.org/">their website, which monitors the digital gender gap</a>, was first released, particularly in view of the pace of technological progress in general, and the importance placed on closing the gap. Citing India as an example, Kashyap points out that in 2019 the ratio of access to the internet for men versus women was 0.619 – fewer than two women had access for every three men with access. In the subsequent half decade this digital gender gap has closed by just 7.1% to a ratio of 0.663.</p>
<div id="fig-2" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center" alt="The digital gender gap. Ratio of female-to-male internet use estimated using the Facebook Gender Gap Index^[Leasure D R, Yan J, Bondarenko M, Kerr D, Fatehkia M, Weber I &amp; Kashyap R. Digital Gender Gaps Web Application, v1.0.0. Zenodo, GitHub (2023) [doi:10.5281/zenodo.7897491](https://github.com/OxfordDemSci/dgg-www)]">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="https://realworlddatascience.net/foundation-frontiers/posts/2024/09/17/images/Digital gender gap.png" class="img-fluid quarto-figure quarto-figure-center figure-img" alt="The digital gender gap. Ratio of female-to-male internet use estimated using the Facebook Gender Gap Index^[Leasure D R, Yan J, Bondarenko M, Kerr D, Fatehkia M, Weber I &amp; Kashyap R. Digital Gender Gaps Web Application, v1.0.0. Zenodo, GitHub (2023) [doi:10.5281/zenodo.7897491](https://github.com/OxfordDemSci/dgg-www)]">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2: The digital gender gap. Ratio of female-to-male internet use estimated using the Facebook Gender Gap Index<sup>4</sup>
</figcaption>
</figure>
</div>
<p>In countries where the gender disparity for access to the internet is large, there is evidence to suggest that those women who do have access are of the more affluent echelons of society. Analysis of the type of device used, which can also be retrieved from the Facebook ad platform, highlighted that where women are less likely to be online, the relative proportion of iOS users tends to be higher among women than among men, and as Kashyap points out, ‘iOS users are on average wealthier’. Fortunately, among the stakeholders starting to see the benefit of closing the gap in access to the internet between the genders are the mobile network providers, who are looking for ways to tap into this part of the market through incentives and discounts on SIMs for women. However, it is unclear to what extent these types of schemes are ultimately beneficial in closing the wider gap.</p>
<p>Kashyap and her colleagues also found that a key predictor of the digital gender gap was the gender gap in educational attainment. ‘I think that’s quite telling, because it’s showing that accessing education and going to educational institutions is also a pathway to becoming more digitally integrated,’ says Kashyap, flagging that schools and educational institutions are where women and girls often access computers and digital technologies. She highlights that beyond giving people a device ‘more of the challenge’ is helping them make good use of it by ‘giving people skills to feel that this is actually meaningful for them, and allows them to do things that they wouldn’t be able to do otherwise, and feeling confident and safe and secure.’ She emphasises the importance of men valuing gender equality, highlighting work from South Asia that shows that even when women have a device, their use of it may be curtailed or scrutinised by male members of the household, sometimes on the grounds of <a href="https://www.gsma.com/solutions-and-impact/connectivity-for-good/mobile-for-development/blog/the-mobile-gender-gap-in-south-asia-is-now-widening/">doubts over women’s safety online</a>.</p>
</section>
<section id="gender-disparities-in-fears-of-online-harms" class="level2">
<h2 class="anchored" data-anchor-id="gender-disparities-in-fears-of-online-harms">Gender disparities in ‘fears’ of online harms</h2>
<p>Safety can be a knotty issue when it comes to enabling women to have a voice online. A study by the Alan Turing Institute<sup>5</sup> earlier this year suggested just 23% of women in general feel comfortable expressing political opinions online, compared with 40% of men. This might be down to women in general being exposed to online violence more than men, as previous studies of online harms have suggested. Indeed, a key takeaway from the Alan Turing Institute’s study was that women reported greater fears of exposure for all categories of harm, although this included types of harm that women reported experiencing less frequently than men.</p>
<p>Previous studies have largely surveyed women-only sample-groups so that their conclusions were drawn without data on men against which to compare. In contrast, the researchers at the Alan Turing Institute, including researcher <a href="https://www.turing.ac.uk/people/researchers/tvesha-sippy">Tvesha Sippy</a>, took a nationally representative survey of 2,000 men and women. They investigated whether they had been exposed to various types of online harms, their fears surrounding such exposure, the psychological impact of those experiences in general, tendencies to use protective tools for digital activities, and how comfortable they felt with online behaviours such as expressing opinions and sharing information online. The study revealed that women were more likely to report experiencing some harms, such as online misogyny, cyberflashing, cyberstalking, image-based abuse and eating disorder content to a significantly greater extent than men. However, there were several harms that men reported being the direct targets of to a greater extent than women, such as hate speech, misinformation, trolling and threats of physical violence.</p>
<p>By using a representative cohort, the Alan Turing Institute study tells a more nuanced story than those sampling women only and highlights challenges in similar assessments for minority groups. For example, those identifying as non-binary were excluded from the analysis by the Alan Turing Institute because, although as Sippy emphasises, ‘We do want to look at minoritised genders,’ they did not have sufficient numbers of respondents in this category within their nationally representative survey to do any meaningful analysis. Ultimately, a higher budget enabling larger samples would allow analysis of minority groups as well.</p>
<p>As for the greater fears for all online harms reported by women, ‘it’s a very complex phenomenon,’’ Sippy tells Real World Data Science, highlighting the need for further research. She points to several possible explanations such as differences in the impacts of the harms experienced more by women versus men, as well as innate fearfulness potentially from the offline world translating to behaviour online. Sippy also highlights the differences in how men and women experience online harms, which may offer clues. Women were more likely to report that their fears stem from the experience of a public figure (35% of the women surveyed compared with 26% of the men) or a female friend (37% of the women compared with 27% of the men). Furthermore, the experience of a male friend was much less often cited as the source of online fears for both groups (8% of the women and 14% of the men). There is also the possibility that women’s adaptive behaviours make them less exposed to future online harms than men, since women were more likely to make use of protective tools from disabling location-sharing on a device, and limiting who can engage with images, posts and tweets, or even find their profile. While protective, such adaptive behaviours could also dampen the influence women have in online discourse.</p>
<p>Rather than relying on adaptive behaviour for self-protection, it would seem a lot of people are keen to see more action from social media companies and governments to help people to feel safer online. In 2023, researchers at the Turing Institute led by senior research associate Florence Enock published a study investigating <a href="https://www.turing.ac.uk/news/publications/experiences-online-harms">attitudes to online interventions</a>. They found that 79% thought social media platforms should ban or suspend users who create harmful content and 73% thought that platforms should remove harmful content. According to the report ‘this was consistent across age, gender, educational background, income and political ideology.’</p>
<p>There are some complications for social media companies who need to balance privacy needs with protection, as well as having the resources required to handle multilingual posts when investigating what action to take. However, Sippy feels there remains a need to have a civil remedy in place so that a user can request a platform take down content which is harmful without having to pursue criminal proceedings and get the police involved. Where the additional resources needed for social media companies to take corrective action and a lack of business incentive pose an obstacle, government legislation may help. The same study into attitudes to online interventions also reported that for platforms that fail to deal with harmful content online more than 70% of respondents felt the government should be able to issue large fines, and 66% thought that legal action should be taken.</p>
<p>‘The Online Safety Act is a really good start,’ adds Sippy, also highlighting the importance of proposals by the previous UK government to criminalise the creation of sexually explicit deep fakes. She points to a 2019 report by AI firm Deeptrace, suggesting that of 15,000 deep fake videos they found online, 96% constituted nonconsensual pornography with women disproportionately targeted<sup>6</sup>. In a recent Alan Turing Institute survey 90% of respondents expressed concerns about deepfakes increasing misogyny and online violence against women and girls<sup>7</sup>. ‘I do see there’s more advocacy, but it remains to be seen what approach the new Government will take.’</p>
</section>
<section id="gender-disparities-for-making-an-impact-online" class="level2">
<h2 class="anchored" data-anchor-id="gender-disparities-for-making-an-impact-online">Gender disparities for making an impact online</h2>
<p>Challenges to women being heard online seem to go beyond safety issues. Recent research by Kashyap and collaborators at the University of Oxford and collaborators in Iran and Germany has also highlighted differences in how influential women’s professional networks are relative to male counterparts<sup>8</sup>. In previous work with Florianne Verkroost, also at the University of Oxford, Kashyap had investigated the gender gaps in those who have a LinkedIn profile to see how they vary across industries<sup>9</sup>. They found that use of the platform broadly mirrors female-to-male ratios of representation in technical and managerial professions. In reference 8, they then investigated what insights LinkedIn data might provide as to the cause of some of the gender disparities in these professions, and ultimately why women are not progressing in technical and professional jobs as well as male counterparts.</p>
<p>‘One argument is that that’s often because they don’t have advantageous networks,’ says Kashyap, adding that women may be restricted by the need to resume care commitments at home instead of staying for drinks after work or travelling to attend conferences. One might expect online avenues for networking would be able to mitigate such obstacles. In fact, studies of LinkedIn data did suggest that although women are less likely to be in professional and technical occupations as reflected in the platform’s data, in some instances their numbers exceeded them. Kashyap suggests this could be ‘where they’re using online platforms to make themselves more visible, because other fine forms of networking are less available, or they have less time for it.’ Indeed, women who were on LinkedIn were more likely to report a promotion than their male counterparts, suggesting an element of positive selection among the female LinkedIn user population. However, the potential equalising impact of moving professional networking online seems to have its limits.</p>
<p>Their study of LinkedIn data showed women were less likely to report a relocation for work, which Kashyap suggests, ‘is a sign that the work family trade-off is probably still remaining acute for this highly selected group.’ In another 2023 study Kashyap and colleagues had also reported a lower mobility for women, specifically among published scientists, researchers and academics based on bibliometric data from over 33 million Scopus publications<sup>10</sup>. In addition, when Kashyap and her colleagues looked at women on LinkedIn working in the tech sector, they found that they had a lower chance of being connected to those working in one of the “big five” firms in the tech sector than men, when not working in one themselves. ‘One way to interpret that is to say that they have maybe less influential online social networks, right, even when they are on the platform.’</p>
<div id="fig-4" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center" alt="Leaky pipeline. The proportion of women working in science decreases towards the mid and senior career stages">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-4-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="https://realworlddatascience.net/foundation-frontiers/posts/2024/09/17/images/shutterstock_1215562669-h350.jpg" class="img-fluid quarto-figure quarto-figure-center figure-img" alt="Leaky pipeline. The proportion of women working in science decreases towards the mid and senior career stages">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-4-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;3: Leaky pipeline. The proportion of women working in science decreases towards the mid and senior career stages.
</figcaption>
</figure>
</div>
<p>Kashyap suggests several reasons why women may have less influential networks online. For one, online networks are still likely to be influenced by the scenarios playing out offline, since referrals on these networks are based on the people you already know. The difference may also be based on the types of companies women tend to work in and the positions they hold. For instance, women are more likely to work in IT service support than programming-intensive occupations, and here once again Kashyap suggests the work family trade off plays a role in women seeking less intensive or more flexible jobs. She highlights that girls equal or exceed the achievement of male counterparts through school and continue to match them in their early careers before their numbers start to drop off dramatically. ‘I think now there’s a growing recognition that this is actually a real conflict, the work family conflict,’ she tells Real World Data Science. Today’s young women are socialised to have ‘high achieving aspirations’, which can be hard to reconcile with ‘regressive norms’ for women to shoulder the bulk of caring responsibilities, particularly when starting a family.</p>
</section>
<section id="real-world-gender-disparities-in-career-development" class="level2">
<h2 class="anchored" data-anchor-id="real-world-gender-disparities-in-career-development">Real world gender disparities in career development</h2>
<p>Neuroscientist Joanne Kenney has also been following data on the gender gap in the science and tech sectors and co-authored ‘A Snapshot of Female Representation in Twelve Academic Psychiatry Institutions Around the World’<sup>11</sup> with Assistant Professor of Psychiatry at Harvard Medical School Elisabetta del Re. The figures published here also show that globally women represent a large majority of early career scientists, but their numbers steadily decrease towards the mid and senior career stages so that there is a negative correlation between career stages and female presence in science, often referred to as the ‘leaky pipeline’ or ‘sticky floor’. ‘You don’t always hear their stories or the reasons why they’ve left,’ says Kenney who highlights that in her experience in academia exit interviews are rare. Just 24% of the UK total workforce in the tech sector are women, while black women account for only 0.7% of IT professionals according to the 2024 UN Women UK and Kearney Consulting report <a href="https://www.kearney.com/about/diversity-equity-and-inclusion/gap-to-gateway">‘Gap to Gateway: diversity in tech as the key to the future’</a> for which Kenney was an external collaborator. Kenney is currently working on another project with a team of scientists from Europe, Africa, and North and South America led by del Re to gather stories from women and other underrepresented groups in academic institutions around the world through focus groups aimed at better understanding their experiences of working in science.</p>
<p>For those who stick at it, the career path appears to be a steeper hike for women than their male counterparts. There is a citation-bias favouring male-authored articles<sup>12</sup>. Women also take on average nine years to transition to senior author whereas men take five<sup>13</sup>, and women are less likely to be promoted to leadership positions<sup>14</sup>. While women in science bear a measurably unequal career impact on entering parenthood<sup>15</sup>, some of these inequalities may also stem from sexism, which can range from fewer opportunities for mentorship and collaboration to outright harassment<sup>16</sup>.</p>
<p>‘I think a lack of mentorship and sponsorship are two big ones,’ says Kenney when it comes to the key discouraging factors for women at the mid-career point in tech and academia. In AI, in particular, less than 3% of venture capital funding deals involving AI startups go to women-founded companies. The gender pay gap, which at 16% in the sector exceeds the overall pay gap of 11.6% may be another disincentive.</p>
<p>In short there is evidence of various patriarchal subcultures at play, both in the tech and science sectors and the world in general that can still pose a significant disadvantage to women. As Sippy points out, ‘Those subcultures also translate to the online world.’ Ultimately while digital technologies may offer creative loopholes for side-stepping some aspects of gender bias and disadvantage, gender inequality needs to be tackled in both spaces in tandem.</p>
<div class="article-btn">
<p><a href="../../../../../foundation-frontiers/index.html">Explore more data science ideas</a></p>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-12">
<dl>
<dt>About the author</dt>
<dd>
<strong>Anna Demming</strong> is a freelance science writer and editor based in Bristol, UK. She has a PhD from King’s College London in physics, specifically nanophotonics and how light interacts with the very small, and has been an editor for Nature Publishing Group (now Springer Nature), IOP Publishing and New Scientist. Other publications she contributes to include The Observer, New Scientist, Scientific American, Physics World and Chemistry World..
</dd>
</dl>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>Copyright and licence</dt>
<dd>
© 2024 Anna Demming
</dd>
</dl>
<p><a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> <img style="height:22px!important;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"></a> Text, code, and figures are licensed under a Creative Commons Attribution 4.0 (CC BY 4.0) <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;">International licence</a>, except where otherwise noted. Thumbnail image by <a href="https://www.shutterstock.com/image-photo/mute-key-on-neat-white-keyboard-1832448097">Shutterstock/Park Kang Hun</a> <a href="https://creativecommons.org/licenses/by/4.0/">Licenced by CC-BY 4.0</a>.</p>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>How to cite</dt>
<dd>
Demming, Anna. 2024. “Are we at risk of muting the female voice in the digital world?” Real World Data Science, September 17, 2024. <a href="https://realworlddatascience.net/foundation-frontiers/posts/2024/09/17/digital-gender-gap.html">URL</a>
</dd>
</dl>
</div>
</div>
</div>


</section>


<div id="quarto-appendix" class="default"><section id="footnotes" class="footnotes footnotes-end-of-document"><h2 class="anchored quarto-appendix-heading">References</h2>

<ol>
<li id="fn1"><p>Sicat M, Xu A, Mehetaj E, Ferrantino M &amp; Chemutai V Leveraging ICT Technologies in Closing the Gender Gap World Bank <em>World Bank Group, Washington DC</em> (2020) <a href="https://documents1.worldbank.org/curated/en/891391578289050252">https://documents1.worldbank.org/curated/en/891391578289050252</a>↩︎</p></li>
<li id="fn2"><p>Web Foundation. The Costs of Exclusion: Economic Consequences of the Digital Gender Gap. Alliance for Affordable Internet (2021) <a href="https://a4ai.org/report/the-costs-of-exclusion-economic-consequences-of-the-digital-gender-gap/">https://a4ai.org/report/the-costs-of-exclusion-economic-consequences-of-the-digital-gender-gap/</a>↩︎</p></li>
<li id="fn3"><p>Fatehkia M, Kashyap R &amp; Ingmar Weber I Using Facebook ad data to track the global digital gender gap <em>World Development</em> <strong>107</strong> 189-209 (2018) <a href="https://www.sciencedirect.com/science/article/pii/S0305750X18300883">https://www.sciencedirect.com/science/article/pii/S0305750X18300883</a>↩︎</p></li>
<li id="fn4"><p>Leasure D R, Yan J, Bondarenko M, Kerr D, Fatehkia M, Weber I &amp; Kashyap R. Digital Gender Gaps Web Application, v1.0.0. Zenodo, GitHub (2023) <a href="https://github.com/OxfordDemSci/dgg-www">doi:10.5281/zenodo.7897491</a>↩︎</p></li>
<li id="fn5"><p>Stevens F, Enock F E, Sippy T, Bright J, Cross M, Johansson P, Wajcman J, Margetts H Z Understanding gender differences in experiences and concerns surrounding online harms: A nationally representative survey of UK adults Alan Turing Institute (2024) <a href="https://www.turing.ac.uk/news/publications/understanding-gender-differences-experiences-and-concerns-surrounding-online">https://www.turing.ac.uk/news/publications/understanding-gender-differences-experiences-and-concerns-surrounding-online</a>↩︎</p></li>
<li id="fn6"><p>Ajder H, Patrini G, Cavalli F &amp; Cullen L The State of Deepfakes: Landscape, Threats, and Impact, (2019) <a href="https://regmedia.co.uk/2019/10/08/deepfake_report.pdf">https://regmedia.co.uk/2019/10/08/deepfake_report.pdf</a>↩︎</p></li>
<li id="fn7"><p>Sippy T, Enock F E, Bright J &amp; Margetts H Z Behind the Deepfake: 8% Create; 90% Concerned Alan Turing Institute (2024) <a href="https://www.turing.ac.uk/news/publications/behind-deepfake-8-create-90-concerned">https://www.turing.ac.uk/news/publications/behind-deepfake-8-create-90-concerned</a>↩︎</p></li>
<li id="fn8"><p>Kalhor G, Gardner H, Weber I, Kashyap R <em>Proceedings of the Eighteenth International AAAI Conference on Web and Social Media</em> <strong>18</strong> (2024) <a href="https://ojs.aaai.org/index.php/ICWSM/article/view/31353">https://ojs.aaai.org/index.php/ICWSM/article/view/31353</a>↩︎</p></li>
<li id="fn9"><p>Kashyap R &amp; Verkroost F C J Analysing global professional gender gaps using LinkedIn advertising data EPJ Data Science <strong>10</strong> 39 (2021) <a href="https://epjds.epj.org/articles/epjdata/abs/2021/01/13688_2021_Article_294/13688_2021_Article_294.html">https://doi.org/10.1140/epjds/s13688-021-00294-7</a>↩︎</p></li>
<li id="fn10"><p>Zhao X , Akbaritabar A, Kashyap R &amp; Zagheni E A gender perspective on the global migration of scholars <em>PNAS</em> <strong>120</strong> e2214664120 <a href="https://www.pnas.org/doi/10.1073/pnas.2214664120">https://doi.org/10.1073/pnas.2214664120</a>↩︎</p></li>
<li id="fn11"><p>Kenney J, Ochoa S, Alnor M A, Ben-Azu B, Diaz-Cutraro L, Folarin R, Hutch A, Luckhoff H K, Prokopez C R, Rychagov N, Surajudeen B, Walsh L, Watts T, Del Re E C A Snapshot of Female Representation in Twelve Academic Psychiatry Institutions Around the World <em>Psychiatry Research</em> (2021) <a href="https://pubmed.ncbi.nlm.nih.gov/34986430/">doi: 10.1016/j.psychres.2021.114358</a>↩︎</p></li>
<li id="fn12"><p>Dworkin J D, Linn K A, Teich E G, Zurn P, Shinohara R T &amp; Bassett D S The extent and drivers of gender imbalance in neuroscience reference lists <em>Nature</em> <strong>23</strong> 918-926 (2020) <a href="https://www.nature.com/articles/s41593-020-0658-y">https://www.nature.com/articles/s41593-020-0658-y</a>↩︎</p></li>
<li id="fn13"><p>Bearden C E Accelerating the Bending Arc Toward Equality: A Commentary on Gender Trends in Authorship in Psychiatry Journals <em>Biological Psychiatry</em> <strong>86</strong> 575-576 (2019)<a href="https://www.biologicalpsychiatryjournal.com/article/S0006-3223(19)31588-4/abstract">https://www.biologicalpsychiatryjournal.com/article/S0006-3223(19)31588-4/abstract</a>↩︎</p></li>
<li id="fn14"><p>Clark J &amp; Horton R A coming of age for gender in global health <em>The Lancet</em> <strong>393</strong> p2367-2369 (2019) <a href="https://www.thelancet.com/journals/lancet/article/PIIS0140-6736(19)30986-9/abstract">https://www.thelancet.com/journals/lancet/article/PIIS0140-6736(19)30986-9/abstract</a>↩︎</p></li>
<li id="fn15"><p>Morgan A C, Way S F, Hoefer M J D, Larremore D B, Galesic M &amp; Clauset A The unequal impact of parenthood in academia <em>Science Advnaces</em> <strong>7</strong> eabd1996 <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7904257/">doi: 10.1126/sciadv.abd1996</a>↩︎</p></li>
<li id="fn16"><p>O’Connor P s gendered power irrelevant in higher educational institutions? Understanding the persistence of gender inequality *Interdisciplinary Science Reviews” <strong>48</strong> 669-686 (2023) <a href="https://www.tandfonline.com/doi/full/10.1080/03080188.2023.2253667#d1e144">https://doi.org/10.1080/03080188.2023.2253667</a>↩︎</p></li>
</ol>
</section></div> ]]></description>
  <category>gender equality</category>
  <category>skills</category>
  <category>ethics</category>
  <guid>https://realworlddatascience.net/foundation-frontiers/posts/2024/09/17/digital-gender-gap.html</guid>
  <pubDate>Tue, 17 Sep 2024 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/foundation-frontiers/posts/2024/09/17/images/Minoan-Illustration-991.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>New open access journal - RSS: Data Science and Artificial Intelligence</title>
  <link>https://realworlddatascience.net/the-pulse/posts/2024/08/01/RWDS-journal.html</link>
  <description><![CDATA[ 





<p><img src="https://realworlddatascience.net/the-pulse/posts/2024/08/01/images/RSS-DSAI-Logo-blue.png" class="img-fluid" style="width:80.0%" alt="RSS Data Science and AI logo"><br>
</p>
<p>The Royal Statistical Society (RSS) is launching a new fully open access journal, <em>RSS: Data Science and Artificial Intelligence</em>. Created in recognition of the growing importance of data science and artificial intelligence in science and society, the new journal’s remit spans the breadth of data science; you can <a href="https://academic.oup.com/rssdat/pages/general-instructions">submit articles</a> covering disciplines including statistics, machine learning, deep learning, econometrics, bioinformatics, engineering and computational social science.</p>
<p>As well as three primary paper types - method papers, applications papers and behind-the-scenes papers - RSS: Data Science and Artificial Intelligence will publish editorials, op-eds, interviews, and reviews/perspectives in line with <a href="https://academic.oup.com/rssdat/pages/about">its goal to become a primary destination for data scientists</a>.</p>
<p>Published by Oxford University Press, this new journal is the first addition to the RSS family of world class statistics journals since 1952.</p>
<p><a href="https://academic.oup.com/rssdat/pages/why-publish">Learn more</a> about why <em>RSS: Data Science and Artificial Intelligence</em> is the ideal platform for showcasing your research.</p>
<div class="keyline">
<hr>
</div>
<section id="meet-the-journals-editors-in-chief-and-editorial-board" class="level3">
<h3 class="anchored" data-anchor-id="meet-the-journals-editors-in-chief-and-editorial-board">Meet the journal’s editors-in-chief and editorial board</h3>
<p>&nbsp;</p>
<div class="grid">
<div class="g-col-12 g-col-md-4">
<p><img src="https://realworlddatascience.net/the-pulse/posts/2024/08/01/images/Mukherjee_Sach.jpg" class="img-fluid" alt="Photo of Mukherjee, Director of Research in Machine Learning for Biomedicine at the MRC"></p>
<p><strong>Sach Mukherjee</strong> is Director of Research in Machine Learning for Biomedicine at the Medical Research Council (MRC) Biostatistics Unit, University of Cambridge, and Head of Statistics and Machine Learning at the German Center for Neurodegenerative Diseases.</p>
</div>
<div class="g-col-12 g-col-md-4">
<p><img src="https://realworlddatascience.net/the-pulse/posts/2024/08/01/images/silvia-chiappa.jpeg" class="img-fluid" alt="Silvia Chiappa, Research Scientist at Google DeepMind"></p>
<p><strong>Silvia Chiappa</strong> is a Research Scientist at <a href="https://deepmind.com/">Google DeepMind</a> London, where she leads the Causal Intelligence team, and Honorary Professor at the <a href="https://www.ucl.ac.uk/computer-science/">Computer Science Department</a> of University College London.</p>
</div>
<div class="g-col-12 g-col-md-4">
<p><img src="https://realworlddatascience.net/the-pulse/posts/2024/08/01/images/neil-lawrence.png" class="img-fluid" alt="Neil Lawrenece, DeepMind Professor of Machine Learning at the University of Cambridge"></p>
<p><strong>Neil Lawrenece</strong> is the inaugural DeepMind Professor of Machine Learning at the University of Cambridge. He has been working on machine learning models for over 20 years. He recently returned to academia after three years as Director of Machine Learning at Amazon.</p>
</div>
</div>
<p><br>
</p>
<p><strong>View the full editorial board here:</strong> <a href="https://academic.oup.com/rssdat/pages/editorial-board">Editorial Board | RSS Data Science | Oxford Academic (oup.com)</a></p>
<div class="article-btn">
<p><a href="../../../../../the-pulse/index.html">Discover more The Pulse</a></p>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-6">
<dl>
<dt>Copyright and licence</dt>
<dd>
© 2023 Royal Statistical Society
</dd>
</dl>
<p><a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> <img style="height:22px!important;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"></a> This article is licensed under a Creative Commons Attribution (CC BY 4.0) <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;">International licence</a>.</p>
</div>
<div class="g-col-12 g-col-md-6">

</div>
</div>
</div>


</section>

 ]]></description>
  <category>AI</category>
  <category>Data Science</category>
  <category>Machine learning</category>
  <category>Deep learning</category>
  <category>Econometrics</category>
  <guid>https://realworlddatascience.net/the-pulse/posts/2024/08/01/RWDS-journal.html</guid>
  <pubDate>Thu, 01 Aug 2024 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/the-pulse/posts/2024/08/01/images/RSS-DS-AI-cover.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>Nowcasting upgrade for better real time estimation of GDP and inflation</title>
  <dc:creator>Atmajitsinh Gohil</dc:creator>
  <link>https://realworlddatascience.net/foundation-frontiers/datasciencebites/posts/2024/6/25/nowcasting-3step.html</link>
  <description><![CDATA[ 





<p>Governments, policymakers and central banks across the world are wrestling to keep rising prices under control using monetary policies such as interest rate increases. The effectiveness of such policy changes should be assessed by monitoring inflation data as well as studying the impact on real GDP, making timely and accurate access to key economic indicators crucial for policy planning. The delay in publishing economic indicators such as Real GDP, inflation and other labour related series, makes this real time assessment of the economy particularly challenging. Now Menzie Chinn at the University of Wisconsin, Baptiste Meunier at the European Central Bank and Sebastian Stumpner at the Banque de France report an approach for “nowcasting” built on previous research that develops a framework using different machine learning techniques and is flexible and adaptable compared with traditional methods<sup>1</sup>. They report on the accuracy of their 3-step framework for nowcasting global trade volume estimates, showing how it can outperform traditional methods. They also highlight that the 3-step framework can be extended beyond World Trade data.</p>
<p>Nowcasting, an amalgamation of the term now and forecasting, provides a methodology to assess the current state of the economy by predicting the current value of inflation or Real GDP. The <a href="https://www.newyorkfed.org/research/policy/nowcast#/overview">Federal Reserve Bank of New York</a> and <a href="https://www.atlantafed.org/cqer/research/gdpnow">Federal Reserve Bank of Atlanta</a> have used nowcasting to publish real time GDP estimates, for the USA. Similarly, the <a href="https://www.clevelandfed.org/indicators-and-data/inflation-nowcasting">Federal Reserve Bank of Cleveland estimates real time inflation</a> using nowcasting methods.</p>
<div id="fig-1" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center" alt="GDP digital drawing. Credit: Shutterstock, Vink Fan">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="https://realworlddatascience.net/foundation-frontiers/datasciencebites/posts/2024/6/25/images/GDPshutterstock_2302082265-991.jpg" class="img-fluid quarto-figure quarto-figure-center figure-img" alt="GDP digital drawing. Credit: Shutterstock, Vink Fan">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;1: Growth of GDP with statistical graph, 3d rendering. Digital drawing. Credit: Shutterstock, Vink Fan
</figcaption>
</figure>
</div>
<p>The basic principle of nowcasting is utilising information that is published early such as using data published at higher frequency, survey data, financial indicators or economic indicators. For example, the running estimate of Real GDP (aka GDPNow) that the Federal Reserve Bank of Atlanta provides is updated 6 or 7 times a month on weekdays when one of the 7 input data sources are released. Similarly, the real GDP growth estimate that the Federal Reserve Bank of New York provides is based on data releases in categories such as housing and construction, manufacturing, surveys, retail and consumption, income, labour, international trade, prices and others.</p>
<p>The traditional methods of nowcasting do not provide an integrated framework, and forecasters need to know which variables to use, and select a method for factor extraction and machine learning regression. Chinn, Meunier and Stumpner propose a sequential framework that selects the most important predictors. The selected variables are then summarized using Principal Component Analysis (PCA) and these factors are used as explanatory variables to perform the regression. Although traditional methods of nowcasting also utilized many of these techniques, the authors test various combinations of pre-selection, factor extraction and regression techniques and propose a combination that improves model accuracy.</p>
<section id="model-framework-improved-flexibility-and-accuracy" class="level2">
<h2 class="anchored" data-anchor-id="model-framework-improved-flexibility-and-accuracy">Model framework improved flexibility and accuracy:</h2>
<p>The 3 steps in the framework are chronological steps to be performed in which the first step is pre-selection of the independent variables with the highest predictive power. The independent variables from the first step are then summarised into a few factors using factor extraction methodology in the second step. The final step consists of using the factors from step 2 to perform regression.</p>
<div id="fig-2" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center" alt="The various methods that can be employed in the 3 step framework in Chinn et al (2024). Credit: National Bureau of Economic Research.">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="https://realworlddatascience.net/foundation-frontiers/datasciencebites/posts/2024/6/25/images/3step-framework-methods-big.png" class="img-fluid quarto-figure quarto-figure-center figure-img" alt="The various methods that can be employed in the 3 step framework in Chinn et al (2024). Credit: National Bureau of Economic Research.">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2: The various methods that can be employed in the 3 step framework in Chinn et al (2024). Credit: National Bureau of Economic Research.
</figcaption>
</figure>
</div>
<p>Figure&nbsp;2 summarises the various methods employed at each step in the 3 step framework. In their report Chinn, Meunier and Stumpner aim to propose the best techniques for pre-selection, factor extraction and regression. As such their 3-step framework comprises performing pre-selection using Least Angle Regression (LARS), factor extraction using Principal Component Analysis (PCA) and employing a Macroeconomic Random Forest (MRF) machine learning technique for nowcasting.</p>
<p>The model performance or accuracy of MRF is compared with traditional methods using Root Mean Square Error (RMSE), a measure of the deviation between the actual data and the predicted data. The 3-step framework model accuracy is tested by holding the preselection and factor extraction fixed to isolate the impact of regression techniques.</p>
<div id="fig-3" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center" alt="Bar chart comparing the accuracy of different methods in terms of RMSE. Credit: National Bureau of Economic Research.">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-3-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="https://realworlddatascience.net/foundation-frontiers/datasciencebites/posts/2024/6/25/images/method-accuracy-big.png" class="img-fluid quarto-figure quarto-figure-center figure-img" alt="Bar chart comparing the accuracy of different methods in terms of RMSE. Credit: National Bureau of Economic Research.">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-3-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;3: Bar chart comparing the accuracy of different methods in terms of RMSE. Credit: National Bureau of Economic Research.
</figcaption>
</figure>
</div>
<p>Figure&nbsp;3 compares the RMSE of traditional methods, machine learning tree and machine learning regression model for backcasting (t-2 and t-1), nowcasting (t) and forecasting (t+1). It highlights the greater model accuracy of MRF and Gradient Boosting compared with traditional models and tree models for backcasting, nowcasting and forecasting.</p>
</section>
<section id="whats-next" class="level2">
<h2 class="anchored" data-anchor-id="whats-next">What’s Next?</h2>
<p>Organisations such as <a href="https://nowcastinglab.org/map">The Nowcasting Lab</a> provide GDP estimates for European countries. Such nowcasting techniques have been employed by humanitarian agencies including the United Nations Refugee Agency (UNHCR) which uses nowcasting to estimate the actual forced displaced population. The nowcasting techniques, dashboards and tools have been implemented and accepted as a reliable source of information at government organisations for policy making, central banks, and financial organisations. The 3-step framework, proposed by Chinn, Meunier and Stumpner, is easily adaptable, flexible and provides higher accuracy, which will be valuable to a range of fields employing nowcasting.</p>
<div class="article-btn">
<p><a href="../../../../../../foundation-frontiers/index.html">Explore more data science ideas</a></p>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-12">
<dl>
<dt>About the author</dt>
<dd>
<strong>Atmajitsinh Gohil</strong> is an independent researcher in the field of AI and ML, specifically managing AI and ML risk. He has worked with consulting firm assisting clients in model risk management. He has graduated from SUNY, Buffalo with a M.S. in Economics.
</dd>
</dl>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>Copyright and licence</dt>
<dd>
© 2024 Atmajitsinh Gohil
</dd>
</dl>
<p><a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> <img style="height:22px!important;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"></a> Text, code, and figures are licensed under a Creative Commons Attribution 4.0 (CC BY 4.0) <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;">International licence</a>, except where otherwise noted. Thumbnail image by <a href="https://www.shutterstock.com/image-illustration/growth-gdp-statistical-graph-3d-rendering-2302082265">Shutterstock Van Fink</a>.</p>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>How to cite</dt>
<dd>
Gohil, Atmajitsinh. 2024. “Nowcasting upgrade for better real time estimation of GDP and inflation.” Real World Data Science, June 25, 2024. <a href="https://realworlddatascience.net/foundation-frontiers/posts/2024/06/25/nowcasting-3step.html">URL</a>
</dd>
</dl>
</div>
</div>
</div>


</section>


<div id="quarto-appendix" class="default"><section id="footnotes" class="footnotes footnotes-end-of-document"><h2 class="anchored quarto-appendix-heading">References</h2>

<ol>
<li id="fn1"><p>Nowcasting World Trade with Machine Learning: a Three-Step Approach Chinn, M. D., Meunier, B. &amp; Stumpner, S. <em>NBER</em> <a href="https://www.nber.org/papers/w31419">DOI 10.3386/w31419</a>) ↩︎</p></li>
</ol>
</section></div> ]]></description>
  <category>Forecasting</category>
  <category>Machine learning</category>
  <guid>https://realworlddatascience.net/foundation-frontiers/datasciencebites/posts/2024/6/25/nowcasting-3step.html</guid>
  <pubDate>Tue, 25 Jun 2024 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/foundation-frontiers/datasciencebites/posts/2024/6/25/images/GDPshutterstock_2302082265-991.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>AI series: Ensuring new AI technologies help everyone thrive</title>
  <dc:creator>Anna Demming</dc:creator>
  <link>https://realworlddatascience.net/foundation-frontiers/posts/2024/06/11/ai-series-7.html</link>
  <description><![CDATA[ 





<p>“There’s some beautiful stories in clinical notes,” said Mark Sales, global strategy leader of the cloud technology company Oracle Life Sciences. He was speaking to delegates at the 2024 London Biotechnology Show about “unlocking health data and artificial intelligence within life sciences”, where opportunities abound, such as exploiting large language models (LLMs) to process some of the detailed information currently hidden in clinical notes into more structured data to inform fields like oncology. Oracle are also looking into using AI to take some of the luck out of connecting the right patients with clinical trials that might help them. The AI in Medicine and Surgery group at the University of Leeds headed by Sharib Ali has demonstrated the potential to reduce the number of times patients need to go through <a href="https://www.sciencedirect.com/science/article/pii/S0016508521030870">uncomfortable procedures like oesophageal scans</a>for Barrett’s syndrome , and is working on the potential to provide haptic feedback for robot mediated surgery. The London Biotechnology Showcase delegates had already heard about all these opportunities. Nonetheless Sales’s talk had opened with a note of caution: “There’s a lot more we could do, and there’s a lot more we probably shouldn’t do.”</p>
<p>It is an increasingly familiar caveat. “In the best scenario, AI could widely enrich humanity, equitably equipping people with the time, resources, and tools to pursue the goals that matter most to them,” suggest the <a href="https://partnershiponai.org/paper/shared-prosperity/">Partnership on AI</a>, a non-profit partnership of academic, civil society, industry, and media organizations. The goal of the partnership is to ensure AI brings a net positive contribution to society as a whole not just a lucky minority, which they suggest will not necessarily be the case if we rely on chance and market forces to direct progress. While people working in developing and deploying AI tackle the burgeoning <a href="https://realworlddatascience.net/foundation-frontiers/posts/2024/04/22/ai-series-1.html">size and complexity of their models</a>, as well as the myriad <a href="https://realworlddatascience.net/foundation-frontiers/posts/2024/05/07/ai-series-3.html">requirements of testing and training data</a>, <a href="https://realworlddatascience.net/foundation-frontiers/posts/2024/05/21/ai-series-4.html">establishing whether a model is fit for purpose</a>, and <a href="https://realworlddatascience.net/foundation-frontiers/posts/2024/06/04/ai-series-6.html">dodging the numerous pitfalls that cause most AI projects to fail</a>, perhaps the greatest challenge remains the range of <a href="https://realworlddatascience.net/foundation-frontiers/posts/2024/05/14/ai-series-2.html">ethical considerations</a> including inclusiveness and fairness, robustness and reliability, transparency and accountability, privacy and security and general forethought and design. The scope of societal impact can reach far further than the immediate sphere of interaction with the model, or the interests of the companies deploying them, suggesting the need for some sort of governing forces.</p>
<p>However, technology is moving fast in a lot of different directions. Even with agreed sound values that all technological developments should respect, there is still space for companies to deploy AI models without supplying the necessary resources and expertise so that the roll out meets ethical and societal expectations. This expertise can range from the statistical skills required to ensure the appropriate level of representation in training datasets to the social science understanding to extrapolate potential implications for human behaviour when interacting with the technology.</p>
<p>Although the right checks and balances to avoid potential negative societal impacts have been slower to develop than the technologies they should be regulating, some guiding principles are emerging from organisations labouring to assess with greater clarity what the real immediate and longer term hazards are, what has worked well in other sectors, and the impact of government actions so far. There is an element of urgency in the challenge. As the Partnership on AI put it, “Our current moment serves as a profound opportunity — one that we will miss if we don’t act now.”</p>
<section id="high-stakes" class="level2">
<h2 class="anchored" data-anchor-id="high-stakes">High stakes</h2>
<p>When Open AI publicised their Voice Engine’s ability to clone human voices from just 15s of audio, they too flagged the potential benefit for people with poor health conditions, since those with deteriorating speech could find a means to <a href="https://www.euronews.com/next/2024/04/01/openai-unveils-ai-voice-cloning-tech-that-only-needs-a-15-second-sample-to-work">have their speech restored</a>. However, voice clones had already been used to make robot calls to voters imitating the voice of President Joe Biden and <a href="https://news.sky.com/story/fake-ai-generated-joe-biden-robocall-tells-people-in-new-hampshire-not-to-vote-13054446">telling voters to stay at home</a>.</p>
<p>“The question you have to ask there is what’s the societal benefit of that tool? And what are the risks,” associate director at the Ada Lovelace Institute Andrew Strait told <em>Real World Data Science</em>. “They thankfully decided to not fully release it,” he adds, highlighting how the timing “right before an election year with 40 democracies across the world” could have made the release particularly problematic.</p>
<div id="fig-1" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center" alt="Themis, goddess of justice. External governance is required to ensure the outcomes of AI deployment are safe and just. Credit Shutterstock, Michal Bednarek">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="https://realworlddatascience.net/foundation-frontiers/posts/2024/06/11/images/shutterstock_2436413315.jpg" class="img-fluid quarto-figure quarto-figure-center figure-img" alt="Themis, goddess of justice. External governance is required to ensure the outcomes of AI deployment are safe and just. Credit Shutterstock, Michal Bednarek">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;1: Themis, goddess of justice. External governance is required to ensure the outcomes of AI deployment are safe and just. Credit Shutterstock, Michal Bednarek.
</figcaption>
</figure>
</div>
<p>While OpenAI’s voice engine might have made voice cloning more accessible had they proceeded with a full release, voice cloning is clearly still well within reach for some already. Strait cites the experiences of hundreds of performing artists in the UK over the past few months that have been brought to the attention of the Ada Lovelace Institute. “They’re brought into a room; they’re asked to record their voice and have their face and likeness scanned; and that’s the end of their career,” says Strait. The sums paid to artists on these transactions are not large either. “They are never going to be asked to come back for audition again, because they [the companies] can generate their likeness, that voice doing anything that a producer wants without any sense of attribution, further payments, or consent to be used in that way.”</p>
<p>Customer service is another sector where jobs have been threatened with replacement by a generative AI chatbot, however the technology can run into problems since gen-AI is known to <a href="https://realworlddatascience.net/the-pulse/editors-blog/posts/2022/11/23/LLM-content-warning.html">“hallucinate”</a>, generating false information. Air Canada has just lost a case defending its use of a chatbot that misinformed a customer that they could apply for a bereavement fare retroactively, which is not the case according to Air Canada’s bereavement fare policy. In their defence Air Canada flagged that the chatbot had supplied a link to a webpage with the correct information but the court ruled that there was no reason to believe the webpage information over the chatbot, or for the customer to double check the information they had been supplied. While there are <a href="https://mitsloanedtech.mit.edu/ai/basics/addressing-ai-hallucinations-and-bias/">ways to mitigate problems</a> with gen-AI with the right teams in place , other industries have also hit problems with the accuracy and reliability of gen-AI, which may dampen the impact AI has on the labour market. All in all the wider picture of how AI deployment may affect jobs is largely a matter of speculation. Here a US piloted scheme may soon provide framework for a more data informed approach to <a href="https://realworlddatascience.net/ideas/posts/2024/05/28/ai-series-5.html">tackling AI’s impact on the workforce</a>.</p>
<p>Strait highlights that conversations that centre around efficiency when weighing up the possible advantages of introducing AI can be ill informed. “If we’re talking about an allocation of resources in which we’re spending an increasing amount of money on automating certain parts of the NHS, or healthcare or the education system, or public sector services, how are we making the decisions that are determining if that is worth the value for money? Instead of investing in more doctors, more teachers, more social workers?” He tells Real World Data Science that these are the questions he and his colleagues at the Ada Lovelace Institute are often pushing governments to try to answer and evidence rather than to just assume the benefits will accrue. When it comes to measures of success of an AI model, Strait says “It’s often defined in terms of how many staff can be cut and still deliver some kind of service…This is not a good metric of success,” he adds. “We don’t want to just get rid of as many jobs as we can, right, we want to actually see improvements in care, improvements in service.”</p>
<p>Michael Katell, ethics fellow in the Turing’s Public Policy Programme and a visiting Senior lecturer at the Digital Environment Research Institute (DERI) at Queen Mary University of London suggests the problems may go deeper still when looking at the use of generative AI in creative industries. “There are definitely parallels with prior waves of disruption,” he says citing as an example the move to drum-based and eventually laser printing as opposed to manual typesetting. “A key difference, though, is that, in the creative arts, we’re talking about contributions to culture, and culture is something that, I think we often take for granted.” He highlights the often overlooked role cultural practices that enable and empower shared experiences have in holding society together. These may come in various forms from works of art to theatre, and the working and living practices among the wider community may play an important role too. While acknowledging there may be interesting and fascinating uses of AI in art to explore, Katell adds, “If we’re not attending to maintaining some aspects, or trying to manage the changes that are happening in our culture, I think we’ll see societal level effects that are much greater than the elimination of some jobs.”</p>
</section>
<section id="the-need-for-legislation" class="level2">
<h2 class="anchored" data-anchor-id="the-need-for-legislation">The need for legislation</h2>
<p>These stakes all highlight the need for regulatory interventions. However, most governments, bar China and the EU, have so far favoured “voluntary commitments” towards AI safety, which would seem to fall short of providing the kind of governance over the sector that can be robustly enforced. In a recent blog Strait alongside the Ada Lovelace Institute’s UK public policy lead Matt Davies and associate director (Law &amp; Policy) Michael Birtwhistle, “evaluate the evaluations” of the UK’s AI Safety Institute for companies that have opted in for <a href="https://www.adalovelaceinstitute.org/blog/safety-first/">these voluntary commitments</a>. They highlight that on the whole the companies planning to release the product hold too much control over how the evaluation can take place, ultimately empowering them to direct tests in their favour, which inhibits efforts at robust monitoring. Furthermore, there is usually no avenue for the necessary scrutiny of training data sets. Even withstanding these limitations, Davies, Strait and Birtwhistle conclude that “conducting evaluations and assessments is meaningless without the necessary enforcement powers to block the release of dangerous or high-risk models, or to remove unsafe products from the market.”</p>
<p>The reticence to implement firmer regulation might be attributed in some part to the perceived benefits to the state when their AI companies succeed. One often perceived benefit is that the percolating profits these companies accrue may benefit the economic buoyancy of the societies they function within. There is also cause for sovereign state competitiveness in “AI prowess” that stems from the potential for AI-based technology to underpin all aspects of society, prompting what has been described as an <a href="https://ainowinstitute.org/publication/a-lost-decade-the-uks-industrial-approach-to-ai">“AI arms race”</a>. Here the UK may well regret allowing Google to acquire Deep Mind, whose output is responsible for bolstering the “UK’s share” of citations in the top 100 recent AI papers from 1.9% to 7.2%. However, a lack of robust regulation may prove as much a disservice to the companies releasing AI products as it is to society as a whole.</p>
<p>“The medicine sector here [in the UK] is thriving, not in spite of regulation, but because of regulation,” says Strait. “People trust that the products you develop here are safe.” Katell, highlights the impact of pollution legislation on the automotive industry. “It jumped forward invention and discovery in automotive technology,” he tells <em>Real World Data Science</em>. “It seems prosaic in hindsight, but it wasn’t, it was a major innovation that was promoted by regulators, promoted by legislators.” The UK government’s chief scientific advisor Angela McLean seems to agree. “Good regulation is good for innovation,” she replied when asked about balancing regulation with favourable conditions for a flourishing AI sector at an Association of British Science Writers’ event in May. “We’re not there yet,” she added. The challenge is pinning down what good regulation looks like.</p>
</section>
<section id="regulatory-ecosystems" class="level2">
<h2 class="anchored" data-anchor-id="regulatory-ecosystems">Regulatory ecosystems</h2>
<p>As has been emphasised throughout the series, making a success of an AI project requires a unique skillset that <a href="https://realworlddatascience.net/foundation-frontiers/posts/2024/06/04/ai-series-6.html">combines expertise in AI with the domain expertise for the sector</a> the project is contributing to, and there is often a dearth of people that straddle both camps. The same hunt for “unicorns” with useful expertise in the tech sector and policymakers can also be an obstacle for developing “good regulation”. One solution is to bring people from the different disciplines together to develop legislation collaboratively, as was arguably the case with the roll out of General Data Protection Regulations (GDPR) in 2018. “Policymakers and academics, they worked very closely together in the crafting of that law,” says Katell. “It was one of those rare moments in which we saw the boundaries really dissolve between policy and academia in a way that delivered something that I think we can agree was largely a positive outcome.”</p>
<p>When it comes to AI, an obstacle to that kind of collaboration has been the lack of a common language. In “Defining AI in policy and practice” in 2020<sup>1</sup>, Katell alongside Peaks Krafft at the University of Oxford and co-authors found that AI researchers favoured definitions of AI that “emphasise technical functionality”, whereas policy-makers tended towards definitions that “compare systems to <a href="https://realworlddatascience.net/foundation-frontiers/posts/2024/04/29/gen-ai-human-intel.html">human thinking and behavior”, which AI systems remain far from achieving</a>. Strait also highlights a recurring theme among those without experience of actually making AI systems in overselling AI capabilities in suggestions that it will “help solve climate change” or “cure cancer”. “How are you measuring that?” he asks. “How are we making a clear sense of the efficacy, the proof behind those kinds of statements? Where are the case studies that actually work, and how are we determining that’s working?”</p>
<div id="fig-2" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center" alt="Safety first. External governance is required to ensure the outcomes of AI deployment are safe and knock on effects have been considered. Credit Shutterstock, 3rdtimeluckystudio">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="https://realworlddatascience.net/foundation-frontiers/posts/2024/06/11/images/shutterstock_2180417651.jpg" class="img-fluid quarto-figure quarto-figure-center figure-img" alt="Safety first. External governance is required to ensure the outcomes of AI deployment are safe and knock on effects have been considered. Credit Shutterstock, 3rdtimeluckystudio">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2: Safety first. External governance is required to ensure the outcomes of AI deployment are safe and knock on effects have been considered. Credit: Shutterstock. Photo by 3rdtimeluckystudio.
</figcaption>
</figure>
</div>
<p>As Krafft <em>et al.</em> point out in their 2020 paper, such exaggerated perceptions of AI capabilities can also hamper regulation. “As a result of this gap,” they write, “ethical and regulatory efforts may overemphasise concern about future technologies at the expense of pressing issues with existing deployed technologies.” Here a better <a href="https://realworlddatascience.net/foundation-frontiers/posts/2024/04/22/ai-series-1.html">understanding of what AI is</a> can be helpful to focus attention on the problems that exist now – not just the potential <a href="https://realworlddatascience.net/foundation-frontiers/posts/2024/05/28/ai-series-5.html">workforce impact</a>, but the carbon cost of training large language models, activities like nonconsensual gen-AI porn aggravating online gender inequality, and a widening digital divide disadvantaging pupils, workers and citizens who cannot afford all the latest AI tools, among others.</p>
<p>Fortunately, there has already been progress to breach the language divide between policy makers and the tech sector. “The current definitions [championed in policy circles] say things like technologies that can perform tasks that require intelligence when humans do them,” says Katell, which he describes as a far more sober and realistic definition than likening technologies to the way humans think and work. “This is really important,” he adds. “Because some of the problems that we see with AI now are symptomatic of the fact that they’re not humans and that they don’t have the same experience of the world.” As an example he describes someone driving a car with child in the car seat, calling on all their training and experience of road use to navigate roads and other traffic, while juggling their attention between driving and the child. “Things that AI is too brittle, to accomplish,” he adds, highlighting how a simple model may identify school buses in images quite impressively until it is presented with an image of a bus upside down. “The flexibility and adaptability, the softness of human reason, is actually its strength, its power.”</p>
<p>Getting everybody on the same page can also help provide a more multimodal approach to governance. Empowering independent assessors of AI product safety prior to release is one thing but as Strait points out, “It could be more like the environmental sector, where we have a whole ecosystem of environmental impact assessments, organisations and consultancies that do this kind of work for different organisations and companies.” Internal teams within companies can play an important role too so long as they work sufficiently independently from the companies themselves. When set up with the right balance of expertise they can be better placed to understand and hence assess the technology and practical elements of its implementation. Although such teams can be expensive, getting the technical evaluation and consideration of ethical issues right can pose a competitive advantage for the companies themselves as well as providing a more thorough safeguard for society at large. Nonetheless there are also obvious advantages in having external regulatory bodies, which do not need to take into account the company’s profit margins or shareholders’ needs. An ideal set up might incorporate both approaches. In fact in their appraisal of the current UK AI Safety Institute arrangement, Davies, Strait and Birtwistle first highlight the need to integrate the AI Safety Institute “into a regulatory structure with complementary parts that can provide appropriate, context-specific assurance that AI systems are safe and effective for their intended use.”</p>
</section>
<section id="prosperity-for-all" class="level2">
<h2 class="anchored" data-anchor-id="prosperity-for-all">Prosperity for all</h2>
<p>With all the precedents in other sectors from environmental impact checks to pharmacology, an organised framework or ecosystem for robust, independent and meaningful evaluation of AI product safety seems an inevitable imperative, albeit potentially expensive. (Davies, Strait and Birtwistle cite £100 million a year as a typical cost for safety driven regulatory systems in the UK<sup>2</sup>, and the expertise demands of AI could further increase costs.) However, such regulatory reform will likely slow down the pace of technological development and the route to market. While the breathing space to adjust to the societal changes they bring with them may be welcomed by some, the delay can be quite unpopular in a tech sector where the ethos is famed for embracing a “move fast, break things” mentality. As Katell points out that ideal is based on the notion that the things being broken were unimportant – when it’s vulnerable people and societies that is “unacceptable breakage”.</p>
<p>Strait also highlights the cultural mismatch between the companies developing AI products – where the research to market pipeline is extremely fast – and the sectors those tools are intended to serve, such as social care, education and health. Although Open AI eventually decided against full release of the Voice Engine, when it comes to the ethos of some AI technology companies , “The default is to put things out there and to not think through the ethical and societal implications,” says Strait who has direct experience of working for a company producing AI tools in the past. “I think it’s so critical for data scientists and ethicists to explore, and do that translation and interrogation of what are the ethics of the sector that we’re working in?”</p>
<p>Katell voices concern shared by many that at present AI is under the control of a very small handful of very large, powerful technology companies, and as a result the AI releases making the most impact are targeting the agendas of the companies releasing them and their current and anticipated customer base, as opposed to the needs of society. The potential for such large tech agents to become too big to fail poses additional regulatory challenges. While many may lament the tension between a demand for open source data sets for testing AI models versus the need to respect data privacy, security and confidentiality, there have already been widely mooted instances where certain companies may <a href="[https://www.bloomberg.com/news/articles/2024-04-04/youtube-says-openai-training-sora-with-its-videos-would-break-the-rules?embedded-checkout=true">not have met expectations for respecting copyright and terms of service</a>. In fact the tech giants are not the only people developing AI models and the open source community have been known to pose valuable competition that may temper the tendency for AI to concentrate a lot of power into the hands of a small few<sup>3</sup>. However, open source developers can also pose a certain amount of <a href="https://datainnovation.org/2024/03/the-eus-ai-act-creates-regulatory-complexity-for-open-source-ai/">regulatory complexity</a>.</p>
<p>There is also an argument that these efforts should broaden their scope beyond baseline AI safety and aim to focus efforts in AI development towards tools that actively promote greater wellbeing and prosperity to the many. “We need to bring in other values like fairness, justice, and simple things like explainability, gender equity, racial equity,” says Katell, highlighting some of the other qualities that demand attention among others. Taking explainability as an example, there is increasing awareness of the need to understand how certain outputs are reached in order for people <a href="https://realworlddatascience.net/foundation-frontiers/posts/2024/06/04/ai">to feel comfortable with the technology</a>, and the outputs requiring explanations differ from person to person. Although it can be hard to explain AI outputs, progress is being made in this direction. As Katell says, “We’re not helpless in managing these types of disruptions. It’s a matter of societies coming together and deciding that they can be managed.”</p>
<div class="article-btn">
<p><a href="../../../../../foundation-frontiers/index.html">Explore more data science ideas</a></p>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-12">
<dl>
<dt>About the authors</dt>
<dd>
<strong>Anna Demming</strong> is a freelance science writer and editor based in Bristol, UK. She has a PhD from King’s College London in physics, specifically nanophotonics and how light interacts with the very small, and has been an editor for Nature Publishing Group (now Springer Nature), IOP Publishing and New Scientist. Other publications she contributes to include The Observer, New Scientist, Scientific American, Physics World and Chemistry World.
</dd>
</dl>
</div>
<div class="g-col-12 g-col-md-6">
<!-- copyright goes to the author, or to Royal Statistical Society if written by staff -->
<dl>
<dt>Copyright and licence</dt>
<dd>
© 2024 Royal Statistical Society
</dd>
</dl>
<!-- confirm licence terms with contributor before publishing - must be Creative Commons licence, but different types of CC licences might be preferred -->
<p><a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> <img src="https://mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1" style="height:22px!important;vertical-align:text-bottom;"><img src="https://mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1" style="height:22px!important;margin-left:3px;vertical-align:text-bottom;"></a> This article is licensed under a Creative Commons Attribution 4.0 (CC BY 4.0) <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> International licence</a>. <!-- Add thumbnail image credit and any licence terms here --></p>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>How to cite</dt>
<dd>
Demming, Anna. 2024. “Ensuring new AI technologies help everyone thrive .” Real World Data Science, June 11, 2024. <a href="https://realworlddatascience.net/foundation-frontiers/posts/2024/06/11/ai-series-7.html">URL</a>
</dd>
</dl>
</div>
</div>
</div>
<!-- Make sure to update main site homepage (index.qmd) before publishing. See README for details. -->


</section>


<div id="quarto-appendix" class="default"><section id="footnotes" class="footnotes footnotes-end-of-document"><h2 class="anchored quarto-appendix-heading">References</h2>

<ol>
<li id="fn1"><p>Krafft, P. M., Young, M., Katell, M., Huang, K. &amp; Bugingo, G. <a href="https://dl.acm.org/doi/abs/10.1145/3375627.337583">Defining AI in Policy versus Practice</a> <em>AIES ’20: Proceedings of the AAAI/ACM Conference on AI, Ethics, and Society</em> 72-78 (2020)↩︎</p></li>
<li id="fn2"><p>Smakman, J, Davies, M. &amp; Birtwhistle, M. <a href="https://www.adalovelaceinstitute.org/policy-briefing/ai-safety/">Mission critical</a> <em>Ada Lovelace Policy Briefing</em> (2023)↩︎</p></li>
<li id="fn3"><p><a href="https://www.semianalysis.com/p/google-we-have-no-moat-and-neither">Google “We Have No Moat, And Neither Does OpenAI</a> <em>semianalysis.com</em> (2023) (semianalysis.com)↩︎</p></li>
</ol>
</section></div> ]]></description>
  <category>AI</category>
  <category>AI ethics</category>
  <category>Regulation</category>
  <guid>https://realworlddatascience.net/foundation-frontiers/posts/2024/06/11/ai-series-7.html</guid>
  <pubDate>Tue, 11 Jun 2024 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/foundation-frontiers/posts/2024/06/11/images/shutterstock_2436413315.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>AI series: What is “best practice” when working with AI in the real world?</title>
  <dc:creator>Anna Demming</dc:creator>
  <link>https://realworlddatascience.net/foundation-frontiers/posts/2024/06/04/ai-series-6.html</link>
  <description><![CDATA[ 





<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/SoOoj9iUTM0" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<p>Over the course of the Real World Data Science AI series, we’ve had articles laying out the nitty gritty of what AI is, how it works, or at least how to get an explanation for its output as well as burning issues around the data involved, evaluating these models, ethical considerations, and gauging societal impacts such as changes in workforce demands. The ideas in these articles give a firm footing for establishing what best practice with AI models should look like but there is often a divide between theory and practice, and the same pitfalls can trip people up again and again. Here we discuss how to wrestle with real world limitations and flag these common hazards.</p>
<p>Our interviewees, in order of appearance, are:</p>
<p><strong>Ali Al-Sherbaz</strong>, academic director in digital skills at the University of Cambridge in the UK</p>
<p><strong>Janet Bastiman</strong>, Napier chief data scientist and chair of the Royal Statistical Society Data Science &amp; AI Section</p>
<p><strong>Jonathan Gillard</strong>, professor of statistics/data science at Cardiff University, and a member of the Real World Data Science Board</p>
<p><strong>Fatemeh Torabi</strong>, senior research officer and data scientist, health data science at Swansea University, and also a member of the Real World Data Science board</p>
<p><strong>It is often said that while almost everybody is now trying to leverage AI in their projects, most AI projects fail. What nuggets of wisdom do the panel have for swelling that minority that succeed with their AI projects, and what should you do before you start doing anything?</strong></p>
<p><strong>Ali Al-Sherbaz</strong>: It’s not easy to start, especially for people who are not aware how AI works. My advice is, first, they have to understand the basics of how AI works because the expectation could be overpromising, and that is a danger. Just 25 years ago, a master dissertation might be about developing a simple – we call it simple now but it was a master’s project 25 years ago – a simple model with a neural network of a combination of nodes to classify data. Whatever the data is – it could be drawing shapes, simple shapes, square, circle triangle – just classifying them was worth an MSc. Now, kids can do it. But that is not the same as understanding what the neural network or the AI is. It’s a matrix of numbers, and actually, for the learning process each does multiple iterations to find the best combination of these numbers – product of sum; sum of product – to classify, to do something, and train them for a certain situation, and that is a supervised learning. Over the last 25 years – especially in the last 10 years – the computational power is getting better, so AI is now working better.</p>
<p>There are other things people have to learn. There’s the statistics as well, and of course people who would like to work in AI and data science must understand the data, and they should also be experts in the data itself. For instance, I can talk about cybersecurity, I can talk about networking and other things, but if it comes to something regarding health data, or financial services, or stock markets, I’m not an expert in the data. So I’m not going to be actively working on those things even if I use the same AI tools. This is in a nutshell why I think some people fail sometimes using AI, or they succeed using AI. And we should emphasise the human value. The AI is there, and it exists to help us to make a better more accurate decision, but the human value is still there. We have to insist on that.</p>
<p><strong>Janet Bastiman</strong>: I would just like to build on all of that great stuff that Ali’s just said. When you look at basically the non-data scientist side of it, you often get businesses who think AI can solve a certain problem. They might go out and hire a team – whether that’s directly or indirectly – and get them to try and solve a problem that, as Ali said, they may not have the domain expertise for. The business might not even have the right data for it, and AI might not even be the right way of solving that problem. I think that’s one of the fundamental things to think about – really understanding what you’re trying to solve, and how you’re going to solve it before you start throwing complex tools, and potentially very expensive teams at the problem.</p>
<p>When you look at a lot of the failures, it’s been because businesses have just gone, we can solve this problem, I’m just going to hire a team and let these intelligent people look at something. And then they’re restricted on the data that they’ve got, which won’t even answer the question; they’re restricted on the resources they have; and even restricted in terms of wider buy in from the company. So really understanding what is it that you want to solve? What are you trying to do? Is AI the right thing? And can you even do it with the resources you have available? And I think that’s, that’s a fundamental starting point. Because, you can have wonderful experts, who have that domain knowledge, who understand the statistics, and all that essential stuff that Ali just said. But then if from a business point of view, if you don’t give them the right data to work on, or you don’t let them do their job and tell you when they can’t do their job, then again, you’re going to be doomed to failure.</p>
<p><strong>Jonathan Gillard</strong>: Explainability is a big issue when it comes to AI models, as well. They are at the moment, very largely “black box” – data goes in, then these models get trained on dumb data and answers get popped out. And when it works, well, it works fabulously well. And we’ve seen lots of examples of that happening. But often for business, industry or real life, we want to learn. We want to understand the laws of the universe, and to understand the reasons why this answer came about. Because this explainability piece is missing – because everything is hidden away almost – I think that’s a big issue in successful execution. And particularly when it comes to industries where there’s a degree of regulation there as well, if you can’t explain how a particular input arose to a particular output, then how can you justify to regulatory bodies that what you’ve got is satisfactory, ethical, and that you’re learning and you’re doing things in the right way?</p>
<p><strong>There have been efforts at trying to get explanations from these models. How do you think things are progressing there?</strong></p>
<p><strong>JG</strong>: Yeah, that’s a good question. I think where we are with explainability is in very simple scenarios, very simple models. This is where traditional statistical models do very well. There’s an explicit model which says if you put these things inside then you’ll get this output. So [for today’s AI] I think we’re actually very far away from having that complete explainability picture, particularly as we fetishise more and more grand models. The AI models are only getting bigger, more complex, and that makes the explainability per se even more challenging. And that’s why I think, as Ali says, at the moment, the human in the loop is absolutely crucial.</p>
<p>What AI does share with classical statistics (or classical data science if you want to call it that) is it can still only be as good as the data that’s put into it, that’s still a fundamental truth. I think a lot of the assumptions currently with AI models – and this is where there could be a few trip ups is that it can create something from nothing. It’s “artificial intelligence” – almost the wording suggested it’s artificial. But fundamentally, we still need a robust and reliable comprehensive source of data there in order to train these models in the first place.</p>
<p><strong>In terms of having outsourced expertise for these projects– does that make more problems if you’re then trying to understand what this AI has done?</strong></p>
<p><strong>JB</strong>: Oh, hugely. Let’s say that domain expertise – that’s something Ali touched on –you’ve got to understand your data. Because even that fundamental initial preparation of data before you try and train anything is absolutely crucial – really looking at where are the gaps? Where are the assumptions? How is this data even being collected? Has it been manipulated before you got to it? If you don’t understand your industry, well enough you won’t know where those pitfalls might be – and a lot of teams do this, they just take the data, and then they just put it in, turn the handle and out comes something and it looks like it’s okay. What they’re really missing there – because they’re not putting that effort in to really understand those inputs, what the models are doing, they’re just turning the handle until they get something that feels about right – what they miss out is where it goes wrong. And there are some industries, where the false positives and false negatives from classification or the bad predictions from running things really have a severe human impact. And if you don’t understand what’s going in, and the potential impact of what comes out, then it’s very, very easy to just churn these things out and go, “it’s 80% accurate, but that’s fine” without really understanding the human impact of the 20% [that it gets wrong].</p>
<p>Going back to what Jon said about that explainability, it’s so crucial. It is challenging, and it is difficult, but going from these opaque systems to more transparent systems – we need that for trust. As humans, we divulge our trust very differently, depending on the impact. One of the examples I use all the time is, you know, sort of weather prediction stuff, you know, we don’t really care too much, because it’s not got a huge impact. But when you look at sort of financials or medicals, we really, really want to know that that output is good, and how we got to that output. The Turing Institute’s come out with some great research that says, as humans, if we want to understand why when another human has told us something, then we want the same thing from the models, and that can vary from person to person. So building that explainable level into everything we do, has to be one of the things we think about upfront. But you’ve got to really, truly deeply understand that data. And it’s not just a question of offloading a data set to a generalist who can turn that handle, otherwise you will end up with huge, huge problems.</p>
<p><strong>Fatemeh Torabi</strong>: I very much agree with all the points that my colleagues raised. I also think it’s very important that we know why we are doing things. Having those incremental stages in our planning for any project, and then having a vision of where we see AI can contribute into this process and can give us further efficiency – and how – is very important. If we don’t have defined measures to see how this AI algorithm is contributing to this specific element of the project, we can get really lost bringing these capabilities on board. Yes, it might generate something, but how we are going to measure that something is very important. I think, as members of the scientific community, we must all view AI as a valuable tool. However, it has its own risks and benefits.</p>
<p>For example, in healthcare when we use AI for risk predictions, it can be a really great tool to aid clinicians to save time. However, in each stage, we need to assess the data quality, how these data are fed into the algorithm, what procedures, what models, and how we generate those models. And then which discriminative models do we use to balance the risk and eventually predict the risk of outcomes in patients? It’s very much a balance between risks and benefits for usefulness of these tools in practice. We have all these brilliant ideas of what best practice is. But in real terms, sometimes it’s a little bit tricky to follow through.</p>
<p><strong>Could you give us some thoughts on the sort of best practice with data, for example, that doesn’t quite turn out to be quite so easy to follow in practice, and what you might do about it?</strong></p>
<p><strong>FT</strong>: We always call these AI algorithms, data hungry algorithms, because the models that we fit require us to see patterns in the data that we feed into them so that the learning happens. And then the discriminative functions come in place to balance and kind of give a score to wherever the learning is happening and give an evaluation of each step. However, the data that we put into these algorithms comes first – the quality of that data. Often in healthcare, because of its sensitivity, the data is held within a secure environment. So we cannot, at this point in time, expose an AI algorithm to a very diverse example, specifically for investigating rare diseases or rare conditions. And above that, there is also complexities in the data itself. We need to evaluate and clean the data before we feed it into these algorithms. We need to evaluate the diversity of the data itself – for example, the tabular data, the imaging data, the genomic data – and each one requires its own specific or tailored approach in data cleaning stages.</p>
<div id="fig-1" class="quarto-float quarto-figure quarto-figure-center anchored" alt="The panel. Clockwise from top left: Ali Al-Sherbaz, Janet Bastiman, Fatemeh Torabi and Jonathan Gillard" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="https://realworlddatascience.net/foundation-frontiers/posts/2024/06/04/images/panel-991.jpg" class="img-fluid quarto-figure quarto-figure-center figure-img" alt="The panel. Clockwise from top left: Ali Al-Sherbaz, Janet Bastiman, Fatemeh Torabi and Jonathan Gillard">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;1: The panel. Clockwise from top left: Ali Al-Sherbaz, Janet Bastiman, Fatemeh Torabi and Jonathan Gillard
</figcaption>
</figure>
</div>
<p>We also have another level that is now being discovered in the health data science community, which is the generation of synthetic data. We can give AI models access to these synthetic versions of the data that we hold. However, that also has its own challenges because it requires reading the patterns from real data, and then creating those synthetic versions of data.</p>
<p>For example, Dementia Platforms UK is one of the pioneers in developing this. We hold a range of cohort data, patients’ data, genomics data and imaging data. In each one of these when we try to develop those processing algorithms, there are specific tailored approaches that we need to consider to ensure we are actually creating a low fidelity level of data that is holding some of the patterns in it for the AI algorithm to allow the learning to happen. However, we also need to consider whether it is safe enough so that we can ensure the data provided are secure to be released for use at a lower governance level compared to the actual data. So there are quite a lot of challenges, and we captured a lot of it in our <a href="https://realworlddatascience.net/foundation-frontiers/posts/2024/05/07/ai-series-3.html">article</a>.</p>
<p><strong>A A-S</strong>: I can talk about the cybersecurity and other relevant data network security, the point being the amount of data we receive to analyse. It’s really huge. And when I say huge I mean about one gigabyte, probably in a couple of hours, or one terabyte in a week – that’s huge. One gigabyte of a text file – if I printed out this file with A4 – that would leave me with a stack of A4 paper, three times the Eiffel Tower.</p>
<p>Now, if I have cyber traffic, and try to detect any cyber attack, AI helps with that. However, if we train this model properly, they have to detect cyber attacks in real time – when I say real time, we’re talking about within microseconds or a millisecond – and the decision has to be correct. AI alone doesn’t work, doesn’t help. Humans should also intervene, but rather than having 100,000 records to check for a suspected breach, AI can reduce that to 100. A human can interact with that. And then in terms of the authentication or verification, humans alongside AI can learn whether this is a false positive, or a real attack or a false negative. This is a challenge in the cybersecurity area.</p>
<p><strong>JB</strong>: I just wanted to dive in from the finance side – again the data is critical, and we have very large amounts of data. However in addition – and I think we probably suffer from the same sort of problem that Ali does in this – when I’m trying to detect things, there are people on the other side actively working against what I’m trying to detect, which I suppose is a problem that maybe Fatemeh doesn’t have in healthcare.</p>
<p>When you’re trying to build models to look for patterns, and those patterns are changing underneath you, it can be incredibly difficult. I have an issue that all of my client’s data legally has to be kept separated – some of it has to be kept in certain parts of the world so we can’t put that into one place. We can try and create synthetic data that has the same nuances of the snapshots that we can see at any one point in time, and we can try and put that together in one place, but what we can detect now will very quickly not be what we need to detect in a month’s time. As soon as transactions start getting stopped, as soon as suspicious activity reports are raised, and banks are fined, everything switches and how all of that financial crime occurs, changes. And it’s changing, on a big scale worldwide, but also subtly because, there are a team of data scientists on the other side trying desperately to circumvent the models that me and my team are building. It’s absolutely crazy. So while I would love to be able to pull all of the data that I have access to in one place and get that huge central visual view, legally I can’t do that because of all the worldwide jurisdictional laws around data and keeping it in certain places.</p>
<p>Then I’ve also got the ethical side of it, which is something that Fatemeh touched on. If I get it wrong, that can have a material impact on usually some of the most marginalised in society. The profile of some of the transactions that are highly correlated with financial crime are also highly correlated with people in borderline poverty, even in Western countries. So false positives in my world have a huge, huge ethical impact. But at the same time, we’re trying really hard to minimise those false negatives – that balance is critical, and the data side of it is such a problem.</p>
<p>Fatemeh mentioned the synthetic side of it. There’s a huge push, particularly in the UK to get good synthetic data to really showcase some of these things that we’re trying to detect. But by the time you get that pooling, and the synthesising of data that you can ethically use and share around without fear of all the legal repercussions, what we’re trying to detect has already moved on. So we’re constantly several steps behind.</p>
<p>I imagine Ali has similar problems in the cybercrime space in that as soon as things are detected, the ways in which they work move on. So there’s an awful lot I think that, as an industry, although we have different verticals, we can share best practices on.</p>
<p><strong>Is there a demand for new types of expertise?</strong></p>
<p><strong>A A-S</strong>: There is a huge gap in the in the UK, at least and worldwide about finding people working as a data scientist or working with the data. So we created a course in Cambridge, which we call the data science career accelerator for people who work in data, and would like to move on and learn more. We did market research, and we interviewed around 50 people between CEO and head of security and head of data scientists, in science departments and in industry, to tell us – what kind of skills are you after? What problems do you currently have? And then we designed this course.</p>
<p>We found that first of all there are people who don’t know from where to start – what kind of data they need, what tools they have to learn with… Even if they learn the tools, they still need to learn what kind of machine learning process to use. And then suddenly, we have ChatGPT turned out, and the LLM [large language model] development – all of that in one course, it is a real challenge.</p>
<p>The course has started now, the first cohort. The big advice from industry we have is that during the course they have to work on real world case studies, on scenarios with data that nobody has touched before – that is, it’s new, not public. We teach them on a public data, but companies also have their own data, and we get consent from them to use that data for the students so we can test the skills they learned on virgin data that nobody has touched before.</p>
<p>We just started this month, and the students are going to start with the first project now. They are enjoying the course but that is the challenge we have now. How did we handle that? It’s to work together with the industry side by side, even during the delivery. We have an academic from Cambridge, and we have experts from the industry to support the learners to learn to get the best of both worlds.</p>
<p><strong>The industry has changed so much in the last couple of years. Does that mean that the expertise and demands are also changing very quickly or is there a common thread that you can work with?</strong></p>
<p><strong>A A-S</strong>: Well, there is a common thread, but having new tools – I mean, Google just released Gemini, and that’s a new skill they have learnt and been tested on, and looked into how others feel about it and compared it to ChatGPT, or Claude 3 or Copilot. That’s all happened in the last 12 months. And then, of course, reacting on that, reflecting on the material, teaching the material – it’s a challenge. It’s not easy and you need to find the right person. Of course, people who have this kind of experience are in demand, and it’s hard to secure these kinds of human resources as well as to deliver the course. So there are challenges and we have to act dynamically and be adaptive.</p>
<p><strong>What are your thoughts on the evaluation of these models, and how to manage the risk of something that you haven’t thought of before, and the role of regulation.</strong></p>
<p><strong>JG</strong>: I think a lot of our discussions at the moment are assuming that we’ve got well meaning, well intentioned people and well meaning, well intentioned companies and industries, who are trying to seek to do their best ethically and regulatorily and with appropriate data, and so on. But there is a space here for bad actors in the system.</p>
<p>Unfortunately, digital transformation of human life will happen in a good and bad way – unfortunately, I think there are going to be those two streams to this. Individuals are very capable now of making their own large language models by following a video guide if they wanted to, and having that data is, of course going to enable them maybe to do bad things with it.</p>
<p>Data is already a commodity in quite a strong way, but I do think we have to visit data security, and even the risks of open data as well. We live in a country, which I think does very well in producing lots of publicly available data. But that could be twisted in a way that we might not expect. And when I speak of those things, we’re usually thinking of groundwork – writing and implementing your own large language models – but there were recent examples of where just by using very clever prompting of existing large language models, you could get quite dangerous material, shall we say, which circumnavigated inbuilt existing safeguards. Again, that’s an emerging thing that we have to have to try and address as it comes on.</p>
<p>I think my final point with ethics and regulation is it will rapidly evolve, and it will rapidly change. And a story which I think can illustrate that is, when the first motorcar was introduced into the UK, it was law for a human to walk in front of the motorcar with a large red flag to warn passers-by of the incoming car because people weren’t really familiar with it. Now, of course, that’s in distant memory, right? We don’t have people with red flags, walking in front of cars. I do wonder, in 20 years or 50 years, what will the ethical norms regarding AI and its use be? Likewise, will we have deregulation? That seems to be the common theme in history that when we get more familiar with things, we deregulate because we’re more comfortable with their existence. That makes me quite curious about what the future holds.</p>
<p><strong>FT</strong>: Jon raised a very interesting point and Janet touched upon keeping financial data in silos but we are facing this in healthcare as well. Data has to be checked within a trusted research environment or secure data environment that’s making the data silos. However, efforts at this point in time are on enhancing these digital platforms to bring data and federal data together. Alongside what is happening in terms of our progression towards development of a new ethical or legal requirement, is documenting what is being practised at the moment, because at the moment there are quite a lot of bubbles. Each institution has their own data and applies their own rules to it. So understanding what it is that we are currently working on – the data flows that are flowing into the secure environments – is building the basis of developments that are going on in terms of developing standardisation and common frameworks. A lot of projects have been focused on understanding the current to develop on it for the future.</p>
<p>We know for example, the Data Protection Act, put forward some specific requirements, but that was developed in 2018, before we had this massive AI consideration. In my academic capacity as well, we are facing what Jon mentioned, in terms of the diversity of assessments for students. For example, when we ask these questions, even if the data is provided within the course and within this defined governance, we know that the answers can possibly be aided by AI – a model. So we are defining more diverse assessment methods in academic practice to ensure that we have a way to evaluate the outcome that we are receiving by the human eye, rather than being blinded by what we receive from AI, and then calling it high quality output, whether in research practice or in academic practice. So there’s quite a lot of consideration of these issues, I think that is bringing our past knowledge to the current point where we now have to balance between human and machine interactions in every single process that we are facing.</p>
<p><strong>How does this change the skill set required of data scientists, as AI is getting more and more developed?</strong></p>
<p><strong>A A-S</strong>: Regarding the terminology of data scientists, when we talk about data we immediately link that with statistics, and statistics is an old topic. There has been an accumulation of expertise for 100 years, to the best of my knowledge or more in statistics, and people who are new to data analysis or data, have to learn about this legacy. And when we develop the course, we should mention these skills in statistics and build this knowledge on top, that is, when we reach the right point, then we talk about learning or machine learning, supervised and unsupervised, and about LLM – these are the new skills they have to learn. As I mentioned, it’s tricky when we teach learners about it, we have to provide them with simple datasets to teach them something complex in statistics because it’s a danger to teach both [data and statistics at the same time] – we will lose them, they will lose concentration and it’s hard to follow up. So, a little bit of statistics – they have to learn the basics like normal distribution, the distribution, the type, and what does it mean when we have these distributions, the meaning of the data – and that is the point I made earlier about how people should have a sense for the numbers. What does it mean, when I say 0.56 in healthcare? Is that a danger? 60% – is that OK? In cybersecurity, if the probability of attack today is 60% should I inform the police? Should I inform someone; is that important? Or for example, for the stock market? Say we have dropped off 10% – Is that something we have to worry about? So making sense of the numbers is part of it.</p>
<p>That is part of personalised learning because it depends on their background or what they have learned – it’s not straightforward, and it has to be personalised not just for people taking the course now, for instance for someone who is 18 years old coming from their A levels. No, it’s for a wide range. People from diverse courses like to approach this data science course. And now we are in the era of people who are in social science, and engineering, doctors, journalism, art, they are all interested in learning a little bit of data science, and utilising AI for their benefit. So there is no one answer.</p>
<p><strong>You emphasise that people still need to be able to make sense of numbers. We’re often told that AI will devalue knowledge and devalue experience – it sounds like you don’t feel that’s the case.</strong></p>
<p><strong>A A-S</strong>: I have to stick with the following: human value is just that – value. AI without humans is worth nothing. I have one example: In 1997, some software was developed for chess, to play against a human, and for the first time, that computer programme (called AI now) beat Kasparov. Guess what happened? Did chess disappear? No, we still value human to human competition. The value of the human is the same for art and for music. So we still have human value, and we have to maintain that for the next generation. They shouldn’t lose this human value, and handover to AI value, which I feel is zero without the human.</p>
<p><strong>J B</strong>: I think one of the things we are seeing is that diversity in people’s backgrounds coming into data science, which is fantastic, because I think that really helps with the understanding of when things can go wrong, and how things can be misused. If you have this cookie cutter set of people that have all got a degree from the same place and all had the same experience, which is very similar – this happens a lot in the financial industry where there’s like five universities that all feed into the banks – they all think and solve problems in the same way because that’s how they’ve been trained. But as soon as you start bringing in people with different backgrounds, they’re the ones that say, hang on, this is a problem. So having those different backgrounds is really useful.</p>
<p>But then as Ali said there’s so many people who call themselves a data scientist that don’t understand data, or science. And I think he was absolutely right. If you’ve got a probability of 60%, or you’ve got a small standard deviation, when is that an issue? What do you really understand about that based on your industry, and based on your statistical knowledge? That’s so so key. And it’s something that a lot of people who are self-trained and call themselves data scientists have missed out on. So coming back to your original question about is it harder or is it easier, in some respects, it’s a lot harder, because someone who calls himself a data scientist now needs to do everything from basically fundamental research, trying to make models better, you’ve got to understand statistics, you’ve got to understand machine learning, engineering, production, isolation, efficiencies, effectiveness, ethics – it’s this huge, huge sphere. And it’s too much for one person. So you’ve really got to have well balanced teams and support. Because you can’t keep on top of your game across all of those. It’s just not possible. So I think that becomes really difficult. When I look at how things have changed, there’s so many basic principles from, you know, the 80s and 90s, in standard, good quality computer programming and testing. And I think the one thing that we’re really missing as an industry is a specialist AI testing role. Someone who understands enough about how models work and how they can go wrong and can do the same thing for AI solutions, as good QA analysts can do for standard software engineering models. Someone who can really test them to extremes with what happens when I put the wrong data in.</p>
<p>We saw this – there were a couple of days under COVID, where all the numbers went wrong, because the data hadn’t been delivered correctly, or not enough of it had been delivered. There were no checks in place to say, actually, we’ve only got 10% of what we were expecting, so don’t automatically publish these results. It’s things like that, that we really need to make sure are built into the systems because those are the things that, again, could cause problems. As soon as you get a model that’s not doing the right thing – going back to our original question – when they do go wrong, you can then find a company pulls that model even though it could be easily fixed. And then they’re disillusioned with AI, and won’t use it. That’s that whole project, and all of the expense and investment on that just thrown away when a bit more testing and understanding could have saved it.</p>
<div class="article-btn">
<p><a href="../../../../../foundation-frontiers/index.html">Explore more data science ideas</a></p>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-12">
<dl>
<dt>About the authors</dt>
<dd>
<strong>Anna Demming</strong> is a freelance science writer and editor based in Bristol, UK. She has a PhD from King’s College London in physics, specifically nanophotonics and how light interacts with the very small, and has been an editor for Nature Publishing Group (now Springer Nature), IOP Publishing and New Scientist. Other publications she contributes to include The Observer, New Scientist, Scientific American, Physics World and Chemistry World..
</dd>
</dl>
</div>
<div class="g-col-12 g-col-md-6">
<!-- copyright goes to the author, or to Royal Statistical Society if written by staff -->
<dl>
<dt>Copyright and licence</dt>
<dd>
© 2024 Royal Statistical Society
</dd>
</dl>
<!-- confirm licence terms with contributor before publishing - must be Creative Commons licence, but different types of CC licences might be preferred -->
<p><a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> <img src="https://mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1" style="height:22px!important;vertical-align:text-bottom;"><img src="https://mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1" style="height:22px!important;margin-left:3px;vertical-align:text-bottom;"></a> This article is licensed under a Creative Commons Attribution 4.0 (CC BY 4.0) <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> International licence</a>. <!-- Add thumbnail image credit and any licence terms here --></p>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>How to cite</dt>
<dd>
Demming, Anna. 2024. “What is “best practice” when working with AI in the real world?.” Real World Data Science, June 4, 2024. <a href="https://realworlddatascience.net/foundation-frontiers/posts/2024/05/20/ai-series-6.html">URL</a>
</dd>
</dl>
</div>
</div>
</div>
<!-- Make sure to update main site homepage (index.qmd) before publishing. See README for details -->



 ]]></description>
  <category>AI</category>
  <category>large language models</category>
  <category>machine learning</category>
  <guid>https://realworlddatascience.net/foundation-frontiers/posts/2024/06/04/ai-series-6.html</guid>
  <pubDate>Tue, 04 Jun 2024 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/foundation-frontiers/posts/2024/06/04/images/panel-991.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>AI series: Meeting the unprecedented challenges AI poses in the labour market</title>
  <dc:creator>Julia Lane, Lesley Hirsch, and Adam Leonard</dc:creator>
  <link>https://realworlddatascience.net/foundation-frontiers/posts/2024/05/28/ai-series-5.html</link>
  <description><![CDATA[ 





<p>Roughly $280 billion of new funding was authorized to boost research and production of semiconductors in the US under the CHIPS and Science Act in 2022 - an amount greater than the inflation-adjusted initial spending to create the US Interstate Highway System. The legislation was just one of multiple acts engineered to subsidise and support emerging technologies in the US that are bound to have seismic impacts on the labor market. It signifies how swift changes in new and emerging technologies have the potential to profoundly change the demand for skills and the structure of work. Here AI has the potential to be more disruptive than any other technological development since the industrial revolution.</p>
<p>The US is not alone. Countries across the globe are trying to understand the potential for AI to affect their workforce and economic activity. IPSOS, Group SA, a multinational market research company with headquarters in France, recently attempted to gauge people’s feelings towards AI across the world through a survey across 31 countries and interviews with a small cohort of AI leaders (<a href="https://www.ipsos.com/sites/default/files/ct/news/documents/2023-07/Ipsos%20Global%20AI%202023%20Report-WEB_0.pdf">Global Views on AI 2023</a>). However although extensive, the data retrieved shares the limitations common to all surveys. The OECD’s most recent <a href="https://www.oecd-ilibrary.org/sites/08785bba-en/index.html?itemId=/content/publication/08785bba-en">Employment Outlook</a> devotes six out of seven chapters to understanding the impact of AI on the workforce. But the OECD also notes that “No comprehensive method exists by which to track and compare AI R&amp;D funding across countries and agencies.” <sup>1</sup> Not surprisingly, the inability to track, let alone compare AI R&amp;D funding, means that it is difficult to make predictions about the R&amp;D induced global labor market consequences.</p>
<p>The lack of a comprehensive method, and the resultant uncertainty about impact, is a clarion call to action. There are many challenges that need to be addressed. A partial list would include the following: a) a lack of a common definition of AI; b) a lack of information about the needed AI capabilities and how they will change; c) mapping AI capabilities to occupational skillls; and d) an inability to measure the impact of AI on job replacement or job augmentation.</p>
<p>Fortunately, there is hope, with new partnerships being established in the US by universities, federal, and state agencies. A new data infrastructure is being developed at the Institute for Research on Innovation and Science (IRIS) at the University of Michigan, joint with Ohio State University, in the United States, funded by the federal US National Science Foundation (NSF). The pilot joins up existing data using university and state sources to trace how scientific innovation translates to the labor market <sup>2</sup>. The NSF, which was been charged with the regional implementation of the CHIPS and Science investments, is funding the pilot precisely because it needs “innovative tools to accurately assess the impact of these investments across the U.S. <sup>3</sup></p>
<section id="how-bad-is-the-problem" class="level2">
<h2 class="anchored" data-anchor-id="how-bad-is-the-problem">How bad is the problem?</h2>
<p>The lack of data results in conflicting information. Some reports have warned of apocalyptic takeovers of the job market for many professions. Indeed, a heavily cited report by Goldman Sachs <sup>4</sup> predicted that AI could replace 300 million jobs. But the same BBC report that cited the Goldman Sachs prediction quoted the future-of-work director at Oxford University, Carl Benedikt Frey as saying “The only thing I am sure of is that there is no way of knowing how many jobs will be replaced by generative AI”. Simply put, as the former US Federal CIO, Suzette Kent, said “we lack useful information for informing strategic decisions for national workforce matters.”</p>
<p>So just how much of a problem is it that there is no information on how investments in science and technology affect the labor market? Why should we worry if we cannot accurately predict the impact of AI on workers, firms, and jobs? One reason is to avoid the mistakes of the past, in which both workers and firms have borne the consequences of bad information. Just in recent history, digitization and globalization resulted in a devastating loss of jobs in many countries. And geographic inequality soared as jobs in the midwestern and northeastern urban centers were lost and a service economy on the coasts burgeoned. Efforts to reduce the loss of jobs and earnings came too little, too late <sup>5</sup> <sup>6</sup>. Another reason is to make evidence based policy recommendations. For example, the US National AI Research Resources Taskforce, which was directly charged by the President and Congress with recommending ways to invest in AI research to strengthen and democratize the U.S. AI innovation ecosystem did not have joined up data between science investment and the workforce to inform their final recommendations. <sup>7</sup></p>
<p>In other words, governments need more timely, local, and actionable data so that they can understand changes in the tasks that employers need performed, which types of jobs and firms will be affected, and where. Concomitantly, data will be needed about the effects of AI on different population groups and different geographic areas so that the costs of change are not unfairly distributed. Armed with such information, policy makers can make investments that mitigate or counteract negative impacts and workers can be trained in the new necessary skills and matched with the firms that need them. But the swift pace of change in AI means that the urgency to create timely, local, and actionable labor market information to guide these investments has never been greater.</p>
</section>
<section id="a-new-approach" class="level2">
<h2 class="anchored" data-anchor-id="a-new-approach">A new approach</h2>
<p>The IRIS approach, called the “Industry of Ideas” builds on the “economics of ideas” framework for which Paul Romer received the 2018 Nobel Prize in Economics”. <sup>8</sup> <sup>9</sup>. People who create ideas – new technologies – that can be reused, form the foundations of new industries. In other words, “the discovery of new ideas lie at center of economic growth…” (Charles Jones describing Paul Romer’s conceptual framework) <sup>10</sup>.</p>
<p>The project recognizes that, as Robert Oppenheimer said “the best way to transmit knowledge is to wrap it up in a human being”. <sup>11</sup> It uses people-centric methods for following the movement of ideas from investments in research into the marketplace. The approach identifies businesses that employ people with deep skills in AI and other emerging technology areas and developing early, never-before-available indicators that can provide alerts associated with potential impacts on current and future workforce. Initially focused on the artificial intelligence and electric vehicle industries in Ohio, the pilot is creating a data system that can be expanded and applied to other industries and other states across the country.</p>
<p>The new tools are innovative because they build on new opportunities to produce usable information that is local, about relevant industries, and that directly tie investments in new technologies, such as AI, to labor market impacts.</p>
<p>Another key aspect of the NSF piloted “Industry of Ideas” is the focus on tying innovation at its source - individual data on university research activities - to the local workforce data reported by firms to their state departments of labor. The need for local data is critical because so many labor markets are local, not national in scope. Even in a global economy, many businesses and workers are locally based – as are the training providers that work to ensure that labor demand and supply are well matched. Thus the Industry of Ideas pilot provides policy makers, workers, firms, and educational institutions with access to an array of local, timely, granular, actionable resources to help them make decisions. That way, local leaders who need labor market data don’t need to rely on national unemployment figures, which are reported once a month.</p>
</section>
<section id="connecting-science-investments-with-jobs" class="level2">
<h2 class="anchored" data-anchor-id="connecting-science-investments-with-jobs">Connecting science investments with jobs</h2>
<p>The Industry of Ideas approach directly connects investment in science and the labor market, moving beyond the current approach for evaluating investment by studying scientific papers and publications <sup>12</sup> <sup>13</sup> which are disconnected from workers and jobs. The data seeds were sown almost two decades ago. President Bush’s Science Advisor, John Marburger III, who, quite sensibly was unconvinced of the scientific and practical value of relying primarily on document-based, bibliometric approaches to studying science to understand its practical effects, called for a “Science of Science Policy” <sup>14</sup> <sup>15</sup>.</p>
<p>The Industry of Ideas is testing the potential to securely combine university and state data to measure the link between federal investments on local and regional economies for AI. It uses people-centric data generated by the administrative processes at universities and firms. With this data the Industry of Ideas project can capture the organization of people in science at multiple levels (e.g.&nbsp;individuals, teams, projects, and institutions), their multiple sources of funding (federal scientific and programmatic agencies, philanthropic foundations, industry, and state and local government), inputs into science from vendors (such as computing services, instruments, biological specimens), as well as the dynamics of their careers across time (individual career earnings and employment trajectories).</p>
<div id="fig-1" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center" alt="The Industry of Ideas Infrastructure (provided by Jason Owen-Smith, IRIS, University of Michigan)">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="https://realworlddatascience.net/foundation-frontiers/posts/2024/05/28/images/Industry-of-ideas991-724.png" class="img-fluid quarto-figure quarto-figure-center figure-img" alt="The Industry of Ideas Infrastructure (provided by Jason Owen-Smith, IRIS, University of Michigan)">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;1: The Industry of Ideas Infrastructure (provided by Jason Owen-Smith, IRIS, University of Michigan)
</figcaption>
</figure>
</div>
<p>The IRIS infrastructure, developed over the past decade, provides administrative records on more than 41% of U.S. total R &amp; D spending at universities <sup>16</sup>. The infrastructure also provides links to survey data, as well as data from private sector suppliers <sup>17</sup>, and can trace the flows of university funded researchers into the private sector <sup>18</sup> by joining up the university administrative data with state workforce data.</p>
</section>
<section id="tying-information-about-ai-to-skills-needs" class="level2">
<h2 class="anchored" data-anchor-id="tying-information-about-ai-to-skills-needs">Tying information about AI to skills needs</h2>
<p>How is it possible to tie changes in AI to changing needs for skills? State leaders in workforce and education agencies have identified new ways to collaborate, build staff capacity, and develop solutions, services, and products that respond to local need. An example of how to use data to get better information that more accurately connects workers with firms in the swiftly changing labor market is the New Jersey Career Navigator. It provides job seekers recommendations on new careers, available job postings, and relevant training programs based on skills similarity, labor market demand, and wage impacts observed in the underlying data. These recommendations, which are in themselvers generated by AI, show how AI technology can be used to navigate the changes in the labour market AI may cause. The New Jersey Career Navigator draws on millions of wage records, providing earnings and industry information on all workers covered by unemployment insurance in New Jersey firms; employment and wage outcomes from hundreds of thousands of graduates of occupational skills training programs in New Jersey; several years of online job postings from the National Labor Exchange Research Hub (NLx); and the resumes of 400,000 New Jersey residents.</p>
<p>In other words, as the Industry of Ideas pilot evolves, new ideas from states like New Jersey can be used not only to trace the flows of ideas from academia to the workplace but also to develop a new system that targets reskilling efforts once the type and location of skills needs have been identified. The new joined up data and evidence can be used to address challenges such as low labor force participation, and supplies education and training providers the data they need to align their programs with the needs of the labor market. Such a system would help government, business, educators, and workers adjust regional talent pipelines continuously in response to the changes in AI and enable workers to successfully navigate the changes that it brings.</p>
</section>
<section id="new-approaches-to-classifying-industries-industries-of-ideas" class="level2">
<h2 class="anchored" data-anchor-id="new-approaches-to-classifying-industries-industries-of-ideas">New approaches to classifying industries: “Industries of Ideas”</h2>
<p>An important outcome of the new NSF pilot is the potential to transform the way in which we classify firms into industries. The current industry classifications are rule based. They are designed for the economy as it was organized 40 years ago, so are not designed to describe AI. A case in point is the state of Texas – a state that anecdotally has generated a lot of high tech jobs. Current industry data for Texas is limited because firms are grouped into industries that are defined by what they produce, or how they produce it, rather than describing what new technology is being developed or utilized by those firms. As a result, the main source of labor market data in Texas provides an implausibly low picture of AI activity <sup>19</sup>.</p>
<p>The Industries of Ideas approach could provide states with a new way to classify firms, based on clever new ideas of how firms can do their business, and by grouping firms by the people who created and use the technologies they will adopt <sup>20</sup>. Examples just for Ohio include funding to use AI to improve the ways in which medicine is delivered, and advancing digital agricuture , which includes things like precision livestock farming, or precision agriculture that reduces waste and improves productivity more generally. As they interact with farmers, the clustering of university researchers and the ideas embodied in them alongside the farms that adopt those ideas represents this new type of industry cluster . Such a classification framework is a sea change from earlier industrial classifications based on what goods are physically produced - like manufacturing and agriculture <sup>21</sup>.</p>
</section>
<section id="the-future" class="level2">
<h2 class="anchored" data-anchor-id="the-future">The Future</h2>
<p>Such a bottom-up classification and analysis system, based on local links between researchers and firms, could be designed locally but scaled nationally. It could address the challenges identified at the beginning of this piece. The definition of AI firms could evolve and be defined by the links between AI researchers and the firms with which they work. The lack of information about the needed AI capabilities would be resolved by the direct mapping of firm skill demand and their hiring patterns, as exemplified in New Jersey. The same New Jersey mapping could tie AI capabilities to occupational skills. And the direct impact of AI on job replacement or job augmentation could be mapped from the joined up university and workforce data.</p>
<p>Of course, much needs to be done. The implementation will depend on the success of the pilot, and the ability to build on existing assets. Not all states and universities have the capacity to build a similar system, but the fact that 30 universities and 15 state agencies are participating in advisory boards for the NSF Industry of Ideas pilot is grounds for hope. Indeed, a new generation of data leaders is leading the way, not only at the local and regional government level but also at universities and professional associations (Advisory Committee on Data for Evidence Building) <sup>22</sup>.</p>
<p>We began this paper by noting that the urgency to create timely, local, and actionable labor market information has never been greater. We close by arguing that our capacity to fundamentally change the way in which we can use data and information to understand the demand for skills and the structure of work has also never been greater. The opportunity is ours for the taking.</p>
<!-- article text to go here -->
<div class="article-btn">
<p><a href="../../../../../foundation-frontiers/index.html">Explore more data science ideas</a></p>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-12">
<dl>
<dt>About the authors</dt>
<dd>
<strong>Julia Lane</strong> is a Professor at New York University’s Wagner Graduate School of Public Service. She was a senior advisor in the Office of the Federal CIO at the White House, supporting the implementation of the Federal Data Strategy. She recently served on two White House committees: the Advisory Committee on Data for Evidence Building and the National AI Research Resources Task Force.
</dd>
<dd>
<p><strong>Adam Leonard</strong> is the Chief Analytics Officer &amp; Director of the Division of Information Innovation &amp; Insight (I|3) for the Texas Workforce Commission (TWC). Adam envisioned and founded I|3 to help TWC leverage its most important untapped resource - its data – to help the agency and its partners better help employers, individuals, families, and communities achieve &amp; maintain prosperity.</p>
</dd>
<dd>
<p><strong>Lesley Hirsch</strong> is the Assistant Commissioner of Research and Information at the New Jersey Department of Labor and Workforce Development. Her vision for the department is to bring cutting-edge digital tools to bear to deliver labor market intelligence to the department’s internal and external customers where, when, and how they need it and to mine every data source so it can tell its full story.</p>
</dd>
</dl>
</div>
<div class="g-col-12 g-col-md-6">
<!-- copyright goes to the author, or to Royal Statistical Society if written by staff -->
<dl>
<dt>Copyright and licence</dt>
<dd>
© 2024 Royal Statistical Society
</dd>
</dl>
<!-- confirm licence terms with contributor before publishing - must be Creative Commons licence, but different types of CC licences might be preferred -->
<p><a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> <img src="https://mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1" style="height:22px!important;vertical-align:text-bottom;"><img src="https://mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1" style="height:22px!important;margin-left:3px;vertical-align:text-bottom;"></a> This article is licensed under a Creative Commons Attribution 4.0 (CC BY 4.0) <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> International licence</a>. <!-- Add thumbnail image credit and any licence terms here --></p>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>How to cite</dt>
<dd>
Lane, J., Hirsch, L. and Leonard, A. 2024. “Meeting the unprecedented challenges AI poses in the labour market.” Real World Data Science, May 28, 2024. <a href="https://realworlddatascience.net/foundation-frontiers/posts/2024/05/13/ai-series-5.html">URL</a>
</dd>
</dl>
</div>
</div>
</div>
<!-- Make sure to update main site homepage (index.qmd) before publishing. See README for details. -->


</section>


<div id="quarto-appendix" class="default"><section id="footnotes" class="footnotes footnotes-end-of-document"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p>A new approach to measuring government investment in AI-related R&amp;D. Galindo-Rueda, F. &amp; Cairns, S. <em>oecd.ai</em> (2021)↩︎</p></li>
<li id="fn2"><p><a href="https://www.aei.org/research-products/report/the-industry-of-ideas-measuring-how-artificial-intelligence-changes-labor-markets/">The Industry of Ideas: Measuring How Artificial Intelligence Changes Labor Markets</a> Lane, J. AEI (2023)↩︎</p></li>
<li id="fn3"><p><a href="https://www.aei.org/research-products/report/the-industry-of-ideas-measuring-how-artificial-intelligence-changes-labor-markets/">NSF launches pilot to assess the impact of strategic investments on regional jobs</a> *new.nsf.gov (2023)↩︎</p></li>
<li id="fn4"><p><a href="https://www.bbc.co.uk/news/technology-65102150">AI could replace equivalent of 300 million jobs - report</a> Vallance, C. <em>BBC news</em> (2023)↩︎</p></li>
<li id="fn5"><p><a href="https://www.aeaweb.org/articles?id=10.1257/aer.103.5.1553">The Growth of Low-Skill Service Jobs and the Polarization of the US Labor Market</a> Autor, D. H. &amp; Dorn, D. <em>American Economic Review</em> <strong>103</strong> pp.&nbsp;1553-97 (2013)↩︎</p></li>
<li id="fn6"><p><a href="https://www.aeaweb.org/articles?id=10.1257/aer.104.8.2509">Explaining Job Polarization: Routine-Biased Technological Change and Offshoring</a> Goos, M., Manning, A. &amp; Salomons, A. <em>American Economic Review</em> <strong>104</strong> 2509-26 (2014)↩︎</p></li>
<li id="fn7"><p><a href="https://www.ai.gov/wp-content/uploads/2023/01/NAIRR-TF-Final-Report-2023.pdf">Strengthening and Democratizing the U.S. Artificial Intelligence Innovation Ecosystem</a> Office of Science and Technology Policy (2023)↩︎</p></li>
<li id="fn8"><p><a href="https://paulromer.net/deep_structure_growth/">The Deep Structure of Economic Growth</a> Romer, P. <em>paulromer.net</em> (2019)↩︎</p></li>
<li id="fn9"><p><a href="https://hdsr.mitpress.mit.edu/pub/zgu2u8y6/release/2">Interview With Paul Romer</a> Romer, P. &amp; Lane, J. (2022)↩︎</p></li>
<li id="fn10"><p><a href="https://onlinelibrary.wiley.com/doi/abs/10.1111/sjoe.12370">Paul Romer: Ideas, nonrivalry, and endogenous growth</a>(Jones, C. I. <em>The Scandinavian Journal of Economics</em> <strong>121</strong> 859-883 (2019)↩︎</p></li>
<li id="fn11"><p><a href="https://www.science.org/doi/10.1126/science.aac5949">Wrapping it up in a person: Examining employment and earnings outcomes for Ph.D.&nbsp;recipients</a> Zolas, N. <em>et al.</em> <em>Science</em> **350 1367-1371 (2015)↩︎</p></li>
<li id="fn12"><p><a href="https://www.nature.com/articles/464488a">Let’s make science metrics more scientific</a> Lane, J. <em>Nature</em> <strong>464</strong> 488–489 (2010)↩︎</p></li>
<li id="fn13"><p><a href="https://issues.org/democratizing-government-data-lane/">A Vision for Democratizing Government Data</a> Lane, J. <em>Issues in Science and Technology</em> <strong>XXXIX</strong> (2022)↩︎</p></li>
<li id="fn14"><p><a href="https://www.nature.com/articles/464488a">Let’s make science metrics more scientific</a> Lane, J. <em>Nature</em> <strong>464</strong> 488–489 (2010)↩︎</p></li>
<li id="fn15"><p><a href="https://www.science.org/doi/10.1126/science.1114801">Wanted: Better Benchmarks</a> Marburger III, J. H. <em>Science</em> <strong>308</strong> p1087(2005)↩︎</p></li>
<li id="fn16"><p><a href="https://iris.isr.umich.edu/research-data/2022datarelease-summarydoc/">The Institute for Research on Innovation &amp; Science (IRIS). Summary Documentation for the IRIS UMETRICS 2022 Data Release</a> Nicholls, N., Brown, C. A., Ku, R. L. and Owen-Smith, J. D. <em>Ann Arbor, MI: The Institute for Research on Innovation &amp; Science</em> (2022) doi: 10.21987/df2a-ha30↩︎</p></li>
<li id="fn17"><p><a href="https://hdsr.mitpress.mit.edu/pub/u073rjxs/release/3">A Linked Data Mosaic for Policy-Relevant Research on Science and Innovation: Value, Transparency, Rigor, and Community</a> Chang, W.-Y., Garner, M., Basner, J., Weinberg, B. and Owen-Smith, J. <em>Harvard Data Science Review</em> (2022) doi: 10.1162/99608f92.1e23fb3f↩︎</p></li>
<li id="fn18"><p><a href="https://www.aei.org/research-products/report/the-industry-of-ideas-measuring-how-artificial-intelligence-changes-labor-markets/">The Industry of Ideas: Measuring How Artificial Intelligence Changes Labor Markets</a> Lane,J. <em>American Enterprise institute</em> (2023)↩︎</p></li>
<li id="fn19"><p>[Outside of the Box Use of Administra4ve and Wage Data in Texas] (https://digitaleconomy.stanford.edu/wp-content/uploads/2024/03/Adam-Leonard.pdf) Leonard, A. <em>digitaleconomy.standford.edu</em> (2024)↩︎</p></li>
<li id="fn20"><p><a href="https://www.aei.org/research-products/report/the-industry-of-ideas-measuring-how-artificial-intelligence-changes-labor-markets/">The Industry of Ideas: Measuring How Artificial Intelligence Changes Labor Markets</a> Lane,J. <em>American Enterprise institute</em> (2023)↩︎</p></li>
<li id="fn21"><p><a href="https://www.bea.gov/system/files/papers/P2007-7.pdf">Converting historical industry time series data from SIC to NAICS. The Federal Committee on Statistical Methodology</a> Yuskavage, R. <em>Federal Committee on Statistical Methodology</em> (2007)) – or by how services and goods are produced – like the delivery of health, financial, and investment services <a href="https://www.jstor.org/stable/23487551">The Statistics Corner: The NAICS Is Coming. Will We Be Ready?</a> Haver, M. A. <em>Business Economics</em> <strong>32</strong> 63-65 (1997)↩︎</p></li>
<li id="fn22"><p><a href="https://www.bea.gov/system/files/2022-10/supplemental-acdeb-year-2-report.pdf">Year 2 Report Supplemental Information</a> Advisory Committee on Data for Evidence Building (ACDEB) (2022)↩︎</p></li>
</ol>
</section></div> ]]></description>
  <category>AI</category>
  <category>Data management</category>
  <category>Forecasting</category>
  <guid>https://realworlddatascience.net/foundation-frontiers/posts/2024/05/28/ai-series-5.html</guid>
  <pubDate>Tue, 28 May 2024 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/foundation-frontiers/posts/2024/05/28/images/Industry-of-ideas991-724.png" medium="image" type="image/png" height="105" width="144"/>
</item>
<item>
  <title>AI series: Evaluation essentials for safe and reliable AI model performance</title>
  <dc:creator>Isabel Sassoon</dc:creator>
  <link>https://realworlddatascience.net/foundation-frontiers/posts/2024/05/21/ai-series-4.html</link>
  <description><![CDATA[ 





<p>It took just sixteen hours for <a href="https://blogs.microsoft.com/blog/2016/03/25/learning-tays-introduction/">Microsoft’s shiny new chatbot</a> Tay to be shut down for profanity. The chatbot had been released on the social media platform, X, then known as Twitter, following extensive evaluation and stress testing under different conditions to ensure that interacting with the chatbot would be a positive experience. Unfortunately, the testing plan had not bargained on a coordinated attack exploiting the chatbot’s vulnerability when exposed to a torrent of offensive material. Tay soon began tweeting wildly inappropriate words and images and was taken offline within hours.</p>
<p>The chatbot’s failure highlights just how hard yet imperative it can be to test and evaluate a model before real world deployment. With the recent flux of accessible “off-the-shelf” machine learning algorithms, building AI models, in particular generative AI models is now relatively straight forward. However, the simplicity with which models are deployed undermines the complexity of evaluating them. Nonetheless, deploying the model anywhere outside the data and context it has been trained on can be risky if its performance is not evaluated. The evaluation process requires clear definitions for good performance as well as highlighting the potential risks, and can throw up unexpected requirements in the test data. Not only are the subtle nuances in the initial evaluation requirements important, but once deployed a process needs to be in place so that the algorithm can be monitored over time.</p>
<section id="know-your-goals" class="level2">
<h2 class="anchored" data-anchor-id="know-your-goals">Know your goals</h2>
<p>The first point to note is that checking how well the output from an AI model matches the data in the training set is not an adequate indication of how well it will perform once deployed on other data. The problem can be exemplified by considering a simple model based on an equation that best fits a training data set. Data values are inevitably subject to measurement uncertainties and local conditions that add various types of noise, so taking the line defined by the equation identified as best matching the training data and measuring how good that match is falls short of adequate evaluation - the more perfectly a model matches this noisy data, the less perfectly it will fit an alternative set of data, a scenario described as “overfitting”. Similarly, what a machine learning or AI algorithm or model learns when it optimises its fit to the training data may not be generalisable.</p>
<div id="fig-1" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center" alt="Reliable deployment of an algorithm requires identifying metrics, risks and rigorous, ongoing evaluation. Image created by Isabel Sassoon using firefly to show a technical report process flow of statistical model performance and a huge numbers chart.">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="https://realworlddatascience.net/foundation-frontiers/posts/2024/05/21/images/Evaluation_thumbnail.jpg" class="img-fluid quarto-figure quarto-figure-center figure-img" alt="Reliable deployment of an algorithm requires identifying metrics, risks and rigorous, ongoing evaluation. Image created by Isabel Sassoon using firefly to show a technical report process flow of statistical model performance and a huge numbers chart.">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;1: Evaluation plots. The kinds of charts of monitored performance and risk metrics that are plotted to evaluate an AI model. Reliable deployment of an algorithm requires identifying appropriate metrics for performance and risk as well as rigorous, ongoing evaluation. Image created by Isabel Sassoon using Adobe Firefly to show a technical report process flow of statistical model performance and a huge numbers chart.
</figcaption>
</figure>
</div>
<p>There are a number of possible approaches and factors to take into account when sourcing test data but the first thing to consider when drawing up a process for evaluating an AI model is its objective. With this objective in mind it is then possible to pin down an appropriate measure of performance, which will shape how to use the test data to evaluate the model performance. Among the distinguishing factors between different measures used to evaluate how a model performs on test data, some will be suitable when the objective is to classify (e.g high or low risk based on health data?) while others are useful for models that estimate or predict (e.g What is the estimated height of a child given their parents’ heights).</p>
<p>Classification model performance can be measured using accuracy, confusion matrices, sensitivity, specificity and the receiver operating characteristic (ROC). Classification accuracy summarises the performance of a classification model as the number of cases in which the model correctly classifies divided by the total number of cases used in the test set. However, this can be a blunt tool as there are cases where there is a different cost or consequence depending on the direction of the error. Confusion matrices are helpful to explore how the model performs in correctly classifying the different classes. The confusion matrix sums up the number of cases the model classifies correctly within each of the classes, for example how many actual high-risk cases are correctly classified as high risk by the model. The number of cases the model classifies as high risk, for example, that are not high risk is referred to as the False Positives. In the context of medical tests (e.g the covid lateral flow tests) testing positive for a condition that is not actually there is potentially less damaging than testing negative when the condition is there.</p>
<div id="fig-2" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center" alt="The receiver operating characteristic can provide a helpful means of visualising performance. Credit: shutterstock .">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="https://realworlddatascience.net/foundation-frontiers/posts/2024/05/21/images/shutterstock_2377152411.jpg" class="img-fluid quarto-figure quarto-figure-center figure-img" alt="The receiver operating characteristic can provide a helpful means of visualising performance. Credit: shutterstock .">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2: The receiver operating characteristic can provide a helpful means of visualising performance. Credit: shutterstock
</figcaption>
</figure>
</div>
<p>Additionally, the sensitivity and specificity can provide a more detailed look at model performance. The sensitivity refers to the proportion of cases labelled as positive that are classified as positive by the model, whereas specificity refers to the proportion labelled as negative that it classifies as negative. It is useful to visualise model performance and the receiver operating characteristic (ROC) provides a method to do just that. The ROC plots the True Positive rate against the False Positive rate for the model. This can be further summarised in one value as the area under the curve (AUC). The larger the AUC the better the model is performing.</p>
<p>Deciding whether accuracy is enough or whether there is a need to delve into the directions of the errors depends on the context of the model’s deployment. Other examples in medicine include the risk models that were developed to assess an individual’s risk of a specific medical condition, such as <a href="https://qrisk.org/">QRISK</a> <sup>1</sup> which calculates a person’s risk of developing a heart attack or stroke over the next 10 years. Here model performance needs to go beyond accuracy and consider the direction of the errors it makes. A good overview of performance evaluation is outlined by Flach (2019) <sup>2</sup>. Is it better to tell someone they may be at risk of disease X, run a blood test and rule it out (False Positive) than to tell them they are not at risk and not check (False Negative)? All this needs to be considered and factored into the validation of the model. It is worth noting that a systematic direction for its errors can also cause an algorithm to hit <a href="https://realworlddatascience.net/foundation-frontiers/posts/2024/05/14/ai-series-2.html">ethical problems</a>.</p>
<p>When evaluating the performance of models that are estimating a numerical value (e.g height of child from height of parents) the measures used are based on how far off the model’s estimate is from the actual value (which is known for testing data). There are then a multitude of ways of summarising that quantity. The mean square error (MSE) is computed by taking the average squared difference between the estimated values from the model and the actual value in the data. Other variations include root mean square error (RMSE) and mean absolute error (MAE). The RMSE is computed in the same way as the MSE but the value is square rooted. The MAE takes a different approach by summing up the absolute errors (i.e.&nbsp;the error magnitude). Each of these three measures involve dividing the value obtained by the number of rows in the data. Depending on the context one of these measures may be better suited than others. For example the MSE is sensitive to outliers so can be easily skewed by a small number of extreme values, which may be useful to highlight them, whereas the RMSE has the advantage of being measured in the same units as the original variable the model is designed to estimate.</p>
<p>Large Language Models (LLMs, e.g.&nbsp;Gemini, ChatGPT) are also models trained on a data set and as such also need to be evaluated and monitored. Whereas in the models discussed so far there are some standard metrics, evaluating LLMs is more challenging as there are a multitude of benchmarks and metrics<sup>3</sup>. When LLMs are used to answer questions (when you ask a chatbot a question) then monitoring the performance of the model (the trained LLM) can involve anything. Is the answer correct? Is the answer clear? Is the answer biased? The possible metrics are varied and not as simple to capture in one measure. It is also possible to use a LLM to evaluate or score another LLMs’ answer to a question. However this adds its own risk as LLMs are not 100% accurate or consistent themselves, and they can <a href="https://realworlddatascience.net/the-pulse/editors-blog/posts/2022/11/23/LLM-content-warning.html">hallucinate</a>.</p>
</section>
<section id="getting-data-right" class="level2">
<h2 class="anchored" data-anchor-id="getting-data-right">Getting data right</h2>
<p>Not only is separate test data needed for an evaluation, but care is needed to ensure the test data is suitably representative. Similar requirements apply for test data as for the original training data to ensure the dataset is representative of the context the model will be deployed in. For instance, if an algorithm is being developed to handle photos from the UK, training and testing it on photos where the sun always shines may cause problems. The model needs to be trained and tested on a set of photos that include rain and clouds otherwise it cannot be assumed it will reliably classify such photos if they appear during deployment in the real world. Getting the training and test data set right may mean using a smaller more curated set than simply one that contains everything available.</p>
<p>These data sets also need to have reliable labelling i.e.&nbsp;the rows of data need to be accurate so that the model’s performance can be assessed objectively against a trusted “ground truth”. For example, if we want to evaluate the performance of a fraud transaction classification model using accuracy as the performance metric, then we need a reliable training data set with true fraud transactions to evaluate how good the model is at detecting them. A data set with a list of transactions that are not accurately identified (or labelled) as fraud or not is not helpful. Thinking about how some commercial LLMs are trained on all the data in the “internet” it is worth asking whether a smaller more curated and specific training set would be better for model performance as well as being more ethical and safer.</p>
<p>Several approaches for generating test data sets take training and test data as distinct subsets from the same initial data set <sup>4</sup>. There are different ways of doing this to make the most of the data to evaluate the model as systematically and exhaustively as possible. Perhaps the simplest example is using a hold-out set, which involves taking all the data available and taking a random subset of the data to use for testing the model. Depending on how much data is available then this can be 50% or less.</p>
<p>A slightly more sophisticated approach is k-fold cross validation, which involves splitting all the data you have available into k subsets and then doing k iterations where in each iteration a different kth of the data is used as the testing data for evaluation of the model built by training it on the remaining (k-1/k) of the data. This is repeated k times each time using a different one of the k subsets for testing. The performance of the model can then be averaged over the k iterations. (The measure of performance can be, say, accuracy or sensitivity depending on the context). For example, if k is 3 then the data is split into 3, and each iteration will take a different 2/3 of the data as training data to build the model, and the remaining 1/3 as testing data to evaluate the model.</p>
<div id="fig-1" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center" alt="K fold cross validation can indicate how sensitive a model is to the test data. Credit: Fabian Flöck CC-BY-AS-3.0">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="https://realworlddatascience.net/foundation-frontiers/posts/2024/05/21/images/k-fold-cross-validation.png" class="img-fluid quarto-figure quarto-figure-center figure-img" alt="K fold cross validation can indicate how sensitive a model is to the test data. Credit: Fabian Flöck CC-BY-AS-3.0">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;3: K fold cross validation can indicate how sensitive a model is to the test data. Credit: Fabian Flöck CC-BY-AS-3.0
</figcaption>
</figure>
</div>
<p>Bootstrap is a more computationally intensive approach and it involves creating multiple samples by randomly sampling with replacement from the original data. Typically, hundreds or thousands of and such samples are generated, each will be different. These multiple samples provide multiple versions of the training and testing data so the model can be evaluated on all these variations. As bootstrap relies on sampling with replacement this means that each row of data in the original data can appear multiple times in a sample training or test data during each iteration, or not appear in other samples. As with k-fold cross validation the performance of the model can be then averaged over these multiple iterations. It is important that bootstrap does not rely on only a handful of iterations. Both bootstrap and cross validation offer an opportunity to see how sensitive the model’s performance is to the characteristics of the test data, but when the data sets available are small, the use of the bootstrap approach provides a more robust way of estimating the model’s performance.</p>
<p>An approach that can be useful to test whether the performance of the model is sensitive to time is time-based splits. This involves taking a “sliding window” ensuring that data is split into back-to-back time periods. Using a back-to-back (sliding window) further ensures that the data the model is trained on is separate from the one it is tested on.</p>
</section>
<section id="maintained-monitoring" class="level2">
<h2 class="anchored" data-anchor-id="maintained-monitoring">Maintained monitoring</h2>
<p>Once an algorithm has been let loose it can be challenging to maintain any rigorous monitoring, but it is worth highlighting the importance of taking on the challenge of ongoing monitoring and promising approaches to it. Some of the same metrics will apply to keep a handle on the myriad of issues that could arise. These range from the banal, such as data input errors, to the complex as is the case in model drift.</p>
<p>In the first case, if a model makes use of data that is fed into it from another system (e.g.&nbsp;a billing system) any update to this other system can affect model performance. Identifying this involves checking that the characteristics of the data used to train the model and the latest data fed into the model are not too dissimilar, since a difference in the data such as an increase by a factor of 10 or a hundred can cause the algorithm to fail. The magnitude of acceptable change in the data will depend on the context. Such a step change (due to source system update) in one of the model inputs can be identified and can potentially be an easy fix.</p>
<p>Model drift is more complex as real-world data evolves over time. There are two types of model drift: data drift and concept drift. Data drift refers to the change that can occur to data over time, whilst concept drift<sup>5</sup> is a deterioration or change in the relationship between the target variable and input variables of a model. An example of data drift could be in the context of billing data the addition of new price plans or phones to the data, whilst an example of concept drift can arise when there is a change in the relationship between the effect (for instance, leaving one mobile phone provider for another) and underlying factors changes. In the context of the mobile phone provider market, a concept drift may mean that leaving for another provider is no longer dictated so much by price sensitivity as the type of network. Both types of drift lead to a deterioration in performance of the model as time goes by. Performance monitoring of the model is key to detecting model drift but differentiating between data or concept drift requires additional specialist approaches. Some of these are outlined in (Rotalinti, 2022)<sup>6</sup> and (Davis, 2020)<sup>7</sup>.</p>
<p>In some cases, refreshing a model to account for the change in the underlying data (both training and test) can be quick and easy. However, if concept drift is detected, then it may take more than just a model refresh as the relationships between the variable we are trying to model, and the explanatory data has changed. This may involve finding new data sources and could lead to significant changes in the model, for example moving from a regression model to a neural network. Deciding to rebuild or retrain a model can also in some cases have environmental impact (particularly for the more resource intensive models such as deep learning and LLMs). Either way, where models are subject to peer review or some form of governance this can be a more onerous task.</p>
<p>Even with each step in a model’s evaluation stringently adhered to it is also important to assess the context for its deployment for risks and rogue scenarios that might break or in the case of Tay despoil it. And like all other stages of the evaluation this should not just be at the time of deployment but also over time. When models (machine learning or other) are used to inform or make important decisions providing information on how and when the model was evaluated, and how it is monitored should be standard practice not just to avoid the wasted expense of another broken AI model (algorithm) left on the shelf but more importantly to safeguard the welfare of those who come into contact with it.</p>
<div class="article-btn">
<p><a href="../../../../../foundation-frontiers/index.html">Explore more data science ideas</a></p>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-12">
<dl>
<dt>About the author</dt>
<dd>
<strong>Isabel Sassoon</strong> is senior lecturer in the Department of Computer Science, Brunel University London.
</dd>
</dl>
</div>
<div class="g-col-12 g-col-md-6">
<!-- copyright goes to the author, or to Royal Statistical Society if written by staff -->
<dl>
<dt>Copyright and licence</dt>
<dd>
© 2024 Royal Statistical Society
</dd>
</dl>
<!-- confirm licence terms with contributor before publishing - must be Creative Commons licence, but different types of CC licences might be preferred -->
<p><a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> <img src="https://mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1" style="height:22px!important;vertical-align:text-bottom;"><img src="https://mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1" style="height:22px!important;margin-left:3px;vertical-align:text-bottom;"></a> This article is licensed under a Creative Commons Attribution 4.0 (CC BY 4.0) <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> International licence</a>. <!-- Add thumbnail image credit and any licence terms here --></p>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>How to cite</dt>
<dd>
Sassoon, Isabel. 2024. “Evaluation essentials for safe and reliable AI model performance .” Real World Data Science, May 21, 2024. <a href="https://realworlddatascience.net/foundation-frontiers/posts/2024/05/06/ai-series-4.html">URL</a>
</dd>
</dl>
</div>
</div>
</div>
<!-- Make sure to update main site homepage (index.qmd) before publishing. See README for details. -->


</section>


<div id="quarto-appendix" class="default"><section id="footnotes" class="footnotes footnotes-end-of-document"><h2 class="anchored quarto-appendix-heading">References</h2>

<ol>
<li id="fn1"><p>Hippisley-Cox, J., Coupland, C. and Brindle, P. Development and validation of QRISK3 risk prediction algorithms to estimate future risk of cardiovascular disease: prospective cohort study.<em>BMJ</em> (2017) <a href="https://www.bmj.com/content/357/bmj.j2099">doi: https://doi.org/10.1136/bmj.j2099</a>.↩︎</p></li>
<li id="fn2"><p>Flach, P. (2019). Performance evaluation in machine learning: the good, the bad, the ugly, and the way forward. <em>Proceedings of the AAAI conference on artificial intelligence</em> pp.&nbsp;9808-9814 (2019) <a href="https://ojs.aaai.org/index.php/AAAI/article/view/5055">doi: https://doi.org/10.1609/aaai.v33i01.33019808</a>.↩︎</p></li>
<li id="fn3"><p>Chang, Y. <em>et al.</em> A survey on evaluation of large language models. <em>ACM Transactions on Intelligent Systems and Technology</em> (2023) <a href="https://dl.acm.org/doi/10.1145/3641289">doi: https://doi.org/10.1145/3641289</a>.↩︎</p></li>
<li id="fn4"><p>Witten, I. H., Frank, E. and Hall, M. A. Data mining: Practical machine learning tools and techniques. Morgan Kaufmann (2011).↩︎</p></li>
<li id="fn5"><p>Bayram, F., Ahmed, B. S. and Kassler A. From concept drift to model degradation: An overview on performance-aware drift detectors. <em>Knowledge-Based Systems</em> (2022) <a href="https://www.sciencedirect.com/science/article/pii/S0950705122002854">doi: https://doi.org/10.1016/j.knosys.2022.108632</a>.↩︎</p></li>
<li id="fn6"><p>Rotalinti, Y., Tucker, A., Lonergan, M., Myles, P. and Branson, R. Detecting drift in healthcare AI models based on data availability. <em>Joint European Conference on Machine Learning and Knowledge Discovery in Databases</em> 243-258 (2022) Springer Nature Switzerland. <a href="https://link.springer.com/chapter/10.1007/978-3-031-23633-4_17">doi: https://doi.org/10.1007/978-3-031-23633-4_17</a>↩︎</p></li>
<li id="fn7"><p>Davis, S. E., Greevy Jr, R. A., Lasko, T. A., Walsh, C. G. and Matheny, M. E. Detection of calibration drift in clinical prediction models to inform model updating. <em>Journal of biomedical informatics</em> (2020) <a href="https://www.sciencedirect.com/science/article/pii/S1532046420302392">doi: https://doi.org/10.1016/j.jbi.2020.103611</a>.↩︎</p></li>
</ol>
</section></div> ]]></description>
  <category>AI</category>
  <category>Machine Learning</category>
  <category>Large Language Models</category>
  <guid>https://realworlddatascience.net/foundation-frontiers/posts/2024/05/21/ai-series-4.html</guid>
  <pubDate>Tue, 21 May 2024 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/foundation-frontiers/posts/2024/05/21/images/Evaluation_thumbnail.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>AI series: On AI ethics - influencing its use in the delivery of public good</title>
  <dc:creator>Olivia Varley-Winter</dc:creator>
  <link>https://realworlddatascience.net/foundation-frontiers/posts/2024/05/14/ai-series-2.html</link>
  <description><![CDATA[ 





<!-- article text to go here -->
<p>Criminal <a href="https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing">sentencing biased by race</a> in the US, <a href="https://www.theguardian.com/education/2021/feb/18/the-student-and-the-algorithm-how-the-exam-results-fiasco-threatened-one-pupils-future">students systematically downgraded</a> in UK public examinations with no process for appeal, and <a href="https://orientblackswan.com/details?id=9789352875429#:~:text=Dissent%20on%20Aadhaar%20argues%20that,surveillance%20and%20commercial%20data%2Dmining">decisions to rescind food welfare</a> in India riddled with errors and discrepancies are all instances where AI algorithms have hit the headlines. When Bill Gates wrote that the age of <a href="https://www.linkedin.com/pulse/age-ai-has-begun-bill-gates/">AI has begun</a> and “will change the way people work, learn, travel, get health care, and communicate with each other,” those probably weren’t the changes he had in mind. Nor need they be an inevitable side effect of living with AI.</p>
<p>A number of points require consideration to work safely with AI, from the potential for bias in input and training data, and consent over data use, to the transparency and fairness of applying an algorithm – who has decided the problem, or set of problems, it is to solve? The steps that are taken to explain and involve an organisation’s stakeholders in the conclusions that AI reaches also require ethical consideration, as does ethical development of AI. Its use for social policies and services highlights an additional set of problems.</p>
<p>As AI becomes more active in society, AI ethics involves not only defining the objectives for data scientists, researchers and technologists to work on. It involves governing bodies, regulators, policy makers, businesses and organisations, the media, and civil society, working to handle and communicate AI’s benefits and mitigate its harms. Organisations with international clout – such as the United Nations Educational, Scientific and Cultural Organization (<a href="https://www.unesco.org/en/artificial-intelligence/recommendation-ethics">UNESCO</a>) and the Organisation for Economic Co-operation and Development (<a href="https://www.oecd.org/gov/ethics/ethicscodesandcodesofconductinoecdcountries.htm">OECD</a>) – have prominently set out ethical principles that can broadly apply. Nonetheless, a lot can go wrong.</p>
<section id="bias-in-bias-out" class="level2">
<h2 class="anchored" data-anchor-id="bias-in-bias-out">Bias in bias out</h2>
<p>In 2016 when ProPublica launched an investigation into potential biases in a ‘risk assessment’ algorithm used by the US criminal justice system, it was the first independent investigation of its kind. This was despite the widespread use of the algorithm and its power to influence a judge’s sentence, in one instance <a href="ttps://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing">doubling the duration while increasing the severity</a> of the imprisonment. On examining 7000 risk assessment scores and the records detailing whether the subjects of those scores had reoffended in the subsequent two years, Propublica found “Only 20 percent of the people predicted to commit violent crimes actually went on to do so”. Even when the full range of crimes was taken into account “the algorithm was somewhat more accurate than a coin flip” at 61%. Part of the enthusiasm for these algorithms had been the expectation that they might bypass the prejudices and unconscious biases of human judges, enabling fairer justice. However, while many might baulk at the thought of tossing a coin to determine someone’s prison sentence, it turns out this might be a fairer approach than the algorithm, which was found to “falsely flag black defendants as future criminals” at twice the rate of white defendants.</p>
<div id="Eleanor_Roosevelt-991724" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="https://realworlddatascience.net/foundation-frontiers/posts/2024/05/14/images/Eleanor_Roosevelt-991724.jpg" class="img-fluid figure-img" alt="Eleanor Roosevelt reads the Universal Declaration of Human Rights in 1949; FDR Presidential Library &amp; Museum 64-165 CC-BY-2.0"></p>
<figcaption>Eleanor Roosevelt reads the Universal Declaration of Human Rights in 1949; FDR Presidential Library &amp; Museum 64-165 CC-BY-2.0</figcaption>
</figure>
</div>
<p>Since Propublica’s investigation there have been multiple reports highlighting problems with algorithms trained on historic data for use in the criminal justice system. The risk illustrated here, which can be generalised, is that such algorithms will tend to propagate social biases. In this case it means that those from ethnic minorities and lower socioeconomic backgrounds are awarded harsher sentences. Compounding the problem was the proprietary nature of the algorithms involved, which made it difficult to launch independent investigations. However, in the case of the algorithm investigated by Propublica, the input data, which is taken from questions put to the defendant and their prison records, did provide clues as to the scope for unfair outcomes. Although race is not explicitly identified, it likely correlates with other data that is used as input. This meant that the outcomes would be biased with respect to race all the same. A lot more work is needed to mitigate the effects of historical social injustices in how the criminal justice system uses data. Innovators in this area need to have confidence in what will be affected by their evidence base, as well as support from independent legal and ethical reviewers, and from regulators, to determine what will make a good innovation, and what will not.</p>
</section>
<section id="consent-human-rights-and-data-provenance" class="level2">
<h2 class="anchored" data-anchor-id="consent-human-rights-and-data-provenance">Consent, human rights, and data provenance</h2>
<p>The testing and training of AI algorithms can also run into other ethical questions about the ratio of public to private benefits from data and who governs those benefits. On the eve of the UK’s AI Summit in 2023, <a href="https://www.linkedin.com/pulse/ai-beneath-surface-pivotal-role-data-smart-data-research-uk-betwe/">Joe Cuddeford of Smart Data Research UK wrote</a>: “Many AI systems rely on data collected passively from individuals, raising questions about transparency, privacy, and who benefits from these data-driven advancements.”</p>
<p>Large scale AI models, such as generative AI models, are <a href="https://www.washingtonpost.com/technology/2023/10/25/data-provenance/">often trained on web-scraped data</a> from online platforms. This leads to questions about the fairness of internet data, the ownership of it (e.g.&nbsp;<a href="https://www.nytimes.com/2024/04/06/technology/tech-giants-harvest-data-artificial-intelligence.html">potential violation of copyright law</a>), and methods for users’ consent and human rights to be embedded and respected. There are, once again, questions about accuracy and bias: what do algorithms “learn” from data scraped from the internet, and is the information appropriately curated for use?</p>
<p>Civil liberties concerns also similarly arise when people are compelled to give up data about themselves by powerful arms of the state. For example, the national Facial Verification Testing program run by the National Institute of Standards and Technology, a part of the U.S. Department of Commerce, has held and <a href="https://slate.com/technology/2019/03/facial-recognition-nist-verification-testing-data-sets-children-immigrants-consent.html">made use of images of vulnerable individuals</a> to test and validate the performance of commercialised AI technologies. The data used by the agency for testing include ‘mugshots’ or facial images from arrests or from other encounters with law enforcement. <sup>1</sup> An additional programme focuses on testing the performance of facial recognition algorithms against an image database of sexually exploited children (<a href="https://www.nist.gov/programs-projects/chexia-face-recognition">CHEXIA-FACE</a>). Having statistics from this kind of agency testing has clear commercial benefit: it helped win the case for the vendors who could match those statistics when the <a href="https://www.met.police.uk/SysSiteAssets/media/downloads/force-content/met/advice/lfr/other-lfr-documents/lfr-accuracy-and-demographic-differential.pdf">London Metropolitan police purchased live facial recognition technology</a>. However, the interests of the people that have been documented do not come up for discussion in this form of data governance. There are many participatory methods that could be used for more ethical stewardship of the data that people are compelled to give. <sup>2</sup></p>
<p>To address the scope for minorities and vulnerable groups to play their part in data collection, it should be possible for data scientists to adopt strategies that consciously address the bias in data collection. Eun Seo Jo (from Stanford University) and Timnit Gebru (formerly at Google) have suggested library and archival approaches. In Strategies for Collecting Sociocultural Data in Machine Learning, <sup>3</sup> they note that internet data is subject to historical and representative biases. Recognising and mitigating biases will “start with a statement of commitment to collecting the cultural remains of certain concepts, topics, or demographic groups.” A public mission statement, which highlights the interests of communities and minorities they plan to support, “forces [archival] researchers to reckon with their data composition.”</p>
<p>These strategies also need to be supported by good management of data collection and curation. A report by the Royal Academy of Engineering (2021) <a href="https://reports.raeng.org.uk/datasharing/implications-for-policy">Towards trusted data sharing: implications for policy and practice</a> has highlighted that, to support the use of data for research, good data management must exist among the data owners. Strong relationships with data owners predicated on data quality and ethics will help researchers to specify what data sets they are looking for and how they can best be curated for AI purposes. Good data management will not only help AI developers but also all potential users (as well as the public) to understand the scope and the quality of what’s being shared. “Defining the requirements for data quality, and ensuring these requirements are delivered, remains a central challenge.” (<a href="https://reports.raeng.org.uk/datasharing/implications-for-policy">RAE report</a>)</p>
<p>Advocates for accurate and fair data and machine learning have worked hard to clarify what good data management and sharing looks like, which is cause for optimism. However there is the sense that this is the area in which AI has the furthest to go, as data sets currently available fall far wide from the standards recommended by their work. Nonetheless the rise of Trusted Research Environments, Data Safe Havens and other methods of open-source transparency enable more AI innovators to disclose their sources without placing any of the personal information they use at further risk, as <a href="https://realworlddatascience.net/foundation-frontiers/posts/2024/05/07/ai-series-3.html">discussed previously in the AI series</a>. Leadership on ethical standards for data sharing may yet help to improve the <a href="https://oecd.ai/en/dashboards/ai-principles/P8">robustness, security, safety, and fairness of AI tools</a>, which the OECD advocates as key principles for AI.</p>
</section>
<section id="openness-explainability-and-the-scope-to-challenge-ai-decisions" class="level2">
<h2 class="anchored" data-anchor-id="openness-explainability-and-the-scope-to-challenge-ai-decisions">Openness, explainability, and the scope to challenge AI decisions</h2>
<p>A principle that many data science communities have been working on, is towards ensuring transparency and explainability of AI (<a href="https://oecd.ai/en/dashboards/ai-principles/P7">OECD AI Principle</a>). In OECD parlance that is in part “to ensure that people understand when they are engaging with [artificial intelligence] and can challenge outcomes.” In acknowledgement that some AI applications make this disclosure harder and more unappealing, the OECD suggests that the fact that AI is in use should be disclosed “with proportion to the importance of the outcome … so that consumers, for example, can make more informed choices”. The OECD emphasises the importance of the “explainability” of the algorithms, which it defines as “enabling people affected by the outcome of an AI system to understand how it was arrived at. … notably – to the extent practicable – the factors and logic that led to an outcome.”</p>
<p>The <a href="https://www.oii.ox.ac.uk/research/projects/a-fairwork-foundation-towards-fair-work-in-the-platform-economy/">tens of millions of digital ‘platform workers’</a> that now live all over the world are a case in point for where explainability is needed. They perform short-term, freelance, or temporary work through digital platforms or apps in the “gig economy”. There is little transparency about how algorithms and AI influence outcomes for gig workers, and whether platform algorithms are contributing systematically to unfair outcomes. <a href="https://www.oii.ox.ac.uk/research/projects/a-fairwork-foundation-towards-fair-work-in-the-platform-economy/">Platform workers themselves have come together</a> to share their data to understand more about the outcomes of the algorithms, or AI, which is shaping their lives.</p>
<p>It follows that where the use of an AI system does not affect outcomes for people, there may be less of a demand to publicly justify how AI arrived at its outcomes. For example, where AI is used to simulate something, or to research a decision, rather than to make a decision, there could be less weight placed on explaining the model publicly.</p>
<div id="Aerial_view_of_Silion_Valley991" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="https://realworlddatascience.net/foundation-frontiers/posts/2024/05/14/images/Aerial_view_of_Silicon_Valley991.jpg" class="img-fluid figure-img" alt="Aerial view of tech cluster in Silicon Valley, taken on 29 March 2013, courtesy of Patrick Nouhaillier CC-BY-3.0"></p>
<figcaption>Aerial view of tech cluster in Silicon Valley, taken on 29 March 2013, courtesy of <a href="Patrick Nouhaillier">https://www.flickr.com/photos/patrick_nouhailler/</a> CC-BY-3.0</figcaption>
</figure>
</div>
<p>François Candelon, Theodoros Evgeniou, and David Martens, writing for the Harvard Business Review have outlined that their preference is for <a href="https://hbr.org/2023/05/ai-can-be-both-accurate-and-transparent">accuracy as well as explainability</a>. Often, to strike this balance, they will prefer ‘white box’ models which are transparent and interpretable. But not always. “In [complex] applications such as face-detection for cameras, vision systems in autonomous vehicles, facial recognition, image-based medical diagnostic devices, illegal/toxic content detection, and most recently, generative AI tools like ChatGPT and DALL-E, a black box approach may be advantageous or even the only feasible option.”</p>
<p>Even where the algorithm is too large and complicated to be interpretable, work like that conducted by the Alan Turing Institute in <a href="https://www.turing.ac.uk/research/research-projects/project-explain">Project ExplAIn</a> finds ways of extracting some kind of explanation, for instance by embedding layers in the coding. The case for opening up AI in this way has to be balanced against concerns for intellectual property, information security and privacy. There can be <a href="https://www.tripwire.com/state-of-security/ai-transparency-why-explainable-ai-essential-modern-cybersecurity">cybersecurity issues</a> with making the different layers of an AI model more open to interrogation. Nonetheless, experiments with transparent and explainable models enable developers to advance their understanding of AI, as well as to consider whether its use for decision-making is ethically sound. The OECD principles make clear that it is important that AI doesn’t elude human insight, checks and balances. As Andrew Ng highlighted in the <a href="https://youtu.be/nIIPMmZaK-s?si=T6ahpP6R1QjuUIsq">RSS fireside chat in 2021</a>: “AI is increasing concentration of power like never before…governments and regulators need to look at that and think of what to do.”</p>
</section>
<section id="appropriate-human-centred-governance" class="level2">
<h2 class="anchored" data-anchor-id="appropriate-human-centred-governance">Appropriate, human-centred governance</h2>
<p>When school exams in England were cancelled during the Covid-19 pandemic, the government’s Department for Education decided that an algorithm should be used to allot grades to A-Level students, partly as a measure to counter grade inflation (a trend in which the grades awarded for the same standard of work will tend to rise, year on year). Algorithms had been used before in previous years to adjust the marks that were awarded for exams and coursework. Here instead of exams and coursework, the input data was gathered from Ofqual’s historical records about how particular schools’ pupils had performed in previous years, and some was generated by teachers. Efforts had been made at transparency in terms of how the new algorithm would arrive at these decisions (it was a relatively simple, white box algorithm). But there were ‘outliers’ acknowledged in the model even prior to deployment. Coupled with the widespread downgrading of teacher-estimated grades to fit a curve that would avoid grade inflation, there was not a clear process by which students and schools could appeal to change their grades. <a href="https://www.theguardian.com/education/2021/feb/18/the-student-and-the-algorithm-how-the-exam-results-fiasco-threatened-one-pupils-future">Dissatisfaction with the grades awarded</a> in the absence of exams or coursework was rife, as young people regarded as academically talented by their schools fell short of the grades their teachers had predicted, and lost university places.</p>
<p>In the resulting furore, the Department for Education determined that its original policy was wrong and adopted the teacher estimated grades with an appeal process in place. The incident demonstrates that achieving the functional transparency of an algorithm is only one step in due process. Controversial policies could be using an algorithm to apportion losses across the population (e.g.&nbsp;to try to reduce grade inflation) in ways that are abhorred by individuals.</p>
<p>Vested interests also surfaced during investigation of an algorithm brought into use to <a href="https://orientblackswan.com/details?id=9789352875429#:~:text=Dissent%20on%20Aadhaar%20argues%20that,surveillance%20and%20commercial%20data%2Dmining.">tackle fraud in India’s welfare system</a>. “From 2014 to 2019, the government of Telangana “<a href="https://www.aljazeera.com/economy/2024/1/24/how-an-algorithm-denied-food-to-thousands-of-poor-in-indias-telangana">cancelled more than 1.86 million existing food security cards</a> and rejected 142,086 fresh applications without any notice.” reported Al Jazeera in January of this year. Despite the government’s initial claims that the cancelled food security cards were fraudulent, critical data scholarship in India and elsewhere has established discrepancies and errors in the algorithms used, such as, confusing the records of a valid claimant with a car-owning citizen by the same name. (Under the government’s policies, SUV owners cannot receive food aid.) Further investigations revealed that at least 7.5 per cent of the food security cards were wrongly cancelled. The investigations highlight what can be a common problem: a focus on reducing the costs of welfare programmes tends to lead services to identify false positives - wrongful claimants – rather than false negatives. Thus efforts to correct sloppy data may meet resistance if this leads to fewer “frauds” being identified, even when citizens bring evidence to challenge it.</p>
<p>There is a similar type of example in the <a href="https://www.computerweekly.com/feature/Post-Office-Horizon-scandal-explained-everything-you-need-to-know">UK’s Post Office scandal</a>, in which many sub-postmasters were wrongfully prosecuted for false accounting, after the Post Office adopted accounting software that contained significant bugs, which were covered up for many years. This similarly goes to show how far organisations can pursue wrongful judgements, and the life-changing consequences.</p>
<p>The <a href="https://digital-strategy.ec.europa.eu/en/policies/regulatory-framework-ai">EU’s new AI Act</a> advocates a risk-based approach, to balance the desire to minimise the burden of compliance while ensuring the safety of people who may be affected by the implementation of AI algorithms. Systems assessed as <a href="https://digital-strategy.ec.europa.eu/en/policies/regulatory-framework-ai">high risk according to specific criteria</a> are then “subject to strict obligations before they can be put on the market”.</p>
<p>Governments across the industrialised world have raised their hopes for AI that will help to drive increases in productivity, and do so safely in ways that are fairly constructed, making use of legitimate data sources, and with fair outcomes for society. The work of data scientists is integral to the foundations by which AI can be used for social good, from establishing protocols for data management and sharing, to understanding the workings of complex algorithms, and the use of large and unstructured data sources. Data scientists and researchers are getting closer to understanding what good looks like, not just in terms of the ethical values to uphold but the technicalities of the code and data involved. However, a great deal of not only data work but also other work also needs to be maintained to uphold the ideal of ‘AI ethics’. Support for well-established ethical and legal rights and principles, to meaningfully involve people in policies that will be affected by AI use, and to develop data governance and infrastructure. It is always possible that when we’re working on AI ethics, we find that there are fairer and more ethical approaches that should precede the use of AI.</p>
<p>“AI development raises a range of ethical questions for data practitioners, whether they are data scientists, econometricians, analysts, or statisticians,” Daniel Gibbons, Vice Chair of the Royal Statistical Society’s Data Ethics and Governance Section told <em>Real World Data Science</em>. Today, many data scientists would urge that ethical considerations precede the development of an AI algorithm and must inform its design and use, particularly for processes that significantly affect people, to ensure it does not propagate errors and injustices.</p>
<div class="article-btn">
<p><a href="../../../../../foundation-frontiers/index.html">Explore more data science ideas</a></p>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-12">
<dl>
<dt>About the author</dt>
<dd>
<strong>Olivia Varley-Winter</strong> Olivia is an experienced policy manager who has worked for the Royal Statistical Society, the Open Data Institute, Open Data Charter, the Nuffield Foundation, and the Alan Turing Institute. She was part of the Ada Lovelace Institute’s founding team in 2018 to 2020 and has since supported the development of other policy-related programmes and partnerships relating to data, AI and ethics. She is presently working for Smart Data Research UK on matters pertaining to ethics and responsible data governance. She has an MSc. in Nature, Society, and Environmental Policy from University of Oxford.
</dd>
</dl>
</div>
<div class="g-col-12 g-col-md-6">
<!-- copyright goes to the author, or to Royal Statistical Society if written by staff -->
<dl>
<dt>Copyright and licence</dt>
<dd>
© 2024 Royal Statistical Society
</dd>
</dl>
<!-- confirm licence terms with contributor before publishing - must be Creative Commons licence, but different types of CC licences might be preferred -->
<p><a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> <img src="https://mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1" style="height:22px!important;vertical-align:text-bottom;"><img src="https://mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1" style="height:22px!important;margin-left:3px;vertical-align:text-bottom;"></a> This article is licensed under a Creative Commons Attribution 4.0 (CC BY 4.0) <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> International licence</a>. <!-- Add thumbnail image credit and any licence terms here --></p>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>How to cite</dt>
<dd>
Varley-Winter, O., Author. 2024. “On AI ethics - influencing its use in the delivery of public good.” Real World Data Science, May 14, 2024. <a href="https://realworlddatascience.net/foundation-frontiers/posts/2024/04/22/ai-series-2.html">URL</a>
</dd>
</dl>
</div>
</div>
</div>
<!-- Make sure to update main site homepage (index.qmd) before publishing. See README for details. -->


</section>


<div id="quarto-appendix" class="default"><section id="footnotes" class="footnotes footnotes-end-of-document"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p>Grother, P., Ngan, M. &amp; Hanaoka K. Face Recognition Vendor Test (FRVT) Part 3: Demographic Effects NISTIR 8280 (2019) https://nvlpubs.nist.gov/nistpubs/ir/2019/NIST.IR.8280.pdf↩︎</p></li>
<li id="fn2"><p>Participatory data stewardship (2021) Ada Lovelace Institute https://www.adalovelaceinstitute.org/wp-content/uploads/2021/11/ADA_Participatory-Data-Stewardship.pdf ↩︎</p></li>
<li id="fn3"><p>Jo, E. S. &amp; Gebru T. Lessons from Archives: Strategies for Collecting SocioculturalData in Machine Learning Proceedings of the 2020 Conference on Fairness, Accountability, and Transparency (2020) https://dl.acm.org/doi/epdf/10.1145/3351095.3372829↩︎</p></li>
</ol>
</section></div> ]]></description>
  <category>AI</category>
  <category>AI ethics</category>
  <guid>https://realworlddatascience.net/foundation-frontiers/posts/2024/05/14/ai-series-2.html</guid>
  <pubDate>Tue, 14 May 2024 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/foundation-frontiers/posts/2024/05/14/images/Eleanor_Roosevelt-991724.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>Forecasting the Health Needs of a Changing Population</title>
  <dc:creator>Luke Shaw (BNSSG ICB), Rich Wood (BNSSG ICB, University of Bath), Christos Vasilakis (University of Bath), Zehra Onen Dumlu (University of Bath)</dc:creator>
  <link>https://realworlddatascience.net/applied-insights/case-studies/posts/2024/05/08/dpm.html</link>
  <description><![CDATA[ 
<div class="page-columns page-rows-contents page-layout-article"><div class="social-share"><a href="https://twitter.com/share?url=https://realworlddatascience.net/applied-insights/case-studies/posts/2024/05/08/dpm.html&amp;text=Forecasting the Health Needs of a Changing Population" target="_blank" class="twitter"><i class="fab fa-x-twitter fa-fw fa-lg"></i></a><a href="https://www.linkedin.com/shareArticle?url=https://realworlddatascience.net/applied-insights/case-studies/posts/2024/05/08/dpm.html&amp;title=Forecasting the Health Needs of a Changing Population" target="_blank" class="linkedin"><i class="fa-brands fa-linkedin-in fa-fw fa-lg"></i></a>  <a href="mailto:?subject=Forecasting the Health Needs of a Changing Population&amp;body=Check out this link:https://realworlddatascience.net/applied-insights/case-studies/posts/2024/05/08/dpm.html" target="_blank" class="email"><i class="fa-solid fa-envelope fa-fw fa-lg"></i></a><a href="https://bsky.app/intent/compose?text=https://realworlddatascience.net/applied-insights/case-studies/posts/2024/05/08/dpm.html Forecasting the Health Needs of a Changing Population" target="_blank" class="bsky"><i class="fa-brands fa-bluesky"></i></a></div></div>





<section id="background" class="level2">
<h2 class="anchored" data-anchor-id="background">Background</h2>
<p>Decisions around medium and long-term allocation of healthcare resources are fraught with challenges and uncertainties, which explains the use of blunt resource allocations based on across-the-board annual percentage uplifts.</p>
<p>The Bristol, North Somerset, South Gloucestershire Integrated Care Board (BNSSG ICB - we love elaborate acronyms in the National Health Service!), in the south west of England, is part of the local NHS apparatus responsible for planning the current and future health needs of the one million resident population.</p>
<div id="fig-bnssg-map" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-bnssg-map-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="tv-iframe-container">
  <iframe class="responsive-iframe" src="images/bnssg-map.html" title="fig-bnssg-map" width="80%" height="500"></iframe>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-bnssg-map-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;1: A map of the area covered by BNSSG, a space covered by three local authorities, with about 1 million people living inside it.
</figcaption>
</figure>
</div>
</section>
<section id="population-segmentation" class="level2">
<h2 class="anchored" data-anchor-id="population-segmentation">Population Segmentation</h2>
<p>Before tackling the complex problem of forecasting healthcare resources into the future, we first need to understand the current situation regarding the distribution of health needs.</p>
<p>While every individual has a unique set of circumstances, population segmentation is an approach used to help understand overall need by combining individuals into different groups, based on certain criteria.</p>
<p>We use the <a href="https://pubmed.ncbi.nlm.nih.gov/32015079/">Cambridge Multimorbidity Score</a> which is a metric designed to summarise the presence of multiple health conditions, known as multimorbidity. Using that score, which applies different weights to different health conditions, we <a href="https://www.tandfonline.com/doi/full/10.1080/20479700.2023.2232980">previously</a> found a way of splitting the adult (17+) population into five Core Segments, with <span style="color:#77A033;"><strong>Core Segment 1</strong></span> patients having the lowest score and being the least ill and <span style="color:#FF6C53;"><strong>Core Segment 5</strong></span> being those with the most multimorbidity.</p>
<p>Applied to the BNSSG adult population (of around 750K individuals), the following interesting properties were found:</p>
<ol type="1">
<li><strong>Halving</strong>: Going up one segment results in roughly half the number of people in that segment</li>
<li><strong>Doubling</strong>: Going up one segment results in roughly twice the NHS monetary spend per person per year</li>
</ol>
<p>We can see this in Figure&nbsp;2.</p>
<div id="fig-halving-doubling" class="quarto-float quarto-figure quarto-figure-center anchored" alt="Table showing the 5 Core Segments with CS1 having a Cambridge Score of <0.09, 52% of the population and £300 mean annual spend per person as the first row. This then changes by row through to CS1 having a Cambridge Score of >2.94 with 3% of the population and £5600 mean annual spend per person as the last row. The propoportion of population column roughly halved row-by-row, the mean annual spend per person roughly doubled row by row.">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-halving-doubling-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="https://realworlddatascience.net/applied-insights/case-studies/posts/2024/05/08/images/halving-doubling-no-arrows.png" class="img-fluid figure-img" alt="Table showing the 5 Core Segments with CS1 having a Cambridge Score of <0.09, 52% of the population and £300 mean annual spend per person as the first row. This then changes by row through to CS1 having a Cambridge Score of >2.94 with 3% of the population and £5600 mean annual spend per person as the last row. The propoportion of population column roughly halved row-by-row, the mean annual spend per person roughly doubled row by row.">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-halving-doubling-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2: Halving-Doubling Effect of the Core Segments
</figcaption>
</figure>
</div>
</section>
<section id="sec-creating-the-model" class="level2">
<h2 class="anchored" data-anchor-id="sec-creating-the-model">Creating The Model</h2>
<p>To forecast health needs of the population, in terms of how many people will be in which Core Segment in what future year, the Dynamic Population Model (DPM) takes information from two different sources:</p>
<ol type="1">
<li><p>The Office for National Statistics <a href="https://www.ons.gov.uk/peoplepopulationandcommunity/populationandmigration/populationprojections/datasets/localauthoritiesinenglandtable2">projections</a> for our area. From this, we get yearly projections for not just the total 17+ population, but also the predicted number of people turning 17 (and so entering our model), deaths, and in- and out-ward migration.</p></li>
<li><p>NHS patient attribute and activity data, stored in the <a href="https://bnssghealthiertogether.org.uk/population-health-management/">System Wide Dataset</a> (SWD). This gives us: past and current information on the adult population’s NHS healthcare usage; the Core Segment breakdown of our current and past populations; the proportion of those turning 17, migrating, and dying that are in each Core Segment. From this, we estimate the historical rates of transition within Core Segments, which is essentially the yearly number of people getting sicker or healthier.</p></li>
</ol>
<p>By synthesising these pieces of data, we create our DPM forecast. Starting from the most up to date Core Segment population breakdown, the model takes yearly time steps into the future, at each time step using the inputs to estimate how many people are to be in each Core Segment. This modelling approach of having discrete time steps and different movements between states can be set up as a Markov chain, although here we have formulated it as a set of difference equations - through which the outflow of each Core Segment population at each time step is deterministic. The design was led by <a href="https://researchportal.bath.ac.uk/en/persons/zehra-onen-dumlu">Zehra</a> and <a href="https://researchportal.bath.ac.uk/en/persons/christos-vasilakis">Christos</a>, through a collaboration between the NHS and the <a href="https://www.bath.ac.uk/research-centres/centre-for-healthcare-innovation-and-improvement-chi2/">Centre for Healthcare Innovation and Improvement (CHI2)</a> at the University of Bath.</p>
<p>The model can be thought of as having the following inputs:</p>
<table class="caption-top table">
<colgroup>
<col style="width: 31%">
<col style="width: 59%">
<col style="width: 8%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">Model Input</th>
<th style="text-align: left;">Description</th>
<th style="text-align: left;">Data Source</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">initial population</td>
<td style="text-align: left;">The starting number of people in each Core Segment</td>
<td style="text-align: left;">SWD</td>
</tr>
<tr class="even">
<td style="text-align: left;">inner transition matrix</td>
<td style="text-align: left;">The yearly proportions of people moving from one Core Segment to another</td>
<td style="text-align: left;">SWD</td>
</tr>
<tr class="odd">
<td style="text-align: left;">births, net migration, deaths - numbers</td>
<td style="text-align: left;">The yearly number of people moving in and out of the area</td>
<td style="text-align: left;">ONS</td>
</tr>
<tr class="even">
<td style="text-align: left;">births, net migration, deaths - proportions</td>
<td style="text-align: left;">The proportion of births/migrations/deaths that come from each Core Segment group</td>
<td style="text-align: left;">SWD</td>
</tr>
</tbody>
</table>
<p>From these inputs, it deterministically outputs the yearly forecasts for the number of people in each Core Segment. From these yearly Core Segment population figures, we can also forecast use by point of delivery by taking historic SWD information on the activity used by current Core Segment breakdown, under the assumption that stays the same into the future.</p>
<p>We combine these population health segment projections – i.e., how many people will be in which Core Segment in what future year – with recent NHS healthcare usage data to yield forecasted changes for various delivery points, like Emergency Department (ED) visits or maternity service appointments.</p>
</section>
<section id="findings" class="level2">
<h2 class="anchored" data-anchor-id="findings">Findings</h2>
<p>The first output of the model is the population forecast for each Core Segment, as plotted in Figure&nbsp;3. The visualisation is a type of sankey diagram called an alluvial plot, which shows the proportion of people moving between the Core Segments each year. As it is to be expected, the majority of individuals stay in the same Core Segment year-on-year as the process of acquiring conditions and developing multimorbidity takes places over many years and decades.</p>
<p>The concerning insight shown in Figure&nbsp;3 is that all Core Segments apart from (the most healthy) <span style="color:#77A033;"><strong>Core Segment 1</strong></span> are due to increase in size, with <span style="color:#FF6C53;"><strong>Core Segment 5</strong></span> having the largest percentage increase over the next 20 years. While, at first glance, this could be attributed to the effect an ageing population, in which people are staying alive for longer we will see in the next set of results that this itself does not wholly explain the forecasted Core Segment changes.</p>
<div id="fig-sankey" class="quarto-float quarto-figure quarto-figure-center anchored" alt="over 20 years when scaled to 1000 population initially we have that population changes in the following ways: CS1 decreases from 520 to 490, CS2 increases from 240 to 310, CS3 increased from 130 to 180, CS4 increases from 70 to 110, CS5 increases from 40 to 60.">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-sankey-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="https://realworlddatascience.net/applied-insights/case-studies/posts/2024/05/08/images/dpm-sankey-no-title.png" class="img-fluid figure-img" alt="over 20 years when scaled to 1000 population initially we have that population changes in the following ways: CS1 decreases from 520 to 490, CS2 increases from 240 to 310, CS3 increased from 130 to 180, CS4 increases from 70 to 110, CS5 increases from 40 to 60.">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-sankey-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;3: All Core Segments, except the most healthy (CS1), are forecast to increase in size. BNSSG Population rescaled to have an initial population of 1,000.
</figcaption>
</figure>
</div>
<p>In applying the typical NHS healthcare usage per Core Segment to the projections of Figure&nbsp;3, we derive the expected future healthcare usage for various healthcare settings (Figure&nbsp;4). In overlaying to these the equivalent projections due solely to demographic factors (both for total population size and capturing the effect of Age and Sex), we see that the DPM projections for increased resource use are not solely attributable to an ageing and growing population, but also to a population becoming gradually less healthy over time.</p>
<p>Specifically, from Figure&nbsp;4 we can glean the following insights:</p>
<ol type="a">
<li><p>In all areas except Maternity, the DPM forecasts an increased use beyond just the growing, aging population. The reason that Maternity can be explained as the exception is due to it closely following the demographic changes forecast, specifically for numbers of women of child bearing age.</p></li>
<li><p>For Community contacts, with the highest proportion of use from <span style="color:#FF6C53;"><strong>Core Segment 5</strong></span> patients, the DPM forecasts the highest increase into the future. This is because, relative to current size, the number of <span style="color:#FF6C53;"><strong>Core Segment 5</strong></span> patients is set to increase the largest and so that has the largest impact on Community contacts, which include home visits to patients to support rehabilitation and services to manage long-term mobility issues such as physiotherapy.</p></li>
<li><p>Whilst Secondary Elective and Non-Elective activity is forecast to grow at similar rates, the Carbon and Cost values are forecast to grow more for Secondary Non-Elective due to the average Carbon and Cost usage per person in Core Segment 5 being higher. In this context ‘Secondary’ is a hospital stay, with ‘Elective’ being planned and ‘Non-Elective’ being unplanned. For example, a hip replacement is elective whereas an admission following a road traffic accident is non-elective.</p></li>
</ol>
<div id="fig-pod-forecasts" class="quarto-float quarto-figure quarto-figure-center anchored" alt="the image shows 15 separate graphs, with the columns being Community, Maternity, Secondary Elective, Secondary Non-Elective and Total, and the rows being Activity, Carbon, and Cost. All graphs have similar overall shape of increase into the future, but with different gradients.">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-pod-forecasts-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="https://realworlddatascience.net/applied-insights/case-studies/posts/2024/05/08/images/dpm-pod-forecasts.png" class="img-fluid figure-img" alt="the image shows 15 separate graphs, with the columns being Community, Maternity, Secondary Elective, Secondary Non-Elective and Total, and the rows being Activity, Carbon, and Cost. All graphs have similar overall shape of increase into the future, but with different gradients.">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-pod-forecasts-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4: Forecasts by activity, carbon, and cost for four different points of delivery.
</figcaption>
</figure>
</div>
</section>
<section id="limitations" class="level2">
<h2 class="anchored" data-anchor-id="limitations">Limitations</h2>
<blockquote class="blockquote">
<p>It’s difficult to make predictions, especially about the future.</p>
<p>– <cite>Danish Proverb</cite></p>
</blockquote>
<p>As with any modelling / forecasting method, there are limitations to be mindful of.</p>
<ol type="1">
<li><p>The cost and activity usage estimates are made under the assumption that we will continue to deliver services as they are currently being delivered. We know this isn’t going to be true, as healthcare-seeking behaviour evolves over time, with younger people accessing healthcare in different ways to previous generations. On top of that, healthcare advances can result in significant changes in healthcare provision, in ways unaccounted for within this model.</p></li>
<li><p>The model is tied to ONS forecasts for population change, and robust forecasting is hard. It is difficult to estimate what the population will look like in 20 years’ time, and the influence of uncertain and unknown future local development and housing plans. Having said this, population forecasts tend to be robust, one way to consider this is that everyone who will be an adult by the end of the forecast in 20 years’ time has already been born.</p></li>
<li><p>The DPM does not explicitly account for the interaction of demand and capacity: it simply predicts future healthcare resource requirement assuming that health needs of a given Core Segment patient are met in the same way they are met now. This is an essential assumption to help ensure legitimate use of the empirically derived Core Segment transition rates. However, it inevitably limits practical use, as flexing demand and capacity assumptions is of importance to planners and service managers.</p></li>
<li><p>It is not possible to validate the model on historic data, firstly because of point 3. above but also because we only have good quality SWD information for the past two years, so cannot reliably look further back into the past and create a forecast that we can check against what actually happened.</p></li>
<li><p>Whilst it is possible to use the model in other healthcare systems and geographic areas, the underlying data required to generate the Core Segments is non-trivial, so significant data pipelining may be required to get to create local model inputs, as explained above in Section&nbsp;3.</p></li>
</ol>
</section>
<section id="what-next" class="level2">
<h2 class="anchored" data-anchor-id="what-next">What Next</h2>
<p>We have already generated local use cases for the DPM in forecasting different geographical areas or specific hospital trusts. We envisage the DPM becoming a standard tool in most forward planning initiatives and will continue to refine the model as more information becomes available both for calibration and validation.</p>
<p>Outside of BNSSG, we are keen to disseminate our modelling approach to others who may be interested, as well as expanding our collaboration. There are also other innovative approaches in this space, such as the <a href="https://www.health.org.uk/publications/health-in-2040">Health in 2040</a> report by the Health Foundation which looks at England-level and uses the same ONS forecasts, but using a different ‘micro simulation’ modelling approach.</p>
<blockquote class="blockquote">
<p>If long-term forecasting in the NHS is of interest to you and your work, we’d love to chat! Please get in touch at <a href="mailto:bnssg.analytics@nhs.net">bnssg.analytics@nhs.net</a></p>
</blockquote>
</section>
<section id="summary" class="level2">
<h2 class="anchored" data-anchor-id="summary">Summary</h2>
<p>Reliably forecasting longer-term population health needs and healthcare resource requirements is essential if the NHS is to effectively plan for tomorrow’s problems today.</p>
<p>While this is undoubtedly a difficult problem – both conceptually and statistically – our modelling, undertaken through an academic-NHS collaboration, demonstrates that there are alternatives beyond the commonly-used but simplistic approaches based only on demographic factors.</p>
<div class="article-btn">
<p><a href="../../../../../../applied-insights/case-studies/index.html">Find more case studies</a></p>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-12">
<dl>
<dt>About the authors</dt>
<dd>
<strong>Luke Shaw</strong> is a Data Scientist working in the NHS.
</dd>
<dd>
<strong>Rich Wood</strong> is Head of Modelling Analytics at BNSSG ICB and Senior Visiting Research Follow at University of Bath School of Management.
</dd>
<dd>
<strong>Christos Vasilakis</strong> is Director of the Centre for Healthcare Innovation and Improvement (CHI2), and Professor at the University of Bath School of Management.
</dd>
<dd>
<strong>Zehra Onen Dumlu</strong> is a Research Associate at CHI2 and Lecturer at the University of Bath.
</dd>
</dl>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>Copyright and licence</dt>
<dd>
© 2024 Luke Shaw
</dd>
</dl>
<p><a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> <img style="height:22px!important;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"></a> This article is licensed under a Creative Commons Attribution 4.0 (CC BY 4.0) <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> International licence</a>.</p>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>How to cite</dt>
<dd>
Shaw, Luke et al 2024. “Forecasting the Health Needs of a Changing Population” Real World Data Science, May 08, 2024. <a href="https://realworlddatascience.net/applied-insights/case-studies/posts/2024/05/08/dpm.html">URL</a>
</dd>
</dl>
</div>
</div>
</div>


</section>

 ]]></description>
  <category>Health and wellbeing</category>
  <category>Forecasting</category>
  <guid>https://realworlddatascience.net/applied-insights/case-studies/posts/2024/05/08/dpm.html</guid>
  <pubDate>Wed, 08 May 2024 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/applied-insights/case-studies/posts/2024/05/08/images/doctor-patient-thumbnail.png" medium="image" type="image/png" height="105" width="144"/>
</item>
<item>
  <title>AI series: Healthy datasets for optimised AI performance</title>
  <dc:creator>Fatemeh Torabi, Lewis Hotchkiss, Emma Squires, Prof. Simon E. Thompson and Prof. Ronan A. Lyons</dc:creator>
  <link>https://realworlddatascience.net/foundation-frontiers/posts/2024/05/07/ai-series-3.html</link>
  <description><![CDATA[ 





<!-- article text to go here -->
<p>In Charles Babbage’s <a href="https://www.gutenberg.org/files/57532/57532-h/57532-h.htm">Passages from the Life of a Philosopher</a> he recalls two incidents where he is asked, “Pray, Mr.&nbsp;Babbage, if you put into the machine wrong figures, will the right answers come out?” Reflecting on these incidents he comments, “I am not able rightly to apprehend the kind of confusion of ideas that could provoke such a question.” Similarly, accurate and clean data is at the core of a functional AI model. However, ensuring accuracy of input data to avoid any “wrong figures” creeping into training datasets used to train AI models, demands meticulous attention during the stages of data wrangling, cleaning, and curation.</p>
<p>This necessity is particularly pronounced when dealing with the vast datasets used for training machine learning algorithms which are at the core of AI models. The predictive power of these models are highly dependent on the quality of the training data. <sup>1</sup> The most obvious errors which often require meticulous attention at data processing stages are duplication, missingness and data imbalance (Figure&nbsp;1). The presence of any of these errors can exert multifaceted impacts both in the training and testing stage of machine learning algorithms that are at the core of any AI models, and the challenge does not end there. The provenance, content, format and structure of the data require attention as well. Even data that is essentially correct may be “wrong” for a particular data set.</p>
<section id="obviating-the-obvious-errors" class="level2">
<h2 class="anchored" data-anchor-id="obviating-the-obvious-errors">Obviating the obvious errors</h2>
<p>Duplicated records can mask existing diversities within the data, diminishing the representativeness of important subgroups and leading to a biased training set and model outcomes. If duplication originates from data labelling issues, it can lead to fundamental challenges during the training of supervised models. <sup>2</sup> In healthcare data, this issue can arise when linking data across multiple sources where each source holds different labels for the same data. <sup>3</sup></p>
<p>Missingness directly leads to loss of information required for training the algorithms on various real-world scenarios. It is typically addressed via two primary routes: deletion of missing rows or imputation. Deleting missing rows results in a reduction of the sample size and bias. For instance, when it comes to health data, using electronic medical records from a single health provider such as general practice may give rise to a lot of missingness in other aspects of an individual’s health such as their hospital records, pathology testing data or medical imaging. On the one hand, structured missingness can serve as an informative feature to explore within the data. However in cases where missing data causes pixelation in the comprehensive health picture we are attempting to construct, it often conceals an underlying narrative. <sup>4</sup> For instance, the COVID-19 response involved many initiatives across the AI community, however, during the early stages of the pandemic partial availability of data pixelated the picture and impacted models predictive ability which resulted in a minimal improvement according to the UK’s national centre for data science and AI report. <sup>5</sup></p>
<p>Imputing missing values can preserve the whole sample. However, the introduction of noise during the imputation process may compromise the quality of fitted models, contingent upon the proportion of missing records. One way to offset this may be to use larger and larger data sets that might inevitably include a fuller training picture to the algorithm, just as adding dots to a pixelated image makes it more and more clear what is depicted.</p>
<p>It is often perceived that for certain instances, particularly in the context of deep learning models, such as neural networks, the model itself is capable of handling missing values without explicit imputation or deletion procedures. <sup>6</sup> Is this really true in a real-world scenario? Are these models advanced enough to achieve an optimised performance even when data quality is not at an optimised level? <sup>7</sup> Köse et al.&nbsp;(2020) investigated the effect of two conventional imputation approaches: Multiple imputation (MICE) <sup>8</sup> and Factor analysis of mixed data (FAMD) <sup>9</sup> on performance of deep learning models. Their study endorsed the use of such explicit imputation approaches, showing an enhancement in model performance. <sup>10</sup></p>
<p>Data imbalance issues, arise within datasets where there is a disproportionate amount of information pertaining to a specific aspect. When imbalanced data, rich in focused information, is used to train an AI model, the model becomes adept at learning about the specific aspect but may struggle to generalise its findings to diverse scenarios, thus fostering overfitting where the model achieves accurate prediction on the training data but loses accuracy for any new test dataset.</p>
<div id="fig-1" class="quarto-float quarto-figure quarto-figure-center anchored" alt="Stages involved in AI model development" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="https://realworlddatascience.net/foundation-frontiers/posts/2024/05/07/images/Stages-of-model-development-724.png" class="img-fluid quarto-figure quarto-figure-center figure-img" alt="Stages involved in AI model development">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;1: Stages involved in AI model development.
</figcaption>
</figure>
</div>
<p>Overfitting severely undermines the predictive performance of AI models on data beyond their training set, defeating the primary purpose of these models. For instance, out of all strokes that occur, approximately 85% are ischaemic, caused by blockage of blood supply to part of the brain, and 15% are haemorrhagic, caused by bleeding into the brain. Development of machine-learning and AI-based stroke predictive models are therefore being affected by this natural imbalance in the two types of stroke. <sup>11</sup> This type of imbalance also exists in population wide studies where stroke itself is only present in a minority subsection of a healthy population. <sup>12</sup></p>
<p>The circumstances of data collection can lead to bias, so care is needed at early stages to ensure that datasets are representative of the real world. These types of error can be picked up at an initial Quality Assurance (QA) stage conducted to reveal any unexpected errors in data used by AI models. QA checks often involve principle checks on presented values to ensure they are the right data type and within the expected range and have the expected temporal coverage.</p>
<p>Finally the choice of features included in a data set requires consideration since this can also have implications on an algorithm. Taking another example from the COVID-19 pandemic, a group of researchers trained an algorithm on radiological imaging of COVID-19 patients where the position of the patient during radiology was present as a feature in the dataset. However, since more severe cases were lying down and less severe cases were standing up, the existence of this feature resulted in an algorithm that predicted COVID-19 risk based on the position of the patients. Here although the data included was correct, its inclusion in the dataset proved to be “wrong”.</p>
</section>
<section id="things-get-complicated" class="level2">
<h2 class="anchored" data-anchor-id="things-get-complicated">Things get complicated</h2>
<p>When AI algorithms encounter complex, unstructured data, the task of quality assurance suddenly balloons beyond tackling the three main errors highlighted above. Such circumstances require some kind of quality enhancement procedure, where datasets in the form of images or unstructured text go through a curation process which involves enhancement of the quality and standardisation of the format to the level required for integration into AI algorithms. This process of standardization of data is paramount across various domains, especially in healthcare where complex, unstructured health data holds transformative potential for AI driven advances that revolutionise diagnosis, treatment, and prognosis of diseases. From electronic health records to magnetic resonance imaging (MRI) scans and genetic sequences, this data offers a wealth of insights for AI models to learn from. Adopting standardised formats not only facilitates seamless integration of diverse datasets but also streamlines the development and deployment of AI models. However, unlocking this potential requires a strong foundation in high-quality, processed data which begins with standardisation.</p>
<p>One category of complex health data is neuroimaging of which a prime example is MRI. Different institutions will often employ different acquisition protocols and different ways of collecting and storing neuroimaging data. Above all, this can make it very difficult to integrate into existing workflows and processing pipelines, but it also makes it challenging to understand, compare and combine with other datasets. To address these challenges, the neuroimaging community has adopted the Brain Imaging Data Structure (BIDS) <sup>13</sup> – a standardised format for organising and naming MRI data which allows compliant data to integrate smoothly with existing workflows and AI models, streamlining processing and analysis. By embracing standardisation, we can pave the way for common processing tools to enable the generation of AI-ready data.</p>
<p>Next, comes pre-processing. Sticking with the neuroimaging example, MRI scans are susceptible to various forms of noise and artifacts, which can appear as blurring or distortions which, without proper processing, can be misinterpreted by AI models. Pre-processing typically includes steps for spatial normalisation and image registration, involving alignment of brain images from different individuals into a common reference model and alignment of different images of the same subject to a common template. This standardisation facilitates inter-subject and inter-study comparisons, enabling AI models to generalise effectively across diverse datasets. However, the multi-layer aspect of this process means that aligning data to a common template is dependent on the choice of template which itself can introduce bias if the template brain doesn’t accurately reflect the patient’s anatomy (due to age, ethnicity, or disease for example).</p>
<div id="fig-2" class="quarto-float quarto-figure quarto-figure-center anchored" alt="Neuroimaging data" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="https://realworlddatascience.net/foundation-frontiers/posts/2024/05/07/images/neuroimaging.jpg" class="img-fluid quarto-figure quarto-figure-center figure-img" alt="Neuroimaging data">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2: Neuroimaging data.
</figcaption>
</figure>
</div>
<p>Once pre-processing is complete, you may want to combine datasets to increase sample sizes for your AI model. This is where harmonisation techniques <sup>14</sup> <sup>15</sup> come in to deal with inconsistencies and variations in acquisition which can add noise and bias into a model. A typical technique for harmonisation in neuroimaging, known as ComBat <sup>16</sup>, works by modelling data using a hierarchical Bayesian model and followed by empirical Bayes to infer the distribution of the unknown factors. The method is actually borrowed from genomics data but is applicable to situations where multiple features of the same type are collected for each participant, whether that be expression levels for genes, or imaging derived measures such as volumes from different regions. This is a crucial step for combining datasets to enable AI models to focus on learning the actual relationships within the data rather than struggling with inconsistencies across datasets. It also leads to models which can generalise better on unseen data.</p>
</section>
<section id="feeding-hungry-algorithms" class="level2">
<h2 class="anchored" data-anchor-id="feeding-hungry-algorithms">Feeding hungry algorithms</h2>
<p>The public good is at the heart of AI driven approaches and indeed, the aim is to develop models with optimised predictive ability that can be generalised to many scenarios. For this to be achieved a large and diverse training source is required. This is often referred to as data hungry algorithms. To provide a large amount of enriched training data for optimised model development two main approaches have been explored: federated analytics and synthetic data.</p>
<p>Federation is when data from multiple sources is made available for training and analysis of models designed to run on data that is not held in a single place, nominally called distributed models. It provides the opportunity to test algorithms in different populations/settings to ensure generalisability. In the context of patient-level health data, the data is often held institutionally. Enabling federation and trustworthy sharing of these datasets requires extensive attention to governance models and a common model between multiple organisations is a known catalyst of this process <sup>17</sup> <sup>18</sup></p>
<p>Generating synthetic data <sup>19</sup> from original data sources is a resource intensive mechanism. It requires the development of models on the real data to learn existing patterns, formats, and statistical properties within the original data from which it is possible to generate further synthetic versions of these data. When working with sensitive data such as health records, ensuring patient data is safe and secure is covered by information governance. Depending on how close the synthetic data source is to the original data, the same governance level may still be applicable when trying to bring individual/patient data from multiple sources together. A suggested solution to overcome the governance challenges in the context of synthetic data is to use a <a href="https://www.adruk.org/news-publications/news-blogs/accelerating-public-policy-research-with-easier-safer-synthetic-data/">low-fidelity version</a> of the original data which means a level of bias has been added throughout the synthesisation process to ensure safety and security of individual level data. <sup>20</sup> While the low fidelity data sources are generated based on real data, it is worth noting that the rise in generative AI also poses a concern for data pollution, particularly where AI tools such as Gretel.ai <sup>21</sup> are used to generate synthetic data which may also be used to train AI models – the problematic case of AI training AI!</p>
<p>When using sensitive health data of patients a further layer is in place to ensure security of access. These are called Trusted Research Environments (<a href="https://www.hdruk.ac.uk/access-to-health-data/trusted-research-environments/">TREs</a>), secure technology infrastructures which play a crucial role in consolidating disparate data collections into a centralised repository, facilitating researcher access to data for scientific exploration. However, integrating data from various sources into AI models poses challenges due to differences in data collection methods and formats, hindering computational analysis. In response, the FAIR (Findable, Accessible, Interoperable, Reusable) data principles were introduced in 2016 to enhance the reusability of scientific datasets by humans and machines. <sup>22</sup> Adoption of FAIR principles within TREs ensures well-documented, curated, and harmonised datasets, addressing issues raised above such as duplicated records and missing data. <sup>23</sup> Additionally, preprocessing pipelines within TREs streamline data standardisation, creating “AI research-ready” datasets. <sup>24</sup></p>
<p>Access to real-world healthcare data remains challenging, prompting the development of AI models on open-source or synthetic datasets. However, these models often exhibit performance discrepancies when applied to real world data <sup>25</sup> It is therefore imperative to provide researchers with secure access to real-world healthcare data within TREs, bolstered by robust governance and support mechanisms. Initiatives like the GRAIMATTER study <sup>26</sup> and AI risk evaluation workshops <sup>27</sup> exemplify efforts to facilitate AI model development and translation from TREs to clinical settings. By establishing governance guidelines and promoting FAIR datasets, TREs aim to become important resources for the AI research community. Providing standardised and curated data rich repositories that AI models can be developed on is a top priority in UK-TREs. Given the well-defined and secure governance environments of TREs they may also provide the basis for federated data analysis allowing researchers to combine datasets across TREs/data environments. In this way they can provide the large numbers that data hungry algorithms require, while avoiding the wide-ranging and myriad ways that data for a specific dataset can be “wrong”.</p>
</section>
<section id="also-in-the-ai-series" class="level2">
<h2 class="anchored" data-anchor-id="also-in-the-ai-series">Also in the AI series:</h2>
<p><a href="https://realworlddatascience.net/foundation-frontiers/posts/2024/04/22/ai-series-1.html">What is AI? Shedding light on the method and madness in these algorithms</a> <a href="https://realworlddatascience.net/foundation-frontiers/posts/2024/04/29/gen-ai-human-intel.html">Generative AI models and the quest for human-level artificial intelligence</a></p>
<div class="article-btn">
<p><a href="../../../../../foundation-frontiers/index.html">Explore more data science ideas</a></p>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-12">
<dl>
<dt>About the authors</dt>
<dd>
<strong>Fatemeh Torabi</strong> is Senior Research Officer and Data Scientist, at Swansea University and works on Health Data Science and Population Data Science for the Dementias Platform UK.
</dd>
<dd>
<p><strong>Lewis Hotchkiss</strong> is a Research Officer in Neuroimaging at Swansea University and works on Population Data Science for the Dementias Platform UK.</p>
</dd>
<dd>
<p><strong>Emma Squires</strong> is the Data Project Manager for Dementias Platform UK based at Swansea University and works on Population Data Science</p>
</dd>
<dd>
<p><strong>Prof.&nbsp;Simon E. Thompson</strong> is Deputy Associate Director of the Dementias Platform UK</p>
</dd>
<dd>
<p><strong>Prof.&nbsp;Ronan A. Lyons</strong> is the Associate Director of the Dementias Platform UK based at Swansea University and works on Population Data Science.</p>
</dd>
</dl>
</div>
<div class="g-col-12 g-col-md-6">
<!-- copyright goes to the author, or to Royal Statistical Society if written by staff -->
<dl>
<dt>Copyright and licence</dt>
<dd>
© 2024 Royal Statistical Society
</dd>
</dl>
<!-- confirm licence terms with contributor before publishing - must be Creative Commons licence, but different types of CC licences might be preferred -->
<p><a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> <img src="https://mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1" style="height:22px!important;vertical-align:text-bottom;"><img src="https://mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1" style="height:22px!important;margin-left:3px;vertical-align:text-bottom;"></a> This article is licensed under a Creative Commons Attribution 4.0 (CC BY 4.0) <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> International licence</a>. <!-- Add thumbnail image credit and any licence terms here --></p>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>How to cite</dt>
<dd>
Torabi, Fatemeh, Hotchkiss, Lewis, Squires, Emma, Thompson, Simon E. and Lyons, Ronan A. 2024. “Getting the data right for optimised AI performance.” Real World Data Science, May 7, 2024. <a href="https://realworlddatascience.net/foundation-frontiers/posts/2024/05/07/ai-series-3.html">URL</a>
</dd>
</dl>
</div>
</div>
</div>
<!-- Make sure to update main site homepage (index.qmd) before publishing. See README for details. -->


</section>


<div id="quarto-appendix" class="default"><section id="footnotes" class="footnotes footnotes-end-of-document"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p>Li, P. et al.&nbsp;CleanML: A Benchmark for Joint Data Cleaning and Machine Learning [Experiments and Analysis]↩︎</p></li>
<li id="fn2"><p>Azeroual, O. et al.&nbsp;A Record Linkage-Based Data Deduplication Framework with DataCleaner Extension. Multimodal Technol. Interact. 2022, Vol. 6, Page 27 6, 27 (2022).↩︎</p></li>
<li id="fn3"><p>Rajpurkar, P., Chen, E., Banerjee, O. &amp; Topol, E. J. AI in health and medicine. Nat. Med. 2022 281 28, 31–38 (2022).↩︎</p></li>
<li id="fn4"><p>Mitra, R. et al.&nbsp;Learning from data with structured missingness. (2023).↩︎</p></li>
<li id="fn5"><p>Alan Turing Institution. Data science and AI in the age of COVID-19. 2020 https://www.turing.ac.uk/sites/default/files/2021-06/data-science-and-ai-in-the-age-of-covid_full-report_2.pdf↩︎</p></li>
<li id="fn6"><p>Han, J. &amp; Kang, S. Dynamic imputation for improved training of neural network with missing values. Expert Syst. Appl. 194, 116508 (2022).↩︎</p></li>
<li id="fn7"><p>Köse, T. et al.&nbsp;Effect of Missing Data Imputation on Deep Learning Prediction Performance for Vesicoureteral Reflux and Recurrent Urinary Tract Infection Clinical Study. Biomed Res. Int. 2020, (2020).↩︎</p></li>
<li id="fn8"><p>Azur, M. J., Stuart, E. A., Frangakis, C. &amp; Leaf, P. J. Multiple imputation by chained equations: what is it and how does it work? Int. J. Methods Psychiatr. Res. 20, 40–49 (2011).↩︎</p></li>
<li id="fn9"><p>Audigier, V., Husson, F. &amp; Josse, J. A principal component method to impute missing values for mixed data. Adv. Data Anal. Classif. 10, 5–26 (2016).↩︎</p></li>
<li id="fn10"><p>Köse, T. et al.&nbsp;Effect of Missing Data Imputation on Deep Learning Prediction Performance for Vesicoureteral Reflux and Recurrent Urinary Tract Infection Clinical Study. Biomed Res. Int. 2020, (2020).↩︎</p></li>
<li id="fn11"><p>Liu, T., Fan, W. &amp; Wu, C. A hybrid machine learning approach to cerebral stroke prediction based on imbalanced medical dataset. Artif. Intell. Med. 101, 101723 (2019).↩︎</p></li>
<li id="fn12"><p>Kokkotis, C. et al.&nbsp;An Explainable Machine Learning Pipeline for Stroke Prediction on Imbalanced Data. Diagnostics 2022, Vol. 12, Page 2392 12, 2392 (2022).↩︎</p></li>
<li id="fn13"><p>Gorgolewski, K. J. et al.&nbsp;BIDS apps: Improving ease of use, accessibility, and reproducibility of neuroimaging data analysis methods. PLoS Comput. Biol. 13, (2017).↩︎</p></li>
<li id="fn14"><p>Bauermeister, S. et al.&nbsp;Research-ready data: the C-Surv data model. Eur. J. Epidemiol. 38, 179–187 (2023).↩︎</p></li>
<li id="fn15"><p>Abbasizanjani, H. et al.&nbsp;Harmonising electronic health records for reproducible research: challenges, solutions and recommendations from a UK-wide COVID-19 research collaboration. BMC Med. Inform. Decis. Mak. 23, 1–15 (2023).↩︎</p></li>
<li id="fn16"><p>Orlhac, F. et al.&nbsp;A Guide to ComBat Harmonization of Imaging Biomarkers in Multicenter Studies. J. Nucl. Med. 63, 172 (2022).↩︎</p></li>
<li id="fn17"><p>Toga, A. W. et al.&nbsp;The pursuit of approaches to federate data to accelerate Alzheimer’s disease and related dementia research: GAAIN, DPUK, and ADDI. Front. Neuroinform. 17, 1175689 (2023).↩︎</p></li>
<li id="fn18"><p>Torabi, F. et al.&nbsp;A common framework for health data governance standards. Nat. Med. 2024 1–4 (2024) doi:10.1038/s41591-023-02686-w.↩︎</p></li>
<li id="fn19"><p>Tucker, A., Wang, Z., Rotalinti, Y. &amp; Myles, P. Generating high-fidelity synthetic patient data for assessing machine learning healthcare software. npj Digit. Med. 2020 31 3, 1–13 (2020)↩︎</p></li>
<li id="fn20"><p>Tucker, A., Wang, Z., Rotalinti, Y. &amp; Myles, P. Generating high-fidelity synthetic patient data for assessing machine learning healthcare software. npj Digit. Med. 2020 31 3, 1–13 (2020)↩︎</p></li>
<li id="fn21"><p>Noruzman, A. H., Ghani, N. A. &amp; Zulkifli, N. S. A. Gretel.ai: Open-Source Artificial Intelligence Tool To Generate New Synthetic Data. MALAYSIAN J. Innov. Eng. Appl. Soc. Sci. 1, 15–22 (2021).↩︎</p></li>
<li id="fn22"><p>Wilkinson, M. D. et al.&nbsp;The FAIR Guiding Principles for scientific data management and stewardship. Sci. Data 2016 31 3, 1–9 (2016).↩︎</p></li>
<li id="fn23"><p>Chen, Y. et al.&nbsp;A FAIR and AI-ready Higgs boson decay dataset. Sci. Data 9, (2021).↩︎</p></li>
<li id="fn24"><p>Esteban, O. et al.&nbsp;fMRIPrep: a robust preprocessing pipeline for functional MRI. Nat. Methods 16, 111–116 (2018).↩︎</p></li>
<li id="fn25"><p>Alkhalifah, T., Wang, H. &amp; Ovcharenko, O. MLReal: Bridging the gap between training on synthetic data and real data applications in machine learning. Artif. Intell. Geosci. 3, 101–114 (2022).↩︎</p></li>
<li id="fn26"><p>Jefferson, E. et al.&nbsp;GRAIMATTER Green Paper: Recommendations for disclosure control of trained Machine Learning (ML) models from Trusted Research Environments (TREs). doi:10.5281/ZENODO.7089491.↩︎</p></li>
<li id="fn27"><p>DARE UK Community Working Group - DARE UK. https://dareuk.org.uk/dare-uk-community-working-groups/dare-uk-community-working-group-ai-risk-evaluation-working-group/.↩︎</p></li>
</ol>
</section></div> ]]></description>
  <category>AI</category>
  <category>Data management</category>
  <category>Data science education</category>
  <guid>https://realworlddatascience.net/foundation-frontiers/posts/2024/05/07/ai-series-3.html</guid>
  <pubDate>Tue, 07 May 2024 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/foundation-frontiers/posts/2024/05/07/images/Stages-of-model-development-724.png" medium="image" type="image/png" height="105" width="144"/>
</item>
<item>
  <title>AI series: Generative AI models and the quest for human-level artificial intelligence</title>
  <dc:creator>Diego Miranda-Saavedra</dc:creator>
  <link>https://realworlddatascience.net/foundation-frontiers/posts/2024/04/29/gen-ai-human-intel.html</link>
  <description><![CDATA[ 





<p>Generative artificial intelligence (AI) models have taken the world by storm over the past year. The human-like outputs of these systems, and the recent publication of a guideline to determine the degree of consciousness of machines, have again raised the question of whether machines will soon be able to replicate human intelligence. In this article, we discuss some of the merits and limitations of modern machine learning models, and also provide a general view of human intelligence and the position of “intelligent” systems in the constellation of human capabilities.</p>
<p>Large language models (LLMs) such as ChatGPT are designed to process and understand natural language, and to generate human-like text in response to prompts and questions. This is achieved thanks to a specific type of deep learning architecture called the <em>Transformer</em>, which consists of an encoder and a decoder, each made up of some number <em>N</em> of blocks. Here the input text is eventually transformed into predicted (and contextualised) output text (Figure&nbsp;1).<sup>1</sup> LLMs are trained on complex and large bodies of text so that they can learn complex patterns and relationships between words in sentences, in different contexts.</p>
<div id="fig-1" class="quarto-float quarto-figure quarto-figure-center anchored" alt="Architecture of the Transformer. The left-hand block is the Encoder, whereas the right-hand block represents the decoder" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="https://realworlddatascience.net/foundation-frontiers/posts/2024/04/29/images/fig1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" alt="Architecture of the Transformer. The left-hand block is the Encoder, whereas the right-hand block represents the decoder">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;1: Architecture of the Transformer. The left-hand block is the Encoder, whereas the right-hand block represents the decoder.
</figcaption>
</figure>
</div>
<p>The two main types of LLMs are autoregressive models and autoencoding models. Autoregressive models such as OpenAI’s GPT (Generative Pre-trained Transformer) generate text by predicting the next word in a sequence given the previously emitted words. Autoencoding models such as Google’s BERT (Bidirectional Encoder Representations from Transformers) also aim to produce coherent and contextually relevant text, but they do so by attempting to predict missing words (from a corrupted version of the text) while considering the surrounding context.</p>
<p>LLMs are engineering marvels capable of producing syntactically flawless, coherent, and remarkable responses to complex requests such as question answering, text summarisation, computer code generation, document classification, text generation and sentiment analysis. We tend to associate linguistic skills with intelligence because communication via an elaborate language system is largely synonymous with the human intellect. So, do the linguistic skills of tools like ChatGPT mean these systems are close to displaying human-level intelligence? Proponents of the Turing test might well argue “yes”. Most would still say “no”.</p>
<section id="speaking-and-understanding" class="level2">
<h2 class="anchored" data-anchor-id="speaking-and-understanding">Speaking and understanding</h2>
<p>The Turing test was proposed by Alan Turing in the 1950s. It operates on the basis that if a person is unable to tell whether the entity they are interacting with over typed messages is a human or a machine (irrespective of the answers being correct), the machine is said to have achieved human-level intelligence.<sup>2</sup> There’s some debate over whether ChatGPT could pass this test; it has been specifically trained not to impersonate humans and will frequently preface its responses with the phrase, “As a large language model…”, thus giving the game away. But <a href="https://realworlddatascience.net/the-pulse/editors-blog/posts/2023/01/27/talking-chatgpt.html">others are impressed at what developers like OpenAI have been able to achieve</a> in terms of building artificial models that can sustain realistic-sounding conversations.</p>
<p>This, though, is where the Turing test falls apart as a means of assessing machine intelligence. The ability to “<a href="https://www.nature.com/articles/d41586-023-02361-7">mimic human chatter</a>” does not by itself suggest that a machine understands what it is ‘reading’ or ‘writing’ in the same way a human would. Consider a different set of tests, called the Winograd schemas – puzzles that differ by one or two words and whose solutions cannot be determined using statistics but instead require common sense and an understanding of the physical world.<sup>3</sup> For example, the following sentence:</p>
<blockquote class="blockquote">
<p>The trophy would not fit in the suitcase because it was too <strong>small/large</strong>.</p>
</blockquote>
<p>Humans would infer that if the last word of that sentence is <em>small</em>, then <em>suitcase</em> is the object being described, whereas if the word is <em>large</em> then we are referring to the <em>trophy</em>. ChatGPT v3.5 was unable to make this inference when the question was first put to it (see Figure&nbsp;2), although a later test finds it now can – as can other LLMs. Some suggest that this type of improvement comes from training ChatGPT to do better on some of the tasks that are routinely used to highlight model limitations on social media at the expense of <a href="https://www.searchenginejournal.com/chatgpt-quality-worsened/492145/">giving worse answers in other contexts</a>. But could this improvement be due to ChatGPT and other models suddenly having acquired common sense and an understanding of the physical world? A more complex set of Winograd schema questions, the WinoGrande dataset, suggests not: humans still outperform computers on these tests.<sup>4</sup></p>
<div id="fig-2" class="quarto-float quarto-figure quarto-figure-center anchored" alt="Screenshot of author's ChatGPT conversation, prompting the AI chatbot to solve a WinoGrad schema question" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="https://realworlddatascience.net/foundation-frontiers/posts/2024/04/29/images/fig2.png" class="img-fluid quarto-figure quarto-figure-center figure-img" alt="Screenshot of author's ChatGPT conversation, prompting the AI chatbot to solve a WinoGrad schema question">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2: GPT-3.5’s inconclusive answer to a typical WinoGrad schema question.
</figcaption>
</figure>
</div>
<p>Machines will likely beat us all at these puzzles one day, in the same way that they already beat the world champions of chess and Go, can translate across multiple languages, and diagnose rare forms of cancer that escape well-trained doctors. These <em>narrow AI</em> applications that spectacularly outperform humans at very specific tasks will become more and more common. But will a multiplicity of narrow AI soon lead to general AI that can compete or beat humans at <em>all</em> tasks? Will human-level linguistic capabilities inevitably result in machines acquiring human-level intelligence in the not-too-distant future? Some developers and researchers certainly believe or hope so. Others remain sceptical.</p>
</section>
<section id="thinking-and-learning" class="level2">
<h2 class="anchored" data-anchor-id="thinking-and-learning">Thinking and learning</h2>
<p>What is “intelligence”, anyway? More than 70 working definitions currently exist.<sup>5</sup> One that focuses specifically on human-level intelligence while excluding lower types of animal intelligence is this: “intelligence can be understood as the ability to generate a range of plausible scenarios about how the world around you may unfold and then base sensible actions on those predictions”.<sup>6</sup> Does this come anywhere close to describing the way LLMs work, or indeed any other machine learning algorithm?</p>
<p>In my view, part of the reason why attaining human-level intelligence remains a distant goal has to do with how machines think differently from us.</p>
<p>The goal of a machine learning algorithm is always to optimise a particular function – whether the machine is playing chess (the goal is to win) or classifying images (the goal is to correctly classify as many images as possible). The majority of problems that human intelligence has to “solve”, however, do not always have a clear goal. Consider a simple chatbot standing in for a human on a customer helpline: What scalar quantity should it look to optimise? Is it ensuring that engagement with the customer is informative and supportive? Or, perhaps the goal is to build a recurrent relationship. In either case, how will these quantities be measured? Dealing with this type of real-world problem, where the variable to optimise is not well-defined, represents a formidable obstacle for the development of machine learning algorithms whose behaviour must approximate human intelligence.</p>
<p>Moreover, machines can be surprisingly easy to fool. For example, placing an object next to the one we are trying to classify can confuse image classification algorithms – a <a href="https://www.youtube.com/watch?v=i1sp4X57TL4">well-known example shows a patch being placed next to a banana</a>, which makes the deep neural network (DNN) classify the banana as a toaster with a high degree of confidence. We can also fool image classification networks <a href="https://arxiv.org/abs/1811.11553">by showing the same object under different lighting conditions and orientations</a>, such as when we flip a school bus on its side (as in an accident). The reason why a DNN cannot do this trivial mental rotation is because learning algorithms cannot generalise knowledge to unseen (or “out of distribution”) examples – imbuing them with no small amount of “brittleness”.<sup>7</sup> Compare this to the human mind, which learns in a semi-supervised manner: we need only be shown a few guiding examples to be able to extrapolate knowledge. This is a clear evolutionary adaptation since most real-world learning is semi-supervised: we do not need to explore every road to learn to drive, nor do every possible differentiation exercise to become confident at calculus. Likewise, we do not need to become fully bilingual in a language before we start combining newly learned words to try to explain complex concepts.</p>
<p>Next to GPT-4’s <a href="https://arxiv.org/abs/2303.08774">100-trillion parameter model</a>, the human brain seems <a href="https://www.wired.com/story/cerebras-chip-cluster-neural-networks-ai/">much more</a> <a href="https://arxiv.org/pdf/2005.14165">parsimonious</a>. Therefore, progress in AI would perhaps come faster if we could teach machines to learn from a few (or no) labelled examples instead of being so heavily dependent on terabytes of labelled data (supervised learning) and on our own interpretation of the world.<sup>8</sup></p>
<p>Another major limitation of algorithms for achieving human-like adaptive learning in changing environments is the fact that they cannot keep learning without forgetting previously learned training data. This phenomenon is called <em>catastrophic forgetting</em>,<sup>9</sup> and it occurs because of the <em>stability-plasticity dilemma</em>: this states that a certain degree of plasticity is required for the integration of new knowledge, but also radically new knowledge (e.g.&nbsp;large weight changes in a DNN) disrupts the stability necessary for retaining the previously learned representations (Figure&nbsp;3). In other words, weight stability is synonymous with knowledge retention, but it also introduces the rigidity that prevents the learning of new tasks.<sup>10</sup></p>
<div id="fig-3" class="quarto-float quarto-figure quarto-figure-center anchored" alt="Illustration of catastrophic forgetting and ideal learning in a two-class classifier" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-3-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="https://realworlddatascience.net/foundation-frontiers/posts/2024/04/29/images/fig3.png" class="img-fluid quarto-figure quarto-figure-center figure-img" alt="Illustration of catastrophic forgetting and ideal learning in a two-class classifier">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-3-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;3: Illustration of catastrophic forgetting and ideal learning in a two-class classifier.
</figcaption>
</figure>
</div>
<p>Although some ingenious approaches have been developed for mitigating catastrophic forgetting (and which are much smarter than simply building a new network for each new task), it has also been shown that no single method can solve catastrophic forgetting while allowing incremental learning in every possible situation.<sup>11</sup> The problem with catastrophic forgetting is not only that it contradicts a fundamental characteristic of human intelligence – the ability to learn within, and adapt to, changing environments;<sup>12</sup> catastrophic forgetting is also a major bottleneck for the development of adaptable systems that learn incrementally from the constant flow of data in the real world, such as autonomous vehicles, recommender systems, anomaly detection methods and, in general, any device embedded with sensors. Moreover, the development of continual learning methods is key not just for machine intelligence, but also for learning scalability: by 2025 the world will be <a href="https://www.seagate.com/files/www-content/our-story/trends/files/idc-seagate-dataage-whitepaper.pdf">producing some 175 zettabytes of data annually</a>, of which we will only be able to <a href="https://www.uber.com/en-GB/blog/uber-big-data-platform/">store between 3% and 12%</a>. Thus, for learning to be scalable in the future, continual learning methods will need to be able to process data faster and in real time, learn on the fly and then discard the data, much like humans do.</p>
</section>
<section id="how-are-we-wired" class="level2">
<h2 class="anchored" data-anchor-id="how-are-we-wired">How are we wired?</h2>
<p>One further bottleneck for machines emulating human-level intelligence is that we do not yet understand the circuitry of the brain well enough to be able to reproduce it, and therefore we have been working with misleading models. For instance, the realisation of the “all-or-nothing” nature of action potentials (i.e.&nbsp;there is no such thing as the partial firing of a neuron) led McCulloch and Pitts to propose the concept of the artificial neuron and suggest that networks of neurons could equally be modelled as (all-or-nothing) logical propositions.<sup>13</sup> From this point onwards, the dominant idea over most of the past century has been that the brain is essentially a computer. But even on a superficial level of analysis, brains and computers have very different architectures and behaviour, with computers specifically making optimal use of virtually unlimited memory as well as an extraordinary capacity for brute-force searching. On the microscopic level, networks of neurons cannot possibly be modelled as logical propositions because they do not really operate in this manner: a single neuronal synapse is an environment that harbours hundreds of proteins that specifically interact with other proteins in complex networks that possess clear time-space coordinates. Neurons process information and generate not just electrical signals but also discrete biochemical changes that occur in cycles instead of linearly. Moreover, a system like the brain responds to stimuli over long periods of time, which can effect changes in its own behaviour. Understanding at least how some cognitive tasks are performed at an algorithmic level would likely translate into major progress towards emulating human-level intelligence.<sup>14</sup></p>
<p>GPT-4’s impressive capabilities can make people believe that some AI systems are conscious on a human level (since animals display limited consciousness), but this is an illusion. Consciousness is another essential quality that we can easily recognise when we see it, but which (like intelligence) is extraordinarily difficult to define – other than consciousness simply being everything you experience, or, more formally put, the “awareness of internal and external existence”.<sup>15</sup> Could machines eventually achieve consciousness? This is a controversial and key question because, besides intelligence, having a degree of consciousness on the level exercised by humans is believed to be necessary for displaying goal-directed behaviour.<sup>16</sup> Recall that machine learning algorithms do have the general goal of optimising functions but these goals are determined by human programmers, not the machines themselves.</p>
<p>A fundamental question regarding the development of consciousness is this: if an AI system were close to consciousness, how would we know? Butlin and colleagues recently explored the question in a groundbreaking paper where they compiled a list of “indicator properties” drawn from various neuroscientific theories of consciousness (since no theory is clearly superior). The idea is that the more boxes an AI system ticks, <a href="https://arxiv.org/pdf/2308.08708.pdf">the more likely it is close to being conscious</a>. The authors argue that a failure to identify artificial consciousness has important moral implications because an entity that exhibits consciousness invariably influences how we feel it should be treated. While this is likely true, humans do not necessarily need to feel that an entity is conscious in order to develop empathy. Emotional attachment is a basic human instinct, and we have a tendency to anthropomorphise. You may remember the story of hitchBOT, a clearly unconscious yet friendly robot invented by David Smith of McMaster University. <a href="https://twitter.com/hitchbot">HitchBOT</a> could barely speak and its only mission was to autostop. It ended up travelling throughout Europe and North America thanks to the sympathy it generated. The “beheading” of the robot in Philadelphia in 2015 had huge repercussions across the planet because thousands of strangers had developed empathy and become <a href="https://www.gq.com/story/americans-murder-friendly-canadian-hitchhiking-robot">emotionally attached to hitchBOT</a> despite never having met it.<sup>17</sup> Do you think that a machine is likely to develop a degree of human-like empathy anytime soon?</p>
<p>Finally, another fundamental human trait that is absent from machines, and which is particularly important in these trying times, is our capacity for remaining <em>hopeful</em>, which can be seen as a post-hoc rationalisation of our survival instinct. Being hopeful means that we think things will improve beyond what would be reasonable to predict for the immediate or medium-term future given the most recently available data points. Jane Goodall defines hope as “a crucial survival trait that enables us to keep going in the face of adversity”. Desmond Tutu gave an equally ethereal definition: “Hope is being able to see that there is light despite all the darkness”.<sup>18</sup> One fundamental aspect of hope is its undeniable association with <em>agency</em>, i.e.&nbsp;our capacity to <em>voluntarily</em> act in a given environment: even when we are at odds with the desired outcome, hope makes us take action, which in turn fuels more hope, thus establishing a dynamic form of self-stimulation over thousands of ethical actions without necessarily having a clear variable to optimise, which machines are incapable of doing. And, one very interesting thing about hope is that its effects can be quantified in the short term: hope is much better than intelligence and personality at predicting academic performance,<sup>19</sup> as well as performance in the workplace, with hopeful workers being reported as 14% more productive.<sup>20</sup></p>
</section>
<section id="closing-thoughts" class="level2">
<h2 class="anchored" data-anchor-id="closing-thoughts">Closing thoughts</h2>
<p>Generative language-based models have reignited much interest in the possibility of artificially recreating human-level intelligence. Despite being seminal breakthroughs, we must not forget that LLMs are, essentially, just very sophisticated pattern recognition systems which, when trained on even larger datasets, may become even better at predicting the most appropriate responses to different prompts. LLMs are incomplete models of thought, though, plagued by practical problems that we have not discussed here, such as giving incorrect answers, security breaches, privacy concerns regarding personal data used in their training datasets, algorithmic opacity and an inability to meet the EU’s General Data Protection Regulation (GDPR), and their amplification of web <em>bias</em> which can result in answers that discriminate against different groups.<sup>21</sup> Even if these limitations are fixed one day, the capabilities of LLMs still do not approximate general human intelligence.</p>
<p>Generative models are just one type of narrow AI application. Such applications will continue to evolve at a very fast pace and produce breakthroughs of paramount importance. Some of the latest breakthroughs in the biomedical field include the discovery of new antibiotics against deadly antibiotic-resistant bacteria<sup>22</sup> and <a href="https://deepmind.google/discover/blog/alphafold-using-ai-for-scientific-discovery-2020/">AlphaFold’s</a> accurate prediction of a protein’s structure from its amino acid sequence.<sup>23</sup> <sup>24</sup> The number of ways an amino acid sequence may fold is astronomical. Thus being able to predict a protein’s structure as accurately as experimental measurements (by X-ray crystallography or cryo-electron microscopy) represents a gigantic step towards understanding a protein’s likely function and its regulation, how it may be drugged to combat diseases and for antibiotic development, and its manipulation to guide vaccine design as was done during the <a href="https://www.biorxiv.org/content/10.1101/2021.05.10.443524v1">coronavirus pandemic</a>.<sup>25</sup> Most impressively, AlphaFold is able to predict the structural effects of single amino changes (mutations), which is essential for engineering new proteins as well as for understanding evolutionary history and mechanistic aspects of diseases.<sup>26</sup></p>
<p>Being able to harness the power of narrow AI applications and delegate some tasks to machines will allow humans to focus on those tasks at which we do better than machines. <em>Augmented intelligence</em> is the name given to the close collaboration between humans and machines, which was first proposed in the 1950s, and is now <a href="https://pz.harvard.edu/sites/default/files/Intelligence%20Augmentation-%20Upskilling%20Humans%20to%20Complement%20AI.pdf">finally within reach</a>.<sup>27</sup> <sup>28</sup> Current examples of devices that are a functional extension of human beings are virtual reality headsets that expand the users’ senses and perceptions, implantable technologies that substitute access cards, and, in general, any software that automates research and data analysis. Since such technological developments might make us more “intelligent” or at least more productive, will we then still need machines that display human-like intelligence?</p>
<p>The official position of some major players like Microsoft is to not even attempt to replicate human intelligence but to produce “AI centred on assisting human productivity in a responsible way”.<sup>29</sup> Still, a recent paper that reported GPT-4’s impressive performance at solving a number of difficult tasks (in the fields of mathematics, coding, vision, medicine, law and psychology) suggests that GPT-4 displays “<a href="https://arxiv.org/abs/2303.12712">sparks of artificial general intelligence</a>”. This is in line with OpenAI’s <a href="https://openai.com/blog/planning-for-agi-and-beyond">clearly stated goal</a> of developing human-level intelligence. However, the debate over whether we are getting any closer to replicating intelligence with just a few impressive generative models that simply recombine and duplicate data on which they have been trained is self-limiting because it takes a very narrow view of human intelligence. For one thing, mindlessly generating text (“speaking”) and thinking are <a href="https://nymag.com/intelligencer/article/ai-artificial-intelligence-chatbots-emily-m-bender.html">two very different things</a>. It has been shown that while LLMs may excel at formal linguistic competence (understanding language rules and patterns), their performance on tasks that evaluate human thought in the real world (functional linguistic competence) is <a href="https://arxiv.org/abs/2301.06627">very limited</a>. Moreover, GPT-4 is unable to reason. We can define reasoning as the process of drawing justifiable conclusions from a set of premises, which is also a key component of intelligence. When given a set of 21 distinct problems ranging from simple arithmetic and logic puzzles to spatial and temporal reasoning, and medical common sense, <a href="https://medium.com/@konstantine_45825/gpt-4-cant-reason-2eab795e2523">GPT-4 proved incapable of applying elementary reasoning techniques</a>.</p>
<p>OpenAI’s newest headline-grabbing development, <a href="https://openai.com/sora">Sora</a>, shares many of the limitations of GPT-4. Sora is a model that can generate video clips from text prompts – but while it may prove useful for content creation, it seems incapable of understanding the real world. OpenAI’s defence is that Sora still struggles with “simulating the physics of a complex scene” but that it “represents a foundation for models that can understand and simulate the real world”. This is, OpenAI believes, key for training models that will help solve problems that require simulating the physical world (e.g.&nbsp;rescue missions), and eventually for achieving general AI. However, it is suspected that Sora’s limitations in understanding the physical world have nothing to do with physics. For example, in <a href="https://twitter.com/sama/status/1758249750909096142?s=61">a generated video of a monkey playing chess in a park</a>, we see a 7x7 board and three kings. This is likely not an error of insufficient training data or of computational power. This is an error that reveals a failure to discern the cultural regularity of the world by making wrong generalisations despite having ample evidence of the existence of universal 8x8 chess boards and one king per player. A video of <a href="https://twitter.com/openai/status/1758192965703647443?s=61">a stylish woman wandering in Tokyo</a> is also incorrect for the same reason: nobody takes two consecutive left steps in a row (about 30s into the video). Sora also does not appear to understand cause and effect; for example, in a video of a basketball that makes a hoop explode, the net appears to be restored automatically following the explosion. Sora uses arrangements of pixels to predict new pixel configurations, but without trying to understand the cultural context of the images. This is why the images and videos generated by Sora <a href="https://garymarcus.substack.com/p/sora-cant-handle-the-truth">seem correct at the pixel level</a> but <em>globally</em> wrong. Thus, OpenAI’s claim that “<a href="https://openai.com/research/video-generation-models-as-world-simulators">scaling video generation models is a promising path towards building general purpose simulators of the physical world</a>” is open to doubt.</p>
<p>LLMs do not yet approximate the human brain; generative video models do not approximate the physical world; and human intelligence is so much more than combining formal linguistic competence with complete models of thought, or making creative videos that respect the physical constraints of the world. Human intelligence is not limited to specific domains either but exists in the open to challenge currently held views. Ask Noam Chomsky and he will respond that generative models like ChatGPT are essentially “<a href="https://www.nytimes.com/2023/03/08/opinion/noam-chomsky-chatgpt-ai.html">high-tech plagiarism</a>”. Human consciousness includes a sense of self which machines will not be able to replicate anytime soon – or perhaps never will, since a human brain and a computer are <a href="https://www.wired.com/story/artificial-intelligence-consciousness/#:~:text=Pondering%20this%20question%2C%20it's%20important,necessary%20nor%20sufficient%20for%20consciousness.">not the same</a>. Human consciousness is coupled with curiosity, imagination, intuition, emotions, desires, purpose, objectives, wisdom and even humour. If we think about humour, a good sense of humour means thinking outside of the box and connecting concepts and situations in novel ways, which is something that machines are unable to do. Also, by thinking outside the box, humans are able to <em>consciously</em> ask a variety of questions – the most <em>extraordinary</em> of which have led to major leaps in our understanding of the world around us.</p>
<p><em>Reasonable</em> questions can be posed by many and answered logically (some even by machines) using the standard scientific process of experimental design, controls and hypothesis validation. In this context, the faster and more efficient exploration of search space by learning methods, complemented by the delegation of repetitive tasks to machines, will <a href="https://www.technologyreview.com/2023/07/05/1075865/eric-schmidt-ai-will-transform-science/">allow scientists to conduct experiments at greater scale</a> while focusing on designing optimal solutions. Beyond reasonable questions and expected results is the concept of <em>serendipity</em> that machines cannot yet be made to grasp. Some of the greatest discoveries in the history of science are indeed serendipitous (accidental), including the discovery of insulin, penicillin, smallpox vaccination, the anti-malarial drug quinine, X-rays, nylon and the anaesthetic effects of ether and nitrous oxide.<sup>30</sup> Turning accidents into discoveries requires having a questioning mind that can view data from several perspectives and connect seemingly unrelated pieces of information instead of discarding unusual results right away.</p>
<p>And yet beyond serendipitous discoveries we have <em>extraordinary</em> questions, which machines are as yet incapable of asking. Extraordinary questions lie outside of our current frame of knowledge and require an illogical step that is often the product of letting one’s mind wander freely.<sup>31</sup> A classical example here is when Einstein was trying to modify Maxwell’s equations so that they were no longer in contradiction with the constant speed of light that had been observed. After trying to modify these equations for years, Einstein eventually realised that it was not Maxwell’s fault. Rather, our notion of time was incorrect. Einstein thus stumbled upon the very question that led to the idea that the rate at which time passes depends on one’s frame of reference. While machines follow rules, the revolutionary ideas of Einstein, Newton, Darwin, Galileo, Wittgenstein and many others did not follow any rules established at the time. Therefore, the real danger in thinking that we can rely on “intelligent” machines to achieve a human level of imagination, intuition, wisdom or purpose anytime soon is that the world will become an even more statistically predictable place.</p>
</section>
<section id="also-in-the-ai-series" class="level2">
<h2 class="anchored" data-anchor-id="also-in-the-ai-series">Also in the AI series:</h2>
<p><a href="https://realworlddatascience.net/foundation-frontiers/posts/2024/04/22/ai-series-1.html">What is AI? Shedding light on the method and madness in these algorithms</a> <a href="https://realworlddatascience.net/foundation-frontiers/posts/2024/05/07/ai-series-3.html">Healthy datasets for optimised AI performance</a></p>
<div class="article-btn">
<p><a href="../../../../../foundation-frontiers/index.html">Explore more data science ideas</a></p>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-12">
<dl>
<dt>About the author</dt>
<dd>
<strong>Diego Miranda-Saavedra</strong>, PhD, is a data scientist and a financial investor. His book <em>How To Think About Data Science</em> (Chapman &amp; Hall / CRC Press) was published in December, 2022.
</dd>
</dl>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>Copyright and licence</dt>
<dd>
© 2024 Diego Miranda-Saavedra
</dd>
</dl>
<p><a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> <img style="height:22px!important;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"></a> Text, code, and figures are licensed under a Creative Commons Attribution 4.0 (CC BY 4.0) <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;">International licence</a>, except where otherwise noted. Thumbnail image by <a href="https://www.jemimahknightstudio.com/work/ai">Jamillah Knowles</a> / <a href="https://www.betterimagesofai.org">Better Images of AI</a> / Data People / <a href="https://creativecommons.org/licenses/by/4.0/">Licenced by CC-BY 4.0</a>.</p>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>How to cite</dt>
<dd>
Miranda-Saavedra, Diego. 2024. “Generative AI models and the quest for human-level artificial intelligence.” Real World Data Science, April 29, 2024. <a href="https://doi.org/10.5281/zenodo.11237253"><img src="https://zenodo.org/badge/DOI/10.5281/zenodo.11237253.svg" class="img-fluid" alt="DOI"></a>
</dd>
</dl>
</div>
</div>
</div>


</section>


<div id="quarto-appendix" class="default"><section id="footnotes" class="footnotes footnotes-end-of-document"><h2 class="anchored quarto-appendix-heading">References</h2>

<ol>
<li id="fn1"><p>Vaswani A, Shazeer N, Parmar N, Uszkoreit J, Jones L, Gomez AN, Kaiser L, Polosukhin I. <em>Attention is All you Need</em>. In Advances in Neural Information Processing Systems 30 (NIPS 2017), Long Beach, California (USA), 2017. ISBN: 9781510860964.↩︎</p></li>
<li id="fn2"><p>Turing A. <em>Computing Machinery and Intelligence</em>. Mind, LIX(236):433-460, 1950.↩︎</p></li>
<li id="fn3"><p>Levesque HJ, Davis E, Morgenstern L. <em>The Winograd Schema Challenge</em>. In KR’12: Proceedings of the Thirteenth International Conference on Principles of Knowledge Representation and Reasoning, June 2012, Rome, Italy. AIII Press, Palo Alto (CA), USA, 2012. ISBN: 9781577355601.↩︎</p></li>
<li id="fn4"><p>Sakaguchi K, Le Bras R, Bhagavatula C, Choi Y. <em>WinoGrande: An Adversarial Winograd Schema Challenge at Scale</em>. In Proceedings of the Thirty-Fourth AAAI Conference on Artificial Intelligence, 34(05), 8732–8740. February 2020, New York (NY), USA. AIII Press, Palo Alto (CA), USA, 2020. ISSN: 2159–5399.↩︎</p></li>
<li id="fn5"><p>Legg S, Hutter M. <em>A Collection of Definitions of Intelligence</em>. Proceedings of the 2007 Conference on Advances in Artificial General Intelligence: Concepts, Architectures and Algorithms: Proceedings of the AGI Workshop 2006, 17-24. IOS Press, Amsterdam, the Netherlands, 2007. ISBN: 978-1-58603-758-1.↩︎</p></li>
<li id="fn6"><p>Suleyman M, Bhaskar M. <em>The Coming Wave</em>. Bodley Head, London, UK, 2023. ISBN-10: 1847927483.↩︎</p></li>
<li id="fn7"><p>McCarthy J. <em>From Here to Human-Level AI</em>. Artificial Intelligence, 171(18):1174–1182, 2007.↩︎</p></li>
<li id="fn8"><p>LeCun Y, Bengio Y, Hinton G. <em>Deep Learning</em>. Nature, 521(7553):436–444, 2015.↩︎</p></li>
<li id="fn9"><p>McCloskey M, Cohen NJ. <em>Catastrophic Interference in Connectionist Networks: The Sequential Learning Problem</em>. Psychology of learning and motivation, 24:109–165, 1989.↩︎</p></li>
<li id="fn10"><p>Abraham WC, Robins A. <em>Memory Retention - the Synaptic Stability Versus Plasticity Dilemma</em>. Trends in Neurosciences, 28(2):73–78, 2005.↩︎</p></li>
<li id="fn11"><p>Kemker R, McClure M, Abitino A, Hayes T, Kanan C. <em>Measuring Catastrophic Forgetting in Neural Networks</em>. In Proceedings of the AAAI Conference on Artificial Intelligence, 32(1). AAAI Press, Palo Alto (CA), USA, 2018. ISBN: 9781577358008.↩︎</p></li>
<li id="fn12"><p>Hadsell R, Rao D, Rusu AA, Pascanu R. <em>Embracing Change: Continual Learning in Deep Neural Networks</em>. Trends in Cognitive Sciences 24(12): 1028–1040, 2020.↩︎</p></li>
<li id="fn13"><p>McCulloch W, Pitts W. <em>A Logical Calculus of Ideas Immanent in Nervous Activity</em>. Bulletin of Mathematical Biophysics, 5(4):115–133, 1943.↩︎</p></li>
<li id="fn14"><p>Brooks R, Hassabis D, Bray D, Shashua A. <em>Is the Brain a Good Model for Machine Intelligence?</em> Nature 482: 462-463, 2012.↩︎</p></li>
<li id="fn15"><p>Koch C. <em>What Is Consciousness?</em> Nature, 557:S8–S12, 2018.↩︎</p></li>
<li id="fn16"><p>DeWall C, Baumeister R, Masicampo R. <em>Evidence that Logical Reasoning Depends on Conscious Processing</em>. Consciousness and Cognition 17(3): 628, 2008.↩︎</p></li>
<li id="fn17"><p>Darling K, Nandy P, and Breazeal C. <em>Empathic Concern and the Effect of Stories in Human-Robot Interaction</em>. 24th IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN) 2015, Kobe, Japan, August 31 - September 4, pp.&nbsp;770-775. IEEE, Washington (DC), USA, 2015. ISBN: 9781467367042.↩︎</p></li>
<li id="fn18"><p>Goodall J, Abrams D. <em>The Book of Hope: A Survival Guide for an Endangered Planet (1st Edition)</em>. Viking Press, New York (NY), USA, 2021. ISBN-10: 024147857X.↩︎</p></li>
<li id="fn19"><p>Day L, Hanson K, Maltby J, Proctor C, Wood A. <em>Hope Uniquely Predicts Objective Academic Achievement Above Intelligence, Personality, and Previous Academic Achievement</em>. Journal of Research in Personality 44(4): 550-553, 2010.↩︎</p></li>
<li id="fn20"><p>Reichard RJ, Avey JB, Lopez S, Dollwet M. <em>Having the Will and Finding the Way: A Review and Meta-Analysis of Hope at Work</em>. The Journal of Positive Psychology 8(4): 292-304, 2013.↩︎</p></li>
<li id="fn21"><p>Baeza-Yates R. <em>Bias on the Web</em>. Communications of the ACM, 61(6):54–61, 2018.↩︎</p></li>
<li id="fn22"><p>Liu G et al.&nbsp;<em>Deep learning-guided discovery of an antibiotic targeting Acinetobacter baumannii</em>. Nature Chemical Biology 19: 1342-1350, 2023.↩︎</p></li>
<li id="fn23"><p>Senior AW et al.&nbsp;<em>Protein structure prediction using multiple deep neural networks in the 13th Critical Assessment of Protein Structure Prediction (CASP13)</em>. Proteins: Structure, Function and Bioinformatics 87(12):1141–1148, 2019.↩︎</p></li>
<li id="fn24"><p>Senior AW et al.&nbsp;<em>Improved protein structure prediction using potentials from deep learning</em>. Nature 577:706–710, 2020.↩︎</p></li>
<li id="fn25"><p>Higgins MK. <em>Can We AlphaFold Our Way Out of the Next Pandemic?</em> Journal of Molecular Biology 433(20):1–7, 2021.↩︎</p></li>
<li id="fn26"><p>McBride JM, Polev K, Abdirasulov A, Reinharz V, Grzybowski BA, Tlusty T. <em>AlphaFold2 Can Predict Single-Mutation Effects</em>. Phys. Rev.&nbsp;Lett. 121:218401, 2023.↩︎</p></li>
<li id="fn27"><p>Zheng NN, Liu ZY, Ren PJ, Ma YQ, Chen ST, Yu SY, Xue JR, Chen BD, Wang FY. <em>Hybrid-Augmented Intelligence: Collaboration and Cognition</em>. Frontiers of Information Technology &amp; Electronic Engineering 18:153-179, 2017.↩︎</p></li>
<li id="fn28"><p>Bryant PT. <em>Augmented Humanity: Being and Remaining Agentic in a Digitalized World</em>. Palgrave Macmillan, Cham, Switzerland. ISBN: 9783030764449.↩︎</p></li>
<li id="fn29"><p>Lenharo M. <em>If AI Becomes Conscious: Here’s How Researchers Will Know</em>. Nature, 24 August 2023.↩︎</p></li>
<li id="fn30"><p>Roberts RM. <em>Serendipity: Accidental Discoveries in Science (1st Edition)</em>. Wiley-VCH, Weinheim, Germany, 1989. ISBN: 0471602035.↩︎</p></li>
<li id="fn31"><p>Yanai I, Lercher M. <em>What Is The Question?</em> Genome Biology 20(1):289, 2019.↩︎</p></li>
</ol>
</section></div> ]]></description>
  <category>AI</category>
  <category>Large language models</category>
  <category>Machine learning</category>
  <category>Deep neural networks</category>
  <guid>https://realworlddatascience.net/foundation-frontiers/posts/2024/04/29/gen-ai-human-intel.html</guid>
  <pubDate>Mon, 29 Apr 2024 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/foundation-frontiers/posts/2024/04/29/images/data-people.png" medium="image" type="image/png" height="105" width="144"/>
</item>
<item>
  <title>AI series: What is AI? Shedding light on the method and madness in these algorithms</title>
  <dc:creator>Anna Demming</dc:creator>
  <link>https://realworlddatascience.net/foundation-frontiers/posts/2024/04/22/ai-series-1.html</link>
  <description><![CDATA[ 





<!-- article text to go here -->
<p>What do <a href="https://www.simmons-simmons.com/en/publications/clq2gkar900fcu2ewb904uhrj/inappropriate-use-of-chatgpt-exposed-in-tax-case">defence cases in litigation</a>, statistical analyses, book summaries and a description of <a href="https://twitter.com/jimalkhalili/status/1621454981097209857/photo/1">Young’s double slit experiment in the manner of poet Robert Burns</a> have in common? They are all tasks that people have rightly or wrongly attempted to delegate to large language models.</p>
<p>The playground of generative AI algorithms based on large language models extends well beyond the space of generating text-based language but includes creating images, videos and even music from prompts. The capabilities of these algorithms, and the ubiquity of tasks that large language models like OpenAI’s Generative Pre-trained Transformer (GPT) models can have a go at is striking. These large language models and the chatbots and so on based on them have also been catapulted into the centre of mainstream public attention with huge success – who has not heard of ChatGPT? The net result has been something akin to a feeding frenzy as individuals and businesses alike strive to be among the first to benefit from them.</p>
<p>Like others, many data scientists closely familiar with these kinds of algorithms share some enthusiasm for their potential utility, but many also advocate an element of caution. There are some obvious caveats, including accuracy and cost – not just financially but also in terms of the huge energy costs to run these algorithms, a real world consequence that is affecting the planet in the present day but is often eclipsed by fears that AI might take over the world some time in the future. Another concern is security. Should you be sharing the information you are working from with a third party anyway? However, while a lot of attention has focused on what these algorithms can do, fewer have been asking what they actually do – what we know about the initial programming, the training data, the final algorithm and the range of possible outputs, all of which provide useful pointers as to whether a particular algorithm is appropriate for the task in hand, and how best to benefit from it.</p>
<section id="demystifying-machine-learning" class="level2">
<h2 class="anchored" data-anchor-id="demystifying-machine-learning">Demystifying machine learning</h2>
<p>Definitions of artificial intelligence vary, often circling around the theme of a system reaching an “intelligent” decision or output based on multiple inputs, although how “intelligent” might be defined can be hairier still. Nonetheless, there is currently largely a consensus that some kind of machine learning is a route to achieving it. Through machine learning “you are letting the computer adjust the importance of its inputs, and their relationships, to determine an appropriate output” as Napier chief data scientist and chair of the Royal Statistical Society DS &amp; AI Section <a href="https://www.linkedin.com/in/janetbastiman/?originalSubdomain=uk">Janet Bastiman</a> describes it. The term “machine learning” was first proposed by IBM scientist Arthur Samuel in 1952, and it has largely been achieved by two approaches. One is “random forests”, based on constructing multiple decision trees. The other is the neural networks first devised by American psychologist Frank Rosenblatt and simulated at IBM in 1957. Here, a set of artificial neurons – components closer to a capacitor than a biological neuron – is connected to another layer of neurons, which is connected to another layer of neurons, and so on (Figure 1). Crucially the connections are strengthened or not through “learning” based on training data that allows the network to recognise patterns and extract meaningful features.</p>
<div id="fig-neuralnetworks" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-neuralnetworks-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="https://realworlddatascience.net/foundation-frontiers/posts/2024/04/22/images/neuralnetworks.jpg" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-neuralnetworks-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;1: A <a href="https://commons.wikimedia.org/wiki/File:Visualizing_Artificial_Neural_Networks_%28ANNs%29_with_python_library-ANN_Visualizer.jpg">schematic of a neural network</a> depicted with circles connected with lines or arrows.
</figcaption>
</figure>
</div>
<p>“Machine learning is just like linear regression with tonnes of bells and whistles,” says <a href="https://www.danielawitten.com/">Daniela Witten</a>, professor of mathematical statistics at the University of Washington in the US, referring to a statistical method for fitting a line to a set of data points that dates back over a hundred years. There are many other traditional approaches to statistical learning that may be nonlinear and so on, but as an example of the “bells and whistles” Witten describes, whereas a traditional regression model might have 5 inputs or variables, the machine learning version might have 15 million, and instead of assuming it is linear the fit is allowed to be more flexible and so on. However, the fundamental statistical ideas underlying both sets of models are the same. For this reason, although some may beg to differ, she feels doing machine learning before you understand statistics is like trying to jump rope before you can walk. “It’s not that you can’t do it but why would you?” she adds.</p>
<p>Broadly speaking, machine learning can be classified two ways. One is “supervised”, which means that the training data is somehow labelled, for instance with a known output collected from real world records. The alternative is “unsupervised” where the algorithm is set the task of finding a way to learn relationships between input data itself. There are also neural network approaches that fall somewhere between the two, such as reinforcement learning where an algorithm may generate outputs for a task at random such that its performance is initially poor but improves with feedback to reinforce generation of outputs that are closer to those desired. An approach that enjoyed great popularity for a time used another machine learning algorithm to provide this feedback, which would initially also be a poor judge but improve as pitted against the algorithm learning to do the task – generative adversarial networks (<a href="https://proceedings.neurips.cc/paper_files/paper/2014/file/5ca3e9b122f61f8f06494c97b1afccf3-Paper.pdf">GANs</a>). GANs are still used a lot, but usually in a pipeline and may be pre-trained so they are not starting from scratch like they used to.</p>
<p>As the number of layers increased from just a few, the term “deep learning” was adopted along with alternative structures. The first models operated with every neuron in each layer connected to every neuron in the previous layer. “This is very wasteful because not every part of your input relates to each other that much,” says <a href="https://petar-v.com/">Petar Veličković</a>, staff research scientist at Google DeepMind and affiliated lecturer at the University of Cambridge. He cites images as among the first scenarios where people began to implement a tweak to the approach in what is called a convolutional neural network. Based on the assumption that the pixels for each object in an image sit adjacent to each other rather than at opposing corners of the image, the neurons in a convolutional neural network connect only with the neurons in the next layer that are nearby in the image space. In this way the convolutional neural network assumes a kind of structure in the input data – that the image is contiguous, so the pixels for edges and so on are in contact.</p>
<div id="fig-Attentionfigure2" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-Attentionfigure2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="https://realworlddatascience.net/foundation-frontiers/posts/2024/04/22/images/Attentionfigure2.jpg" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-Attentionfigure2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2: Schematics for (left) Scaled Dot-Product Attention and (right) Multi-Head Attention, which consists of several attention layers running in parallel.
</figcaption>
</figure>
</div>
<p>“Transformers are also a neural network but they encode a different kind of structure,” Veličković tells Real World Data Science, as he describes the data architecture at the heart of the large language models creating such a buzz at present. Language has structure too – the letters make up words, which then make up sentences and so on. So it makes sense to program some of that structure into the algorithm rather than leaving it to work it all out. “You would need a lot more training data than there is on the internet to train a system without such structure by itself,” adds Veličković. Transformers structure the training data into tokens, and a key component first reported in 2017 is the way each token then connects with or <a href="https://papers.nips.cc/paper_files/paper/2017/hash/3f5ee243547dee91fbd053c1c4a845aa-Abstract.html">“attends” to all other similar tokens</a> . Here whether they are “similar” is determined by their dot products, a multiplication technique for the kind of vector format of input numbers used for these tokens (Figure 2). Exploiting this “dot product attention” significantly improves the efficiency of the training process.</p>
</section>
<section id="taking-the-world-by-storm" class="level2">
<h2 class="anchored" data-anchor-id="taking-the-world-by-storm">Taking the world by storm</h2>
<p>The transformer architecture proved very powerful as has been seen in the surge to prominence of various AI systems based on generative pre-trained transformer algorithms, such as ChatGPT, BERT and PaLM, although this likely has at least as much to do with the marketing of the recent releases as it does with the algorithm itself. “It was a small evolution rather than a revolution,” says Bastiman in reference to recent GPT releases, explaining that there was an increase in parameter size and the amount of data used for training that gave rise to something that could provide broader answers and was ready for mass market. Nonetheless she adds, “There had been GPT2, GPT1 and all the other previous ones had been released quietly and had all been quite good.”</p>
<p>The marketing spin has not stopped with the product releases as terms like “<a href="https://realworlddatascience.net/the-pulse/editors-blog/posts/2022/11/23/LLM-content-warning.html">hallucination</a>” have entered the lexicon to describe instances when the output is wrong and potentially dangerous. (Figure 3) “The language we are using to describe these models is different to how we describe human intelligence to deliberately instil the sense this is better,” adds Bastiman. “So even if the model is incorrect these terms imply that it is still doing something amazing.”</p>
<div id="fig-hallucinatedreferences" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-hallucinatedreferences-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="https://realworlddatascience.net/foundation-frontiers/posts/2024/04/22/images/hallucinatedreferences.jpg" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-hallucinatedreferences-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;3: “Hallucinated” references. A study found that out of the 178 references cited by ChatGPT, 69 did not have a DOI. Upon extensive internet search, 41 out of these 69 reference articles were found to exist.
</figcaption>
</figure>
</div>
<p>The success of this marketing does have its advantages as Veličković points out, thrusting AI in the spotlight, inviting people to try the algorithms, which thanks to a growth in web-based user interfaces like ChatGPT can reach a much broader audience. This is not only encouraging developers they are doing something potentially useful but prompting important discussions around the potential bias and ethics issues, which many would argue ought to be considered before anything else. Nonetheless Veličković also doubts whether the current AI fanfare can be attributed to advances in the algorithms they use alone, pointing out that neural networks have been around since the 1950s, and the 1980s and 1990s saw the invention of most of the building blocks we need to scale such systems up: the backpropagation algorithm, convolutional and recurrent neural networks, long-short term memory networks, and early variants of linear self-attention and graph neural networks. “It’s just that we needed gamers,” he tells <em>Real World Data Science</em>, suggesting that hardware and engineering have been key to the recent successes of AI. “We needed people to drive the development of graphics cards which are really good hardware for training these things.”</p>
<p>Clearly advances in processing power and the hardware such as GPUs to manage it so that it is possible to compute these algorithms massively affects their potential impact. Although the field no longer relies on GPUs developed for gamers, GPUs are still widely used, as they offer such a good return on investment and are easier to get hold of than alternatives like tensor processing units. Certainly a significant development over the past decade or so is the increase in size of not just the data sets but the algorithms themselves. Implementing algorithms at such colossal scales that require data centres imposes incredibly challenging requirements on the hardware and the electrical and computational engineering involved to set them running and keep them from failure. “When you have a data centre, failure is a common thing,” says Veličković, listing multiple vulnerabilities that balloon at scale such as hardware failures, electrical failures, even apparently exotic events like solar flares can flip bits and scramble data leading to nonsense output. “People underestimate this but good engineering is now the bread and butter of how these systems work.”</p>
</section>
<section id="managing-expectations" class="level2">
<h2 class="anchored" data-anchor-id="managing-expectations">Managing expectations</h2>
<p>The explosion in scale has also created fundamental distinctions from how people work with machine learning algorithms versus statistical methods. Witten highlights “the ability to gauge uncertainty” by quantifying parameters such as confidence intervals and error bars as a key contribution of statistics. “Often with these machine learning models things get very complicated and we do not yet have a way to quantify that uncertainty.”</p>
<p>This quantifying of finite parameters contrasts with the kind of output achieved with the generative AI applications that have grabbed media focus recently. For instance, asking a large language model to describe Young’s double slit experiment in the style of Robert Burns may sound quite a specific prompt, and it may seem impressive if the algorithm returns something akin to what was asked, but the number of possible responses that could be deemed “correct” are infinite. A lot of applications of generative AI – many with more real world impact than describing iconic experiments in archaic scotch rhyme – similarly have a vast set of reasonable outputs.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://realworlddatascience.net/foundation-frontiers/posts/2024/04/22/images/Gamers.jpg" class="img-fluid figure-img"></p>
<figcaption>Gamers drove the development of GPUs which have proven invaluable for training machine learning algorithms</figcaption>
</figure>
</div>
<p>“We shouldn’t be surprised if ChatGPT does well with a question that has a million reasonable answers,” says Witten, contrasting these scenarios with questions that she suggests might have more real-world importance, like whether a patient with breast cancer will respond to a particular treatment. “Actually ChatGPT often gets into trouble if there is a problem with just one answer, and that answer is not part of the training set.”</p>
<p>For predictive AI there is often only one useful answer – the outcome that will come to pass. This has implications if machine learning is used for predictions, particularly if it is in real world settings that affect real people. “If you are deploying an AI model for some healthcare application like what breast cancer treatment you are going to respond best to, we really better make sure that the model works, and that we understand the uncertainty of those predictions,” says Witten. She feels that over the past few years, the machine learning community has increasingly recognized the importance of bringing statistical thinking to bear within the context of complex machine learning/AI algorithms: in particular, interpretability and uncertainty quantification have become major areas of interest in machine learning. Witten suggests that statistics is making progress here citing as an example conformal inference, “which allows recalibration of the predictions of a machine learning model in order to quantify uncertainty appropriately.”</p>
</section>
<section id="explain-yourself" class="level2">
<h2 class="anchored" data-anchor-id="explain-yourself">Explain yourself</h2>
<p>Understanding the uncertainties of output is one thing, but many of these algorithms have now reached the kind of scale that totally obfuscates what they are doing with the input data to reach their outputs. There may be specialists who understand how they are programmed but there are just too many variables to track so that even for them, the final process the algorithm lands on for generating its output from the various inputs is a black box with no neat mathematical description, unlike statistical techniques like regression.</p>
<p>“You can draw a picture with circles and arrows, and arrows cross in a certain way, but you don’t have a clear idea of how one feature that you started with maps to the output,” says Witten. “On an actual quantitative level of scientific understanding we don’t have that.” If decisions are being made for and about people based on AI, people will also sometimes want to know how that conclusion was drawn. “When we want to make decisions there’s a level of deferred trust,” says Bastiman citing a <a href="https://www.turing.ac.uk/research/research-projects/project-explain#:~:text=This%20gap%20in%20AI%20explainability,robust%2C%20reliable%2C%20and%20safe">work by the Alan Turing Institute</a> that began in the late 2010s. “We as humans want explanations from machines in the same scenarios that we want them from humans but that’s not going to be the same for all people.” For example, a person who has had a bad experience in the past will need more convincing than one who has not. Janet suggests that a very normal cognitive bias can be generalised as most people wanting more explanation if the model output is not in their favour. “Similarly, a person accepted for a job where AI is used, may not require any explanation, while another candidate the AI rejected may challenge the decision and want to know why.”</p>
<p>Hybrid implementations including a human in the loop may help to a degree. However, to get a handle on the workings of the algorithm itself, Bastiman points out that it is possible to introduce layers in the algorithm that will help extract how the output is reached even for unsupervised neural networks. “That’s where a lot of effort goes from data scientists and machine learning engineers to make sure the model has that level of transparency and makes sense,” she adds, emphasising the need to ensure a model has these features before it is released and put in use. The process is far from straightforward as the explanation needs to be at the right level and with the right terminology for a range of audiences, be they data scientists, quality assurance professionals, decision makers, end users or impacted individuals. “People say you can’t explain things when what they really mean is that it’s difficult.”</p>
<p>Veličković suggests a lot could be gained in terms of being able to analyse AI algorithms by marrying them with elements of classical algorithms, which are “nicely implemented and interpretable.” Classical algorithms are also impervious to changes in the input data such as an increase by a factor of 10, which can completely throw an algorithm based on machine learning. “The problem is they are trained to be really useful and give you an answer at all times so they won’t even give you a confidence estimate, they will just try to answer even if the answer is completely broken,” he adds. A lot of his research has focused on “<a href="https://www.sciencedirect.com/science/article/pii/S2666389921000994">out-of-distribution generalisation</a>” – the way classical algorithms work with any input data – to see how these features might be sewn into AI to extract the best of both worlds. “There’s a lot of research to be done still but our findings so far indicate that if you want out-of-distribution generalisation you need to look at what makes your problem special and put some of those properties inside your neural network model.”</p>
<p>Even what we know about the way the algorithm reaches a decision has caused concern when it comes to critical real-world applications – for example, <a href="https://www.bu.edu/articles/2023/do-algorithms-reduce-bias-in-criminal-justice/">to determine the likelihood that someone convicted of a crime will reoffend</a>. (More on this to come in the special issue article on ethics). With many commercial algorithms the details of the training data are unknown or essentially constitute the whole internet, which as Witten points out is “a pretty bad place a lot of the time.” While ChatGPT may seem an unlikely choice for anything like gauging risk for recidivism or cancer treatments, concerns remain over biases propagating in AI generated content we might consume through marketing campaigns and other activities. “Even just thinking about deploying AI/machine learning models in critical real-world settings without the associated statistical understanding is just very deeply problematic,” says Witten, emphasising the importance of not just statisticians but also ethicists for tackling these challenges.</p>
<p>The fact is many of us are already interacting with multiple machine learning/AI models on a daily basis through recommendations, search engines and predictive text. “If we are going to deploy these [machine learning algorithms] at scale in a way that will affect human lives, then we first need to understand the implications for humans of these models,” says Witten. “This includes both statistical and ethical considerations.”</p>
<p>Coming up: Forthcoming articles in this special issue will look at machine learning and human-level intelligence, issues around data, techniques for evaluation, gauging workforce impact, governance, best practice and living with AI</p>
</section>
<section id="also-in-the-ai-series" class="level2">
<h2 class="anchored" data-anchor-id="also-in-the-ai-series">Also in the AI series</h2>
<p><a href="https://realworlddatascience.net/foundation-frontiers/posts/2024/04/29/gen-ai-human-intel.html">Generative AI models and the quest for human-level artificial intelligence</a> <a href="https://realworlddatascience.net/foundation-frontiers/posts/2024/05/07/ai-series-3.html">datasets for optimised AI performance</a></p>
<div class="article-btn">
<p><a href="../../../../../foundation-frontiers/index.html">Explore more data science ideas</a></p>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-12">
<dl>
<dt>About the authors</dt>
<dd>
<strong>Anna Demming</strong> is a freelance science writer and editor based in Bristol, UK. She has a PhD from King’s College London in physics, specifically nanophotonics and how light interacts with the very small, and has been an editor for Nature Publishing Group (now Springer Nature), IOP Publishing and New Scientist. Other publications she contributes to include The Observer, New Scientist, Scientific American, Physics World and Chemistry World.
</dd>
</dl>
</div>
<div class="g-col-12 g-col-md-6">
<!-- copyright goes to the author, or to Royal Statistical Society if written by staff -->
<dl>
<dt>Copyright and licence</dt>
<dd>
© 2024 Anna Demming
</dd>
</dl>
<!-- confirm licence terms with contributor before publishing - must be Creative Commons licence, but different types of CC licences might be preferred -->
<p><a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> <img src="https://mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1" style="height:22px!important;vertical-align:text-bottom;"><img src="https://mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1" style="height:22px!important;margin-left:3px;vertical-align:text-bottom;"></a> This article is licensed under a Creative Commons Attribution 4.0 (CC BY 4.0) <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> International licence</a>. <!-- Add thumbnail image credit and any licence terms here -->Thumbnail image courtesy of Serenechan3 reproduced under a Creative Commons Attribution 4.0 (CC BY 4.0) <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> International licence</a></p>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>How to cite</dt>
<dd>
Demming Anna. 2024. “What is AI? Shedding light on the method and madness in these algorithms .” Real World Data Science, April 22, 2024. <a href="https://realworlddatascience.net/foundation-frontiers/posts/2024/04/22/ai-series-1.html">URL</a>
</dd>
</dl>
</div>
</div>
</div>
<!-- Make sure to update main site homepage (index.qmd) before publishing. See README for details. -->


</section>

 ]]></description>
  <category>AI</category>
  <category>algorithms</category>
  <category>statistics</category>
  <guid>https://realworlddatascience.net/foundation-frontiers/posts/2024/04/22/ai-series-1.html</guid>
  <pubDate>Mon, 22 Apr 2024 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/foundation-frontiers/posts/2024/04/22/images/neuralnetworks.jpg" medium="image" type="image/jpeg"/>
</item>
</channel>
</rss>
