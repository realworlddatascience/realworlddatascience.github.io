<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.31">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Brian Tarran">
<meta name="dcterms.date" content="2023-05-18">
<meta name="description" content="Do we need to understand the inner workings of large language models before we use them? Or, is it enough to simply teach people to recognise that model outputs can’t always be relied upon, and that some use cases are better than others? Members of the Royal Statistical Society’s Data Science and AI Section discuss these and other questions in part two of our Q&amp;A.">

<title>Large language models: Do we need to understand the maths, or simply recognise the limitations? – Real World Data Science</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../../../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../../../">
<link href="../../../../../images/rwds-favicon.png" rel="icon" type="image/png">
<script src="../../../../../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../../../../../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../../../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../../../site_libs/quarto-html/quarto-syntax-highlighting-e1a5c8363afafaef2c763b6775fbf3ca.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../../../site_libs/bootstrap/bootstrap-6cf018941c4e0f11d62ea116a4ebc572.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<link href="../../../../../site_libs/quarto-contrib/academicons-1.9.2/all.css" rel="stylesheet">
<link href="../../../../../site_libs/quarto-contrib/academicons-1.9.2/size.css" rel="stylesheet">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-1TTWB7YTR6"></script>

<script type="text/javascript">

window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-1TTWB7YTR6', { 'anonymize_ip': true});
</script>
<!-- Thank you to Ben Ruijl for the progress bar code!
Ben is on GitHub here: https://github.com/benruijl
And you can see the original code here: https://github.com/quarto-dev/quarto-cli/discussions/3842#discussioncomment-4591721 -->

<meta property="og:title" content="Large language models: Do we need to understand the maths, or simply recognise the limitations? – Real World Data Science">
<meta property="og:description" content="Do we need to understand the inner workings of large language models before we use them? Or, is it enough to simply teach people to recognise that model outputs can’t always be relied upon, and that some use cases are better than others? Members of the Royal Statistical Society’s Data Science and AI Section discuss these and other questions in part two of our Q&amp;A.">
<meta property="og:image" content="https://realworlddatascience.net/people-paths/posts/2023/05/18/images/google-deepmind-52afknBiUk4-unsplash.png">
<meta property="og:site_name" content="Real World Data Science">
<meta property="og:image:height" content="724">
<meta property="og:image:width" content="991">
<meta property="og:image:alt" content="3D render of a conceptual visualisation of large language models by artist Tim West. Photo by Google DeepMind on Unsplash.">
<meta name="twitter:title" content="Large language models: Do we need to understand the maths, or simply recognise the limitations? – Real World Data Science">
<meta name="twitter:description" content="Do we need to understand the inner workings of large language models before we use them? Or, is it enough to simply teach people to recognise that model outputs can’t always be relied upon, and that some use cases are better than others? Members of the Royal Statistical Society’s Data Science and AI Section discuss these and other questions in part two of our Q&amp;A.">
<meta name="twitter:image" content="https://realworlddatascience.net/people-paths/posts/2023/05/18/images/google-deepmind-52afknBiUk4-unsplash.png">
<meta name="twitter:site" content="@rwdatasci">
<meta name="twitter:image-height" content="724">
<meta name="twitter:image-width" content="991">
<meta name="twitter:image:alt" content="3D render of a conceptual visualisation of large language models by artist Tim West. Photo by Google DeepMind on Unsplash.">
<meta name="twitter:card" content="summary_large_image">
</head><body class="nav-fixed fullcontent quarto-light"><div id="progress-bar" style="width: 0%; height:4px; background-color: #939bc9;; position: fixed; top: 0px; z-index: 2000;"></div>

<script id="progressbar" type="text/javascript">

document.addEventListener("DOMContentLoaded", function() {

    const bar = document.querySelector('#progress-bar');
    const post = document.querySelector('#quarto-content');
    const html = document.documentElement;
    
    const height = post.scrollHeight + post.offsetTop;
    
    window.addEventListener('scroll', () => {
        bar.style.width = (html.scrollTop / (height- html.clientHeight)) * 100 + '%';
    });
});
</script>


<link rel="stylesheet" href="../../../../../rwds.css">




<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top quarto-banner">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a href="../../../../../index.html" class="navbar-brand navbar-brand-logo">
    <img src="../../../../../images/rwds-logo-150px.png" alt="Real World Data Science brand" class="navbar-logo">
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../../../../case-studies/index.html"> 
<span class="menu-text">Case studies</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../../../foundation-frontiers/index.html"> 
<span class="menu-text">Foundation &amp; Frontiers</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../../../people-paths/index.html"> 
<span class="menu-text">People &amp; Paths</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../../../viewpoints/index.html"> 
<span class="menu-text">Viewpoints</span></a>
  </li>  
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-about-rwds" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">About RWDS</span>
    </a>
    <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="nav-menu-about-rwds">    
        <li>
    <a class="dropdown-item" href="../../../../../about-rwds.html">
 <span class="dropdown-text">Who we are</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../../../../contributor-docs/call-for-contributions.html">
 <span class="dropdown-text">How to contribute</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../../../../CODE_OF_CONDUCT.html">
 <span class="dropdown-text">Code of conduct</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../../../../contact.html">
 <span class="dropdown-text">Contact us</span></a>
  </li>  
    </ul>
  </li>
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">Large language models: Do we need to understand the maths, or simply recognise the limitations?</h1>
                  <div>
        <div class="description">
          <p>Do we need to understand the inner workings of large language models before we use them? Or, is it enough to simply teach people to recognise that model outputs can’t always be relied upon, and that some use cases are better than others? Members of the Royal Statistical Society’s Data Science and AI Section discuss these and other questions in part two of our Q&amp;A.</p>
        </div>
      </div>
                          <div class="quarto-categories">
                <div class="quarto-category">Large language models</div>
                <div class="quarto-category">AI</div>
                <div class="quarto-category">Communication</div>
                <div class="quarto-category">Regulation</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Brian Tarran </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">May 18, 2023</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">





<p><a href="https://realworlddatascience.net/people-paths/posts/2023/05/11/chatgpt-data-science-pt1.html">Part 1 of our conversation with the Royal Statistical Society’s Data Science and AI (DS&amp;AI) Section</a> ended on a discussion around the need to verify that large language models (LLMs), when embedded in workflows and operational processes, are working as intended. But there was also acknowledgement that this could be difficult to achieve, not least of all because, as Giles Pavey said, “nobody knows exactly how these things work – not even the people who build them.” And then, of course, there is the speed at which developments are taking place: Trevor Duguid Farrant made the point that an expert may not even have a chance to finish reviewing the latest version of an LLM before a new iteration is rolled out.</p>
<p>These issues – of verification, explainability and interpretability – are of particular interest to data scientists like Anjali Mazumder, whose work focuses on the impact AI technologies could have, and are having, on society and individuals.</p>
<p>In part 2 of our Q&amp;A about ChatGPT and other LLM-powered advances, and what all of this might mean for data science, Mazumder kicks off the conversation by setting out her perspective.</p>
<p>Our full list of interviewees, in order of appearance, are:</p>
<ul>
<li><p><strong>Anjali Mazumder</strong>, AI and Justice &amp; Human Rights Theme Lead at the Alan Turing Institute, and DS&amp;AI committee member.</p></li>
<li><p><strong>Detlef Nauck</strong>, head of AI and data science research at BT, and editorial board member, Real World Data Science.</p></li>
<li><p><strong>Martin Goodson</strong>, CEO and chief scientist at Evolution AI, and DS&amp;AI committee member.</p></li>
<li><p><strong>Louisa Nolan</strong>, head of public health data science, Public Health Wales, and DS&amp;AI secretary.</p></li>
<li><p><strong>Piers Stobbs</strong>, VP science at Deliveroo, and DS&amp;AI committee member.</p></li>
<li><p><strong>Trevor Duguid Farrant</strong>, senior principal statistician at Mondelez International, and DS&amp;AI committee member.</p></li>
<li><p><strong>Giles Pavey</strong>, global director for data science at Unilever, and DS&amp;AI vice-chair.</p></li>
<li><p><strong>Adam Davison</strong>, head of data science at the Advertising Standards Authority, and DS&amp;AI committee member.</p></li>
</ul>
<div class="keyline">
<hr>
</div>
<p><strong>Anjali Mazumder:</strong> I work in research, but I also sit in the crux of government, industry, and civil society, looking at how they’re using these technologies. For me, it’s about knowing what the opportunities are but also understanding the limitations, the risks and the harms, and how we balance those and put in place oversight mechanisms that act as safeguards to ensure that these technologies don’t cause harm. We’re taking a very socio-technical approach that requires an interdisciplinary team to understand these issues and what should be done. Part of this is about not only the outcomes and the impact but also the upstream side of it – recognising that these models have been built on the work of people who have done the labelling, and that this also has implications – to say nothing of the associated environmental issues or energy issues!</p>
<p><strong>Detlef Nauck:</strong> I think the regulators really have to look at this. It has come completely out of left field for them. All the regulators that we are monitoring, they regulate the space as it was three years ago – they are mainly concerned about predictive models and bias. But if you look at, say, what Microsoft wants to do – putting GPT into Office 365 and into Bing – that will completely change how people interact with and consume information. I think the large tech companies really have a responsibility here, when they make this public, to make sure that people understand what this technology actually is, and how it can be used and has to be used.</p>
<p>Also, they need to open up about how these things have been built. There are a lot of stories around <a href="https://time.com/6247678/openai-chatgpt-kenya-workers/">how OpenAI used cheap labour in order to do the labelling and reinforcement learning for ChatGPT</a>, and these things have to become public knowledge; they need to become part of some kind of Kitemark for these models: “Ethically built, properly checked, hallucinate only a little bit. Whatever you do, don’t take it for granted. Check it!” That’s the kind of disclaimer they need to put on these models.</p>
<div class="pullquote-container">
<div class="grid">
<div class="g-col-12 g-col-lg-12 pullquote-grid pullquote">
<p><img src="../../../../../images/pullquote-purple.png" class="img-fluid" width="50"></p>
<p>If you look at what Microsoft wants to do – putting GPT into Office 365 and into Bing – that will completely change how people interact with and consume information. Large tech companies really have a responsibility here, when they make this public, to make sure that people understand what this technology actually is.</p>
</div>
</div>
</div>
<p><strong>Regulatory principles always seem to stress that AI systems should be understandable, and we should be able to explain how we get particular outputs. But a lot of our conversation has focused on how we don’t really know how these models work. So, is that, in itself, a problem, and is it something that the data science community can help with – to dig into how these things work and try and get that across – to help meet these principles of explainability and interpretability?</strong></p>
<p><strong>DN:</strong> That’s a very specialist job, I would say – specialist research into how these mathematical structures work. It’s not something I could do, and I’ve not seen any significant work there. One thing that we are interested in is whether we can do knowledge embedding, so that you can “teach” concepts that these models can then use to communicate, and that would lead to smaller systems where you have some understanding of what’s inside. But all of this kind of work, I think, is very much just beginning.</p>
<p><strong>Martin Goodson:</strong> Do we actually need this? There’s sort of a big assumption there that you need to understand how LLMs work in order to build in the kinds of things that we care about as a society. But we don’t understand how humans think. Of course, we can ask a human, “Why did you make that decision?” You can’t understand the cause of that decision – that’s a complex neuroscience question. But you can ask what the reason is for making a decision, and you can ask an LLM what its reasoning is as well. I think a lot of these questions about explainability are stuck in the past, when you’re trying to explain how a linear model works. It’s really not the same thing when you’ve got an LLM where you can just say, “Why did you make that decision?”</p>
<p><strong>Louisa Nolan:</strong> I was going to say something very similar. Most people don’t know how most things work…</p>
<p><strong>DN:</strong> My point was, these things are largely still like the Improbability Drive in the <em>Hitchhiker’s Guide to the Galaxy</em>. You press a button, and you don’t really know what comes out, and that’s the problem we need to get our heads around.</p>
<p><strong>LN:</strong> But people don’t know what percentages are, and yet we still use them for decision making. I don’t think people need to understand the maths behind LLMs, and I think it would be a hopeless job to expect everybody to do that. What we do need to understand is what LLMs can and can’t do. What’s the body of work that they are drawing from? What isn’t in there? What are the things that you need to check? So, for some things, it’ll be brilliant: if you’ve written something and you want it rewritten for a nine-year-old; if you want to summarise a paper; if you want to write code, as long as you already know how to code – these could be real labour-saving tasks. If you’re using ChatGPT to write a thesis about something that you haven’t looked at, that’s where the danger is. It’s this kind of simple understanding that people need to get in their heads – and the maths, except for the people who care about it, is beside the point, and probably detrimental, because it means that people won’t engage with it.</p>
<p><strong>DN:</strong> I agree, but I wasn’t talking about the general public. I meant, the people who build these things – they should know what they’re doing.</p>
<div class="pullquote-container">
<div class="grid">
<div class="g-col-12 g-col-lg-12 pullquote-grid pullquote">
<p><img src="../../../../../images/pullquote-purple.png" class="img-fluid" width="50"></p>
<p>There’s a big assumption that you need to understand how LLMs work in order to build in the kinds of things that we care about as a society. But we don’t understand how humans think. You can ask a human what their reason is for making a decision, and you can ask an LLM what its reasoning is as well.</p>
</div>
</div>
</div>
<p><strong>We talked there about communication. There was a webinar recently by the <a href="https://rss.org.uk/membership/rss-groups-and-committees/groups/glasgow/">Royal Statistical Society’s Glasgow Local Group</a>, and the presenter, <a href="https://www.hannahrosekirk.com/">Hannah Rose Kirk</a>, showed how you can take tabular data and statistical results and ask ChatGPT to produce a nice paragraph or two that explains the numbers. Is this the sort of thing that any of you have experimented with? Have you had any successes at using ChatGPT to translate data into readable English that decision makers can act on?</strong></p>
<p><strong>Piers Stobbs:</strong> I have an interesting use case. We had a basic survey: 200-odd responses, multiple languages, and we just said, “Please summarise the results of this survey contained in this CSV file.” And it came up with five or six relevant bullet points. What was amazing was that we could then interrogate it. For example, “Please compare the results that were in English versus in French, and describe the differences.” Again, it did it, but then you have the issue of, was it all correct? Well, the bulk of it was. Now I am intrigued by whether you can ask it to do correlations and some actual statistical things on a dataset, and does it get that right? I don’t know. We’ve not really got to that. But, to go back to one of the earlier discussion points around productivity, that initial survey work could have easily taken a week of someone’s time if we didn’t run it through ChatGPT.</p>
<p><strong>Trevor Duguid Farrant:</strong> Piers, in this case you’re interested in checking and seeing if it’s right. If you’d asked a group of people to do that survey for you and get the results, you’d have just accepted whatever they gave you back. You wouldn’t have questioned it.</p>
<p><strong>PS:</strong> That’s true. And the results were plausible, certainly.</p>
<p><strong>AM:</strong> I think one of the challenges is that the results could seem like they’re plausible, right – whether that’s a statistical output or a text output. This was not a proper experiment, but I asked ChatGPT about colleagues and friends who are quite prominent researchers, asking, “Who is so-and-so?”, and it produced biographies that were quite plausibly them, but it wasn’t them. It might have listed the correct PhD, say, but the date was off by a year, or the date was correct but it was from the wrong institution. So, depending on what the issue is, these seemingly plausible results could have more serious implications.</p>
<p><strong>LN:</strong> So, just to join those two things together: for me, the question is not, “Do we understand how ChatGPT works?” As Martin says, we don’t understand how humans work, and surely we’re trying to develop something that enhances human thinking in some way. The more important question for me is, “How do we know that what is produced is useful?”</p>
<div class="pullquote-container">
<div class="grid">
<div class="g-col-12 g-col-lg-12 pullquote-grid pullquote">
<p><img src="../../../../../images/pullquote-purple.png" class="img-fluid" width="50"></p>
<p>For me, the question is not, ‘Do we understand how ChatGPT works?’ We don’t understand how humans work, and surely we’re trying to develop something that enhances human thinking in some way. The more important question is, ‘How do we know that what is produced is useful?’</p>
</div>
</div>
</div>
<p><strong>Giles, <a href="https://realworlddatascience.net/people-paths/posts/2023/05/11/chatgpt-data-science-pt1.html">you mentioned previously that you’re doing some work at Unilever around how to minimise hallucination</a>. I don’t know how much you can say on what direction that’s going in, and how successful you expect that to be, but that’s obviously going to be a really important part of refining these models to be more widely usable.</strong></p>
<p><strong>Giles Pavey:</strong> I’m by no means an expert, but there’s quite a lot you can do with both the architecture of it and also the pre-prompts that you put in – more or less saying, “Quote what the source is, and if you’re not sure, then tell me you’re not sure.” I think what’s interesting is the question of whether we’ll have to rely on OpenAI or Microsoft to do that work, and it will be just another thing that we have to trust them for. Or, will it be something that people within an organisation can put in themselves?</p>
<p><strong>MG:</strong> I think it’s absolutely critical that open-source models are developed that can compete with these tech companies, otherwise there’s going to be a huge transfer of power to these companies.</p>
<p><strong>GP:</strong> Arguably, the single biggest issue is, who elected Sam Altman (no-one) and are we as society happy with him having so much power over our future?</p>
<p><strong>To close us out, I’d like to return to <a href="https://realworlddatascience.net/people-paths/posts/2023/05/11/chatgpt-data-science-pt1.html">a question Trevor posed earlier</a>, which is: How might organisations like the Royal Statistical Society help companies to embrace LLMs and start using them, so that everyone can benefit from the technology?</strong></p>
<p><strong>Adam Davison:</strong> My instinct is that there’s some great parallel here with the stuff that the Data Science and AI Section have been doing in general, where we’ve said, “OK, there’s lots of good advice out there on how to do things in data science, but how do you make it practical? How do you make it real? How do you apply those ethical principles? How do you make sure you have people with the right technical understanding in charge of projects to get value?” If, five years ago, the hype around data science was leading organisations to hire 100 data scientists in the hope that something innovative would happen, well then, we don’t want those same organisations now thinking that they need to hire 100 prompt engineers and keep their fingers crossed for something special. Our focus has been on “<a href="https://realworlddatascience.net/viewpoints/newsletter/">industrial strength data science</a>”, so I think we can extend that to show what “industrial strength LLM usage” looks like in practice.</p>
<div class="callout callout-style-simple callout-note" style="margin-top: 2.25rem;">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-body-container">
<p>Want to hear more from the RSS Data Science and AI Section? Sign up for its newsletter at <a href="https://rssdsaisection.substack.com/">rssdsaisection.substack.com</a>.</p>
</div>
</div>
</div>
<div class="nav-btn-container">
<div class="grid">
<div class="g-col-12 g-col-sm-6">
<div class="nav-btn">
<p><a href="../../../../../people-paths/posts/2023/05/11/chatgpt-data-science-pt1.html">← Read part one</a></p>
</div>
</div>
<div class="g-col-12 g-col-sm-6">
<div class="nav-btn">
<p><a href="../../../../../people-paths/index.html">Back to Careers</a></p>
</div>
</div>
</div>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-12">
<dl>
<dt>Copyright and licence</dt>
<dd>
© 2023 Royal Statistical Society
</dd>
</dl>
<p><a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> <img src="https://mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1" style="height:22px!important;vertical-align:text-bottom;"><img src="https://mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1" style="height:22px!important;margin-left:3px;vertical-align:text-bottom;"></a> This interview is licensed under a Creative Commons Attribution 4.0 (CC BY 4.0) <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> International licence</a>. Images are not covered by this licence. Thumbnail image by <a href="https://unsplash.com/@deepmind?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Google DeepMind</a> on <a href="https://unsplash.com/photos/52afknBiUk4?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Unsplash</a>.</p>
</div>
<div class="g-col-12 g-col-md-12">
<dl>
<dt>How to cite</dt>
<dd>
Tarran, Brian. 2023. “Large language models: Do we need to understand the maths, or simply recognise the limitations?” Real World Data Science, May 18, 2023. <a href="https://realworlddatascience.net/people-paths/posts/2023/05/18/chatgpt-data-science-pt2.html">URL</a>
</dd>
</dl>
</div>
</div>
</div>



</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp("https:\/\/realworlddatascience\.net\/");
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<input type="hidden" id="giscus-base-theme" value="light">
<input type="hidden" id="giscus-alt-theme" value="dark">
<script>
  function loadGiscus() {
    // Function to get the theme based on body class
    const getTheme = () => {
      let baseTheme = document.getElementById('giscus-base-theme').value;
      let altTheme = document.getElementById('giscus-alt-theme').value;
      return document.body.classList.contains('quarto-dark') ? altTheme : baseTheme;
    };
    const script = document.createElement("script");
    script.src = "https://giscus.app/client.js";
    script.async = true;
    script.dataset.repo = "realworlddatascience/realworlddatascience.github.io";
    script.dataset.repoId = "R_kgDOILnnig";
    script.dataset.category = "General";
    script.dataset.categoryId = "DIC_kwDOILnnis4CSt2s";
    script.dataset.mapping = "title";
    script.dataset.reactionsEnabled = "1";
    script.dataset.emitMetadata = "0";
    script.dataset.inputPosition = "top";
    script.dataset.theme = getTheme();
    script.dataset.lang = "en";
    script.crossOrigin = "anonymous";
    // Append the script to the desired div instead of at the end of the body
    document.getElementById("quarto-content").appendChild(script);
  }
  loadGiscus();
</script>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
<p><a href="../../../../../LICENCE.html">Copyright © 2024 Royal Statistical Society</a></p>
</div>   
    <div class="nav-footer-center">
      <ul class="footer-items list-unstyled">
    <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/realworlddatascience">
      <i class="bi bi-github" role="img" aria-label="GitHub">
</i> 
    </a>
  </li>  
    <li class="nav-item">
    <a class="nav-link" href="https://zenodo.org/communities/realworlddatascience">
<p><i class="ai  ai-zenodo ai-2xl"></i></p>
</a>
  </li>  
    <li class="nav-item compact">
    <a class="nav-link" href="https://www.linkedin.com/showcase/rss-real-world-data-science">
      <i class="bi bi-linkedin" role="img" aria-label="LinkedIn">
</i> 
    </a>
  </li>  
    <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com/rwdatasci">
      <i class="bi bi-twitter-x" role="img" aria-label="Twitter/X">
</i> 
    </a>
  </li>  
    <li class="nav-item compact">
    <a class="nav-link" href="https://fosstodon.org/@rwdatasci">
      <i class="bi bi-mastodon" role="img" aria-label="Mastodon">
</i> 
    </a>
  </li>  
    <li class="nav-item compact">
    <a class="nav-link" href="../../../../../feeds.html">
      <i class="bi bi-rss" role="img" aria-label="RWDS rss">
</i> 
    </a>
  </li>  
</ul>
    <div class="toc-actions"><ul><li><a href="https://github.com/realworlddatascience/realworlddatascience.github.io/edit/main/people-paths/posts/2023/05/18/chatgpt-data-science-pt2.qmd" class="toc-action"><i class="bi bi-github"></i>Edit this page</a></li><li><a href="https://github.com/realworlddatascience/realworlddatascience.github.io/issues/new" class="toc-action"><i class="bi empty"></i>Report an issue</a></li></ul></div></div>
    <div class="nav-footer-right">
<p><a href="../../../../../ts-and-cs.html">Terms &amp; Conditions</a></p>
</div>
  </div>
</footer>




</body></html>