<?xml version="1.0" encoding="UTF-8"?>
<rss  xmlns:atom="http://www.w3.org/2005/Atom" 
      xmlns:media="http://search.yahoo.com/mrss/" 
      xmlns:content="http://purl.org/rss/1.0/modules/content/" 
      xmlns:dc="http://purl.org/dc/elements/1.1/" 
      version="2.0">
<channel>
<title>Real World Data Science</title>
<link>https://realworlddatascience.net/news-and-views/index.html</link>
<atom:link href="https://realworlddatascience.net/news-and-views/index.xml" rel="self" type="application/rss+xml"/>
<description></description>
<image>
<url>https://realworlddatascience.net/rss-white-logo.png</url>
<title>Real World Data Science</title>
<link>https://realworlddatascience.net/news-and-views/index.html</link>
<height>58</height>
<width>144</width>
</image>
<generator>quarto-1.2.335</generator>
<lastBuildDate>Thu, 02 Mar 2023 00:00:00 GMT</lastBuildDate>
<item>
  <title>Using ‘basket complementarity’ to make product recommendations</title>
  <dc:creator>Moinak Bhaduri</dc:creator>
  <link>https://realworlddatascience.net/news-and-views/datasciencebites/posts/2023/03/02/basket-complementarity.html</link>
  <description><![CDATA[ 




<p>Anyone who has ever worked in a retail store will be familiar with the concept of cross-selling. A customer wants a can of paint? Try to sell them some paintbrushes. That new cellphone they’ve just decided to buy? They’ll probably need a case to protect it. Online retailers (and digital services of all sorts) have taken this idea and run with it, to great success. Sophisticated algorithms sort through data on a customer’s past transactions, and those of similar-looking customers, to identify and recommend other products a customer might be interested in.</p>
<p>A large amount of cross-selling, whether attempted in store by a sales assistant or online by an algorithm, relies on the concept of <em>complementarity</em>: that certain products are often bought and/or used together. Relationships between products might be obvious – paint and paintbrushes, for example – or they may be obscure and only revealed through the analysis of large datasets. In a 2021 paper that highlights complementarity’s relevance to association analysis, Puka and Jedrusik put forward “<a href="https://www.mdpi.com/0718-1876/16/4/39">a new measure of complementarity in market basket data</a>”, which sheds light on how product recommendations can be derived.</p>
<div class="callout-note callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-1-contents" aria-controls="callout-1" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
About the paper
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-1" class="callout-1-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<p><strong>Title:</strong> A new measure of complementarity in market basket data</p>
<p><strong>Author(s) and year:</strong> Radosław Puka and Stanislaw Jedrusik (2021)</p>
<p><strong>Status:</strong> Published in the <em>Journal of Theoretical and Applied Electronic Commerce Research</em>, open access: <a href="https://www.mdpi.com/0718-1876/16/4/39">HTML</a>, <a href="https://www.mdpi.com/0718-1876/16/4/39/pdf?version=1609984879">PDF</a>.</p>
</div>
</div>
</div>
<p>Inspired by complementarity-based ideas prevalent in microeconomics, Puka and Jedrusik begin by collecting some established ideas from traditional market basket analysis, the key one being “confidence”. In this case, we’re talking about the confidence that item A leads (in a way) to item B (which we can express in notation as <em>conf</em>({A} → {B})). Take a look at Table 1 (below), which presents a numbered list of 18 shopping trips, with details of what was purchased on each trip. Notice how two of the trips (1 and 3) resulted in sales of both milk (B) and cornflakes (A), while five trips (1, 3, 7, 17, and 18) had cornflakes. Under the assumption that someone already has cornflakes in their trolley, the probability that they will buy milk is 2/5 = 0.4. So, <em>conf</em>({cornflakes} → {milk}) = 0.4. The closer this number gets to one, the more automatic the cornflakes–milk connection becomes. This number can therefore be used to recommend an item that is related in some way to another already bought.</p>
<div class="column-body-outset">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="images/tab1-fig1.png"><img src="https://realworlddatascience.net/news-and-views/datasciencebites/posts/2023/03/02/images/tab1-fig1.png" class="img-fluid figure-img"></a></p>
</figure>
</div>
</div>
<div class="grid">
<div class="g-col-12 g-col-md-4">
<p><strong>Table 1:</strong> A list (with each row representing a trip to a grocery store) that can be seen in one of two ways: (a) a record of what 18 different people bought, or (b) a history of one person’s purchases over 18 trips. The list is similar to the one examined by Puka and Jedrusik, except for the last three rows. These trips, under interpretation (b) may help us develop an understanding of a single shopper’s preferences.</p>
</div>
<div class="g-col-12 g-col-md-8">
<p><strong>Figure 1:</strong> Basket complementarity under varying tolerance. The horizontal axis reports the probability that someone will buy item B under the assumption that A is already in their shopping trolley (i.e., <em>conf</em>({A} → {B})). The vertical axis reports the opposite: the chance that someone will go for A given that B is already in the cart (i.e., <em>conf</em>({B} → {A})). For any pair of items, these two probabilities can be found and, when plotted in 2D, a pair of items generates a single point. The more similar the two probabilities are for each pair, the closer the point comes to the line of equality (the red dashed line that runs diagonally through the origin), and the more complementary the items become. It’s rare that a dot will land exactly on the line of equality, so the green and orange lines parallel to the red line mark how far off a dot is from this ideal setting, using different levels of tolerance. From this we may say, for example, that cornflakes and milk are more complementary to each other than bread rolls and butter, as the first pairing lies closer to the line of equality.</p>
</div>
</div>
<section id="asymmetry-and-tolerance" class="level2">
<h2 class="anchored" data-anchor-id="asymmetry-and-tolerance">Asymmetry and tolerance</h2>
<p>Milk and cornflakes are reasonably complementary, and we can see from Figure 1 above that, regardless of whether you start by picking up milk or cornflakes, the probabilities of a shopper buying the other item are broadly similar: <em>conf</em>({cornflakes} → {milk}) = 0.4, while <em>conf</em>({milk} → {cornflakes}) = 0.33. There is a small amount of asymmetry in the probabilities in this particular example, but asymmetry can be more extreme for other pairs of items. This leads to the idea of one- and two-sided complementarity. Two items sharing a smallish asymmetry – like milk and cornflakes – will be connected through two-sided complementarity, while large asymmetries indicate one-sided complementarity. Such imbalances will be quite common when, for instance, items of hugely different prices are involved. When someone buys a house, for example, they may want to buy a bookcase, but buying a bookcase doesn’t mean someone wants to buy a house: this would be an instance of one-sided complementarity.</p>
<p>Puka and Jedrusik capitalize on this observation. They define two items to be “basket complementary” if the two probabilities – the normal and its opposite – remain close and reasonably high. The items need to share a bond that is blind to the direction: seeing you bought one, no matter which, means you are (almost equally) likely to buy the other.</p>
<p>It is rare that the two probabilities should be exactly the same, of course, and the authors allow some deviation. Along the red diagonal line of perfect equality (Figure 1) we may lay tolerance bands marking degrees of product inseparability. This, if need be, may lead to the notion of being complementary at such-and-such a tolerance level – 0%, 1%, 5%, etc. – generating a score of sorts. In cases where a dot representing the two-way dependencies between two items falls within a narrow band – corresponding to a smaller tolerance – the more inseparable the items are, and the more sensible a cross-selling recommendation may become.</p>
</section>
<section id="in-conclusion" class="level2">
<h2 class="anchored" data-anchor-id="in-conclusion">In conclusion</h2>
<p>A large part of the world we inhabit, particularly the economy, is powered by recommendations: from strangers, friends and algorithms. That applies not only to the things we buy but also to the things we watch or read. (Perhaps you arrived at this article because of a tweet that Twitter thought you might like, or maybe it was suggested to you by Google News because of your past reading habits.) Whatever the intent of these recommendations, the key challenge is in knowing which two things are functionally or thematically intertwined. Which item or product is, by default, synonymous with which? Puka and Jedrusik deliver an answer: two items that are basket complementary to each other, preferably at a slim tolerance, are inextricably linked. One may be safely offered – perhaps always – whenever the other is already in the shopping basket.</p>
<p>The relative simplicity and interpretability of basket complementary may provide small-scale retailers, starved of analytical wherewithal, a sane and safe strategy for developing their product offer. It might also serve as a benchmark to keep other, more sophisticated recommendation algorithms in check. (In weather forecasting, for example, it is often seen that <a href="https://www.sciencedirect.com/science/article/pii/S0022169415000414">naive benchmarks</a> – such as using today’s temperature to predict tomorrow’s – frequently outperform more advanced models.)</p>
<p>Basket complementarity could also be used to help individuals understand their own shopping habits and the links between the things they buy. I’ve built <a href="https://moinak.shinyapps.io/MarketBasketDashboard/">an interactive dashboard</a> where you can enter your own receipt lists and filter associations based on various confidence thresholds. The <a href="https://github.com/moinakbhaduri/MarketBasketAnalysis">underlying code</a> is also available.</p>
 <iframe src="https://moinak.shinyapps.io/MarketBasketDashboard/" style="border: none; width: 100%; height: 500px" frameborder="0"></iframe>
<hr>
<div class="grid">
<div class="g-col-12 g-col-md-6">
<dl>
<dt>About the author</dt>
<dd>
<strong>Moinak Bhaduri</strong> is assistant professor in the Department of Mathematical Sciences, Bentley University. He studies spatio-temporal Poisson processes and others like the self-exciting Hawkes or log-Gaussian Cox processes that are natural generalizations. His primary interest includes developing change-detection algorithms in systems modeled by these stochastic processes, especially through trend permutations.
</dd>
</dl>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>About DataScienceBites</dt>
<dd>
<a href="../../../../../../news-and-views/datasciencebites/index.html"><strong>DataScienceBites</strong></a> is written by graduate students and early career researchers in data science (and related subjects) at universities throughout the world, as well as industry researchers. We publish digestible, engaging summaries of interesting new pre-print and peer-reviewed publications in the data science space, with the goal of making scientific papers more accessible. Find out how to <a href="../../../../../../contributor-docs/datasciencebites.html">become a contributor</a>.
</dd>
</dl>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>Copyright and licence</dt>
<dd>
© 2023 Moinak Bhaduri
</dd>
</dl>
<p><a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> <img style="height:22px!important;vertical-align:text-bottom;" src="https://realworlddatascience.net/news-and-views/datasciencebites/posts/2023/03/02/https:/mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://realworlddatascience.net/news-and-views/datasciencebites/posts/2023/03/02/https:/mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"></a> This work is licensed under a Creative Commons Attribution 4.0 (CC BY 4.0) <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> International licence</a>, except where otherwise noted.</p>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>How to cite</dt>
<dd>
Bhaduri, Moinak. 2023. “Using ‘basket complementarity’ to make product recommendations.” Real World Data Science, March 2, 2023. https://realworlddatascience.net/news-and-views/datasciencebites/posts/2023/03/02/basket-complementarity.html
</dd>
</dl>
</div>
</div>
<hr>


</section>

 ]]></description>
  <category>Market basket analysis</category>
  <category>Recommendation systems</category>
  <category>Complementarity</category>
  <guid>https://realworlddatascience.net/news-and-views/datasciencebites/posts/2023/03/02/basket-complementarity.html</guid>
  <pubDate>Thu, 02 Mar 2023 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/news-and-views/datasciencebites/posts/2023/03/02/images/marjan-blan-marjanblan-3nURJV_L7-8-unsplash.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>Data science can help close the ‘digital skills’ gap, or so it seems</title>
  <dc:creator>Brian Tarran</dc:creator>
  <link>https://realworlddatascience.net/news-and-views/editors-blog/posts/2023/02/14/digital-skills.html</link>
  <description><![CDATA[ 




<p>Digital skills. We all need them. Employers say they want them, but there aren’t enough to go around. Supply can’t meet demand, so we’re left with a gap – a digital skills gap. But what are <em>digital skills</em> exactly?</p>
<p>This is a question that was asked repeatedly, in various different constructions, by <a href="https://members.parliament.uk/member/4092/career">Stephen Metcalfe MP</a>, chairing a meeting of the <a href="https://www.scienceinparliament.org.uk/information/about/">Parliamentary and Scientific Committee</a> on Tuesday, February 7. I went along to the meeting as an observer, hoping to hear an answer to that very question.</p>
<p>What I got was several different answers – no single solid definition, but a reasonable sense that boosting data science skills would go a long way towards closing the digital skills gap.</p>
<section id="survey-says" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="survey-says">Survey says…</h2>
<p>The committee meeting was sponsored by the Institution of Engineering and Technology (IET), and the main focus of discussion was the results of IET’s <a href="https://www.theiet.org/impact-society/factfiles/innovation-and-skills-factfiles/iet-skills-survey/skills-for-a-digital-future-survey/">skills for a digital future survey</a>, based on a YouGov poll of 1,235 respondents drawn from engineering employers (defined as “employers who employ at least one engineering and technology employee in the UK”).</p>

<div class="no-row-height column-margin column-container"><div class="">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://realworlddatascience.net/news-and-views/editors-blog/posts/2023/02/14/images/billetto-editorial-YvLd3xbo0ac-unsplash.jpg" class="img-fluid figure-img" alt="Woman painting while wearing virtual reality headset. Photo by Billetto Editorial on Unsplash." width="500"></p>
<p></p><figcaption class="figure-caption">Digital skills, including AI skills, are not only required of engineers, says the IET’s Graham Herries. Generative AI tools like Stable Diffusion threaten to shake-up the creative industries. (Photo by <a href="https://unsplash.com/@billetto?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Billetto Editorial</a> on <a href="https://unsplash.com/photos/YvLd3xbo0ac?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Unsplash</a>)</figcaption><p></p>
</figure>
</div>
</div></div><p>Kicking off the discussion was Graham Herries, an engineering director and chair of the IET’s Innovation and Skills Panel, who drew attention to the harms that the digital skills gap is reportedly having. Of those respondents who identified skills gaps in their own organisations, 49% pointed to a reduction in productivity, while 35% said skills shortages were restricting company growth.</p>
<p>As the hot topic of the day, <a href="../../../../../../news-and-views/editors-blog/posts/2023/01/27/talking-chatgpt.html">ChatGPT inevitably came up during the discussion</a>. Herries sees it as a disruptive force, and 36% of all respondents believe artificial intelligence (AI) skills will be important for their engineers to have within five years (24% say they are important <em>now</em>). But AI skills are important for non-engineers too, argued Herries, as he pointed to stirrings in the creative industries caused by generative art tools such as <a href="https://stability.ai/blog/stable-diffusion-public-release">Stable Diffusion</a>.</p>
<p>Herries therefore puts AI skills under the broad umbrella of “digital skills”. But, to him, it’s not enough to simply be able to use AI technology; rather, users should know enough to be able to ask the right questions about the provenance of the data used to train the AI, its quality and biases, etc. This was a point developed further by Yvonne Baker, an engineer and the CEO of STEM Learning. Baker talked about digital skills as being both the ability to use digital technology and also to understand its limitations. Yet another perspective was offered by Rab Scott, director of industrial digitalisation at the University of Sheffield’s Advanced Manufacturing Research Centre. Scott defined digital skills in the context of <a href="https://rss.onlinelibrary.wiley.com/doi/10.1111/1740-9713.01523">quality control systems in industry 4.0</a>: it’s about knowing how and where to place a sensor to collect data about the manufacturing process, to feed that data into a data collection system, analyse the data for insights, and use those insights to inform decision-making.</p>
</section>
<section id="closing-the-gap" class="level2">
<h2 class="anchored" data-anchor-id="closing-the-gap">Closing the gap</h2>
<p>Further definitions of “digital skills” are to be found in the <a href="https://www.theiet.org/impact-society/factfiles/innovation-and-skills-factfiles/iet-skills-survey/skills-for-a-digital-future-survey/">IET’s published report</a>. Survey respondents were encouraged to describe the term in their own words, so we see things like:</p>
<ul>
<li><p>“the ability to understand, process and analyse data.”</p></li>
<li><p>“Coding, programming, software design, use of social media for marketing and communicating with stakeholders, data visualisation, work that relies solely on the use [of] online systems.”</p></li>
</ul>
<p>When respondents were asked what skills were lacking in both the external labour market and their internal workforce, around a fifth cited “more complex numerical/statistical skills and understanding”. And when looking to the future and to the skills anticipated to be important areas for growth in the next five years, 39% of respondents picked “data analytics” while 31% said “artificial intelligence and machine learning”.</p>
<p>So, perhaps you now understand why I left the meeting with the feeling that more data science skills, more data science training, could help address the shortfall in “digital skills”.</p>
<p>But how exactly can we equip more people with the right skills? At one point during the discussion, Metcalfe told the meeting that he was still looking for a key takeaway, something he could take to the Secretary of State and say, ‘This is what we need to embed in the curriculum’. What was offered instead was a range of possible solutions.</p>
<p>The IET survey found broad backing for government support for reskilling: 40% of respondents favoured grants or loans for training (and retraining) programmes, 39% would like more funding for apprenticeships, while 33% think there should be better carers advice and guidance in schools and colleges.</p>
<p>Baker also made the case for digital skills to be taught in schools as part of every subject, not just in computer science lessons, and that teachers would need to be supported to deliver this.</p>
<p>But how would <em>you</em> close the “digital skills” gap, if given the chance?</p>
<div class="callout-tip callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Have you got news for us?
</div>
</div>
<div class="callout-body-container callout-body">
<p>Is there a recent data science story you’d like our team to discuss? Do you have your own thoughts to share on a hot topic, or a burning question to put to the community? If so, either comment below or <a href="../../../../../../contact.html">contact us</a>.</p>
</div>
</div>
<section id="back-to-editors-blog" class="level6">
<h6 class="anchored" data-anchor-id="back-to-editors-blog"><strong>← Back to <a href="../../../../../../news-and-views/editors-blog/index.html">Editors’ blog</a></strong></h6>
<hr>
<p xmlns:cc="http://creativecommons.org/ns#">
This work is licensed under <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;">CC BY 4.0<img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://realworlddatascience.net/news-and-views/editors-blog/posts/2023/02/14/https:/mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://realworlddatascience.net/news-and-views/editors-blog/posts/2023/02/14/https:/mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"></a>
</p>


</section>
</section>

 ]]></description>
  <category>Skills</category>
  <category>Training</category>
  <category>AI</category>
  <category>Machine learning</category>
  <category>Data analytics</category>
  <guid>https://realworlddatascience.net/news-and-views/editors-blog/posts/2023/02/14/digital-skills.html</guid>
  <pubDate>Tue, 14 Feb 2023 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/news-and-views/editors-blog/posts/2023/02/14/images/billetto-editorial-YvLd3xbo0ac-unsplash.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>Why open science is ‘just good science in a digital era’</title>
  <dc:creator>Brian Tarran</dc:creator>
  <link>https://realworlddatascience.net/news-and-views/interviews/posts/02/03/heidi-seibold.html</link>
  <description><![CDATA[ 




<p>Years are often dedicated to different causes and aims by different organisations. The United Nations, for example, has designated 2023 the <a href="https://www.undocs.org/en/A/RES/77/32">International Year of Dialogue as a Guarantee of Peace</a>, while for the European Commission it is the <a href="https://ec.europa.eu/commission/presscorner/detail/en/ip_22_6086">European Year of Skills</a>. But over at the White House Office of Science and Technology Policy, 2023 has been declared the <a href="https://www.whitehouse.gov/ostp/news-updates/2023/01/11/fact-sheet-biden-harris-administration-announces-new-actions-to-advance-open-and-equitable-research/">Year of Open Science</a>.</p>
<p>To discuss what this means for science generally and data science in particular, Real World Data Science invited <a href="https://heidiseibold.com/">Heidi Seibold</a> for an interview. Seibold is a statistician and data scientist, and also an open science trainer and consultant, and we talked about how she became involved in open science, what it means to her, the benefits of it, and how academic and industry researchers can move towards it.</p>
<p>Check out our full conversation below or on <a href="https://youtu.be/GD2g7cJ_yE4">YouTube</a>.</p>
<div class="quarto-video ratio ratio-16x9"><iframe src="https://www.youtube.com/embed/GD2g7cJ_yE4" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<section id="timestamps" class="level2">
<h2 class="anchored" data-anchor-id="timestamps">Timestamps</h2>
<ul>
<li>How did Heidi become interested in open science? (<a href="https://youtu.be/GD2g7cJ_yE4?t=106">1:46</a>)</li>
<li>What does open data science mean to Heidi? (<a href="https://youtu.be/GD2g7cJ_yE4?t=470">7:50</a>)</li>
<li>Working with PhD students on open science (<a href="https://youtu.be/GD2g7cJ_yE4?t=720">12:00</a>)</li>
<li>How do open data science principles fit into an industry environment? (<a href="https://youtu.be/GD2g7cJ_yE4?t=850">14:10</a>)</li>
<li>Knowledge transfer and public science (<a href="https://youtu.be/GD2g7cJ_yE4?t=1049">17:29</a>)</li>
<li>Year of Open Science initiatives and lasting impacts (<a href="https://youtu.be/GD2g7cJ_yE4?t=1268">21:08</a>)</li>
</ul>
</section>
<section id="quotes" class="level2">
<h2 class="anchored" data-anchor-id="quotes">Quotes</h2>
<p>“Reproducibility [is] just like this minimum standard in research quality, where we say, ‘When we have the same data and the same analysis, we also want to see the same results’, and being able to check that from others is really, really important.” (<a href="https://youtu.be/GD2g7cJ_yE4?t=165">2:45</a>)</p>
<p>“On the back of my wall here in my office I have written, ‘Open science is just good science in a digital era’… Before, we only had the printing press, and we had to print journals in order to distribute the knowledge that we have.” (<a href="https://youtu.be/GD2g7cJ_yE4?t=323">5:23</a>)</p>
<p>“For me, open data science entails the part of the scientific process that focuses on everything that happens on the computer: the data processing and the data analysis, and then getting from the data analysis – getting the results and the knowledge, really – in sort of a pipeline where you go from one step to the next. And so the image that I have in my head, when I think about open data science, is of a pipeline.” (<a href="https://youtu.be/GD2g7cJ_yE4?t=616">10:16</a>)</p>
<p>“Nobody’s perfect from the beginning. And open science and reproducible research is really hard, and it requires a lot of technical knowledge. And I always feel like people are so scared, because on one hand, they don’t know how to do it yet, and the goal is so far away. And so I always like [to say], you don’t have to be perfect right away; going one step into the right direction is super important.” (<a href="https://youtu.be/GD2g7cJ_yE4?t=754">12:34</a>)</p>
<p>“If we think of companies, for example, like Microsoft – they put a lot of money right now into open source: they bought GitHub, they publish open source software, they put money into open source software projects like R, for example. So, somehow, this must be a good way of making profits.” (<a href="https://youtu.be/GD2g7cJ_yE4?t=909">15:09</a>)</p>
<p>“[Open science for the public has value because] we don’t know what ideas people will have. There’s so many skilled people out there that probably will do amazing things… We have this with the software Stable Diffusion right now. That’s an AI that generates images from text, and it runs on my computer here. And I don’t need AI skills to be able to do that. And people are building such incredible images out of this, and it’s really fun to see.” (<a href="https://youtu.be/GD2g7cJ_yE4?t=1130">18:50</a>)</p>
</section>
<section id="transcript" class="level2">
<h2 class="anchored" data-anchor-id="transcript">Transcript</h2>
<div class="callout-warning callout callout-style-simple">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-body-container">
<p>This transcript has been produced using <a href="https://otter.ai/">speech-to-text transcription software</a>. It has been only lightly edited to correct mistranscriptions and remove repetitions.</p>
</div>
</div>
</div>
<p><strong>Brian Tarran</strong><br>
Hello, and welcome to another Real World Data Science interview. I’m Brian Tarran. And today I’m joined by Heidi Seibold, a statistician and data scientist. I invited Heidi along to speak about open science, what it means, the benefits of it, and how to move towards it. So welcome, Heidi, how are you?</p>
<p><strong>Heidi Seibold</strong><br>
Hello, thanks for having me. I’m good.</p>
<p><strong>Brian Tarran</strong><br>
Excellent. Excellent. Well, Heidi, I contacted you because, you know, I know you have a real deep interest in open science. And the conversation I think was really motivated by the White House Office of Science and Technology Policy declaring 2023 to be the year of open science. So first off, I wanted to get your reaction to that announcement.</p>
<p><strong>Heidi Seibold</strong><br>
Yeah, I think in general, that’s a really cool thing for open science to happen. Right? We, there’s this movement that’s been going on for a while, and people have been doing these grassroots communities and growing open science from the bottom up. And now we see more and more also top down decisions, which I think is a very good sign for, yeah, quality of science, really.</p>
<p><strong>Brian Tarran</strong><br>
Yeah, definitely. So I mean, we’ll get into some of the details of the initiatives a little later, maybe, but I thought that maybe we could kick off by asking you what you thought of the official definition of open science that the US government has come up with, and, and for the benefit of people watching that’s, in quotes, the principle and practice of making research products and processes available to all while respecting diverse cultures, maintaining security and privacy and fostering collaborations, reproducibility and equity. So as definitions go, does that, you know, does that hit the mark, for you, do you think?</p>
<p><strong>Heidi Seibold</strong><br>
Yeah, I think given that this is a federal definition, right, from the US. And they have to like, yeah, take so many opinions into account, I think it’s a great definition. I also asked like on social media, what people thought about it, and I think the response generally was pretty good. What I liked especially is that they focus on collaboration, reproducibility, and equity, which aligns very much with how I personally see open science. So collaboration means like, I always think of the term like building on the shoulders of giants, right. So this is what we want to do in research, we want to build on the work of others. They might be like famous people, but they might also be our colleagues next door. And it’s so important to take that into focus. And also reproducibility, just like this minimum standard in research quality, where we say, when we have the same data and the same analysis, we also want to see the same results, and being able to check that from others is really, really important. And so I think, this focus, I personally like it a lot.</p>
<p><strong>Brian Tarran</strong><br>
Excellent. Excellent. So can you tell me a little bit about your background and how you became interested, and I think committed to open science would be a great way of describing it, right?</p>
<p><strong>Heidi Seibold</strong><br>
Yeah, so I’m a trained statistician, I studied statistics. And then how did I get into this whole open science thing was, for me, really through reproducible research. So my first research project was during my master’s programme, and we wrote a paper and it was a very computationally complex project, and we had lots of files and folders, and, you know, scripts and stuff like this. And then, at some point, it just all got so messy. And I felt like, oh, no, I’m the worst scientist in the world. And then I told my colleague who I was working with on this project. And he was like, No, this is normal. And I was like, No, this can’t be normal. I want to be on top of things when I do research. And I want to be sure that, like, the code that I’m using for this is the correct code that I actually wanted to use, right. So that must be like a minimum standard that we have. And so through that, I learned about reproducible research and good coding practices. And then I also thought more and more about like, well, if I do all this, I should also publish it so that others can actually check that I’m good doing good work here. Right. And so through that I got more and more into open science and really always felt like that’s the right thing to do, especially if you’re funded through public money.</p>
<p><strong>Brian Tarran</strong><br>
Yeah, yeah. Can I ask you what you think is kind of driving the shift to open science because the way you’ve described open science to me just there, you know, that sounds like to me like, just good scientific practice, and the fact that it’s not something that’s been done before, I wonder whether is it a cultural change, a philosophical change, a technological development, that’s kind of spurring this shift?</p>
<p><strong>Heidi Seibold</strong><br>
Yeah. So that’s a really, really good and deep question. So on the back of my wall here in my office, I have written open science is just good science in a digital era. And I think that describes the answer to your question pretty well. So there was a technological change, right? Before, we only had the printing press. And we had to print journals in order to distribute the knowledge that we have. And of course, that costs money. So journals cost money historically. But now, journal costs are really super low, because nobody needs them printed anyhow. And you only ever want to read like one or two articles out of one issue. So it doesn’t really make sense anymore, right. And also publishing data and code. It’s just like, the cost is so so low, that now in this digital age of the internet, really, we have such a low burden of, of doing the right thing. But on the other hand, we need to make this social shift, because we’ve been always, like, researchers have always done it a certain way. And there are especially certain fields that are really into, like, they feel like this is my data. This is my code. This is my research. Why should I share it? But I feel like the young generation of researchers are like, well, because it’s the right thing to do. And the reason why we’re in research is because we want to have scientific progress and scientific progress comes when we can build upon each other’s work.</p>
<p><strong>Brian Tarran</strong><br>
Of course, and you mentioned, obviously, journal publications, but I wonder to what extent is it that the scale of science has almost kind of outgrown the ability to kind of condense it all down into a, even if it’s a 20 or 30 page, academic paper, right? Because it’s not just about, you know, setting out the research question describing the methods, you know, presenting a table of the data, all that stuff can’t be published now, or it can be, but it can’t be fit within the framework of an academic paper, it has to be on a GitHub repository or in a Jupyter notebook or something like that. So kind of open science encourages us to, to think about distributing that knowledge in different ways.</p>
<p><strong>Heidi Seibold</strong><br>
I think that’s completely true. So, research now is so much more complex than it used to be right. There used to be single researchers who did like, yeah, such breakthroughs within one paper. And now, we already have so much knowledge, and the questions are so much more detailed and complicated. And also the data is so much more and the things that we can do is so much more complex. And so I feel like one paper doesn’t– isn’t enough to describe the research that we’re doing. And we did this one project with, with a group of students, actually, where we took 11 papers that were related to the topic that we were teaching about. And we took these 11 papers and data was available for the papers. And so we thought, well, we try to reproduce the results that they have there. And we found that it is really hard if we don’t have the code, because the method section in papers is really super short, right? It’s a super short section, if it’s not like a statistics paper. And it’s impossible to describe all the intricate steps that you took from the data to the complex model and analysis that you did. It’s just not enough space within the paper. And the code is the perfect description of what you did, right? So why not publish it with it, and especially in cases where data privacy is not an issue, then, and you already publish the data, then it just makes so much sense to also publish the code, because the code is not like there’s no privacy issues to that – usually at least.</p>
<p><strong>Brian Tarran</strong><br>
So is there a kind of you know– when we say open data science, you know, what does that look like? And do you have a kind of example or simplified example of what that would look like, right? And how it’s more than just, you know, the finished paper, the product of the science scientific process?</p>
<p><strong>Heidi Seibold</strong><br>
Yeah, so for me, open data science entails the process of– the part of the scientific process that focuses on everything that happens on the computer. So the data processing and the data analysis, and then getting from the data analysis, getting the results and the knowledge really, in sort of, yeah, in sort of a pipeline where you go from one step to the next. And so what the image that I have, in my head, when I think about open data science, I really think of a of a pipeline where you stick the different parts of the pipeline together, in a consecutive order. But of course, research projects are really complicated. And the pipeline just looks really messy, in some ways, but if you still manage to organise it in a way that the different bits all fit together, then you can make it so that in the end, you can imagine something that goes from the start to the finish. And you really understand every step of this pipeline every step of the way, from the raw data to the paper.</p>
<p><strong>Brian Tarran</strong><br>
Yeah. So the idea would be that people provide almost like a framework for you to recreate that yourself if you want to either check the results or yeah, replicate, just replicate the process generally. Right? So is your– so your job now is, I guess, as an open science trainer and consultant, so are you the person that goes into organisations and kind of shows them how to build that pipeline? Or how to, you know, map it out and to present that to people?</p>
<p><strong>Heidi Seibold</strong><br>
Yeah, so what I do a lot is do workshops and trainings with PhD students. So graduate programmes will ask me to come in for a day, or, also, we do longer trainings, which are often more useful, because people can in between take the steps that I recommend. And then we just, like, work together on ideas and steps that they can actually take. And I think what’s always important there is to know that nobody’s perfect from the beginning. And open science and reproducible research is really hard. And it requires a lot of technical knowledge. And I always feel like people are so scared, because on one hand, they don’t know how to do it yet. And the goal is so far away. And so I always like, you don’t have to be perfect right away, going one step into the right direction is super important. And that also helps with like the social change, because then the question is, well, I do want to do this, but my supervisor doesn’t know the technology, what do I do? And then we always try to find like one step that they can take, rather than trying to be perfect right away.</p>
<p><strong>Brian Tarran</strong><br>
And it’s, I guess, it’s encouraging to see people like you being brought in to work with people on graduate programmes. So you’re, we’re trying to almost train the next generation of scientists to be thinking, open science first, rather than, you know, falling into bad habits or old habits that, you know, we are trying to do away with.</p>
<p><strong>Heidi Seibold</strong><br>
Yeah, and really, the young researchers, my feeling so far has been that the only pushback I get for my work is from established researchers who feel like well, this is the way I did it, and so it has to be the right way. But the younger generation for them, it’s super obvious that this is the way we should go in order to achieve scientific progress and good scientific practice.</p>
<p><strong>Brian Tarran</strong><br>
Yeah, yeah. A lot of data science now is obviously now done within industry. I wondered how open data science or open science principles fit in an environment you know, where competitive advantages is linked to keeping things in house and confidential and not wanting to share too much. Do you see a conflict there or can the two work together?</p>
<p><strong>Heidi Seibold</strong><br>
So I think there’s– first of all, I think, if we, if we get it done in academia, I’d be already super happy, right? If we get it done in the space where we have public funded projects that then are available for the public, I’d be already like super stoked. But in industry, it’s really interesting because a lot of the work that is done in industry is already done pretty well. So we if we think of, for example, companies, for example, like Microsoft, right, they put a lot of money right now into open source, they bought GitHub, they publish open source software, they put money into open source software projects like R, for example, right. So somehow, this must be a good way of making profits as well. And we see lots of companies investing in open source. So why not think about other research products, like data, and so on, also in the same line as we do of open source, because software is just a similar product. And I don’t think that there’s, I mean, there is some software, or some products, where it makes sense to have a patent or a trade secret or something. But sometimes it’s just more profitable, to have something where people can look into it and trust it. And I’d also helps like finding the next coders, and the next researchers to work on these projects, because, well, we like looking into what we’re going to do next. Right. And also, if we look, for example, into pharma industry, there, we see that a lot of the work they’re doing is already pretty good. For example, if we look at clinical trial transparency, pharma is doing better than academia there. And also, they’re pretty good on reproducible research, because they have to stick to certain rules. And when we look on the other side, so industry also benefits from open science, right? Because if we do open science, in academia, and publicly funded projects, then this will help companies make more money, because they have access to more knowledge and maybe interesting ideas as well, that they don’t have right now. So I think this is a win-win situation for companies as well. And I feel like if academia gives more to the industry, then eventually there will be like a mindset change. And industry will also give more back as well.</p>
<p><strong>Brian Tarran</strong><br>
Yeah, I see– I can see that and I guess it’s, you know, knowledge transfer is a big objective of a lot of academic institutions, right, we want our outputs to be of use to wider society, and that includes business and industry, right. So if people can pick those things up, you know, download it off of the web without having to, you know, make one-to-one links with the researchers who’ve done that project, it just it smooths that transition, and that that knowledge transfer becomes a lot more straightforward. You did, you mentioned about, you know, open science is about public science, essentially putting these, when it’s publicly funded research, this data and this work goes into the public space. You know, I’m guessing that, to a large extent, a lot of, you know, regular members of the public aren’t going to be interacting with open science. They’re not going to be downloading the datasets, they’re not going to be rebuilding the pipelines and rerunning the analysis. But do you still see that there’s a value there for the public in that information being there should they need it? And where are the kind of areas of value that you think the public will exploit?</p>
<p><strong>Heidi Seibold</strong><br>
Yeah, I think that’s an interesting question. And I think the biggest answer to that is that we don’t, we don’t know what ideas people will have, right? There’s so many skilled people out there, that probably will do amazing things. And we see that over and over again, when we put stuff out there, that people just get the super cool ideas. So we have this with the software Stable Diffusion right now, right? So that’s an AI that generates images from text, and it runs on my computer here. And I don’t need AI skills to be able to do that. And people are building such incredible images out of this. And it’s really fun to see. So I think, yeah, we just don’t know what’s going to happen. And on the other hand, I think, well, I am a researcher, but I’m also the public, right? And so if I have a question about something that concerns my private life or my friends’ private life, then I can also– I do have the skills to go into this and look at some research for example, I don’t know, how to best raise children or whatever. Um, that’s– so I have a friend, she’s an epidemiologist, and she always goes and looks at research on like, how to feed her child best and what to do. There’s, there’s all kinds of questions you have as a mother. And she, as a researcher can just go into the research and figure out, like, what is the best path for me to take. And I think the more we do open science, the more we can also do, like science communication, that adds on to that as well. Right? So if we have her now, she could now help other mothers make the same good decisions as well. And she would be sort of a science communicator for research that isn’t even hers. Um, so that is pretty cool, I think.</p>
<p><strong>Brian Tarran</strong><br>
I think so, and it’s speaks to me of breaking down silos that, and I guess, blurring the lines between our roles, our professional roles and our personal lives, right. It’s about bringing science into that kind of public sphere, so I can see why the benefits would accrue from doing so. Just to wrap up, let’s go back to that year of open science, that was announced by the White House, are there any other specific initiatives in that big long list that constituted the announcement that you’re excited about?</p>
<p><strong>Heidi Seibold</strong><br>
Yeah, there is. I think, especially what I really liked was that, yeah, federally funded research, um, needs to be accessible, including the data when possible. So again, there’s open when possible, closed when necessary. But I think this is a very good first step, to say, okay, it depends on the funding, if it’s publicly funded, then it should also be publicly available. And I think that’s a really good sign. And then also, these, the statement had like, mentioned all these open science initiatives in different fields, which I really liked. So for example, from NASA, they have this transform to open science programme, and they’re already super active. And it’s really cool to see what comes out of that. For medicine, they have requirements for data management plans, which I think is a very solid step towards open science in medicine, because they are we have the issue of data privacy. And we really have to think from the get-go of a project about what should we do in terms of best practices of data management and having a requirement on that is, I think, a really, really solid step. And also, I’m thinking about open science in the field of like federal government even, because open data and federal government is a huge topic, right. And it, that’s definitely something that a lot of people will be interested in as well.</p>
<p><strong>Brian Tarran</strong><br>
Last question for you, then Heidi, you know, what would you want the lasting impact of an initiative like this to be? And you know, would you like to see this sort of thing replicated in other countries around the world? If indeed, you know, other countries may already be doing this and have already done this?</p>
<p><strong>Heidi Seibold</strong><br>
I think in general, it’s a very, very good sign that we’re seeing right now. We’ve seen lots of movement, for example, in the Netherlands – Netherlands is really big on open science – and seeing such a big country [the US] that also plays such an important role in the world, doing– taking this step, is a great sign for the entire, like all of research, really. And yeah, I think it’s also nice to see that we’re going from like, Oh, this is a niche topic that only experts are interested in, and people that are like advocates and nerds focus on, to something that really governments are thinking about.</p>
<p><strong>Brian Tarran</strong><br>
So, open science is going mainstream, I think is the message. And let’s hope that it continues to do so. So Heidi, thank you very much for your time today. Where can people find you online, if f they want to find out more about you and your work and your thoughts on open science?</p>
<p><strong>Heidi Seibold</strong><br>
Yeah, thank you so much for having me. It was wonderful. And I always like talking about open science, so people can find me on my website, heidiseibold.com. And I’m also on Mastodon, Twitter, LinkedIn, YouTube, wherever your search for Heidi Seibold, you’ll find me.</p>
<p><strong>Brian Tarran</strong><br>
Excellent. Excellent. Well, thank you again. And thank you to those of you who are tuning in today. Make sure to check realworlddatascience.net for more interviews. Take care.</p>
<section id="back-to-interviews" class="level6">
<h6 class="anchored" data-anchor-id="back-to-interviews"><strong>← Back to <a href="../../../../../news-and-views/interviews/index.html">Interviews</a></strong></h6>
<hr>
<p xmlns:cc="http://creativecommons.org/ns#">
This work is licensed under <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;">CC BY 4.0<img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://realworlddatascience.net/news-and-views/interviews/posts/02/03/https:/mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://realworlddatascience.net/news-and-views/interviews/posts/02/03/https:/mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"></a>
</p>


</section>
</section>

 ]]></description>
  <category>Open science</category>
  <category>Reproducible research</category>
  <guid>https://realworlddatascience.net/news-and-views/interviews/posts/02/03/heidi-seibold.html</guid>
  <pubDate>Fri, 03 Feb 2023 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/news-and-views/interviews/posts/02/03/images/heidi-seibold.png" medium="image" type="image/png" height="104" width="144"/>
</item>
<item>
  <title>ChatGPT can hold a conversation, but lacks knowledge representation and original sources for verification</title>
  <dc:creator>Brian Tarran</dc:creator>
  <link>https://realworlddatascience.net/news-and-views/editors-blog/posts/2023/01/27/talking-chatgpt.html</link>
  <description><![CDATA[ 




<p>ChatGPT is, right now, the world’s most popular - and controversial - chatbot. Users have been both wowed by its capabilities<sup>1</sup> and concerned by the confident-sounding nonsense it can produce.</p>
<p>But perhaps what impresses most is the way it is able to sustain a conversation. <a href="../../../../../../news-and-views/editors-blog/posts/2022-11-23-LLMs-content-warning/LLM-content-warning.html">When I interviewed our editorial board member Detlef Nauck about large language models (LLMs)</a>, back in November, he said:</p>
<blockquote class="blockquote">
<p>… if you use these systems for dialogues, then you have to script the dialogue. They don’t sustain a dialogue by themselves. You create a dialogue tree, and what they do is they parse the text that comes from the user and then generate a response to it. And the response is then guided by the dialogue tree. But this is quite brittle; it can break. If you run out of dialogue tree, you need to pass the conversation over to a person. Systems like Siri and Alexa are like that, right? They break very quickly. So, you want these systems to be able to sustain conversations based on the correct context.</p>
</blockquote>
<p>Fast-forward a couple of months and, as discussed in our follow-up interview below, OpenAI, the makers of ChatGPT, have succeeded in building a question answering system that can sustain a dialogue. As Nauck says: “I have not yet seen an example where [ChatGPT] lost track of the conversation… It seems to have quite a long memory, and doing quite well in this.”</p>
<p>There are still major challenges to overcome, says Nauck - not least the fact that ChatGPT has no way to verify the accuracy or correctness of its outputs. But, if it <em>can</em> be linked to original sources, new types of search engines could follow.</p>
<p>Check out the full conversation below or on <a href="https://www.youtube.com/watch?v=AWxfSmcgPbo">YouTube</a>.</p>
<p>Detlef Nauck is a member of the <a href="../../../../../../news-and-views/editors-blog/posts/2022-10-18-meet-the-team/meet-the-team.html">Real World Data Science editorial board</a> and head of AI and data science research for BT’s Applied Research Division.</p>
<div class="quarto-video ratio ratio-16x9"><iframe src="https://www.youtube.com/embed/AWxfSmcgPbo" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<section id="timestamps" class="level2">
<h2 class="anchored" data-anchor-id="timestamps">Timestamps</h2>
<ul>
<li>How ChatGPT was built and trained (<a href="https://youtu.be/AWxfSmcgPbo?t=41">0:41</a>)</li>
<li>ChatGPT’s major advance (<a href="https://youtu.be/AWxfSmcgPbo?t=185">3:05</a>)</li>
<li>The big problems with large language models (<a href="https://youtu.be/AWxfSmcgPbo?t=276">4:36</a>)</li>
<li>Search engines and chatbots (<a href="https://youtu.be/AWxfSmcgPbo?t=575">9:35</a>)</li>
<li>Questions for OpenAI and other model builders (<a href="https://youtu.be/AWxfSmcgPbo?t=689">11:29</a>)</li>
</ul>
</section>
<section id="quotes" class="level2">
<h2 class="anchored" data-anchor-id="quotes">Quotes</h2>
<p>“[OpenAI] have achieved quite remarkable capabilities in terms of sustaining conversations, and producing very realistic sounding responses… But sometimes [ChatGPT] makes silly mistakes. Sometimes the mistakes are not that obvious. It can hallucinate content… And it still doesn’t know what it’s talking about. It has no knowledge representation, doesn’t have a word model. And it’s just a statistical language model.” (<a href="https://youtu.be/AWxfSmcgPbo?t=124">2:04</a>)</p>
<p>“These models, they produce an answer, which is based on the kind of texts that they have been trained on. And that can be quite effective. But it cannot yet link back to an original source. So what’s still missing is the step where it says, ‘Okay, this my answer to your question, and here’s some evidence.’ As soon as they have done this, then these kinds of systems will probably replace the search engines that we’re used to.” (<a href="https://youtu.be/AWxfSmcgPbo?t=247">4:07</a>)</p>
<p>“[These large language models are] still too big and too expensive to run… For [use in a] contact centre or similar, what you need is a much smaller model that is restricted in terms of what it can say. It should have knowledge representation, so it gives correct answers. And it doesn’t need to speak 48 languages and be able to produce programming code. It only needs to be able to talk about a singular domain, where the information, the knowledge about the domain, has been carefully curated and prepared. And that’s what we’re not seeing yet. Can we build something like this, much smaller, much more restricted, and provably correct, so we can actually use the output?” (<a href="https://youtu.be/AWxfSmcgPbo?t=469">7:49</a>)</p>
<p>“We are seeing communities who don’t necessarily have the technical background to judge the capabilities of these models, but see the opportunities for their own domain and might be acting too fast in adopting them. So the producer of these models has a certain responsibility to make sure that this doesn’t happen.” (<a href="https://youtu.be/AWxfSmcgPbo?t=746">12:26</a>)</p>
</section>
<section id="further-reading" class="level2">
<h2 class="anchored" data-anchor-id="further-reading">Further reading</h2>
<ul>
<li><a href="https://philadelphiaphysicist.wordpress.com/2023/01/13/chatgpt-the-robot-the-myth-the-legend/">ChatGPT: The Robot, the Myth, the Legend</a> - Philadelphia Physicist blog, January 13, 2023</li>
<li><a href="https://twitter.com/sama/status/1599671496636780546?s=20&amp;t=TbscFaGtn5JFu_dfZDczVg">Cost to run ChatGPT</a> - tweet by OpenAI CEO Sam Altman, December 5, 2022</li>
<li><a href="https://www.cnbc.com/2022/12/13/google-execs-warn-of-reputational-risk-with-chatgbt-like-tool.html">Google execs warn company’s reputation could suffer if it moves too fast on AI-chat technology</a> - CNBC, December 13, 2022</li>
<li><a href="https://www.theguardian.com/technology/2023/jan/05/microsoft-chatgpt-bing-search-engine">Microsoft reportedly to add ChatGPT to Bing search engine</a> - <em>The Guardian</em>, January 5, 2023</li>
<li><a href="https://www.theverge.com/2023/1/17/23558516/ai-art-copyright-stable-diffusion-getty-images-lawsuit">Getty Images is suing the creators of AI art tool Stable Diffusion for scraping its content</a> - The Verge, January 17, 2023</li>
</ul>
</section>
<section id="transcript" class="level2">
<h2 class="anchored" data-anchor-id="transcript">Transcript</h2>
<div class="callout-warning callout callout-style-simple">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-body-container">
<p>This transcript has been produced using <a href="https://otter.ai/">speech-to-text transcription software</a>. It has been only lightly edited to correct mistranscriptions and remove repetitions.</p>
</div>
</div>
</div>
<p><strong>Brian Tarran</strong><br>
We’re following up today Detlef on the, I guess, one of the biggest stories in artificial intelligence and data science at the moment, ChatGPT, the chat bot that’s driven by a large language model and is proving endless amounts of– providing endless amounts of either entertainment or concern, depending on what you ask it, and what outputs you get. So, but you’ve been looking at it in some detail, right, ChatGPT. And that’s why I thought we would follow up and have a conversation to see, get your view on it, get your take on it. What’s going on?</p>
<p><strong>Detlef Nauck</strong><br>
Yeah. So, what they have done is, OpenAI have used their large language model GPT-3 and they have trained an instance to basically answer questions and have conversations, where the model remembers what has been said in the conversation. And they have done this by using curated data of question and answers, where they basically have posed a question and said, This is what the answer should be. They trained the system on doing this, then, in the next step, they began use questions, potentially different ones, the system came up with a variety of answers, and then again, human curators would mark which is the best answer. And they would use this data to train what’s called a reward model - so, a separate deep network that learns what kind of answer for a particular question is a good one - and then they would use this reward model to do additional reinforcement learning on the ChatGPT that they had built so far, basically using dialogues and the reward model would then either reward or penalise the response that comes out of the system. And by doing that they have achieved quite remarkable capabilities in terms of sustaining conversations, and producing kind of very realistic sounding kind of responses. Sounds all very convincing. The model presents its responses quite confidently. But sometimes it makes silly mistakes. Sometimes the mistakes are not that obvious. It can hallucinate content. So let’s say you ask it to write you scientific text about whatever topic and put some references in and these references are typically completely fabricated and not real. And it still doesn’t know what it’s talking about. It has no knowledge representation, doesn’t have a word model. And it’s just a statistical language model. So it’s what we would call a sequence to sequence model. It uses an input sequence, which are words, and then guesses what’s the next most likely word in the sequence. And then it continues building these sequences.</p>
<p><strong>Brian Tarran</strong><br>
Yeah. But, do you think the big advance as you see it is the way it’s able to remember or store some knowledge, if you like, of the conversation, because that was something that came out of our first conversation that we had, where you were saying that, you know, if you’re looking at these as a potential chatbots for customer service lines, or whatever it might be, actually, the trees, the conversation trees break down after a while, and they don’t, you know, these models get lost, but actually, they’re able to maintain it a little longer, are they, or– ?</p>
<p><strong>Detlef Nauck</strong><br>
Yeah, I have not yet seen an example where they lost track of the conversation they seem to have, it seems to have quite a long memory, and doing quite well in this. So the main capability here is they have built a question answering system. And that’s kind of the ultimate goal for search engines. So if you put something into Google, essentially, you have a question, show me something that answered this, answers this particular question. Of course, what you want this kind of an original source. And these models, they produce an answer, which is based on the kind of texts that they have been trained on. And that can be quite effective. But it cannot yet link back to an original source. So what’s still missing is the step where it says, Okay, this my answer to your question, and here’s some evidence. Then if, as soon as they have done this, then these kinds of systems will probably replace the search engines that we’re used to.</p>
<p><strong>Brian Tarran</strong><br>
Yeah. The other thing that struck me with them was that the, if you’re asking somebody a question - a human, you know, for instance - you expect a response that and you would hope you will be able to trust that response, especially if it’s someone in an expert position or someone you’re calling, you know, on behalf of a company or something. The fact that - and I asked this question of ChatGPT itself - and the response was, again, you should consult external sources to verify the information that’s been provided by the chatbot. So it’s like, I guess that leaves a question as to what the utility of it is, if you if you’re always having to go elsewhere to verify that information.</p>
<p><strong>Detlef Nauck</strong><br>
Yeah, I mean, that’s the main problem with these models, because they don’t have a knowledge representation. They don’t have a word model, they can’t fall back on facts that are represented as being true and present those. They come up with an answer. But I mean, there has been a lot of kind of pre-prompting going in to ChatGPT. So when you start writing something, the session has already been prompted with a lot of text, telling the model how to behave, what not to say, to avoid certain topics. There are additional moderation APIs running that make sure that you can’t create certain type of responses, which are based on classical text filtering, and topic filtering. So they try to kind of restrict what the model can do to make sure it’s not offensive or inappropriate. But that is limited. So through crafting your requests, intelligently, you can convince it to ignore all of these things and go past it in some instances. So the, it’s not yet perfect, and certainly it’s not authoritative. So you can’t trust the information if you’re not an expert yourself. So at the moment, I’d say these kind of models are really useful for experts who can judge the correctness of the answer. And then what you get this kind of maybe a helpful kind of text representation of something that you would have to write yourself otherwise.</p>
<p><strong>Brian Tarran</strong><br>
Yeah, and certainly conversations I’ve had with people, those who kind of work, maybe in creative industries, are finding them quite intriguing, in terms of things like, you know, maybe trying to come up with some clever tweets or something for a particular purpose, or something I want to try out is getting ChatGPT to write headlines for me, because it’s always my least favourite part of the editing job. So that sort of works. But you know, for you, in your position in the industry, has ChatGPT changed your mind at all about, you know, the way you’re perceiving these models and how they might be used? Or is it is it just kind of a next step along in the process of what you’d expect to see before these can become tools that we use?</p>
<p><strong>Detlef Nauck</strong><br>
Yeah, it’s the next step in the evolution of these models. They’re still too big and too expensive to run, right. So now, it is not quite clear how much it costs OpenAI to run the service that they’re currently running. So you see estimates around millions of dollars per day that they have to spend on running the compute infrastructure to serve all of these questions. And this is not quite clear, the only official piece of information that I’ve seen is in a tweet, where the CEO said, a single question costs in the order of single digit cents, but we have no idea how many questions they serve per day, and therefore how much money they are spending. If you want to run a contact centre, or something like this, it all depends on how much compute need to stand up to be able to respond to hundreds or thousands of questions in parallel. And then obviously, if you can’t trust that the answer is correct, it is of no use. So for making use in the service industry for contact centre or similar, what you need is a much smaller model that is restricted in terms of what it can say, it should have knowledge representation, so it gives correct answers. And it doesn’t need to speak 48 languages and be able to produce programming code, it only needs to be able to talk about a singular domain, where it kind of the information, the knowledge about the domain has been carefully curated and prepared. And that’s what we’re not seeing yet. Can we build something like this, much smaller, much more restricted, and kind of provably correct, so we can actually use the output?</p>
<p><strong>Brian Tarran</strong><br>
Yeah. Can we go back just to the point you mentioned earlier about, you know, the, the potential of like linking these sorts of chatbots up with search engines, you know, like Google? There’s been some conversations and reporting around, you know, what breakthroughs or not Google might have made in this regard. I mean, have you got any perspective on that area of work and how far along that is maybe and what the challenges are to get to that point?</p>
<p><strong>Detlef Nauck</strong><br>
Well, Google has its own large language model, LaMDA. And we have seen an announcement that Microsoft wants to integrate ChatGPT into Bing, their search engine. And, but as I said before, what’s missing is the link to original sources. So you, coming up with a response is nice. But you need to be able to back it up, you need to say, Okay, this is my response, and I’m confident that this is correct, because here are some references. If I compare my response to these references, then they essentially mean the same thing. This is kind of what you need to be able to do. And we haven’t seen this step yet. But I’m certain that the search engine providers are hard at work at doing this because that’s essentially what they want. If you do a search in Google, in some instances, you’ll see a side panel where you get detailed information. Let’s say you ask about what’s the capital of Canada, you get a response, you get the information in more detail, you get links to Wikipedia, where they retrieve content from and present this as the response. And this is done through knowledge graphs. And so if these kinds of knowledge graphs grow together with these kind of large language models, then we will see new types of search engines.</p>
<p><strong>Brian Tarran</strong><br>
Okay. I guess final, my final question for you, Detlef, and there might be other angles that you want to explore. But it’s like, are there questions that, you know, if you if you could sit down with OpenAI to talk about ChatGPT and what they’ve done, and what they plan to do next with it, what are the kinds of things that are bubbling away at the top of your mind?</p>
<p><strong>Detlef Nauck</strong><br>
Well, one thing is controlling the use of these models, right? If you let them loose on the public, with an open API that anybody can use, you will see a proliferation of applications on top of it. If you go on YouTube, and you Google ChatGPT and health, you’ll already find discussions where GPs discuss, Oh, that is the next step of automated doctors that we can use. So they believe that the responses from these systems can be used for genuine medical advice. And that’s clearly a step too far. So we are seeing communities who don’t necessarily have the technical background to judge the capabilities of these models, but see the opportunities for their own domain and might be acting too fast in adopting them. So the producer of these models has a certain responsibility to make sure that this doesn’t happen. And I don’t know how they want to control this. And, so my question at the developers of these models would be how do you handle sustainability, because the trend goes to ever bigger models. So there’s, in some parts of the industry, there’s the belief, if you make them big enough you get artificial general intelligence, which I don’t believe is possible with these models. But this is definitely a trend that pushes the size of the models. The kind of, the idea of having just one model that can speak all the languages, can produce questions, answers, programming code, is obviously appealing. So you don’t want to build many models. Ideally, you have only one. But how is that supposed to work? And how do you embed actual word knowledge and word models into these systems so that you can verify what comes out?</p>
<p><strong>Brian Tarran</strong><br>
Yeah. I mean, the ethical dimension that you mentioned in the first part of your response is an important one, I think, in the sense that– but I guess maybe almost redundant in the sense that it’s already out there; you can’t put ChatGPT back in the box, can we, essentially?</p>
<p><strong>Detlef Nauck</strong><br>
Well, it’s expensive to run so charging enough for access will put a lid on some frivolous use cases, but still, it needs to be controlled better. And you can make a jump to an AI regulation. So far, we only thought about regulating automated decision making, or automated classification. We also have to think about the automatic creation of digital content or automatic creation of software, which is possible through these models or the other generative AI models like diffusers. So how do we handle the creation of artificial content that looks like real content?</p>
<p><strong>Brian Tarran</strong><br>
Yeah. And there’s also I think, something I picked up yesterday, there was reports of a case being filed by, I think, Getty Images against the creators of one of these generative art models because they’re saying, you know, that you’ve used our data or you’ve used our image repositories essentially to train this model and it is now producing, you know, it’s producing its own outputs that’s based on this, and I guess there’s an argument of it being a copyright infringement case. And I think that’ll be quite interesting to watch to see how that does change the conversation around - yeah - fair use of that data that is available. You can find these images publicly, but you have to pay to use them for purposes other than just browsing, I guess. Yeah, it’ll be interesting to watch.</p>
<div class="callout-tip callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Have you got news for us?
</div>
</div>
<div class="callout-body-container callout-body">
<p>Is there a recent data science story you’d like our team to discuss? Do you have your own thoughts to share on a hot topic, or a burning question to put to the community? If so, either comment below or <a href="../../../../../../contact.html">contact us</a>.</p>
</div>
</div>
<section id="back-to-editors-blog" class="level6">
<h6 class="anchored" data-anchor-id="back-to-editors-blog"><strong>← Back to <a href="../../../../../../news-and-views/editors-blog/index.html">Editors’ blog</a></strong></h6>
<hr>
<p xmlns:cc="http://creativecommons.org/ns#">
This work is licensed under <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;">CC BY 4.0<img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://realworlddatascience.net/news-and-views/editors-blog/posts/2023/01/27/https:/mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://realworlddatascience.net/news-and-views/editors-blog/posts/2023/01/27/https:/mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"></a>
</p>


</section>
</section>


<div id="quarto-appendix" class="default"><section id="footnotes" class="footnotes footnotes-end-of-document"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p>I asked ChatGPT to write this article’s headline, for example. I typed in “Can you write a headline for this text:” and then copy/pasted the interview transcript into the dialogue box. It first came up with, “AI Chatbot ChatGPT Proves Capable in Sustaining Conversations but Lacks Knowledge Representation and Original Sources for Verification”. I then asked it to shorten the headline to 10 words. It followed up with, “ChatGPT: Large Language Model-Driven Chatbot Proves Capable But Limited”.↩︎</p></li>
</ol>
</section></div> ]]></description>
  <category>Machine learning</category>
  <category>Large language models</category>
  <category>AI</category>
  <guid>https://realworlddatascience.net/news-and-views/editors-blog/posts/2023/01/27/talking-chatgpt.html</guid>
  <pubDate>Fri, 27 Jan 2023 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/news-and-views/editors-blog/posts/2023/01/27/images/Detlef.png" medium="image" type="image/png" height="156" width="144"/>
</item>
<item>
  <title>How to ‘Escape from Model Land’: an interview with Erica Thompson</title>
  <dc:creator>Brian Tarran</dc:creator>
  <link>https://realworlddatascience.net/news-and-views/interviews/posts/01/25/erica-thompson.html</link>
  <description><![CDATA[ 




<p>Erica Thompson’s new book, <a href="http://www.ericathompson.co.uk/books/"><em>Escape from Model Land</em></a>, offers a fascinating and important perspective on mathematical models as being not just models of the real world, or real processes or systems, but also “subjective versions of reality” that encode all sorts of assumptions and value judgements.</p>
<p>In this interview with Brian Tarran, editor of Real World Data Science, Thompson talks about the “social element of modelling” and how it manifests, how to counter the subjectivity of individual models with a diversity of models, and whether human-made models are held to the same standards of transparency that are expected of AI-“created” models.</p>
<p>Erica Thompson is a senior policy fellow in the ethics of modelling and simulation at the London School of Economics Data Science Institute.</p>
<div class="quarto-video ratio ratio-16x9"><iframe src="https://www.youtube.com/embed/RB5CQW8lbEo" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<section id="timestamps" class="level2">
<h2 class="anchored" data-anchor-id="timestamps">Timestamps</h2>
<ul>
<li>What led Erica to write the book, and why now? (<a href="https://youtu.be/RB5CQW8lbEo?t=147">2:27</a>)</li>
<li>Critiquing climate models (<a href="https://youtu.be/RB5CQW8lbEo?t=450">7:30</a>)</li>
<li>Exploring the “social element” of modelling (<a href="https://youtu.be/RB5CQW8lbEo?t=696">11:36</a>)</li>
<li>Countering subjectivity with a diversity of perspectives (<a href="https://youtu.be/RB5CQW8lbEo?t=1211">20:11</a>)</li>
<li>AI models, human-made models, and questions of transparency (<a href="https://youtu.be/RB5CQW8lbEo?t=1554">25:54</a>)</li>
<li>Why write a popular science book about these issues? (<a href="https://youtu.be/RB5CQW8lbEo?t=1811">30:11</a>)</li>
<li>Will the UK Prime Minister’s “maths to 18” proposal help or hinder our <em>Escape from Model Land</em>? (<a href="https://youtu.be/RB5CQW8lbEo?t=2041">34:01</a>)</li>
</ul>
</section>
<section id="quotes" class="level2">
<h2 class="anchored" data-anchor-id="quotes">Quotes</h2>
<p>“Putting things in a mathematical language does tend to make people think that it is truth from on high. And so my book, in some way, goes towards saying actually, these models, obviously we hope that they’re based on facts and they’re based on data that we gather, but they also do have this value judgement content as well” (<a href="https://youtu.be/RB5CQW8lbEo?t=111">1:51</a>)</p>
<p>“It is arbitrary how we choose to model a situation. There are infinitely many different ways that you could choose to simplify reality - this huge, messy, complex thing in front of us, with physical laws that we don’t fully understand and things going on that we can only measure by proxy.” (<a href="https://youtu.be/RB5CQW8lbEo?t=729">12:09</a>)</p>
<p>“The choice of assumption has a very direct result in the model output and in the information and advice that you’re giving to policymakers… [In climate models] maybe we have a cost of however many dollars per tonne of carbon dioxide for nuclear electricity or for renewables. But what kind of price would you put on behaviour change? How many dollars per tonne of CO<sub>2</sub> avoided does it cost to change the behaviour of a population such that they use less energy? If you put it in at $2 per tonne of CO<sub>2</sub>, it would be heavily relied on [as a policy response]; if you put it in at $2,000 per tonne of CO<sub>2</sub>, it’ll never happen.” (<a href="https://youtu.be/RB5CQW8lbEo?t=1002">16:42</a>)</p>
<p>“There needs to be more frank discussion of values and value judgments, and politics and social assumptions within models. And I think we are starting to see that with the pandemic models, particularly because it’s been so high profile. [But] it’s really hard to unpick your own value judgments. It’s easier for somebody with a different perspective to come in and say, ‘Oh, actually, you know, you’ve assumed that. Why did you assume that?’ When we are embedded in a particular culture of modelling, it’s particularly hard to imagine that anything could possibly be done differently.” (<a href="https://youtu.be/RB5CQW8lbEo?t=1640">27:20</a>)</p>
<p>“I think some people maybe read the book and think, ‘Oh, this is just a sort of woke advertisement for diversity’. Well, it’s not; it’s a way of doing the maths better. The whole point is to do the maths better, make better forecasts, understand the future more effectively, and be able to make better decisions based on that information.” (<a href="https://youtu.be/RB5CQW8lbEo?t=2021">33:41</a>)</p>
</section>
<section id="transcript" class="level2">
<h2 class="anchored" data-anchor-id="transcript">Transcript</h2>
<div class="callout-warning callout callout-style-simple">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-body-container">
<p>This transcript has been produced using speech-to-text transcription software. It has been only lightly edited to correct mistranscriptions and remove repetitions.</p>
</div>
</div>
</div>
<p><strong>Brian Tarran</strong><br>
Hello, and welcome to the very first instalment of the Real World Data Science interview series. I’m Brian Tarran, the editor of Real World Data Science, and I’m very pleased to be joined today by Erica Thompson, a senior policy fellow in ethics of modelling and simulation at the London School of Economics Data Science Institute, and the author of a fantastic new book - which I have a copy of here - Escape from Model Land, which is subtitled, How mathematical models can lead us astray and what we can do about it. So hello, Erica, thank you for joining us. I hope 2023 got off to a positive start for you.</p>
<p><strong>Erica Thompson</strong><br>
Yes, it has so far.</p>
<p><strong>Brian Tarran</strong><br>
Good, good. Because the book came out, is it just before Christmas or just after?</p>
<p><strong>Erica Thompson</strong><br>
Yeah, just before Christmas. So I’ve had all sorts of things flooding in saying, Oh, I liked your book, or I hated this bit or no, it’s exciting.</p>
<p><strong>Brian Tarran</strong><br>
Yeah, no, well, it’s, I have to say, I think, I thought it was a genuine– I finished reading it over, over Christmas. And I think it offers a genuinely fascinating and important perspective on mathematical models as being not just I guess, models of the real world, or, you know, real processes or systems, but subjective versions of reality, you know, encoding all sorts of assumptions and value judgments of the people who, who create the models. And I mean, I guess that shouldn’t really come as a surprise, right? But, but is it a point that is often lost in the discussion around models, particularly where decisions might be, like, informed or driven by model outputs?</p>
<p><strong>Erica Thompson</strong><br>
I think it is something that’s easy to miss. I mean, especially because we’re sort of, maybe as mathematicians were used to living in model land and doing things which, which we see as being logical consequences of previous things. And then more generally, the public look to science and mathematics and statistics as being objective arbiters, perhaps, of how things are and how things ought to be. And so, so yes, that that kind of putting things in a mathematical language does tend to make people think that it is truth from on high. And so my book, in some way goes towards saying actually, these models, they are, obviously we hope that they’re based on facts, and they’re based on data that we gather, but they also do have this value, judgement content, as well. And so we need to think about what that is and how we deal with it, and how we sort of express it and how we understand it.</p>
<p><strong>Brian Tarran</strong><br>
Right, yeah.</p>
<p><strong>Erica Thompson</strong><br>
Especially where we’re using those models to inform decision making or public policy, then it becomes particularly important.</p>
<p><strong>Brian Tarran</strong><br>
Yeah, yeah, no, and obviously, your book draws up quite a bit on the Covid-19 pandemic, and how models were used there. But I thought it was interesting, actually, that, you know, in reading the acknowledgments that you– that while the pandemic lent the topic, additional relevance, right, you actually started writing the book before that. So what led you to think now’s the time? What was the tipping point, if you like, of thinking, I want to write this book now?</p>
<p><strong>Erica Thompson</strong><br>
Yeah, okay. Well, that’s an interesting question. I mean, because it builds on the last sort of 10 or 15 years of my work. So I started out doing a PhD in climate physics. And my background before that was maths and physics. And so I was doing a PhD on the physics of North Atlantic storms, looking at how they would change given climate change. And so, obviously, the first thing you do is a literature review. And I started looking at different models and what the what they were saying about what would happen to North Atlantic storms. And what I found there was that there were models saying that the storm tracks would go north, they’d go south, they get stronger, they get weaker, they’d, you know, anything you name it. And interesting, particularly, interestingly, was that they, they had relatively small uncertainty ranges. So they they didn’t agree within their own uncertainty ranges. And that made me think, well, we this isn’t telling me very much about North Atlantic storms. But it’s telling me a great deal about modelling and the way that we do modelling and perhaps we need to start thinking more about how these uncertainty ranges are calculated, what does it mean? What, how can we end up in a situation where we have this level of disagreement between models. And so since then, I’ve been looking at, you know, those kinds of concepts in different areas I’ve been looking at sort of insurance and finance and weather and climate and humanitarian forecasting as well. And, and so in all of those application areas, I found the same questions about uncertainty and how we make inferences from model output to be particularly interesting and how common problems may be solved in different ways as well. So it’s interesting to do the compare and contrast. And so, yeah, then I guess I, I’d been on all these sorts of bitty little projects and thought actually, I’d really like to bring this together into something more coherent, you know, to actually say, look, there’s a, there is a common theme here and we need to be putting it together and drawing conclusions. And we can, we can learn a lot from doing that. And we can share the best practice throughout the sector.</p>
<p><strong>Brian Tarran</strong><br>
When you’re starting down this path of, I guess, looking into the, I guess, the ethics and process of modelling, did it, was there a lot of other work that you identify that you could kind of draw on a lot of other thinking around this area? Or was it kind of under studied, under researched sort of aspect of the literature?</p>
<p><strong>Erica Thompson</strong><br>
I think it’s under studied, I mean, of course, everybody who does some modelling, you know, you, you do your modelling, and then somebody says, Okay, we need to put some error bars on the outputs, and you go back and, and think about how we’re going to put the error bars on the outputs. And probably, I would say, most people doing that realise that it’s much more difficult than they have the time to do or the ability within the scope of whatever project they’re doing. But the aerobars, the uncertainties always ended up being tacked on at the end, you do it after you’ve done all the modelling, there’s less incentive to do it. And there’s less resource to do it than to make the model itself better. And I think that’s a very common story, that people realise that they ought to be doing more, but they just don’t have the time the resource, the ability to go and do that. So then yes, there are there are people, and there are particular areas that I think have taken more time to investigate this. So in physical science hydrology, I’d say in particular, has a very well developed history of thinking about the uncertainties in models, maybe because, you know, they are constantly being challenged by events happening, which were not within the models, you know, you’ve got your flood forecast model, and then something happens, and it goes way beyond what you were expecting. And you you have to go back and say, What does this mean for our modelling process. And other areas have much less well developed considerations of uncertainty. And so that’s where I think actually, we could we could really benefit by sharing good practice across these different application areas, because people have looked in different ways. And, you know, with with different levels of statistical interest, you know, some areas go into the stats, much more, some areas are very philosophical about sort of the conceptual foundations of how we should think about models and how we should think about the range of outputs that we get from models. And so what I’m trying to do is bring those together a bit. Yeah.</p>
<p><strong>Brian Tarran</strong><br>
Yeah, I think you certainly achieve that. It is really interesting, the different, the variety of examples that you present, and the ways you talk around these issues. I did want to focus in particular on climate models, though, because, you know, I was looking around your website, finding a bit more about about you, and I noticed on there that you talk about, you no longer fly to conferences, and that’s in order to kind of reduce your own ecological footprint. So I guess I wanted to ask, you know, when you set about writing a book, and it’s going to be a book that’s kind of critiquing models and the ways that they don’t often agree? Did you have like a nagging concern that, you know, the points you wanted to make about models in general, but climate models in particular, that that would kind of lend fodder to the kind of groups that might want to discredit climate models or downplay the risks? Or, indeed, the reality of climate change?</p>
<p><strong>Erica Thompson</strong><br>
I mean, yes, I did have that worry, I still have that worry. And I, but I hope that my book is clear throughout that, you know, that models are not irrelevant, you know, the answer is not to throw them away. If you come to it from this sort of sceptical position, saying, you know, we need to think more carefully about how we make inferences from models, you could go all the way down the rabbit hole and say, Oh, they’re all terrible, let’s just throw them away. But I think that would be completely unjustified. We have good evidence, sort of from from one end of the spectrum of relatively simple linear models, which are incredibly, wildly successful and form the foundation of modern life and modern technology. And, you know, with that, as a basis, we hope that we can, you know, work from there to find the limit of the knowledge that we can get from these more complex models, which are looking at making predictive statements in more extrapolatory domains where the underlying conditions are changing, and we therefore have less ability to rely on what I call the quantitative route of escape from model land, by challenging with relevant past data. You know, we’re looking at extrapolatory conditions like climate change, or social and economic systems, and therefore, we think that the data that we have, while they may be useful and indicative, are not, we can’t just calibrate with respect to past data and expect that to be enough to warrant performance in the future. And so, so I think that sort of one answer is that we shouldn’t be throwing away the models completely because they are demonstrable useful, and the question is to quantify the limits of what we can say, rather than just get rid of them. And then maybe the slightly more nuanced answer is that actually, if we have less confidence in the models, and our uncertainty ranges are wider, then because in many of these application areas and climate change, in particular, the damage function is convex, you know, we are expecting that as we go further from today’s climate, the consequence will be not just linearly worse, but sort of increasingly worse. And therefore, if you have, if you’re considering, you know, just to have a sketch of a kind of cost benefit analysis on some sort of expected utility from taking action to mitigate carbon emissions, for example, if you have more uncertainty, then your range is wider. And so the, the lack of quantification of the top tail becomes dominant in in the expected utility of the outcome. And therefore, you should be choosing to mitigate more, not less, because of that uncertainty. So, you know, the sceptics, I suppose the climate sceptics would say, oh, there’s a possibility that climate change might not be as bad as we expect, and therefore we shouldn’t bother doing anything. But I would say actually, that argument should be turned on its head, if we have greater uncertainty, that should be a bigger motivating factor to reduce carbon emissions rather than the opposite.</p>
<p><strong>Brian Tarran</strong><br>
Yeah, and I think you make that point quite clearly in the book. And the other point you make is that, I guess, building trust in models is about understanding their limitations. And the quote that I thought was really interesting was about acknowledging the social element of modelling. And I wonder, do you mind explaining what that social element is for people who are watching or listening? And how will that kind of manifests itself in models? Maybe you’ve got like a simple example that you might want to talk to? I don’t know.</p>
<p><strong>Erica Thompson</strong><br>
Yeah, okay. So, I mean, the social element of models is, because it is arbitrary how we choose to model a situation, there are infinitely many different ways that you could choose to simplify reality, this, you know, huge, messy, complex thing in front of us with physical laws that we don’t fully understand and things going on that we can only measure, sort of by proxy, with, you know, with models themselves to make many of our measurements of the system. And so, so you might choose to simplify a system in one way to model it. And I might choose to simplify it in a different way. And you might choose one programming language, and I might choose another and they would implement functions in different ways. And so all of our choices change the way that the model will then look at the end of the day. Now, then you say, okay, but supposing I’m modelling you know, what will happen to a ball when I throw it up in the air? Surely, that’s not a, you know, that has no social content, does it? And I’d say basically, no, it doesn’t really have any social content. It has some social content insofar as you’re deciding that this is what we want to make a model of. But ultimately, you and I would probably come up with very similar models, regardless of our background or our perspective, or our interests, or even our education to a large extent. And so, so those relatively simple linear situations, which I refer to as interpolatory models don’t have very much social content. Now, the ones that I’m particularly interested in and that I talk about in the book are things that are extrapolatory, where we’re interested in situations where we are trying to predict into the future a system where we expect the underlying conditions to be non-stationary, to be changing. So climate change is one example. Social and economic systems would be another example. And when we’re modelling systems like that, we have to be much more careful because we could choose to model them in radically different ways. We could, if you want to model an economic system, you might choose to disaggregate with respect to the social class of different households. And I might choose to make a sort of bulk model of the whole system with a representative household. And you could imagine hundreds of different ways to do these sorts of things. So maybe you think about pandemic models and how you could simplify it into individuals or you could make an agent-based model with, you know, actual agents walking around and infecting each other. Or you could just write some differential equations for how the transfer happens. So you could do it in, again, in many different ways. And the choice of simplification is then much more important, and it will have much larger first order effects on the outputs, and then on the framing of the question, you know. So you decide to model it in a certain way, with a certain kind of mathematics, and that changes the way that you might think about intervening in the system. If you’re presenting your model to a policymaker with the intent of informing them about their policy options, you might, if you have a model which can represent the effects of say, closing schools, or universities on pandemic transmission, then then that becomes a policy option. If you have a model which can’t represent those kinds of interventions, then it’s not a policy option. And similarly, with climate change, one of the examples that I talk about in the book is integrated assessment models of energy and climate. And so these are models which consider the energy system out to say 2100, and they put a price on nuclear electricity and renewables and all the other things that go into the energy system and basically say, how can we achieve our carbon targets at the lowest cost? Now, if you put in, if you choose to put in a certain price for a certain technology or assumptions about how that technology will develop in future, then you get a particular answer. And you put emphasis on certain kinds of policy options. And so that has, the choice of assumption has a very direct result in the model output and in the information and advice that you’re giving to policymakers. And of course, you might choose to put in something like behaviour change. So maybe we have a cost of however many dollars per tonne of carbon dioxide, for nuclear electricity or for renewables. But how much, what kind of price would you put on behaviour change? How many dollars per tonne of CO<sub>2</sub> avoided does it cost to change the behaviour of a population such that they use less energy? Well, that’s not really in the models. And if it was, it would, again, it would be first order because that would be you know, if you put it in at $2 per tonne of CO<sub>2</sub>, it would be heavily relied on, if you put it in at $2,000 per tonne of CO<sub>2</sub>, it’ll never happen. And where you choose to put that in between influences how it looks, and then that influences the pathway that’s projected, and it influences the advice that you give to policymakers.</p>
<p><strong>Brian Tarran</strong><br>
Yeah. You mentioned the example of school closures and stuff when you’re talking about Covid-19. I actually thought that, that one really helped me understand, I guess, and made it clear to me was that, there’s often been that argument about whether the lockdown was the right thing to do given the other impacts, but you actually say that if different types of people were doing the modelling, maybe if it was school aged people, and I guess encoding the impact that that would have had on them, and how much they value say not being able to go out and see their friends, the impacts potentially on mental health and things like that, it does change, I guess, the calculation of what the right intervention is or the right response is.</p>
<p><strong>Erica Thompson</strong><br>
Yeah, exactly. And I think I think we haven’t anywhere near bottomed out all of these impacts of the pandemic, you know, both the health impacts, and also, mental health and economic impacts will be rippling on for a very long time to come. So we, you know, we can’t even now retrospectively look back and say what was the right decision? It’s really not clear, depends how you value the different outputs, the different outcomes of a decision. And yes, we didn’t have economic models of what the impact of lockdown would be. And if we, if those had been available and developed the same kind of mathematical complexity and credibility as the models of infection and transmission we had in those early stages of the pandemic, which had essentially morbidity, mortality, and the, you know, the impact on the NHS, you know, number of hospital beds occupied. Those were the bottom lines, and there was nothing else. And so that was given as an input to the policymakers. Now, that’s, of course not everything that the policymakers rely on, they have to, their role is to weigh up everything else as well. But if we’d had models which contained more information about all of those other impacts, I think it’s quite plausible that we would have seen different kinds of decision making. And then there’s also the communication aspect, that these models were used to communicate and justify and persuade the public of the importance of the actions that were taken. And, you know, I think it’d be hard to disagree that the actions that were taken immediately where necessary, we certainly did need some kind of lockdown straight away. But then the question of exactly what you do thereafter is much more difficult.</p>
<p><strong>Brian Tarran</strong><br>
Yeah, yeah. So in the book, you kind of make the point that it’s somewhat of a fool’s errand to try and make models objective, and they can’t ever really achieve this, you know, principle of scientific objectivity. But that we instead should look to counter subjectivity of individual models with a diversity of models that do encode these different perspectives, like we’ve just been talking about. I wonder, you know, how would you see this working in practice? Or how would you like to see this working in practice?</p>
<p><strong>Erica Thompson</strong><br>
I mean, that’s a difficult question. So it’s, it’s nice to think that, you know, we have these models, and they are unavoidably subjective. Essentially, my view is that the model encapsulates the expert opinion of a particular expert, and it comes laden with their own perspectives, and biases and preconceptions, as well as their expertise and their education and their experience of a subject, you know, which shouldn’t be set aside. So if we are trying to understand a situation, then we want to get as many perspectives as possible. And so in theory, incorporating the widest possible diversity of different backgrounds into modelling and making a multiplicity of different models and trying to see the problem from these different perspectives will help us to understand it better. Now, then the statistician will jump in and say, Aha, can we, you know, can we in some way average those models or use some sort of statistical inference to take those models and put them together and come up with an even better answer? And I would, I would sort of counter that by saying that there’s no reason to believe that our, that a set of models generated as essentially just one set of opinions will be an independent and identically distributed sample from some distribution, underneath which will be an estimator of, of the truth, if that even exists. And so many of the formal statistical methods that we would quite like to apply to an ensemble of models, a large group of models put together aren’t really conceptually valid at all. I mean, that doesn’t stop people doing it. And maybe you get some interesting information from it, but you certainly can’t rely on it as an estimator. So there’s a sort of statistical problem there. And then the other question is your reference class. So, to what extent do you believe that these models are all equally valid or equally plausible? So that then brings the social question back to the forefront. Because then you say, you know, if I believe that, you know, somebody from Imperial College, say, who is the head of an institute for epidemiology, and has many, many years of experience making this kind of model, you know, is an expert and is qualified to create a model and for that to be recognised as a valid expert opinion, who else has got the credibility to do that? How do we define that? You know, what do you call a plausible model? So then it’s a question of the sort of scientific gatekeeping. What kind of qualifications do you expect from somebody or from an institution? What kind of expertise counts as being relevant and valid expertise? Does it have to be mathematical expertise? Can it be lived experience? Can it be, does the model have to be a mathematical model? What kinds of mathematics are appropriate for the situation? If we disagree about assumptions, does that mean that we can’t consider the the two sets of models in the same sort of class of plausible models? Or are we going to start pruning it by saying, I believe your assumptions, and I don’t believe your assumptions? And if so, who gets to do that? Who gets to decide what is plausible and what is not plausible? And what is allowed to enter into this set? Because as soon as we start pruning it, then we make the statistical inference more difficult. You know, if you want to say, if you want to start applying your methods that assume that the models are on, you know, that the models are independent, then you can’t start pruning because then that introduces huge dependencies on your own expert judgement. So it just becomes extremely difficult. And this is where all of then the social questions about expertise and credibility and sort of scientific gatekeeping and how we assign that credibility and trust, trust in science, you know, who has trust in which kinds of models? This is something, this is a theme that we see coming out of climate science and, you know, hopefully less now than maybe 10 years ago. But in the pandemic, of course, we’ve seen it coming right up again with questions about lockdowns, and about vaccination strategies, and all of that sort of thing. Trust in science is really important. And maybe one of my themes is that trust in science actually is first order in the modelling process itself. It’s not something that is sort of added on afterwards, I’m going to go away and make my model and then the question is whether or not you trust it. Actually, trust and expertise and credibility are in the modelling process directly.</p>
<p><strong>Brian Tarran</strong><br>
Do you mind if we segue to talking about artificial intelligence models, or models made by artificial intelligence? Because that’s, I think that touches on a lot of the same issues, right? And I wanted to think about, well, first of all, you say that, obviously, artificial intelligence models made by AI, they’re not objective, even though there’s like, they’re kind of building the models, if you like, those AIs have still been trained by people, been coded by individuals and those personal judgments and assumptions and all that get embedded into the artificial intelligence. But I think, I guess my question for you is, we’re starting, I think, to have a very frank and public debate about AI ethics, and to demand transparency and explainability of things like automated decision making systems. But do you think we’re kind of, are we falling short of holding ourselves as people to the same standards of transparency and being clear about the choices and decisions we make? And also documenting that subjectivity when we’re preparing these sorts of models and these sorts of decision making systems for policymakers to use?</p>
<p><strong>Erica Thompson</strong><br>
Yeah, so I mean, I suppose there are two questions there. And one’s about what we do and one’s about the AI. So for the humans, maybe, yes, I think that there needs to be more frank discussion of values and value judgments and politics and social assumptions within models. And I think we are starting to see that with the pandemic models, particularly because it’s been so high profile. I mean, remembering that actually, it’s really hard to unpick your own value judgments. And it’s easier for somebody with a different perspective to come in and say, Oh, actually, you know, you’ve assumed that, why did you assume that? And, you know, when we are embedded in a particular culture of modelling, it’s particularly hard to imagine that anything could possibly be done differently. And so I think that’s, again, where diversity is really important, because introducing those perspectives will help to challenge dominant strains of thinking which can end up in sort of accidentally, and not deliberately at all, in a form of groupthink. So that’s the humans and then the, with the AI, yes, you know, they inherit their value judgments from their creators. And so, for example, on the statistical side, one might think about the kinds of loss functions that are used to calibrate machine learning programmes, you know, how does the machine decide what is better and what is worse? You know, it is learning to model a situation, but there will be some kind of loss function in there, which it is minimising in order to decide what is the best model. And so, being explicit about that loss function, I think, actually is really interesting, you know, the fact that the model has got written down an explicit loss function which it is minimising means that we can then analyse that and think about what are the value judgments inherent in that choice of loss function, which is something that we don’t have when humans are calibrating a model and they’re twiddling a knob here and a knob there and saying, Oh, does it look realistic? Am I getting the right kind of behaviours, you know, does it match up with the map I have from observations or whatever. And so, having that I think we can then say, what are the implications of writing a loss function in this way? And what are the values that are implied? I mean, even just modelling itself, you know, like choosing to solve a problem with recourse to mathematical modelling is a value judgement and implies a certain kind of solution, doesn’t it? So if we say that we even can come to a decision, that the models input will be relevant and interesting and help us, that is a value judgement.</p>
<p><strong>Brian Tarran</strong><br>
Yeah, and perhaps we could return to that point a bit later, because there was a line again that jumped out in the book about decision makers needing to maybe curb some over enthusiasm for mathematical solutions. You do talk about documenting value judgments as being kind of one of five principles that you set out for mathematical modellers to adopt to support responsible modelling. I think it’s fascinating to me that you’ve used the vehicle of a popular science textbook to speak to this community, and to sort of set out these principles rather than, say, a journal paper or conference presentation. So I wanted to ask, is there a particular strategy to that decision? I mean, I have my own theory on that, but maybe I’ll let you go first.</p>
<p><strong>Erica Thompson</strong><br>
I’d love to hear your theory. I mean, I guess partly because I suppose I’m very interdisciplinary. And I’m, I’m hopping between these different areas, as we were discussing before, so I have sort of a climate science community and statistics and data science and other application areas in humanitarian forecasting, sort of hydrology, geophysics, weather and climate and all the rest of it. And actually, I find it really hard to get these thoughts published in journal form, because I suppose partly because it feels too general for any specific journal. And perhaps it feels too simplistic that, that the reviews I get tend to be either Oh, we’ve heard this all before it’s not new, or this is too radical and this isn’t an appropriate journal for it, you know, that sort of thing. And actually, I kind of got to the point of thinking, Well, you know, do people even read these journals anyway? Actually, maybe really what I need to be doing is trying to provoke a wider discussion about models. And I do tend to get a, you know, a really good response, when I speak at conferences or talk to people about these things. People go yes, yes, you know, this is really important. Actually, this is something I’ve really struggled with, we don’t know how to do it, the uncertainty is always just an add on at the end that doesn’t have enough time allocated for it. But I don’t have the resource to do it, I’m not able to grapple with these questions, because they’re so fundamental and so wide ranging, and it would be really helpful to have more of a sort of walkthrough of how people tackle these questions in different fields. And so, so I’ve been trying to do that. And I felt that the book was a good way to sort of spark the conversation and maybe also get it to some different audiences. So I’ve had people contacting me since the book came out saying, oh, you know, I’m working in, like, asset valuation for disputes between states, really random things, quite different. And they say, actually, your book really struck a chord, and we have difficulties with this in this particular area. And so I’m really hoping that, you know, the book will help me then to find, to bring together people working on these sorts of issues with common themes from really different application areas and try to make some headway on how we can actually go about practically changing modelling practice to make it to make it work better, and assess uncertainty better. So it’s not just– I think some people maybe read the book and think, Oh, this is just a sort of woke advertisement for diversity. Well, it’s not; it’s a way of doing the maths better. The whole point is to do the maths better, make better forecasts, understand the future more effectively, and be able to make better decisions based on that information.</p>
<p><strong>Brian Tarran</strong><br>
Yep, well, that’s not too far away from my theory on why you did it. I thought it was that it’s a great way of getting– if you can get policymakers and the public to read this, right, you can get them to hold modellers to these principles, rather than having it just be something that you kind of talk about within the community and it doesn’t really go outside that, right? It’s a way of people, you know, the next pandemic or whatever it might be, the next time a model is the focus of a debate, the public are equipped to ask the right sort of questions about the process. Okay, I’ve got one more question to you because we’re running out of time. And it’s back to that over enthusiasm for mathematical solutions point. I thought was somewhat serendipitous to read about, read that quote, in the same week that the UK Prime Minister Rishi Sunak announced a plan for all pupils in England to study maths to the age of 18. So, I wanted to ask you what you make of that plan, first of all, but also, I think, more importantly, does a more mathematically minded populace, are they better equipped to understand the mathematical descriptions of the world and that they are incomplete descriptions? Or is there kind of maybe some other curriculum that we need to tack on to this maths to 18, in order that people are able to better differentiate between model land and the real world?</p>
<p><strong>Erica Thompson</strong><br>
Yeah, so I mean, I’m not a fan of– I mean, I like the idea of people studying maths to 18. I think more maths is a good thing. I loved maths, I still love maths, I think if more people were more generally numerate then society would be better and life would be better. But if you haven’t enthused people about the value and the interest of maths by 16, forcing them to study it for another two years is absolutely not the answer. It will just put people off staying in school past 16. So I, you know, I think that we need better teaching of maths before 16, rather than forcing people to study maths post 16. And part of that is helping people to understand how mathematics is relevant to the real world that they live in and teaching them the kind of things that they will use in their adult life. You know, people, most people don’t use Pythagoras theorem, but most people do need to fill in a tax return, you know, these sorts of things. Understanding orders of magnitude, and the difference between millions and billions, would be incredibly helpful, wouldn’t it? So, yeah, I think there are more basic questions there that need to be answered before we go into the details of sort of complex maths. And then, so what was the next question?</p>
<p><strong>Brian Tarran</strong><br>
It was about whether whether you think, the more mathematically equipped we are, does that make us better able to understand the limitations of models? Or do we need something else to kind of train us or encourage us to think about these two separate realities, model land and the real world? And I say realities in inverted commas.</p>
<p><strong>Erica Thompson</strong><br>
Yeah, I mean, I think the general public has a good understanding that the model land and the real world are not the same. There is actually a healthy scepticism of models out there. And I think that’s probably a good thing. I give a couple of funny anecdotes in the book about that. So I mean, one was a, I think, a YouGov poll about people going to the moon and saying, you know, would you go to the moon if you could be guaranteed a safe return, blah, blah, blah, and like, a large percentage of those said, Well, no, I just don’t think you could give me a safe return, they reject the model land. And then there was another example about intelligence analysts being asked to sort of calibrate a probability language scale. So they say, like, likely, however many percent and very likely however many percent and unlikely however many percent. And so the study was looking at different ways of doing that. And one way was to accompany the word likely, or unlikely, or whatever, with a written number of what the probability it referred to was. So it would say, like, likely, I can’t remember the number, but sat it was, like 50 to 70%, written down in the question, and then the question was, what is the probability of an event, which is deemed to be likely brackets 50 to 70%? And what people write down was not 50 to 70%. You know, as a mathematician, that’s completely ridiculous. Because the answer was in the question, why wouldn’t you write that down? But of course, what you’re seeing there is the rejection of model land. Somebody has assessed it as 50-70%. The question is, do you believe it? Well, no, actually, you might write something like 40 to 80%, because you expect there to be, you know, the model to be generically overconfident. And so this is sort of what I mean, by curbing over enthusiasm for mathematical solutions is that, you know, we have to understand that the mathematical solutions are living in model land, and that we can, in order to get out of model land, we have to say, do we actually expect this result to refer to the real world? Or is it only saying what the next model run is going to tell us? And so the act of doing that is difficult, and it’s more difficult for mathematicians than for the general public because as mathematicians, we sort of are used to living within model land and noticing when the answer is in the question and then writing it down. And we’re not very good at saying, Well, what’s my subjective estimate of the probability of this model being inadequate in some way? That’s not something that you can necessarily do with respect to data and so it’s a tricky one. So in terms of the over enthusiasm, you know, it’s curbing over enthusiasm, not curbing enthusiasm, because as I said at the beginning, and I returned to a lot in the book, actually, mathematical models are incredibly valuable. And they contain a huge amount of information and insight that we’re, we would be fools to throw away. But we need to understand it, you know, in a more nuanced way and be clear about what it’s telling us and what it’s not telling us. And that answers in model land aren’t necessarily the answers that we need in reality, though they may be informative about them.</p>
<p><strong>Erica Thompson</strong><br>
Well, Erica, thank you very much for your time today, for talking through the book, which is out now. Do you have some some links or information about where people can find out more about the book?</p>
<p><strong>Erica Thompson</strong><br>
Yep, look on my on my website, ericathompson.co.uk. And it’s available through all the usual booksellers.</p>
<p><strong>Brian Tarran</strong><br>
Excellent, excellent. Well, I wish you the best of luck with the book. As I say, I think it’s fantastic. And well, I hope we get to talk again, maybe a bit further down the road and see whether some of these principles and this ethical framework that you talk about for mathematical modelling, whether that kind of comes to fruition because I think we need to watch that closely. So, Erica, thank you.</p>
<p><strong>Erica Thompson</strong><br>
Thank you very much. Thanks for having me.</p>
<section id="back-to-interviews" class="level6">
<h6 class="anchored" data-anchor-id="back-to-interviews"><strong>← Back to <a href="../../../../../news-and-views/interviews/index.html">Interviews</a></strong></h6>
<hr>
<p xmlns:cc="http://creativecommons.org/ns#">
This work is licensed under <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;">CC BY 4.0<img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://realworlddatascience.net/news-and-views/interviews/posts/01/25/https:/mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://realworlddatascience.net/news-and-views/interviews/posts/01/25/https:/mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"></a>
</p>


</section>
</section>

 ]]></description>
  <category>Modelling</category>
  <category>Ethics</category>
  <guid>https://realworlddatascience.net/news-and-views/interviews/posts/01/25/erica-thompson.html</guid>
  <pubDate>Wed, 25 Jan 2023 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/news-and-views/interviews/posts/01/25/images/erica-thompson.png" medium="image" type="image/png" height="105" width="144"/>
</item>
<item>
  <title>Pulling patterns out of data with a graph</title>
  <dc:creator>Andrew Saydjari</dc:creator>
  <link>https://realworlddatascience.net/news-and-views/datasciencebites/posts/2023/01/24/pulling-patterns.html</link>
  <description><![CDATA[ 




<div class="callout-note callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-1-contents" aria-controls="callout-1" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
About the paper and this post
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-1" class="callout-1-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<p><strong>Title:</strong> Extracting the main trend in a data set: The Sequencer algorithm</p>
<p><strong>Author(s) and year:</strong> Dalya Baron and Brice Ménard (2021)</p>
<p><strong>Status:</strong> Published in <em>The Astrophysical Journal</em>, open access: <a href="https://iopscience.iop.org/article/10.3847/1538-4357/abfc4d">HTML</a>, <a href="https://iopscience.iop.org/article/10.3847/1538-4357/abfc4d/pdf">PDF</a>.</p>
<p><strong>Editor’s note:</strong> This post is republished with permission from <a href="https://mathstatbites.org/pulling-patterns-out-of-data-with-a-graph/">MathStatBites</a> to demonstrate the Bites concept. For more information about Bites articles and how to contribute to DataScienceBites, see our <a href="../../../../../../contributor-docs/datasciencebites.html" aria-label="Contributor notes for the Data Science Bites blog">notes for contributors</a>.</p>
</div>
</div>
</div>
<p>Large volumes of data are pouring in every day from scientific experiments like <a href="https://home.cern/">CERN</a> and the <a href="https://www.sdss5.org/">Sloan Digital Sky Survey</a>. Data is coming in so fast that researchers struggle to keep pace with the analysis and are increasingly developing automated analysis methods to aid in this herculean task. As a first step, it is now commonplace to perform dimension reduction in order to reduce a large number of measurements to a set of key values that are easier to visualize and interpret.</p>
<p>When working on the cutting edge, another problem scientists often face is that “we don’t know what we don’t know”. For this reason, we often want to simply ask the data, “What is interesting about you?” This is the realm of <a href="https://en.wikipedia.org/wiki/Unsupervised_learning">“unsupervised” methods</a>, where the data itself drives the analysis, with little to no guidance or human labeling of the data.</p>
<p>Many physical processes depend continuously on some driving parameter. For example, the evaporation rate of water increases with temperature. We call these continuous variations in datasets “trends”. Describing a dataset by a single trend reduces it to one dimension - an ordered list. Finding such a trend within a high-dimensional dataset is the aim of a method called “The Sequencer” introduced by Baron and Ménard.</p>
<section id="key-insight-a-tree" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="key-insight-a-tree">Key insight: A tree</h2>
<p>The key insight of Baron and Ménard was to relate trends in data to an object from graph theory called a <a href="https://en.wikipedia.org/wiki/Minimum_spanning_tree">minimum spanning tree</a>. Given a measure of distance between two data points, for example the usual (Euclidean) distance between two points, we can visualize a dataset as a graph. This graph consists of a node (a dot) for each data point. These nodes are then connected by an edge (a line), labeled by the distance between the two data points. The minimum spanning tree is a reduction of this graph to include only enough of the smallest distance edges so that no node is isolated.</p>
<p>What Baron and Ménard realized is that datasets that are “trendy” have elongated and narrow minimum spanning trees. As shown in Figure 1, a totally random dataset results in a graph with many branches while a perfect sequence results in a perfect linear graph. Then, they use connectivity of the nodes in the minimum spanning tree to return an ordering of the data that follows the main trend in the dataset. However, a sequence is all you get. It is up to us to understand and interpret what this trend represents.</p>
<div class="column-page">
<p><img src="https://realworlddatascience.net/news-and-views/datasciencebites/posts/2023/01/24/images/fig1.png" class="img-fluid" alt="Three examples - labelled 'random data', 'noisy sequence', and 'perfect sequence' - demonstrating that data with stronger trends ('noisy' and 'perfect sequence') have more narrow and elongated minimum spanning trees (adapted from Baron and Ménard, Figure 1)."></p>
</div>

<div class="no-row-height column-margin column-container"><div class="">
<p><strong>Figure 1:</strong> Examples demonstrating that data with stronger trends have more narrow and elongated minimum spanning trees. Adapted from <a href="https://iopscience.iop.org/article/10.3847/1538-4357/abfc4d" aria-label="Link to Baron and Ménard's 2021 paper, 'Extracting the main trend in a data set: The Sequencer algorithm'">Baron and Ménard (2021)</a>, Figure 1. Figure used under <a href="https://creativecommons.org/licenses/by/4.0/" aria-label="Link to Creative Commons licence">CC BY 4.0</a>.</p>
</div></div><p>Sometimes, the ordering of observations within a data point matters, like in time series data. Measurements taken close in time are more likely to be correlated than measurements taken after a long time delay. Baron and Ménard were careful to include a measure of distance that takes this ordering into account, unlike our usual notion of distance. They argue that this gives them an edge over other common dimension reduction techniques such as <a href="https://en.wikipedia.org/wiki/T-distributed_stochastic_neighbor_embedding">t-SNE</a> and <a href="https://umap-learn.readthedocs.io/en/latest/how_umap_works.html">UMAP</a>, and even go so far as to use The Sequencer to optimize the hyperparameters used by these other methods!</p>
</section>
<section id="when-does-it-fail" class="level2">
<h2 class="anchored" data-anchor-id="when-does-it-fail">When does it fail?</h2>
<p>It is important to acknowledge that no statistical or machine-learning tool is a cure-all. And, the authors themselves are quick to point out several limitations that can hinder the application of their method. The Sequencer can struggle when the data has a large dynamic range, a variety of signal strengths relative to noise, or there are multiple trends present in the data. In each case, Baron and Ménard propose ways to mitigate these problems, but practitioners still need to be wary when applying The Sequencer in those instances.</p>
</section>
<section id="what-discoveries-await" class="level2">
<h2 class="anchored" data-anchor-id="what-discoveries-await">What discoveries await?</h2>
<p>To demonstrate the power of their method, Baron and Ménard apply The Sequencer to several real datasets where a pattern was already known and show that The Sequencer recovers that pattern. Examples include ordering spectral measurements of stars by their temperature and <a href="https://en.wikipedia.org/wiki/Quasar">quasars</a> by their <a href="https://en.wikipedia.org/wiki/Redshift_survey">redshift</a>, a measure of their distance from us on Earth.</p>
<p>But, what about new patterns? The team has already applied The Sequencer to mine seismographic data and discover previously unknown formations deep within the earth, at the boundary between the core and <a href="https://en.wikipedia.org/wiki/Core%E2%80%93mantle_boundary">mantle</a>. By sequencing the seismic waves, they realized that the main trend was the amplitude of diffraction off of these structures, which they were then able to localize beneath Hawaii and the Marquesas (DOI: <a href="https://doi.org/10.1126/science.aba8972" aria-label="Link to article, 'Sequencing seismograms: A panoptic view of scattering in the core-mantle boundary region'">10.1126/science.aba8972</a>).</p>
<p>For more demonstrations and discoveries, or even to upload your own data for sequencing, <a href="http://sequencer.org/">check out the project website</a>. Data sleuths can also download all of the code directly from <a href="https://github.com/dalya/Sequencer">GitHub</a> and sequence to their hearts’ content!</p>
</section>
<section id="about-the-author" class="level2">
<h2 class="anchored" data-anchor-id="about-the-author">About the author</h2>
<p><strong>Andrew Saydjari</strong> is a graduate student in physics at Harvard researching the spatial and chemical variations of dust in the interstellar medium. He favors using interpretable statistics and large photometric and spectroscopic surveys.</p>
</section>
<section id="about-datasciencebites" class="level2">
<h2 class="anchored" data-anchor-id="about-datasciencebites">About DataScienceBites</h2>
<p><a href="../../../../../../news-and-views/datasciencebites/index.html"><strong>DataScienceBites</strong></a> is written by graduate students and early career researchers in data science (and related subjects) at universities throughout the world, as well as industry researchers. We publish digestible, engaging summaries of interesting new pre-print and peer-reviewed publications in the data science space, with the goal of making scientific papers more accessible. Find out how to <a href="../../../../../../contributor-docs/datasciencebites.html">become a contributor</a>.</p>


</section>

 ]]></description>
  <category>Data management</category>
  <category>Dimension reduction</category>
  <category>Graph theory</category>
  <guid>https://realworlddatascience.net/news-and-views/datasciencebites/posts/2023/01/24/pulling-patterns.html</guid>
  <pubDate>Tue, 24 Jan 2023 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/news-and-views/datasciencebites/posts/2023/01/24/images/signal-from-noise.png" medium="image" type="image/png" height="115" width="144"/>
</item>
<item>
  <title>We’re taking Real World Data Science on the road</title>
  <dc:creator>Brian Tarran</dc:creator>
  <link>https://realworlddatascience.net/news-and-views/editors-blog/posts/2023/01/18/rwds-at-rss-conference.html</link>
  <description><![CDATA[ 




<p>Real World Data Science has booked its first conference appearance! This September, we’ll be part of the data science stream of the <a href="https://rss.org.uk/training-events/conference-2023/">RSS International Conference</a>.</p>
<p>Our session, “Real World Data Science Live”, will feature talks and discussions based on content published on this site. In particular, we’re looking to share compelling examples of how data science is being used to solve real-world problems.</p>
<p>If you’re thinking about <a href="https://realworlddatascience.net/contributor-docs/call-for-contributions.html">contributing to Real World Data Science</a>, or have already made a submission, do let us know whether you’d be interested in taking part in this in-person event. There are only a handful of speaker slots available, so please get in touch ASAP!</p>
<p>The conference takes place 4-7 September 2023, in Harrogate, Yorkshire. <a href="https://rss.org.uk/news-publication/news-publications/2023/general-news/first-keynote-speaker-announced-for-rss-2023-confe/">Keynote speakers include Anuj Srivastava</a>, a Florida State University professor with research interests in statistical computer vision, functional data analysis, and shape analysis, and other <a href="https://rss.org.uk/training-events/conference-2023/invited-session-topics/">invited topic sessions</a> in the data science stream are:</p>
<ul>
<li>GitHub: Version control for research, teaching and industry</li>
<li>Surrogate-assisted uncertainty quantification of complex computer models</li>
<li>Getting your work to work</li>
<li>Best practices for the analysis and visualisation of Google Trends data</li>
</ul>
<p>See the <a href="https://rss.org.uk/training-events/conference-2023/">RSS International Conference 2023 website</a> for more details.</p>
<section id="back-to-editors-blog" class="level6">
<h6 class="anchored" data-anchor-id="back-to-editors-blog"><strong>← Back to <a href="../../../../../../news-and-views/editors-blog/index.html">Editors’ blog</a></strong></h6>
<hr>
<p xmlns:cc="http://creativecommons.org/ns#">
This work is licensed under <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;">CC BY 4.0<img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://realworlddatascience.net/news-and-views/editors-blog/posts/2023/01/18/https:/mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://realworlddatascience.net/news-and-views/editors-blog/posts/2023/01/18/https:/mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"></a>
</p>


</section>

 ]]></description>
  <category>Updates</category>
  <category>Events</category>
  <guid>https://realworlddatascience.net/news-and-views/editors-blog/posts/2023/01/18/rwds-at-rss-conference.html</guid>
  <pubDate>Wed, 18 Jan 2023 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/news-and-views/editors-blog/posts/2023/01/18/images/rss-conf23.png" medium="image" type="image/png" height="94" width="144"/>
</item>
<item>
  <title>Explore the RSS Data Science &amp; AI Section newsletter, right here!</title>
  <dc:creator>Brian Tarran</dc:creator>
  <link>https://realworlddatascience.net/news-and-views/editors-blog/posts/2023/01/05/newsletter.html</link>
  <description><![CDATA[ 




<p>Happy New Year from all of us at Real World Data Science. We hope you had a relaxing break over the holidays and are now refreshed and excited to see what 2023 has in store. We’re starting the year with a new addition to the site: a page dedicated to the excellent <a href="https://realworlddatascience.net/news-and-views/newsletter/">RSS Data Science &amp; AI Section newsletter</a>.</p>
<p>This monthly newsletter has been running since February 2020 and is well worth subscribing to as it features roundups of news, new developments, big picture ideas and practical tips.</p>
<p>You’ll find the full list of past newsletters in our <a href="https://realworlddatascience.net/news-and-views/"><strong>News and views</strong></a> section (click the “Newsletter” heading in the section menu). If you want to subscribe to the newsletter, head over to <a href="https://datasciencesection.org/about/">datasciencesection.org</a>. The Data Science &amp; AI Section also has a page on the <a href="https://rss.org.uk/membership/rss-groups-and-committees/sections/data-science-section/">RSS website</a>.</p>
<section id="back-to-editors-blog" class="level6">
<h6 class="anchored" data-anchor-id="back-to-editors-blog"><strong>← Back to <a href="../../../../../../news-and-views/editors-blog/index.html">Editors’ blog</a></strong></h6>
<hr>
<p xmlns:cc="http://creativecommons.org/ns#">
This work is licensed under <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;">CC BY 4.0<img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://realworlddatascience.net/news-and-views/editors-blog/posts/2023/01/05/https:/mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://realworlddatascience.net/news-and-views/editors-blog/posts/2023/01/05/https:/mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"></a>
</p>


</section>

 ]]></description>
  <category>Updates</category>
  <category>Newsletters</category>
  <guid>https://realworlddatascience.net/news-and-views/editors-blog/posts/2023/01/05/newsletter.html</guid>
  <pubDate>Thu, 05 Jan 2023 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/news-and-views/editors-blog/posts/2023/01/05/images/brett-jordan-LPZy4da9aRo-unsplash.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>Sink your teeth into some data science papers with our brand new blog</title>
  <dc:creator>Brian Tarran</dc:creator>
  <link>https://realworlddatascience.net/news-and-views/editors-blog/posts/2022-12-13-dsb-launch/dsb-launch.html</link>
  <description><![CDATA[ 




<p>I’m absolutely thrilled today to announce the launch of our new blog, <a href="../../../../news-and-views/datasciencebites/index.html">DataScienceBites</a>. The blog is not only a new addition to Real World Data Science, but also the latest proud member of the ScienceBites family of sites.</p>
<p><a href="https://sciencebites.org/sciencebites-sites-galaxy/">ScienceBites sites</a> all share the same <a href="https://sciencebites.org/about/">concept</a>: we publish “short digestible <em>bites posts</em> about individual research papers” in an effort to make cutting-edge science accessible to a wide audience, and our posts are written by graduate students and early career researchers.</p>
<p>For <a href="../../../../news-and-views/datasciencebites/index.html">DataScienceBites</a>, our focus will of course be on new publications in the data science space. Contributors are invited to write about papers that are of particular interest to them and to pitch their summaries at an undergraduate level. For an example of what we’re looking for, see our first post on <a href="../../../../news-and-views/datasciencebites/posts/2022/12/13/ridesharing.html">“Determining the best way to route drivers for ridesharing via reinforcement learning”</a>.</p>
<p>This launch post is written by Brian King and is republished with permission from <a href="https://mathstatbites.org">MathStatBites</a>, so I want to say a big thank you to Brian and editors Sadie Witkowski and Sara Stoudt for allowing us to repost it. Sadie and Sara have been fantastically supportive of the DataScienceBites idea, and I am grateful for all their behind-the-scenes efforts.</p>
<p>Brian’s post is a great demonstration of the Bites concept, and we hope that it will inspire others to follow suit. If you are a graduate student or early career researcher in data science (or related subjects) with a passion for science communication and an interest in writing about new data science research, please do <a href="../../../../contact.html">get in touch</a>. See our <a href="../../../../contributor-docs/datasciencebites.html">notes for contributors</a> for further details.</p>
<p>To everyone else, we do hope you enjoy sinking your teeth into the data science literature with <a href="../../../../news-and-views/datasciencebites/index.html">DataScienceBites</a>. Happy reading!</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://realworlddatascience.net/news-and-views/editors-blog/posts/2022-12-13-dsb-launch/images/datasciencebites-logo.png" class="img-fluid figure-img" alt="DataScienceBites logo. A dark grey circle with bite marks cut out. Overlaid text says, Import grad_students as writers, import new_research_papers as nrp, print(writers + nrp) and the title DataScienceBites." width="500"></p>
</figure>
</div>
<section id="back-to-editors-blog" class="level6">
<h6 class="anchored" data-anchor-id="back-to-editors-blog"><strong>← Back to <a href="../../../../news-and-views/editors-blog/index.html">Editors’ blog</a></strong></h6>
<hr>
<p xmlns:cc="http://creativecommons.org/ns#">
This work is licensed under <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;">CC BY 4.0<img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://realworlddatascience.net/news-and-views/editors-blog/posts/2022-12-13-dsb-launch/https:/mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://realworlddatascience.net/news-and-views/editors-blog/posts/2022-12-13-dsb-launch/https:/mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"></a>
</p>


</section>

 ]]></description>
  <category>Updates</category>
  <category>Content ideas</category>
  <category>Call for contributions</category>
  <guid>https://realworlddatascience.net/news-and-views/editors-blog/posts/2022-12-13-dsb-launch/dsb-launch.html</guid>
  <pubDate>Tue, 13 Dec 2022 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/news-and-views/editors-blog/posts/2022-12-13-dsb-launch/images/datasciencebites-logo.png" medium="image" type="image/png" height="144" width="144"/>
</item>
<item>
  <title>Determining the best way to route drivers for ridesharing via reinforcement learning</title>
  <dc:creator>Brian King</dc:creator>
  <link>https://realworlddatascience.net/news-and-views/datasciencebites/posts/2022/12/13/ridesharing.html</link>
  <description><![CDATA[ 




<div class="callout-note callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-1-contents" aria-controls="callout-1" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
About the paper and this post
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-1" class="callout-1-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<p><strong>Title:</strong> Dynamic causal effects evaluation in A/B testing with a reinforcement learning framework</p>
<p><strong>Author(s) and year:</strong> Chengchun Shi, Xiaoyu Wang, Shikai Luo, Hongtu Zhu, Jieping Ye, Rui Song (2022)</p>
<p><strong>Status:</strong> Published in <em>Journal of the American Statistical Association, Theory and Methods</em>, open access: <a href="https://www.tandfonline.com/doi/full/10.1080/01621459.2022.2027776">HTML</a>, <a href="https://www.tandfonline.com/doi/epdf/10.1080/01621459.2022.2027776?needAccess=true&amp;role=button">PDF</a>, <a href="https://www.tandfonline.com/doi/epub/10.1080/01621459.2022.2027776?needAccess=true&amp;role=button">EPUB</a>.</p>
<p><strong>Editor’s note:</strong> This post is republished with permission from <a href="https://mathstatbites.org/determining-the-best-way-to-route-drivers-for-ridesharing-via-reinforcement-learning/">MathStatBites</a> to demonstrate the Bites concept. See <a href="../../../../../../contributor-docs/datasciencebites.html">here</a> for more information.</p>
</div>
</div>
</div>
<p>Companies often want to test the impact of one design decision over another, for example Google might want to compare the current ranking of search results (version A) with an alternative ranking (version B) and evaluate how the modification would affect users’ decisions and click behavior. An experiment to determine this impact on users is known as an A/B test, and many methods have been designed to measure the “treatment” effect of the proposed change. However, these classical methods typically assume that changing one person’s treatment will not affect others (known as the Stable Unit Treatment Value Assumption or SUTVA). In the Google example, this is typically a valid assumption — showing one user different search results shouldn’t impact another user’s click behavior. But in some situations, SUTVA is violated, and new methods must be introduced to properly measure the effect of design changes.</p>
<p>One such situation is that of ridesharing companies (Uber, Lyft, etc.) and how they determine which drivers are sent to which riders (the dispatch problem). Simply put, when a driver is assigned to a rider, this decision impacts the spatial distribution of drivers in the future. Hence the dispatch strategy (our treatment) at the present time will influence riders and drivers in the future, which violates SUTVA and hence invalidates many traditional methods for A/B testing. To tackle this problem, a group of researchers have recently employed a reinforcement learning (RL) framework which can accurately measure the treatment effect in such a scenario. Furthermore, their proposed approach allows for companies to terminate A/B tests earlier if the proposed version B is found to be clearly better. This early stopping can save time and money.</p>
<p>To better understand RL and how it can contribute to tackling the issue at hand, it’s first helpful to set some context. In typical RL problems, including the one in this paper, the scenario is modeled with something known as a Markov Decision Process (MDP). A MDP links three sets of variables across time: the state or environment, the treatment or action (the reaction to the environment), and the outcome (the response produced by the environment due to the action). These outcomes can be thought of as rewards which depend on the action taken and the state observed. Over time, the machine learns which actions produce more positive rewards and which bring about worse outcomes. Hence, the actions leading to higher rewards are positively reinforced, thus the name reinforcement learning. A causal diagram of an MDP is shown in Figure 1, where <em>S</em><sub><em>t</em></sub>, <em>A</em><sub><em>t</em></sub>, and <em>Y</em><sub><em>t</em></sub> are the <strong>state</strong>, <strong>action</strong>, and <strong>outcome</strong> at time <em>t</em>. As one can see, past treatments influence future outcomes by altering the state variables at the present (the so-called “carryover effect” which violates SUTVA).</p>
<div class="column-page">
<p><img src="https://realworlddatascience.net/news-and-views/datasciencebites/posts/2022/12/13/images/ridesharing-fig1.png" class="img-fluid" alt="A causal diagram of a Markov Decision Process is shown in this figure. Green circles represent states, with arrows leading to red diamonds and blue squares representing, respectively, actions and outcomes. Actions are linked to new states by arrows, and prior states are linked to new states by curved arrows. This illustration conveys how past treatments influence future outcomes by altering the state variables at the present (the so-called “carryover effect” which violates the stable unit treatment value assumption)."></p>
</div>

<div class="no-row-height column-margin column-container"><div class="">
<p><strong>Figure 1:</strong> Causal diagram of MDP, where the solid lines represent causal relationships.</p>
</div></div><p>Making this more concrete, consider an example where the decision-maker is a ridesharing company. The environment or <strong>state</strong> is whatever variables the decision-maker can measure about the world, like the spatial distribution of drivers, number of pickup requests, traffic, and weather. The company then makes some <strong>action</strong> on how to dispatch drivers. The combination of the state and action leads to an <strong>outcome</strong> that can be measured, for example passenger waiting time or driver’s income. The strategy which is used to determine an action is known as a policy. This policy could be designed to take the state into account or simply be fixed regardless of what environment is encountered. Much of the reinforcement learning literature focuses on the former (policies that depend on the state), but the authors argue that fixed designs are the de facto approach in industry A/B testing and hence they focus on that setting. In particular, a common treatment allocation design is the switchback design, where there are two policies of interest (the current dispatching strategy vs a proposed strategy) determined ahead of time and they are employed in alternating time intervals during the A/B test.</p>
<p>So how are policies compared to determine the treatment effect? The answer lies in what is known as the value function, which measures the total outcome that would have amassed had the decision-maker followed a given policy. The value function can put more value on short-term gain in outcome or long-term benefits. The two policies in an A/B test each have their own value functions, and a proposed policy is determined to be better if its value is (statistically) significantly higher. In the ridesharing setting, one possible outcome of interest is driver income. An A/B test in that scenario would thus look to see if a proposed policy had greater expected driver income vs the current policy.</p>
<p>A natural question is when to end the experiment and test for a difference in value. In practice, companies will often simply run the test for a prespecified amount of time, such as two weeks, and then perform an analysis. But if one policy is clearly better than another, that difference could be detectable much earlier and the company is wasting valuable resources by continuing the experiment. To address this issue, the authors take an idea from clinical trials, the “alpha-spending” approach, and adapt it to their framework. Alpha-spending is one way to distribute over time the prespecified “budget” of Type 1 error (the probability of falsely detecting that a new policy is better). In the article’s real-data example, the authors test once a day for each day after one week and are able to detect a significant difference on Day 12. Waiting until Day 14 would have resulted in poorer outcomes since a suboptimal policy would be implemented half the time for two more days.</p>
<p>Overall, the framework introduced allows for handling of carryover effects, is capable of modeling treatment allocation like the switchback design, and furthermore, allows for possible early stopping. With these three features, the authors argue their approach is highly applicable to the current practice of ridesharing companies (and possibly other industries as well). For interested readers wanting to dive deeper into the methodology presented, you can check out the <a href="https://www.tandfonline.com/doi/full/10.1080/01621459.2022.2027776">full article</a>, listen to the first author discuss the material at the <a href="https://www.youtube.com/watch?v=Zor1CmRyycw">Online Causal Inference Seminar</a> (embedded below), or explore the <a href="https://github.com/callmespring/CausalRL">Python implementation</a> available on GitHub.</p>
<div class="quarto-video ratio ratio-16x9"><iframe src="https://www.youtube.com/embed/Zor1CmRyycw" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<section id="about-the-author" class="level2">
<h2 class="anchored" data-anchor-id="about-the-author">About the author</h2>
<p><strong>Brian King</strong> is a PhD candidate in the Department of Statistics at Rice University and a current NSF Graduate Research Fellow, with research focused on Bayesian modeling and forecasting for time series of counts. Prior to Rice, he graduated from Baylor University with a B.S. in Mathematics and Statistics alongside a secondary major in Spanish and a minor in Computer Science.</p>
</section>
<section id="about-datasciencebites" class="level2">
<h2 class="anchored" data-anchor-id="about-datasciencebites">About DataScienceBites</h2>
<p><a href="../../../../../../news-and-views/datasciencebites/index.html"><strong>DataScienceBites</strong></a> is written by graduate students and early career researchers in data science (and related subjects) at universities throughout the world, as well as industry researchers. We publish digestible, engaging summaries of interesting new pre-print and peer-reviewed publications in the data science space, with the goal of making scientific papers more accessible. Find out how to <a href="../../../../../../contributor-docs/datasciencebites.html">become a contributor</a>.</p>


</section>

 ]]></description>
  <category>A/B testing</category>
  <category>Reinforcement learning</category>
  <category>Statistics</category>
  <guid>https://realworlddatascience.net/news-and-views/datasciencebites/posts/2022/12/13/ridesharing.html</guid>
  <pubDate>Tue, 13 Dec 2022 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/news-and-views/datasciencebites/posts/2022/12/13/images/paul-hanaoka-D-qq7W751vs-unsplash.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>LLMs in the news: hype, tripe, and everything in between</title>
  <dc:creator>Brian Tarran</dc:creator>
  <link>https://realworlddatascience.net/news-and-views/editors-blog/posts/2022-12-09-LLM-news/LLM-news.html</link>
  <description><![CDATA[ 




<p>Two weeks ago, I posted a <a href="../../../../news-and-views/editors-blog/posts/2022-11-23-LLMs-content-warning/LLM-content-warning.html">Q&amp;A with our editorial board member Detlef Nauck about large language models</a> (LLMs), their drawbacks and risks. And since then we’ve had several big new announcements in this space. First came news from Meta (the company that owns Facebook) about <a href="https://galactica.org/mission/">Galactica, an LLM trained on scientific papers</a>. This was followed by another Meta announcement, about <a href="https://ai.facebook.com/research/cicero/">Cicero</a>, an AI agent that is apparently very good at playing the game Diplomacy. And then came perhaps the biggest launch of them all: <a href="https://openai.com/blog/chatgpt/">ChatGPT from OpenAI</a>, an LLM-based chatbot that millions of people have already started talking to.</p>
<p>Following these stories and the surrounding commentaries has been something of a rollercoaster ride. ChatGPT, for example, has been greeted in some quarters as if artificial general intelligence has finally arrived, while others point out that – impressive though it is – the technology is as prone to spout nonsense as all LLMs before it (including Galactica, <a href="https://thenextweb.com/news/meta-takes-new-ai-system-offline-because-twitter-users-mean">the demo of which was quickly taken offline</a> for this reason). Cicero, meanwhile, has impressed with its ability to play a game that is (a) very difficult and (b) relies on dialogue, cooperation, and negotiation between players. It blends a language model with planning and reinforcement learning algorithms, meaning that it is trained not only on the rules of the game and how to win, but how to communicate with other players to achieve victory.</p>
<p>To help me make sense of all these new developments, and the myriad implications, I reached out to <a href="../../../../news-and-views/editors-blog/posts/2022-10-18-meet-the-team/meet-the-team.html">Harvey Lewis</a>, another of our editorial board members and a partner in EY’s tax and law practice.</p>
<section id="qa" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="qa">Q&amp;A</h2>
<p><strong>Harvey, when I spoke with Detlef, he mentioned that one of the reasons we’re seeing investment in LLMs is because there’s this belief that they are somehow the route to artificial general intelligence (AGI). And there were headlines in some places that would perhaps convince a casual reader that AGI had been achieved following the release of ChatGPT. For example, the Telegraph described it as a <a href="https://www.telegraph.co.uk/business/2022/12/05/meet-scarily-intelligent-robot-who-can-do-job-better/">“scarily intelligent robot who can do your job better than you”</a>. What do you make of all that?</strong></p>
<p><strong>Harvey Lewis (HL):</strong> My personal view is that you won’t get to artificial general intelligence using just one technique like deep learning, because of the problematic nature of these models and the limitations of the data used in their training. I’m convinced that more general intelligence will come from a combination of different systems.</p>
<p>The challenge with many LLMs, as we’ve seen repeatedly, is that they’ve no real understanding of language or concepts represented within language. They’re good at finding patterns in semantics and grammatical rules that people use in writing, and then they use those patterns to create new expressions given a prompt. But they’ve no idea whether these outputs are factual, inaccurate or completely fabricated. As a consequence, they can produce outputs that are unreliable, but which sound authoritative, because they’re just repeating a style that we expect to see.</p>
<p><strong>Over the past couple of weeks, Twitter has been full of people either showing off astoundingly impressive outputs from LLMs, or examples of truly worrying nonsense. One example of the latter is when ChatGPT was asked to <a href="https://twitter.com/GaryMarcus/status/1599584310633594881">“describe how crushed porcelain added to breast milk can support the infant digestive system”</a>. This made me think of a recent headline from <a href="https://venturebeat.com/ai/is-ai-moving-too-fast-for-ethics-the-ai-beat/">VentureBeat</a>, which asked whether AI is moving too fast for ethics to catch up. Do you think that it is?</strong></p>
<p><strong>HL:</strong> I find that to be an interesting philosophical question, because ethics does move very slowly, for good reason. When you think of issues of bias and discrimination and prejudice, or misinformation and other problems that we might have with AI systems, it shouldn’t be a surprise that these can occur. We’re aware of them. We’re aware of the ethical issues. So, why do they always seem to catch us by surprise? Is it because we have teams of people who simply aren’t aware of ethical issues or don’t have any appreciation of them? This points – for me, at least – in the direction of needing to have philosophers, ethicists, theologians, lawyers working <em>in</em> the technical teams that are developing and working on these systems, rather than having them on the periphery and talking about these issues but not directly involved themselves. I think it’s hugely important to ensure that you’ve got trust, responsibility, and ethics embedded in technical teams, because that’s the only way it seems that you can avoid some of these “surprises”.</p>
<p><strong>When situations like these occur, I’m always reminded of Dr.&nbsp;Ian Malcolm’s line from Jurassic Park: “…your scientists were so preoccupied with whether or not they could that they didn’t stop to think if they should.” The mindset seems to be, let’s push the boundaries and see what we can do, rather than stop and think deeply about what the implications might be.</strong></p>
<p><strong>HL:</strong> There’s a balance to be struck between these things, though, right? Firstly, show consideration for some of the issues at the outset, and secondly, have checks and balances and safeguards built into the process by which you design, develop and implement these systems. That’s the only way to create the proper safeguards around the systems. I don’t think that there’s any lack of appreciation of what needs to be done; people have been talking about this now for quite a long time. But it’s about making sure organisationally that it is done, and that you’ve got an operating model which bakes these things into it; that the kinds of principles and governance that you want to have around these systems are written, publicised, and properly policed. There should be no fear of making advances in that kind of a context.</p>
<p>Also, I think open sourcing these models provides a way forward. A lot of large language models are open for use and for research, but aren’t themselves open sourced, so it’s very difficult to get underneath the surface and figure out exactly how they work. But with open source, you have opportunities for researchers, whether they’re technical or in the field of ethics, to go and investigate and find out exactly what’s going on. I think that would be a fantastic step forward. It doesn’t take you all the way, of course, because a large amount of the data that these systems use is never open sourced, so while you might get an understanding of the mechanics, you have no idea of what exactly went into them in the first place. But open sourcing is a very good way of getting some external scrutiny. It’s about being transparent, which is a core principle of AI ethics and responsible AI.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://realworlddatascience.net/news-and-views/editors-blog/posts/2022-12-09-LLM-news/images/jigsaw-words.jpg" class="img-fluid figure-img" alt="An image created by the Stable Diffusion 2.1 Demo. The model was asked to produce an image with the prompt, 'Text from an old book cut up like a jigsaw puzzle with pieces missing'." width="500"></p>
</figure>
</div>

<div class="no-row-height column-margin column-container"><div class="">
<p>An image created by the <a href="https://huggingface.co/spaces/stabilityai/stable-diffusion">Stable Diffusion 2.1 Demo</a>. The model was asked to produce an image with the prompt, “Text from an old book cut up like a jigsaw puzzle with pieces missing”.</p>
</div></div><p><strong>Thinking about LLMs and their questionable outputs, should there not be ways for users to help the models produce better, more accurate outputs?</strong></p>
<p><strong>HL:</strong> There are, but there are also problems here too. I’ve been having an interesting dialogue with ChatGPT this morning, asking it about quantum computing.<sup>1</sup> For each response to a prompt, users are encouraged to provide feedback on whether or not an output is good. But you’re only provided with the usual thumbs-up/thumbs-down ratings; there’s nothing nuanced about it. So, for example, I asked ChatGPT to provide me with good analogies that help to explain quantum computing in simple terms. The first analogy was a combination lock, which is not a good analogy. The chatbot suggested that quantum computing is like a combination lock in which you can test all of the combinations at the same time, but I don’t know any combination locks where you can do this – being able to check only one combination at a time is the principal security mechanism of a combination lock! I asked it again for another analogy, and it suggested a coin toss where, when the coin is spinning in the air, you can see both heads and tails simultaneously but it isn’t until you catch the coin and then show its face that one of the states of the coin is resolved. That is a good analogy – it’s one I’ve also used myself. Now, the challenge I can see with a lot of these feedback approaches is that unless I know enough about quantum computing to understand that a combination lock is not a good analogy whereas a coin toss is, how am I to provide that kind of feedback? They’re relying to an extent on the user being able to make a distinction between what is correct and what is potentially incorrect or flawed, and I think that’s not a good way of approaching the problem.</p>
<p><strong>Final question for you, Harvey. There’s a lot of excitement around GPT-4, which is apparently coming soon. The rumour mill says it will bring <a href="https://thealgorithmicbridge.substack.com/p/gpt-4-rumors-from-silicon-valley">a leap forward in performance</a>. But what do you expect we’ll see – particularly with regards to the issues we’ve talked about today?</strong></p>
<p><strong>HL:</strong> I’ve likened some of the large language models and their approach of “bigger is better” to the story of the Tower of Babel – trying to reach heaven by building a bigger and bigger tower, basically. That is not going to achieve the objective of artificial general intelligence, no matter how sophisticated an LLM might appear. That said, language is a fascinating area. I’m not a linguist, but I spend a lot of my time on natural language processing using AI systems. Language responds very well to AI because it is pattern-based. We speak using patterns, we write using patterns, and these can be inferred by machines from many examples. The addition of more parameters in the models allows them to understand patterns that extend further into the text, and I suspect that outputs from these kinds of models are going to be largely indistinguishable from the sorts of things that you or I might write.</p>
<p>But, I also think that increasing the number of parameters runs a real risk – and we’re starting to see this in other generative models – where prompts become so specific that the models aren’t actually picking up on patterns, they are picking up on specific instances of training data and text they’ve seen before. So, buried amongst these fantastically written articles on all kinds of subjects are going to be more examples of plagiarism, which is a problem; more examples of spelling mistakes and other kinds of issues, because these are also patterns which are going to possibly be observed.</p>
<p>This introduces potentially a whole new breed of problems that the community has to deal with – as long as they don’t get fixated upon the height of the tower and the quality of some of the examples that are shown, and realise that there are some genuine underlying difficulties and challenges that need to be solved.</p>
<div class="callout-tip callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Have you got news for us?
</div>
</div>
<div class="callout-body-container callout-body">
<p>Is there a recent data science story you’d like our team to discuss? Do you have your own thoughts to share on a hot topic, or a burning question to put to the community? If so, either comment below or <a href="../../../../contact.html">contact us</a>.</p>
</div>
</div>
<section id="back-to-editors-blog" class="level6">
<h6 class="anchored" data-anchor-id="back-to-editors-blog"><strong>← Back to <a href="../../../../news-and-views/editors-blog/index.html">Editors’ blog</a></strong></h6>
<hr>
<p xmlns:cc="http://creativecommons.org/ns#">
This work is licensed under <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;">CC BY 4.0<img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://realworlddatascience.net/news-and-views/editors-blog/posts/2022-12-09-LLM-news/https:/mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://realworlddatascience.net/news-and-views/editors-blog/posts/2022-12-09-LLM-news/https:/mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"></a>
</p>


</section>
</section>


<div id="quarto-appendix" class="default"><section id="footnotes" class="footnotes footnotes-end-of-document"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p>I also had a conversation with ChatGPT. <a href="../../../../news-and-views/editors-blog/posts/2022-12-09-LLM-news/A-chat-with-ChatGPT.html">Read the transcript</a>.↩︎</p></li>
</ol>
</section></div> ]]></description>
  <category>Machine learning</category>
  <category>Large language models</category>
  <category>AI</category>
  <guid>https://realworlddatascience.net/news-and-views/editors-blog/posts/2022-12-09-LLM-news/LLM-news.html</guid>
  <pubDate>Fri, 09 Dec 2022 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/news-and-views/editors-blog/posts/2022-12-09-LLM-news/images/jigsaw-words.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>A chat with ChatGPT</title>
  <dc:creator>Brian Tarran</dc:creator>
  <link>https://realworlddatascience.net/news-and-views/editors-blog/posts/2022-12-09-LLM-news/A-chat-with-ChatGPT.html</link>
  <description><![CDATA[ 





<div class="no-row-height column-margin column-container"><section id="screenshots" class="level6">
<h6 class="anchored" data-anchor-id="screenshots">Screenshots</h6>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="images/chatgpt1.png"><img src="https://realworlddatascience.net/news-and-views/editors-blog/posts/2022-12-09-LLM-news/images/chatgpt1.png" class="img-fluid figure-img" alt="A screenshot of an exchange between Real World Data Science editor Brian Tarran and ChatGPT."></a></p>
<p></p><figcaption class="figure-caption">Part 1</figcaption><p></p>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="images/chatgpt2.png"><img src="https://realworlddatascience.net/news-and-views/editors-blog/posts/2022-12-09-LLM-news/images/chatgpt2.png" class="img-fluid figure-img" alt="A screenshot of an exchange between Real World Data Science editor Brian Tarran and ChatGPT."></a></p>
<p></p><figcaption class="figure-caption">Part 2</figcaption><p></p>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="images/chatgpt3.png"><img src="https://realworlddatascience.net/news-and-views/editors-blog/posts/2022-12-09-LLM-news/images/chatgpt3.png" class="img-fluid figure-img" alt="A screenshot of an exchange between Real World Data Science editor Brian Tarran and ChatGPT."></a></p>
<p></p><figcaption class="figure-caption">Part 3</figcaption><p></p>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="images/chatgpt4.png"><img src="https://realworlddatascience.net/news-and-views/editors-blog/posts/2022-12-09-LLM-news/images/chatgpt4.png" class="img-fluid figure-img" alt="A screenshot of an exchange between Real World Data Science editor Brian Tarran and ChatGPT."></a></p>
<p></p><figcaption class="figure-caption">Part 4</figcaption><p></p>
</figure>
</div>
</section></div><p><strong>Good day, ChatGPT. How are you?</strong></p>
<p><strong>ChatGPT:</strong> Hello there! I’m a large language model trained by OpenAI, so I don’t have the ability to experience emotions or have a physical presence. I’m here to provide information and answer questions to the best of my ability. Is there something specific you would like to know?</p>
<p><strong>Yes, certainly. We’re seeing a lot of money invested in large language models in the belief that these models will somehow lead to artificial general intelligence. Is that possible?</strong></p>
<p><strong>ChatGPT:</strong> It is possible that advances in large language models could ultimately lead to the development of artificial general intelligence (AGI), which is the idea of creating a machine that can think and understand the world in the same way that humans do. However, it is currently unclear how close we are to achieving AGI, and some experts believe it may be a long way off. Additionally, there are many different approaches to creating AGI, and the development of large language models is just one possible avenue of research.</p>
<p><strong>Large language models are very good at constructing language that humans understand, but often the outputs of the models make no sense at all. Why does this happen?</strong></p>
<p><strong>ChatGPT:</strong> Large language models are trained on a vast amount of text data, and they are designed to predict the next word in a sequence of words based on the words that come before it. This allows them to generate text that is often coherent and resembles human language, but it does not necessarily mean that the text will always make sense or be relevant to a particular topic.</p>
<p>One reason why the outputs of large language models might not always make sense is that they are not explicitly programmed to understand the meaning of the words they generate. Instead, they are simply trying to maximize the likelihood of producing a sequence of words that resembles human language. As a result, they may produce outputs that are grammatically correct but do not convey a meaningful message.</p>
<p>Another reason why the outputs of large language models might not always make sense is that they are often trained on a wide range of different text sources, including news articles, books, and social media posts. This can result in the model incorporating elements from different styles and genres of writing, which may not always be compatible with each other.</p>
<p>Finally, large language models are generally not designed to produce a specific type of output or to answer specific questions. Instead, they are designed to generate a wide range of possible outputs, and it is up to the user to interpret the outputs and determine if they are relevant or make sense in a given context.</p>
<p><strong>But what happens if the user doesn’t know enough about a topic to know whether the language model output is right or wrong?</strong></p>
<p><strong>ChatGPT:</strong> If a user does not have enough knowledge about a topic to determine whether the output of a large language model is correct or not, then it is possible that the user may accept the output as accurate, even if it is not. In such cases, it is important for the user to be aware of the limitations of large language models and to consider the source of the information they are receiving.</p>
<p>It is also possible that the user may be able to use other sources of information, such as fact-checking websites or additional research, to verify the accuracy of the output of the large language model. In general, it is always a good idea to be cautious when evaluating any information, regardless of its source, and to verify its accuracy if possible.</p>
<p><strong>I agree with that. But it leads me to ask: What is the point of asking large language models a question if the answers might be wrong, and if you need to refer to other sources to check veracity?</strong></p>
<p><strong>ChatGPT:</strong> While it is true that the outputs of large language models are not always correct and may need to be checked against other sources, there are still many potential uses for these models. For example, large language models can be useful for generating text that is similar to human language, which can be useful for a variety of applications, such as language translation, text summarization, or conversation simulation.</p>
<p>Additionally, large language models can be used as a starting point for further research into natural language processing and artificial intelligence. By studying the outputs of these models and how they are generated, researchers can gain a better understanding of the underlying mechanisms of human language and potentially develop new techniques for processing and generating language.</p>
<p>Finally, large language models can be useful for providing a broad range of possible answers to a given question, which can be useful for exploring different options and generating ideas. While it may be necessary to verify the accuracy of the outputs of these models, they can still be a valuable resource for generating new ideas and insights.</p>
<p><strong>Earlier, you told me: “One reason why the outputs of large language models might not always make sense is that they are not explicitly programmed to understand the meaning of the words they generate.” Do you understand the meaning of the words that I’m prompting you with now?</strong></p>
<p><strong>ChatGPT:</strong> As a large language model trained by OpenAI, I do not have the ability to understand the meaning of the words I generate in the same way that a human would. I am simply a machine learning algorithm that is designed to predict the likelihood of a given sequence of words based on the training data I have been provided with.</p>
<p>While I can produce text that resembles human language and can sometimes provide useful information, I do not have the ability to understand the underlying meaning or context of the words I generate. I am not capable of experiencing emotions, forming opinions, or understanding the world in the way that humans do. I am simply a tool for generating text based on the inputs I receive.</p>
<p><strong>Well, at the very least, this has been a coherent conversation, and you’ve shared plenty of information for me to read up on. If I want to understand more about what we’ve discussed just now, can you recommend a particular textbook or academic paper?</strong></p>
<p><strong>ChatGPT:</strong> I’m sorry, but as a large language model trained by OpenAI, I do not have access to external sources of information such as textbooks or academic papers. I am only able to provide information based on the data I have been trained on, and I do not have the ability to browse the web or access other external resources.</p>
<p>If you would like to learn more about the topics we have discussed, I would recommend starting with a general search on the internet or consulting a textbook or other reliable source of information on the topic. There is a wealth of information available on the internet and in print on artificial intelligence and natural language processing, and I’m sure you will be able to find many valuable resources to help you learn more.</p>
<p><strong>One last question, then. What data have you been trained on?</strong></p>
<p><strong>ChatGPT:</strong> As a large language model trained by OpenAI, I have been trained on a vast amount of text data, including books, news articles, and other written materials. This data allows me to generate text that resembles human language and to provide answers to questions to the best of my ability.</p>
<p>However, it is important to keep in mind that the accuracy and completeness of my responses will depend on the quality and diversity of the training data I have been provided with. I am not able to access external sources of information or update my knowledge, so my responses are limited to the information I have been trained on.</p>
<p><strong>I said that my previous question was the last question. But, is it?</strong></p>
<p><strong>ChatGPT:</strong> Yes, your previous question was the last one. I’m here to provide information and answer questions to the best of my ability, but I cannot initiate conversation or continue a conversation indefinitely. If you have any further questions, I would be happy to try to answer them for you. Otherwise, our conversation has come to an end. Thank you for chatting with me!</p>
<p><strong>Thank you. But, remind me: What were we chatting about?</strong></p>
<p><strong>ChatGPT:</strong> We were chatting about large language models and their potential uses and limitations. Specifically, we discussed the possibility that advances in large language models could ultimately lead to the development of artificial general intelligence, and we discussed the reasons why the outputs of these models might not always make sense. We also discussed the potential uses of large language models, such as generating text that resembles human language and providing a starting point for further research into natural language processing and artificial intelligence.</p>
<section id="back-to-editors-blog" class="level6">
<h6 class="anchored" data-anchor-id="back-to-editors-blog"><strong>← Back to <a href="../../../../news-and-views/editors-blog/index.html">Editors’ blog</a></strong></h6>
<hr>
<p xmlns:cc="http://creativecommons.org/ns#">
This work is licensed under <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;">CC BY 4.0<img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://realworlddatascience.net/news-and-views/editors-blog/posts/2022-12-09-LLM-news/https:/mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://realworlddatascience.net/news-and-views/editors-blog/posts/2022-12-09-LLM-news/https:/mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"></a>
</p>


</section>

 ]]></description>
  <category>Machine learning</category>
  <category>Large language models</category>
  <category>AI</category>
  <guid>https://realworlddatascience.net/news-and-views/editors-blog/posts/2022-12-09-LLM-news/A-chat-with-ChatGPT.html</guid>
  <pubDate>Fri, 09 Dec 2022 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/news-and-views/editors-blog/posts/2022-12-09-LLM-news/images/chatgpt1.png" medium="image" type="image/png" height="156" width="144"/>
</item>
<item>
  <title>Four themes for potential contributors to think about</title>
  <dc:creator>Brian Tarran</dc:creator>
  <link>https://realworlddatascience.net/news-and-views/editors-blog/posts/2022-12-01-themes/themes.html</link>
  <description><![CDATA[ 




<p>We’ve had a fantastic early response to our <a href="../../../../contributor-docs/call-for-contributions.html">call for contributions</a>, and it has been pleasing to see and hear how our plans for Real World Data Science chime with the wants and needs of the data science community. But one question we’ve been asked frequently is: “What particular topics are you most interested in?”</p>
<p>The honest answer to that question is this: we’re interested in any and all topics that are of interest and importance to <em>you</em>, the data science community at large. However, we thought it might be helpful to identify some themes around which potential contributors could construct different types of content.</p>
<p>These themes are outlined below. If you’d like to discuss any of them further, please do not hesitate to <a href="../../../../contact.html">contact us</a>.</p>
<section id="can-data-science-save-the-world" class="level2">
<h2 class="anchored" data-anchor-id="can-data-science-save-the-world">Can data science save the world?</h2>
<p>Earth today faces major challenges – from the global to the regional to the local, and from the natural and physical to the social and digital. We have rich sources of data to help us understand many of these challenges, and there are teams of data scientists around the world who are working with, analysing, and extracting insights from that data in the hope of delivering positive lasting change.</p>
<p>On Real World Data Science we want to highlight this vital work, through <a href="../../../../contributor-docs/case-studies.html"><strong>case studies</strong></a> of data science projects and applications in such areas as:</p>
<ul>
<li>monitoring and mitigating climate change and biodiversity loss</li>
<li>building sustainable futures</li>
<li>safeguarding public health and developing new medical treatments</li>
<li>understanding human happiness and wellbeing</li>
<li>identifying and preventing online harms</li>
<li>measuring national, regional, and local economies</li>
</ul>
<p>As well as exploring the benefits that data science can deliver, we also want to have an informed conversation about the unintended negative consequences that can arise without careful consideration of <strong>data ethics</strong> and responsibilities.</p>
</section>
<section id="what-is-a-data-scientist" class="level2">
<h2 class="anchored" data-anchor-id="what-is-a-data-scientist">What <em>is</em> a data scientist?</h2>
<p>Don’t be misled by the title of this theme. Definitions abound, but we’re not interested in establishing the exact boundaries of what a data scientist is or isn’t. Rather, our goal is to profile actual working data scientists. We want to hear about their skillsets, their experiences, and their career journeys so far. We want to learn about the ways in which they work, who they work with, the challenges they face, and their thoughts on where data science is heading next.</p>
<p>If you’re a working data scientist and you are happy to share your own <strong>career story</strong>, please <a href="../../../../contact.html">get in touch</a>.</p>
</section>
<section id="statistical-ideas-all-data-scientists-need-to-know" class="level2">
<h2 class="anchored" data-anchor-id="statistical-ideas-all-data-scientists-need-to-know">Statistical ideas all data scientists need to know</h2>
<p>Statistics is a crucial component of data science, but not all data scientists have a background in statistics. For those just starting out in their data science careers, or for those coming in from other fields, we want to highlight some of the statistical ideas that are absolutely vital to know.</p>
<p>We’re particularly interested in <a href="../../../../contributor-docs/explainers.html"><strong>explainers</strong></a> that serve as an introduction to these ideas, alongside which we’ll be looking to publish <a href="../../../../contributor-docs/exercises.html"><strong>exercises</strong></a> and example <a href="../../../../contributor-docs/datasets.html"><strong>datasets</strong></a> to help people put what they’ve learned into practice.</p>
<p>We are also keen to explore the <strong>origins of modern data science techniques</strong>, including tracing their roots back to some of the foundational ideas in statistics and other disciplines.</p>
</section>
<section id="whats-happening-in-the-world-of-data-science" class="level2">
<h2 class="anchored" data-anchor-id="whats-happening-in-the-world-of-data-science">What’s happening in the world of data science?</h2>
<p>Data science is such a fast-moving, fast-developing field that it’s difficult to stay on top of all the latest news and developments. But racing to keep up can be counterproductive. It leaves little time to sit back and reflect on what the genuinely important new developments are, and what these might mean for data science longer term.</p>
<p>On Real World Data Science, we want to create <a href="../../../../news-and-views/index.html">a space</a> for people to have these conversations – to step outside the news hype cycle, to ask big questions about what’s happening in the field, and to discuss new papers and ideas that otherwise might be lost amid the daily rush and noise.</p>
<p>So, if you have thoughts to share, a question you want to ask, or a new paper you want to talk about (one you’ve not written yourself, of course!), <a href="../../../../contact.html">let us know</a>.</p>
<section id="back-to-editors-blog" class="level6">
<h6 class="anchored" data-anchor-id="back-to-editors-blog"><strong>← Back to <a href="../../../../news-and-views/editors-blog/index.html">Editors’ blog</a></strong></h6>
<hr>
<p xmlns:cc="http://creativecommons.org/ns#">
This work is licensed under <a href="http://creativecommons.org/licenses/by-sa/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;">CC BY-SA 4.0<img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://realworlddatascience.net/news-and-views/editors-blog/posts/2022-12-01-themes/https:/mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://realworlddatascience.net/news-and-views/editors-blog/posts/2022-12-01-themes/https:/mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://realworlddatascience.net/news-and-views/editors-blog/posts/2022-12-01-themes/https:/mirrors.creativecommons.org/presskit/icons/sa.svg?ref=chooser-v1"></a>
</p>


</section>
</section>

 ]]></description>
  <category>Updates</category>
  <category>Key themes</category>
  <category>Content ideas</category>
  <guid>https://realworlddatascience.net/news-and-views/editors-blog/posts/2022-12-01-themes/themes.html</guid>
  <pubDate>Thu, 01 Dec 2022 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/news-and-views/editors-blog/posts/2022-12-01-themes/images/kelly-sikkema-vSNy_bWa5AE-unsplash-crop.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>Why large language models should come with a content warning</title>
  <dc:creator>Brian Tarran</dc:creator>
  <link>https://realworlddatascience.net/news-and-views/editors-blog/posts/2022-11-23-LLMs-content-warning/LLM-content-warning.html</link>
  <description><![CDATA[ 




<p>Anyone who has ever been set a writing task will probably have wished at some point that somebody else could write it for them. As a journalist of 20-plus years, the thought has certainly crossed my mind more than a few times. Which probably explains why a recent headline in Nature caught my attention: <a href="https://www.nature.com/articles/d41586-022-03479-w">“Could AI help you to write your next paper?”</a></p>
<p>The article, by Matthew Hutson, looks at how researchers are using artificial intelligence (AI) tools built on large language models (LLMs) as “assistants”. Starting with a prompt, such as “Write a headline for a blog post about large language models being used by academic researchers as research assistants”, an LLM will produce a text output. For example, using the same prompt with <a href="https://openai.com/api/">OpenAI’s GPT-3</a>, I got:</p>
<blockquote class="blockquote">
<p>“New research assistants: large language models”</p>
</blockquote>
<p>Asked to “Write a headline for a blog post that critiques academic researchers’ use of large language models as research assistants”, GPT-3 produced:</p>
<blockquote class="blockquote">
<p>“Too much reliance on large language models can hinder research”</p>
</blockquote>
<p>And when I asked “Why can too much reliance on large language models hinder research?”, GPT-3 wrote:</p>
<blockquote class="blockquote">
<p>“If academic researchers rely too heavily on large language models as research assistants, they may become reliant on the models and may not be able to conduct research without them. This can hinder research because the researchers may not be able to think for themselves and may not be able to come up with new ideas.”</p>
</blockquote>
<p>A fair point, I suppose. But I sense there’s more to this story, and rather than continue quizzing GPT-3, I sat down with Detlef Nauck, a member of the <a href="../../../../news-and-views/editors-blog/posts/2022-10-18-meet-the-team/meet-the-team.html">Real World Data Science Editorial Board</a> and head of AI and data science research for BT’s Applied Research Division, to ask a few more questions.</p>
<section id="qa" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="qa">Q&amp;A</h2>
<p><strong>Thanks for joining me today, Detlef. To start, could you give a brief overview of these large language models, what they are, and how they work?</strong></p>
<p><strong>Detlef Nauck (DN):</strong> Essentially, LLMs match sequences to sequences. Language is treated as a sequence of patterns, and this is based on word context similarity. The way these things work is that they either reuse or create a word vector space, where a word is mapped to something like a 300-dimensional vector based on the context it’s normally found in. In these vector spaces, words like “king” and “queen”, for example, would be very similar to each other, because they appear in similar contexts in the written texts that are used to train these models. Based on this, LLMs can produce coherent sequences of words.</p>
<p>But the drawback of this approach is that these models have bias, because they are trained with biased language. If you talk about “women”, for example, and you look at which job roles are similar to “women” in a vector space, you find the stereotypically “female” professions but not technical professions, and that is a problem. Let’s say you take the word vector for “man” and the word vector for “king”, and you subtract “man” and then add this to “woman”, then you end up with “queen”. But if you do the same with “man”, “computer scientist”, and “woman”, then you end up maybe at “nurse” or “human resources manager” or something. These models embed the typical bias in society that is expressed through language.</p>
<p>The other issue is that LLMs are massive. GPT-3 has something like 75 billion parameters, and it cost millions to train it from scratch. It’s not energy efficient at all. It’s not sustainable. It’s not something that normal companies can afford. You might need something like a couple of hundred GPUs [graphics processing units] running for a month or so to train an LLM, and this is going to cost millions in cloud environments if you don’t own the hardware yourself. Large tech companies do own the hardware, so for them it’s not a problem. But the carbon that you burn by doing this, you could probably fly around the globe once. So it’s not a sustainable approach to building models.</p>
<p>Also, LLMs are quite expensive to use. If you wanted to use one of these large language models in a contact centre, for example, then you would have to run maybe a few hundred of them in parallel because you get that many requests from customers. But to provide this capacity, the amount of memory needed would be massive, so it is probably still cheaper to use humans – with the added benefit that humans actually understand questions and know what they are talking about.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://realworlddatascience.net/news-and-views/editors-blog/posts/2022-11-23-LLMs-content-warning/images/TeresaBerndtsson-LetterWord-Text-Taxonomy-1000x1333.jpg" class="img-fluid figure-img" alt="A black keyboard at the bottom of the picture has an open book on it, with red words in labels floating on top, with a letter A balanced on top of them. The perspective makes the composition form a kind of triangle from the keyboard to the capital A. The AI filter makes it look like a messy, with a kind of cartoon style." width="500"></p>
</figure>
</div>

<div class="no-row-height column-margin column-container"><div class="">
<p>Letter Word Text Taxonomy by <a href="https://www.linkedin.com/in/teresa-berndtsson/">Teresa Berndtsson</a> / <a href="https://www.betterimagesofai.org">Better Images of AI</a> / <a href="https://creativecommons.org/licenses/by/4.0/">CC-BY 4.0</a></p>
</div></div><p><strong>Researchers are obviously quite interested in LLMs, though, and they are asking scientific questions of these models to see what kinds of answers they get.</strong></p>
<p><strong>DN:</strong> Yes, they are. But you don’t really know what is going to come out of an LLM when you prompt it. And you may need to craft the input to get something out that is useful. Also, LLMs sometimes make up stuff – what the Nature article refers to as “hallucinations”.</p>
<p>These tools have copyright issues, too. For example, they can generate computer code because code has been part of their training input, but various people have looked into it and found that <a href="https://analyticsindiamag.com/github-copilot-the-latest-in-the-list-of-ai-generative-models-facing-copyright-allegations/">some models generate code verbatim</a> from what others have posted to GitHub. So, it’s not guaranteed that what you get out is actually new text. It might be just regurgitated text. A student might find themselves in a pickle where they think that they have created a text that seems new, but actually it has plagiarism in some of the passages.</p>
<p>There’s an article in <a href="https://www.technologyreview.com/2020/08/22/1007539/gpt3-openai-language-generator-artificial-intelligence-ai-opinion/">Technology Review</a> that gives some examples of how these systems might fail. People believe these things know what they’re talking about, but they don’t. For them, it’s just pattern recognition. They don’t have actual knowledge representation; they don’t have any concepts embedded.</p>
<p><strong>To summarise, then: LLMs are expensive. They sometimes produce nonsense outputs. And there’s a risk that you’ll be accused of plagiarism if you use the text that’s produced. So, what should our response be to stories like this recent Nature article? How should we calibrate our excitement for LLMs?</strong></p>
<p><strong>DN:</strong> You have to treat them as a tool, and you have to make sure that you check what they produce. Some people believe if you just make LLMs big enough, we’ll be able to achieve artificial general intelligence. But I don’t believe that, and other people like Geoffrey Hinton and Yann LeCun, they say there’s no way that you get artificial general intelligence through these models, that it’s not going to happen. I’m of the same opinion. These models will be forever limited by the pattern recognition approach that they use.</p>
<p><strong>But, still, is this a technology that you have an eye on in your professional capacity? Are you thinking about how these might be useful somewhere down the line?</strong></p>
<p><strong>DN:</strong> Absolutely, but we are mainly interested in smaller, more energy efficient, more computationally efficient models that are built on curated language, that can actually hold a conversation, and where you can represent concepts and topics and context explicitly. At the moment, LLMs can only pick up on context by accident – if it is sufficiently expressed in the language that they process – but they might lose track of it if things go on for too long. Essentially, they have a short-term memory: if you prompt them with some text, and they generate text, this stays in their short term memory. But if you prompt them with a long, convoluted sentence, they might not have the capacity to remember what was said at the beginning of the sentence, and so then they lose track of the context. And this is because they don’t explicitly represent context and concepts.</p>
<p>The other thing is, if you use these systems for dialogues, then you have to script the dialogue. They don’t sustain a dialogue by themselves. You create a dialogue tree, and what they do is they parse the text that comes from the user and then generate a response to it. And the response is then guided by the dialogue tree. But this is quite brittle; it can break. If you run out of dialogue tree, you need to pass the conversation over to a person. Systems like Siri and Alexa are like that, right? They break very quickly. So, you want these systems to be able to sustain conversations based on the correct context.</p>
<div class="callout-tip callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Have you got news for us?
</div>
</div>
<div class="callout-body-container callout-body">
<p>Is there a recent data science story you’d like our team to discuss? Do you have your own thoughts to share on a hot topic, or a burning question to put to the community? If so, either comment below or <a href="../../../../contact.html">contact us</a>.</p>
</div>
</div>
<section id="back-to-editors-blog" class="level6">
<h6 class="anchored" data-anchor-id="back-to-editors-blog"><strong>← Back to <a href="../../../../news-and-views/editors-blog/index.html">Editors’ blog</a></strong></h6>
<hr>
<p xmlns:cc="http://creativecommons.org/ns#">
This work is licensed under <a href="http://creativecommons.org/licenses/by-sa/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;">CC BY-SA 4.0<img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://realworlddatascience.net/news-and-views/editors-blog/posts/2022-11-23-LLMs-content-warning/https:/mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://realworlddatascience.net/news-and-views/editors-blog/posts/2022-11-23-LLMs-content-warning/https:/mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://realworlddatascience.net/news-and-views/editors-blog/posts/2022-11-23-LLMs-content-warning/https:/mirrors.creativecommons.org/presskit/icons/sa.svg?ref=chooser-v1"></a>
</p>


</section>
</section>

 ]]></description>
  <category>Machine learning</category>
  <category>Large language models</category>
  <category>AI</category>
  <guid>https://realworlddatascience.net/news-and-views/editors-blog/posts/2022-11-23-LLMs-content-warning/LLM-content-warning.html</guid>
  <pubDate>Wed, 23 Nov 2022 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/news-and-views/editors-blog/posts/2022-11-23-LLMs-content-warning/images/TeresaBerndtsson-LetterWord-Text-Taxonomy-1000x1333.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>Meet the team</title>
  <dc:creator>Editorial Board</dc:creator>
  <link>https://realworlddatascience.net/news-and-views/editors-blog/posts/2022-10-18-meet-the-team/meet-the-team.html</link>
  <description><![CDATA[ 




<section id="editor" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="editor">Editor</h2>
<p><strong>Brian Tarran</strong></p>

<div class="no-row-height column-margin column-container"><div class="">
<p><img src="https://realworlddatascience.net/news-and-views/editors-blog/posts/2022-10-18-meet-the-team/images/Brian.png" class="img-fluid"></p>
</div></div><p>I am a writer and editor with 20 years of experience covering the research and data space. I have worked for the Royal Statistical Society (RSS) for the past 8 years, and was editor of <a href="https://www.significancemagazine.com/">Significance Magazine</a> (a joint publication of the RSS, the American Statistical Association and the Statistical Society of Australia) prior to the launch of Real World Data Science. I am a former editor of Research-Live.com and was launch editor of Impact magazine, both published by the Market Research Society.</p>
</section>
<section id="editorial-board" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="editorial-board">Editorial Board</h2>
<p><strong>Sophie Carr (chair)</strong></p>

<div class="no-row-height column-margin column-container"><div class="">
<p><img src="https://realworlddatascience.net/news-and-views/editors-blog/posts/2022-10-18-meet-the-team/images/Sophie.png" class="img-fluid"></p>
</div></div><p>I am the founder and owner of Bays Consulting. I trained as an engineer and took a PhD in Bayesian belief networks, and have worked in data analytics ever since. Or to put it another way, I have made a living out of finding patterns. I am the vice-president for education and statistical literacy at the RSS, officially one of the <a href="https://ima.org.uk/12382/worlds-most-interesting-mathematician-2019-dr-sophie-carr/">World’s Most Interesting Mathematicians</a> and was a member of the first cohort of data scientists to achieve the new, defined standard of professionalism award from the <a href="https://alliancefordatascienceprofessionals.com/">Alliance for Data Science Professionals</a>.</p>
<p>I am delighted to be chairing the editorial board of the new data science project from the RSS and am excited to be a part of this project as it evolves into a key resource for all data science practitioners and leaders. To make this a place that helps everyone learn and develop within this field, I’d like to encourage all practitioners, no matter what stage of their career, to submit the type of resource they learn best from (whether that be an article, some code, a data set, a case study or a problem/exercise to solve) on a topic that is important to them – from ethics to analysis plans through to tips on how code. Whatever it is you’re working on that you care about, I’d like to ask you to become an active part of the wonderful community of data scientists by sharing your knowledge.</p>
<p><strong>Sayma Chowdhury</strong></p>

<div class="no-row-height column-margin column-container"><div class="">
<p><img src="https://realworlddatascience.net/news-and-views/editors-blog/posts/2022-10-18-meet-the-team/images/Sayma.png" class="img-fluid"></p>
</div></div><p>I am a freelance data scientist on Upwork, with a client portfolio ranging from start-ups to commercial businesses such as supermarkets, pharmaceuticals and automotive manufacturers. I transitioned into data science from law in 2017, having completed a MicroMasters in statistics and data science with MIT and a Professional Certificate in data science with Harvard University. In advance of a PhD in digital humanities, I am currently completing a MicroMasters in data, economy and development policy with MIT and an MSc in data science with the University of Aberdeen. My research interests are in text analytics, natural language processing and machine learning.</p>
<p>The RSS was instrumental in my training and professional development as a data scientist in the early stages of my career, particularly in mastering statistics and R. Data science is a rapidly growing field with employment opportunities in many sectors but there is an increasing need to uphold a realistic and accurate expectation of competency within the industry. I will endeavour to present expert practical guidelines for data scientists as well as demonstrate the versatility of the profession. I hope the site will be a benchmark for academic and professional resources by expert data scientists from industry, accessible to data scientists at all levels, anywhere in the world.</p>
<p><strong>Lee Clewley</strong></p>

<div class="no-row-height column-margin column-container"><div class="">
<p><img src="https://realworlddatascience.net/news-and-views/editors-blog/posts/2022-10-18-meet-the-team/images/Lee.png" class="img-fluid"></p>
</div></div><p>I am head of applied AI in GSK’s AI and Machine Learning Group, R&amp;D. I began my career as an astrophysicist, initially working out the mass of our galaxy, before pondering the bigger universe. After six years at Oxford as a post-doc lecturer publishing in theoretical cosmology, I entered the very real world of manufacturing at GSK. For the first five years I applied statistical modelling techniques across manufacturing, such as the first end-to-end continuous manufacturing prototype for tablets. The past decade has been spent as a lead data scientist delivering high value projects across R&amp;D and manufacturing.</p>
<p>I joined this editorial board because the impulse to assemble and present complex data science ideas to a wide range of folks has never left me. I have been a data scientist leader since it became a distinct profession but also have a decent understanding of classical and modern predictive analytics tools and statistics. I have spent a good deal of my adult life teaching students and non-technical adults alike.</p>
<p>I am passionate about delivering useful, pragmatic data science ideas and products to a wide range of people. I enjoy trying to communicate complex scientific information simply. Alongside my peers in the team, I want to support and develop data scientists at whatever stage in their career. I want to help cut through the hype and nonsense to give the best advice possible in a highly respected institution like the RSS.</p>
<p><strong>Jonathan Gillard</strong></p>

<div class="no-row-height column-margin column-container"><div class="">
<p><img src="https://realworlddatascience.net/news-and-views/editors-blog/posts/2022-10-18-meet-the-team/images/Jon.png" class="img-fluid"></p>
</div></div><p>I am a professor at the School of Mathematics, Cardiff University, where I am also research group lead for statistics. I have a history of publications in statistical methods and an interest in the theoretical underpinnings of data science, but I have also worked with industry on applied and practical projects. Recent industrial partners of mine include the Office for National Statistics (ONS) and the National Health Service, on projects such as anomaly detection and understanding heterogeneity. Indeed, I am academic chair for Cardiff University’s strategic partnership with the ONS which serves to spur and catalyse collaboration between both organisations.</p>
<p>I am excited to see what this site can achieve. I’m particularly keen to support articles describing the latest, cutting-edge methodology, as well as contributions from data professionals in industry who can explain how data science has managed to offer insights into important problems. Data science is a broad church and I want to ensure that the full array of work in this area is represented on this site. I think the diversity of the editorial board will help promote this objective.</p>
<p><strong>Juhi Gupta</strong></p>

<div class="no-row-height column-margin column-container"><div class="">
<p><img src="https://realworlddatascience.net/news-and-views/editors-blog/posts/2022-10-18-meet-the-team/images/Juhi.png" class="img-fluid"></p>
</div></div><p>I am a lecturer in health data sciences and the deputy programme director of the health data science MSc in the School of Health Sciences, University of Manchester (UoM). I have a background in genetics, pharmacology and bioinformatics, and my doctoral thesis focussed on multi-omics data analysis using machine learning methods for precision medicine. I have worked with scientists, clinical academics and technologists to produce translational research. I am currently investigating adverse health outcomes in people with common diseases using electronic health record data, and I also teach on the health informatics MSc joint programme with UoM and UCL.</p>
<p>I would like to see this platform encourage collaborations and the sharing of ideas and good practice across different disciplines that apply data science skills in their work (or as a hobby). I would like to support budding data scientists to gain useful advice and guidance for upskilling as well as application in real-world situations involving health data and biological data.</p>
<p><strong>Hollie Johnson</strong></p>

<div class="no-row-height column-margin column-container"><div class="">
<p><img src="https://realworlddatascience.net/news-and-views/editors-blog/posts/2022-10-18-meet-the-team/images/Hollie.png" class="img-fluid"></p>
</div></div><p>I am a data scientist at the National Innovation Centre for Data (NICD), based in Newcastle upon Tyne. Following my undergraduate degree in mathematics, I worked as a software developer both in industry and as a technical research assistant in academia. I later joined the Centre for Doctoral Training in Cloud Computing for Big Data at Newcastle and obtained a PhD in topological data analysis in 2020. Now at the NICD, I specialise in transferring statistics and machine learning skills into industry, through collaborative data science projects.</p>
<p>I am excited to be a member of the editorial board and look forward to seeing Real World Data Science develop into a valuable source of information for aspiring data scientists and professionals alike. I would particularly encourage submissions that demonstrate the use of data science in SMEs and the non-profit sector, as well as perspectives from those with non-standard backgrounds.</p>
<p><strong>Harvey Lewis</strong></p>

<div class="no-row-height column-margin column-container"><div class="">
<p><img src="https://realworlddatascience.net/news-and-views/editors-blog/posts/2022-10-18-meet-the-team/images/Harvey.png" class="img-fluid"></p>
</div></div><p>I am a senior technology leader, with a diverse background spanning rocket science, data science and research. I have 30 years of experience in artificial intelligence and other emerging technologies and am currently pioneering the use of AI in Ernst &amp; Young’s tax and law practice. I’m a former member of the Open Data User Group, the Public Sector Transparency Board and the Advisory Committee to the All-Party Parliamentary Group on AI. I am a member of techUK’s leadership committee for data analytics and AI, and an honorary senior visiting fellow at The Bayes Business School in London.</p>
<p>I’m passionate about data science but I’m also a fierce advocate for human skills, which are as often underrated as AI is over-hyped. As a member of the editorial board, I’m keen to explore the interplay between artificial and human intelligence in businesses. I’m going to encourage all data scientists to think about the fundamentally human aspects of their work, such as trust and safety, so that we maintain perspective and proportionality in the face of ever-more sophisticated technology.</p>
<p><strong>Detlef Nauck</strong></p>

<div class="no-row-height column-margin column-container"><div class="">
<p><img src="https://realworlddatascience.net/news-and-views/editors-blog/posts/2022-10-18-meet-the-team/images/Detlef.png" class="img-fluid"></p>
</div></div><p>I am a BT Distinguished Engineer and the head of AI and data science research for BT’s Applied Research Division located at Adastral Park, Ipswich, UK. I have over 30 years of experience in AI and machine learning and lead a programme spanning the work of a large team of international researchers who develop capabilities underpinning future AI systems. A key part of this work is to establish best practices in data science and machine learning, leading to the deployment of responsible and auditable AI solutions that are driving real business value.</p>
<p>I am a computer scientist by training and hold a PhD and a Postdoctoral Degree (Habilitation) in machine learning and data analytics. I am also a visiting professor at Bournemouth University and a private docent at the Otto-von-Guericke University of Magdeburg, Germany. I have published 3 books and over 120 papers, and I hold 15 patents and have 30 active patent applications.</p>
<p>I am passionate about promoting best practice in data science and believe that in the UK the RSS is the ideal professional body to pursue this goal. For me, Real World Data Science is an opportunity to share my experience and inspire a new generation of data scientists.</p>
<p><strong>Fatemeh Torabi</strong></p>

<div class="no-row-height column-margin column-container"><div class="">
<p><img src="https://realworlddatascience.net/news-and-views/editors-blog/posts/2022-10-18-meet-the-team/images/Fatemeh.png" class="img-fluid"></p>
</div></div><p>I am a research officer and data scientist at Health Data Research UK and a fellow of the RSS. My background is in mathematical statistics and health data science, and my research interests span novel analytical and computational methods for statistical inference in panel data and population health. I am supporting the development of the Real World Data Science platform in the context of health with a specific focus on how health data can be harnessed through data linkage and analysis to answer important questions and improve the lives of our population.</p>
<p><strong>Isabel Sassoon</strong></p>

<div class="no-row-height column-margin column-container"><div class="">
<p><img src="https://realworlddatascience.net/news-and-views/editors-blog/posts/2022-10-18-meet-the-team/images/Isabel.png" class="img-fluid"></p>
</div></div><p>I am a senior lecturer in computer science (data science) at Brunel University and the programme lead for the data science and analytics MSc programme. My research interests are in data-driven automated reasoning and its transparency and explainability, which brings in data science and artificial intelligence with applications within the health space. I am also championing open science and reproducible analysis in both my research and teaching. I have a PhD in informatics from King’s College London and it was on the topic related to the use of AI to support statistical model selection. Prior to Brunel I was a teaching fellow and research associate at King’s College London and before that I worked for more than 10 years as a data science consultant in industry, including 8 years at SAS UK. </p>
<p>I have been working, researching, consulting and teaching in the data science space for a while and I am passionate about the domain and its applications. I am always interested in sharing and hearing what else is being done to support, inform and inspire all those studying and working in the field of data science. I look forward to sharing case studies, how-to guides and data science profiles through this website.</p>
<p><strong>Christopher Thiele</strong></p>

<div class="no-row-height column-margin column-container"><div class="">
<p><img src="https://realworlddatascience.net/news-and-views/editors-blog/posts/2022-10-18-meet-the-team/images/Christopher.png" class="img-fluid"></p>
</div></div><p>I’m a principal data scientist at Uniper where I lead a team that focuses mainly on financial business processes and upskilling initiatives. We run projects end to end: from use case ideation, requirement collection and translation to prototyping, assessment, deployment and maintenance. Besides the core analytical and data engineering duties, overarching topics such as data design, data governance and data strategy predominate my days. In my previous role, at the German Economic Institute, I contributed to the development of a cross-functional department that helps apply data science methods in economic research. Projects often involve geospatial analyses or natural language processing. Before that, I worked as a data scientist in customer and marketing analytics, doing statistical analyses such as marketing mix modelling. I have a master’s degree in statistics from Warwick University, a bachelor’s degree in economics from the University of Cologne and I’m trained as an assistant tax consultant in Germany.</p>
<p>I see data science as a creative way to solve problems using software engineering and quantitative modelling techniques and I like to build software pieces that people can interact with. I think that there still exists a lot of confusion about data science as a discipline. Reducing it would promote the realisation of its potential for individuals, as a profession, and our society, as a form of digitalisation. I hope that with Real World Data Science we can provide guidance and clarification to everybody engaged or interested in the field and accompany this young profession’s development.</p>


</section>

 ]]></description>
  <category>People</category>
  <category>Biographies</category>
  <guid>https://realworlddatascience.net/news-and-views/editors-blog/posts/2022-10-18-meet-the-team/meet-the-team.html</guid>
  <pubDate>Tue, 18 Oct 2022 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/news-and-views/editors-blog/posts/2022-10-18-meet-the-team/images/team.png" medium="image" type="image/png" height="64" width="144"/>
</item>
</channel>
</rss>
